{"episode": 0.0, "episode_reward": 0.0, "eval_time": 29.127387762069702, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 0}
{"episode": 4.0, "episode_reward": 99.1, "eval_time": 28.388742685317993, "mean_episode_reward": 99.1, "best_episode_reward": 991.0, "step": 1000}
{"episode": 8.0, "episode_reward": 0.0, "eval_time": 28.27596116065979, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 2000}
{"episode": 12.0, "episode_reward": 100.0, "eval_time": 28.358835458755493, "mean_episode_reward": 100.0, "best_episode_reward": 1000.0, "step": 3000}
{"episode": 16.0, "episode_reward": 0.0, "eval_time": 26.867074728012085, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 4000}
{"episode": 20.0, "episode_reward": 0.0, "eval_time": 28.203086614608765, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 5000}
{"episode": 24.0, "episode_reward": 17.9, "eval_time": 28.359781503677368, "mean_episode_reward": 17.9, "best_episode_reward": 179.0, "step": 6000}
{"episode": 28.0, "episode_reward": 10.2, "eval_time": 28.06576371192932, "mean_episode_reward": 10.2, "best_episode_reward": 102.0, "step": 7000}
{"episode": 32.0, "episode_reward": 122.0, "eval_time": 28.012444496154785, "mean_episode_reward": 122.0, "best_episode_reward": 770.0, "step": 8000}
{"episode": 36.0, "episode_reward": 13.7, "eval_time": 28.02170705795288, "mean_episode_reward": 13.7, "best_episode_reward": 137.0, "step": 9000}
{"episode": 40.0, "episode_reward": 0.0, "eval_time": 28.112034797668457, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 10000}
{"episode": 44.0, "episode_reward": 0.0, "eval_time": 28.465893268585205, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 11000}
{"episode": 48.0, "episode_reward": 330.7, "eval_time": 28.23098087310791, "mean_episode_reward": 330.7, "best_episode_reward": 990.0, "step": 12000}
{"episode": 52.0, "episode_reward": 53.5, "eval_time": 28.129774570465088, "mean_episode_reward": 53.5, "best_episode_reward": 409.0, "step": 13000}
{"episode": 56.0, "episode_reward": 99.4, "eval_time": 28.283671379089355, "mean_episode_reward": 99.4, "best_episode_reward": 585.0, "step": 14000}
{"episode": 60.0, "episode_reward": 293.7, "eval_time": 28.4250807762146, "mean_episode_reward": 293.7, "best_episode_reward": 989.0, "step": 15000}
{"episode": 64.0, "episode_reward": 241.3, "eval_time": 27.756927490234375, "mean_episode_reward": 241.3, "best_episode_reward": 933.0, "step": 16000}
{"episode": 68.0, "episode_reward": 426.0, "eval_time": 28.047646284103394, "mean_episode_reward": 426.0, "best_episode_reward": 987.0, "step": 17000}
{"episode": 72.0, "episode_reward": 415.7, "eval_time": 27.98402714729309, "mean_episode_reward": 415.7, "best_episode_reward": 997.0, "step": 18000}
{"episode": 76.0, "episode_reward": 297.1, "eval_time": 28.08069682121277, "mean_episode_reward": 297.1, "best_episode_reward": 996.0, "step": 19000}
{"episode": 80.0, "episode_reward": 165.2, "eval_time": 28.338902473449707, "mean_episode_reward": 165.2, "best_episode_reward": 988.0, "step": 20000}
{"episode": 84.0, "episode_reward": 591.4, "eval_time": 28.504362106323242, "mean_episode_reward": 591.4, "best_episode_reward": 995.0, "step": 21000}
{"episode": 88.0, "episode_reward": 99.0, "eval_time": 28.76950693130493, "mean_episode_reward": 99.0, "best_episode_reward": 990.0, "step": 22000}
{"episode": 92.0, "episode_reward": 244.7, "eval_time": 28.915799140930176, "mean_episode_reward": 244.7, "best_episode_reward": 997.0, "step": 23000}
{"episode": 96.0, "episode_reward": 121.2, "eval_time": 29.298603534698486, "mean_episode_reward": 121.2, "best_episode_reward": 984.0, "step": 24000}
{"episode": 100.0, "episode_reward": 4.6, "eval_time": 29.561596632003784, "mean_episode_reward": 4.6, "best_episode_reward": 46.0, "step": 25000}
{"episode": 104.0, "episode_reward": 195.9, "eval_time": 29.40516686439514, "mean_episode_reward": 195.9, "best_episode_reward": 981.0, "step": 26000}
{"episode": 108.0, "episode_reward": 189.5, "eval_time": 28.917279958724976, "mean_episode_reward": 189.5, "best_episode_reward": 976.0, "step": 27000}
{"episode": 112.0, "episode_reward": 295.5, "eval_time": 28.933265447616577, "mean_episode_reward": 295.5, "best_episode_reward": 989.0, "step": 28000}
{"episode": 116.0, "episode_reward": 543.1, "eval_time": 28.607169151306152, "mean_episode_reward": 543.1, "best_episode_reward": 999.0, "step": 29000}
{"episode": 120.0, "episode_reward": 437.3, "eval_time": 28.2665057182312, "mean_episode_reward": 437.3, "best_episode_reward": 973.0, "step": 30000}
{"episode": 124.0, "episode_reward": 758.2, "eval_time": 28.163511037826538, "mean_episode_reward": 758.2, "best_episode_reward": 991.0, "step": 31000}
{"episode": 128.0, "episode_reward": 766.1, "eval_time": 28.1297504901886, "mean_episode_reward": 766.1, "best_episode_reward": 990.0, "step": 32000}
{"episode": 132.0, "episode_reward": 820.8, "eval_time": 28.071779012680054, "mean_episode_reward": 820.8, "best_episode_reward": 989.0, "step": 33000}
{"episode": 136.0, "episode_reward": 685.3, "eval_time": 28.309326887130737, "mean_episode_reward": 685.3, "best_episode_reward": 992.0, "step": 34000}
{"episode": 140.0, "episode_reward": 798.4, "eval_time": 28.06348729133606, "mean_episode_reward": 798.4, "best_episode_reward": 997.0, "step": 35000}
{"episode": 144.0, "episode_reward": 844.7, "eval_time": 27.983887910842896, "mean_episode_reward": 844.7, "best_episode_reward": 988.0, "step": 36000}
{"episode": 148.0, "episode_reward": 790.0, "eval_time": 28.21837019920349, "mean_episode_reward": 790.0, "best_episode_reward": 993.0, "step": 37000}
{"episode": 152.0, "episode_reward": 682.9, "eval_time": 28.159099578857422, "mean_episode_reward": 682.9, "best_episode_reward": 994.0, "step": 38000}
{"episode": 156.0, "episode_reward": 864.5, "eval_time": 28.000138998031616, "mean_episode_reward": 864.5, "best_episode_reward": 990.0, "step": 39000}
{"episode": 160.0, "episode_reward": 893.5, "eval_time": 28.174885511398315, "mean_episode_reward": 893.5, "best_episode_reward": 994.0, "step": 40000}
{"episode": 164.0, "episode_reward": 864.0, "eval_time": 28.090338706970215, "mean_episode_reward": 864.0, "best_episode_reward": 992.0, "step": 41000}
{"episode": 168.0, "episode_reward": 494.8, "eval_time": 28.121419429779053, "mean_episode_reward": 494.8, "best_episode_reward": 991.0, "step": 42000}
{"episode": 172.0, "episode_reward": 861.9, "eval_time": 28.15176272392273, "mean_episode_reward": 861.9, "best_episode_reward": 994.0, "step": 43000}
{"episode": 176.0, "episode_reward": 801.3, "eval_time": 28.034791231155396, "mean_episode_reward": 801.3, "best_episode_reward": 994.0, "step": 44000}
{"episode": 180.0, "episode_reward": 834.4, "eval_time": 28.08142328262329, "mean_episode_reward": 834.4, "best_episode_reward": 1000.0, "step": 45000}
{"episode": 184.0, "episode_reward": 863.4, "eval_time": 28.05981945991516, "mean_episode_reward": 863.4, "best_episode_reward": 1000.0, "step": 46000}
{"episode": 188.0, "episode_reward": 878.5, "eval_time": 28.081140756607056, "mean_episode_reward": 878.5, "best_episode_reward": 994.0, "step": 47000}
{"episode": 192.0, "episode_reward": 934.9, "eval_time": 28.187125205993652, "mean_episode_reward": 934.9, "best_episode_reward": 998.0, "step": 48000}
{"episode": 196.0, "episode_reward": 897.6, "eval_time": 28.13126540184021, "mean_episode_reward": 897.6, "best_episode_reward": 1000.0, "step": 49000}
{"episode": 200.0, "episode_reward": 911.5, "eval_time": 28.116368770599365, "mean_episode_reward": 911.5, "best_episode_reward": 990.0, "step": 50000}
{"episode": 204.0, "episode_reward": 859.7, "eval_time": 28.496385097503662, "mean_episode_reward": 859.7, "best_episode_reward": 990.0, "step": 51000}
{"episode": 208.0, "episode_reward": 921.1, "eval_time": 28.147019624710083, "mean_episode_reward": 921.1, "best_episode_reward": 1000.0, "step": 52000}
{"episode": 212.0, "episode_reward": 957.1, "eval_time": 28.005043268203735, "mean_episode_reward": 957.1, "best_episode_reward": 993.0, "step": 53000}
{"episode": 216.0, "episode_reward": 966.9, "eval_time": 28.059536933898926, "mean_episode_reward": 966.9, "best_episode_reward": 995.0, "step": 54000}
{"episode": 220.0, "episode_reward": 958.1, "eval_time": 27.97107481956482, "mean_episode_reward": 958.1, "best_episode_reward": 991.0, "step": 55000}
{"episode": 224.0, "episode_reward": 888.4, "eval_time": 28.057287454605103, "mean_episode_reward": 888.4, "best_episode_reward": 993.0, "step": 56000}
{"episode": 228.0, "episode_reward": 935.6, "eval_time": 28.09299063682556, "mean_episode_reward": 935.6, "best_episode_reward": 993.0, "step": 57000}
{"episode": 232.0, "episode_reward": 914.2, "eval_time": 27.999801874160767, "mean_episode_reward": 914.2, "best_episode_reward": 993.0, "step": 58000}
{"episode": 236.0, "episode_reward": 944.2, "eval_time": 28.053711414337158, "mean_episode_reward": 944.2, "best_episode_reward": 995.0, "step": 59000}
{"episode": 240.0, "episode_reward": 949.6, "eval_time": 27.968292236328125, "mean_episode_reward": 949.6, "best_episode_reward": 1000.0, "step": 60000}
{"episode": 244.0, "episode_reward": 963.9, "eval_time": 27.974513292312622, "mean_episode_reward": 963.9, "best_episode_reward": 989.0, "step": 61000}
{"episode": 248.0, "episode_reward": 914.0, "eval_time": 28.100537061691284, "mean_episode_reward": 914.0, "best_episode_reward": 1000.0, "step": 62000}
{"episode": 252.0, "episode_reward": 953.3, "eval_time": 28.049181699752808, "mean_episode_reward": 953.3, "best_episode_reward": 990.0, "step": 63000}
{"episode": 256.0, "episode_reward": 942.6, "eval_time": 28.003762006759644, "mean_episode_reward": 942.6, "best_episode_reward": 993.0, "step": 64000}
{"episode": 260.0, "episode_reward": 913.1, "eval_time": 28.08325505256653, "mean_episode_reward": 913.1, "best_episode_reward": 990.0, "step": 65000}
{"episode": 264.0, "episode_reward": 946.9, "eval_time": 28.003288984298706, "mean_episode_reward": 946.9, "best_episode_reward": 992.0, "step": 66000}
{"episode": 268.0, "episode_reward": 932.6, "eval_time": 28.067826509475708, "mean_episode_reward": 932.6, "best_episode_reward": 993.0, "step": 67000}
{"episode": 272.0, "episode_reward": 971.4, "eval_time": 28.124985218048096, "mean_episode_reward": 971.4, "best_episode_reward": 993.0, "step": 68000}
{"episode": 276.0, "episode_reward": 946.1, "eval_time": 27.988763332366943, "mean_episode_reward": 946.1, "best_episode_reward": 991.0, "step": 69000}
{"episode": 280.0, "episode_reward": 928.1, "eval_time": 27.997307538986206, "mean_episode_reward": 928.1, "best_episode_reward": 1000.0, "step": 70000}
{"episode": 284.0, "episode_reward": 925.9, "eval_time": 28.063383102416992, "mean_episode_reward": 925.9, "best_episode_reward": 994.0, "step": 71000}
{"episode": 288.0, "episode_reward": 934.1, "eval_time": 27.591782569885254, "mean_episode_reward": 934.1, "best_episode_reward": 990.0, "step": 72000}
{"episode": 292.0, "episode_reward": 952.7, "eval_time": 28.103187322616577, "mean_episode_reward": 952.7, "best_episode_reward": 991.0, "step": 73000}
{"episode": 296.0, "episode_reward": 930.7, "eval_time": 28.096357583999634, "mean_episode_reward": 930.7, "best_episode_reward": 993.0, "step": 74000}
{"episode": 300.0, "episode_reward": 962.8, "eval_time": 28.123087167739868, "mean_episode_reward": 962.8, "best_episode_reward": 992.0, "step": 75000}
{"episode": 304.0, "episode_reward": 966.1, "eval_time": 28.124818325042725, "mean_episode_reward": 966.1, "best_episode_reward": 997.0, "step": 76000}
{"episode": 308.0, "episode_reward": 945.0, "eval_time": 28.258002519607544, "mean_episode_reward": 945.0, "best_episode_reward": 991.0, "step": 77000}
{"episode": 312.0, "episode_reward": 969.2, "eval_time": 28.135657787322998, "mean_episode_reward": 969.2, "best_episode_reward": 993.0, "step": 78000}
{"episode": 316.0, "episode_reward": 953.9, "eval_time": 28.145620584487915, "mean_episode_reward": 953.9, "best_episode_reward": 993.0, "step": 79000}
{"episode": 320.0, "episode_reward": 953.0, "eval_time": 28.117533445358276, "mean_episode_reward": 953.0, "best_episode_reward": 993.0, "step": 80000}
{"episode": 324.0, "episode_reward": 951.2, "eval_time": 28.18261456489563, "mean_episode_reward": 951.2, "best_episode_reward": 989.0, "step": 81000}
{"episode": 328.0, "episode_reward": 973.9, "eval_time": 28.246330499649048, "mean_episode_reward": 973.9, "best_episode_reward": 992.0, "step": 82000}
{"episode": 332.0, "episode_reward": 949.8, "eval_time": 27.97650909423828, "mean_episode_reward": 949.8, "best_episode_reward": 991.0, "step": 83000}
{"episode": 336.0, "episode_reward": 948.2, "eval_time": 28.382489442825317, "mean_episode_reward": 948.2, "best_episode_reward": 1000.0, "step": 84000}
{"episode": 340.0, "episode_reward": 946.1, "eval_time": 28.403336763381958, "mean_episode_reward": 946.1, "best_episode_reward": 992.0, "step": 85000}
{"episode": 344.0, "episode_reward": 974.8, "eval_time": 28.41263747215271, "mean_episode_reward": 974.8, "best_episode_reward": 996.0, "step": 86000}
{"episode": 348.0, "episode_reward": 977.7, "eval_time": 28.58646035194397, "mean_episode_reward": 977.7, "best_episode_reward": 993.0, "step": 87000}
{"episode": 352.0, "episode_reward": 967.3, "eval_time": 28.407182693481445, "mean_episode_reward": 967.3, "best_episode_reward": 993.0, "step": 88000}
{"episode": 356.0, "episode_reward": 964.7, "eval_time": 28.58651614189148, "mean_episode_reward": 964.7, "best_episode_reward": 999.0, "step": 89000}
{"episode": 360.0, "episode_reward": 979.6, "eval_time": 28.481916427612305, "mean_episode_reward": 979.6, "best_episode_reward": 993.0, "step": 90000}
{"episode": 364.0, "episode_reward": 964.7, "eval_time": 28.46888542175293, "mean_episode_reward": 964.7, "best_episode_reward": 989.0, "step": 91000}
{"episode": 368.0, "episode_reward": 964.1, "eval_time": 28.48281455039978, "mean_episode_reward": 964.1, "best_episode_reward": 994.0, "step": 92000}
{"episode": 372.0, "episode_reward": 970.7, "eval_time": 28.46780300140381, "mean_episode_reward": 970.7, "best_episode_reward": 999.0, "step": 93000}
{"episode": 376.0, "episode_reward": 970.0, "eval_time": 28.466320991516113, "mean_episode_reward": 970.0, "best_episode_reward": 993.0, "step": 94000}
{"episode": 380.0, "episode_reward": 962.1, "eval_time": 28.495368242263794, "mean_episode_reward": 962.1, "best_episode_reward": 993.0, "step": 95000}
{"episode": 384.0, "episode_reward": 982.8, "eval_time": 28.495903253555298, "mean_episode_reward": 982.8, "best_episode_reward": 1000.0, "step": 96000}
{"episode": 388.0, "episode_reward": 956.7, "eval_time": 28.41539216041565, "mean_episode_reward": 956.7, "best_episode_reward": 996.0, "step": 97000}
{"episode": 392.0, "episode_reward": 948.2, "eval_time": 28.459789037704468, "mean_episode_reward": 948.2, "best_episode_reward": 990.0, "step": 98000}
{"episode": 396.0, "episode_reward": 970.5, "eval_time": 28.43799352645874, "mean_episode_reward": 970.5, "best_episode_reward": 995.0, "step": 99000}
{"episode": 400.0, "episode_reward": 943.6, "eval_time": 28.421541690826416, "mean_episode_reward": 943.6, "best_episode_reward": 989.0, "step": 100000}
{"episode": 404.0, "episode_reward": 950.6, "eval_time": 28.50415563583374, "mean_episode_reward": 950.6, "best_episode_reward": 995.0, "step": 101000}
{"episode": 408.0, "episode_reward": 960.5, "eval_time": 28.52880048751831, "mean_episode_reward": 960.5, "best_episode_reward": 999.0, "step": 102000}
{"episode": 412.0, "episode_reward": 956.5, "eval_time": 28.081765174865723, "mean_episode_reward": 956.5, "best_episode_reward": 995.0, "step": 103000}
{"episode": 416.0, "episode_reward": 970.4, "eval_time": 28.548535585403442, "mean_episode_reward": 970.4, "best_episode_reward": 995.0, "step": 104000}
{"episode": 420.0, "episode_reward": 982.5, "eval_time": 28.41993737220764, "mean_episode_reward": 982.5, "best_episode_reward": 1000.0, "step": 105000}
{"episode": 424.0, "episode_reward": 973.4, "eval_time": 28.463618516921997, "mean_episode_reward": 973.4, "best_episode_reward": 998.0, "step": 106000}
{"episode": 428.0, "episode_reward": 960.6, "eval_time": 28.561120986938477, "mean_episode_reward": 960.6, "best_episode_reward": 992.0, "step": 107000}
{"episode": 432.0, "episode_reward": 965.2, "eval_time": 28.498469352722168, "mean_episode_reward": 965.2, "best_episode_reward": 996.0, "step": 108000}
{"episode": 436.0, "episode_reward": 945.7, "eval_time": 28.437455415725708, "mean_episode_reward": 945.7, "best_episode_reward": 992.0, "step": 109000}
{"episode": 440.0, "episode_reward": 969.4, "eval_time": 28.551642179489136, "mean_episode_reward": 969.4, "best_episode_reward": 995.0, "step": 110000}
{"episode": 444.0, "episode_reward": 977.5, "eval_time": 28.487193822860718, "mean_episode_reward": 977.5, "best_episode_reward": 999.0, "step": 111000}
{"episode": 448.0, "episode_reward": 972.7, "eval_time": 28.439541339874268, "mean_episode_reward": 972.7, "best_episode_reward": 993.0, "step": 112000}
{"episode": 452.0, "episode_reward": 973.8, "eval_time": 28.64542055130005, "mean_episode_reward": 973.8, "best_episode_reward": 993.0, "step": 113000}
{"episode": 456.0, "episode_reward": 968.2, "eval_time": 28.470938205718994, "mean_episode_reward": 968.2, "best_episode_reward": 991.0, "step": 114000}
{"episode": 460.0, "episode_reward": 968.8, "eval_time": 28.3858962059021, "mean_episode_reward": 968.8, "best_episode_reward": 992.0, "step": 115000}
{"episode": 464.0, "episode_reward": 973.4, "eval_time": 28.87832498550415, "mean_episode_reward": 973.4, "best_episode_reward": 998.0, "step": 116000}
{"episode": 468.0, "episode_reward": 964.3, "eval_time": 28.510014057159424, "mean_episode_reward": 964.3, "best_episode_reward": 992.0, "step": 117000}
{"episode": 472.0, "episode_reward": 968.0, "eval_time": 28.481714010238647, "mean_episode_reward": 968.0, "best_episode_reward": 995.0, "step": 118000}
{"episode": 476.0, "episode_reward": 977.0, "eval_time": 28.62158513069153, "mean_episode_reward": 977.0, "best_episode_reward": 994.0, "step": 119000}
{"episode": 480.0, "episode_reward": 966.3, "eval_time": 28.414536237716675, "mean_episode_reward": 966.3, "best_episode_reward": 996.0, "step": 120000}
{"episode": 484.0, "episode_reward": 967.9, "eval_time": 28.470500469207764, "mean_episode_reward": 967.9, "best_episode_reward": 998.0, "step": 121000}
{"episode": 488.0, "episode_reward": 960.9, "eval_time": 28.64518404006958, "mean_episode_reward": 960.9, "best_episode_reward": 997.0, "step": 122000}
{"episode": 492.0, "episode_reward": 961.4, "eval_time": 28.456031560897827, "mean_episode_reward": 961.4, "best_episode_reward": 1000.0, "step": 123000}
{"episode": 496.0, "episode_reward": 983.3, "eval_time": 28.438141345977783, "mean_episode_reward": 983.3, "best_episode_reward": 991.0, "step": 124000}
{"episode": 500.0, "episode_reward": 974.3, "eval_time": 28.69237756729126, "mean_episode_reward": 974.3, "best_episode_reward": 995.0, "step": 125000}
{"episode": 504.0, "episode_reward": 971.6, "eval_time": 28.470476150512695, "mean_episode_reward": 971.6, "best_episode_reward": 995.0, "step": 126000}
{"episode": 508.0, "episode_reward": 959.1, "eval_time": 28.444513082504272, "mean_episode_reward": 959.1, "best_episode_reward": 992.0, "step": 127000}
{"episode": 512.0, "episode_reward": 968.8, "eval_time": 28.61479687690735, "mean_episode_reward": 968.8, "best_episode_reward": 999.0, "step": 128000}
{"episode": 516.0, "episode_reward": 975.5, "eval_time": 28.41016960144043, "mean_episode_reward": 975.5, "best_episode_reward": 1000.0, "step": 129000}
{"episode": 520.0, "episode_reward": 966.3, "eval_time": 28.48369073867798, "mean_episode_reward": 966.3, "best_episode_reward": 991.0, "step": 130000}
{"episode": 524.0, "episode_reward": 973.6, "eval_time": 28.652918100357056, "mean_episode_reward": 973.6, "best_episode_reward": 997.0, "step": 131000}
{"episode": 528.0, "episode_reward": 960.4, "eval_time": 28.43498158454895, "mean_episode_reward": 960.4, "best_episode_reward": 1000.0, "step": 132000}
{"episode": 532.0, "episode_reward": 969.5, "eval_time": 28.586612939834595, "mean_episode_reward": 969.5, "best_episode_reward": 1000.0, "step": 133000}
{"episode": 536.0, "episode_reward": 971.8, "eval_time": 28.609334468841553, "mean_episode_reward": 971.8, "best_episode_reward": 992.0, "step": 134000}
{"episode": 540.0, "episode_reward": 968.2, "eval_time": 28.43729543685913, "mean_episode_reward": 968.2, "best_episode_reward": 995.0, "step": 135000}
{"episode": 544.0, "episode_reward": 962.6, "eval_time": 28.484286546707153, "mean_episode_reward": 962.6, "best_episode_reward": 995.0, "step": 136000}
{"episode": 548.0, "episode_reward": 965.9, "eval_time": 28.57344675064087, "mean_episode_reward": 965.9, "best_episode_reward": 991.0, "step": 137000}
{"episode": 552.0, "episode_reward": 968.5, "eval_time": 28.451897382736206, "mean_episode_reward": 968.5, "best_episode_reward": 997.0, "step": 138000}
{"episode": 556.0, "episode_reward": 953.2, "eval_time": 28.57176423072815, "mean_episode_reward": 953.2, "best_episode_reward": 988.0, "step": 139000}
{"episode": 560.0, "episode_reward": 976.2, "eval_time": 28.549376487731934, "mean_episode_reward": 976.2, "best_episode_reward": 995.0, "step": 140000}
{"episode": 564.0, "episode_reward": 983.0, "eval_time": 28.42014980316162, "mean_episode_reward": 983.0, "best_episode_reward": 1000.0, "step": 141000}
{"episode": 568.0, "episode_reward": 969.2, "eval_time": 28.48718571662903, "mean_episode_reward": 969.2, "best_episode_reward": 992.0, "step": 142000}
{"episode": 572.0, "episode_reward": 977.9, "eval_time": 28.64710569381714, "mean_episode_reward": 977.9, "best_episode_reward": 995.0, "step": 143000}
{"episode": 576.0, "episode_reward": 950.2, "eval_time": 29.080872535705566, "mean_episode_reward": 950.2, "best_episode_reward": 992.0, "step": 144000}
{"episode": 580.0, "episode_reward": 976.4, "eval_time": 28.218971729278564, "mean_episode_reward": 976.4, "best_episode_reward": 993.0, "step": 145000}
{"episode": 584.0, "episode_reward": 970.4, "eval_time": 28.6175856590271, "mean_episode_reward": 970.4, "best_episode_reward": 997.0, "step": 146000}
{"episode": 588.0, "episode_reward": 962.2, "eval_time": 28.56775188446045, "mean_episode_reward": 962.2, "best_episode_reward": 999.0, "step": 147000}
{"episode": 592.0, "episode_reward": 977.7, "eval_time": 28.58001184463501, "mean_episode_reward": 977.7, "best_episode_reward": 995.0, "step": 148000}
{"episode": 596.0, "episode_reward": 964.5, "eval_time": 28.49261498451233, "mean_episode_reward": 964.5, "best_episode_reward": 993.0, "step": 149000}
{"episode": 600.0, "episode_reward": 974.0, "eval_time": 28.35148310661316, "mean_episode_reward": 974.0, "best_episode_reward": 997.0, "step": 150000}
{"episode": 604.0, "episode_reward": 975.9, "eval_time": 28.702919960021973, "mean_episode_reward": 975.9, "best_episode_reward": 998.0, "step": 151000}
{"episode": 608.0, "episode_reward": 949.0, "eval_time": 28.480520009994507, "mean_episode_reward": 949.0, "best_episode_reward": 996.0, "step": 152000}
{"episode": 612.0, "episode_reward": 962.9, "eval_time": 27.99545907974243, "mean_episode_reward": 962.9, "best_episode_reward": 998.0, "step": 153000}
{"episode": 616.0, "episode_reward": 960.0, "eval_time": 28.613820552825928, "mean_episode_reward": 960.0, "best_episode_reward": 999.0, "step": 154000}
{"episode": 620.0, "episode_reward": 969.9, "eval_time": 28.601340770721436, "mean_episode_reward": 969.9, "best_episode_reward": 999.0, "step": 155000}
{"episode": 624.0, "episode_reward": 964.9, "eval_time": 28.038783311843872, "mean_episode_reward": 964.9, "best_episode_reward": 998.0, "step": 156000}
{"episode": 628.0, "episode_reward": 978.0, "eval_time": 28.66965079307556, "mean_episode_reward": 978.0, "best_episode_reward": 1000.0, "step": 157000}
{"episode": 632.0, "episode_reward": 966.8, "eval_time": 28.518203258514404, "mean_episode_reward": 966.8, "best_episode_reward": 992.0, "step": 158000}
{"episode": 636.0, "episode_reward": 962.4, "eval_time": 28.47887635231018, "mean_episode_reward": 962.4, "best_episode_reward": 1000.0, "step": 159000}
{"episode": 640.0, "episode_reward": 929.6, "eval_time": 28.49645185470581, "mean_episode_reward": 929.6, "best_episode_reward": 991.0, "step": 160000}
{"episode": 644.0, "episode_reward": 973.7, "eval_time": 28.330585479736328, "mean_episode_reward": 973.7, "best_episode_reward": 1000.0, "step": 161000}
{"episode": 648.0, "episode_reward": 968.9, "eval_time": 28.624152660369873, "mean_episode_reward": 968.9, "best_episode_reward": 995.0, "step": 162000}
{"episode": 652.0, "episode_reward": 977.7, "eval_time": 28.577758312225342, "mean_episode_reward": 977.7, "best_episode_reward": 994.0, "step": 163000}
{"episode": 656.0, "episode_reward": 948.6, "eval_time": 28.467467308044434, "mean_episode_reward": 948.6, "best_episode_reward": 991.0, "step": 164000}
{"episode": 660.0, "episode_reward": 962.2, "eval_time": 28.46543264389038, "mean_episode_reward": 962.2, "best_episode_reward": 998.0, "step": 165000}
{"episode": 664.0, "episode_reward": 956.7, "eval_time": 28.558866500854492, "mean_episode_reward": 956.7, "best_episode_reward": 993.0, "step": 166000}
{"episode": 668.0, "episode_reward": 982.3, "eval_time": 28.45146131515503, "mean_episode_reward": 982.3, "best_episode_reward": 999.0, "step": 167000}
{"episode": 672.0, "episode_reward": 966.7, "eval_time": 28.585731744766235, "mean_episode_reward": 966.7, "best_episode_reward": 997.0, "step": 168000}
{"episode": 676.0, "episode_reward": 965.0, "eval_time": 28.62287449836731, "mean_episode_reward": 965.0, "best_episode_reward": 993.0, "step": 169000}
{"episode": 680.0, "episode_reward": 966.1, "eval_time": 28.555082321166992, "mean_episode_reward": 966.1, "best_episode_reward": 1000.0, "step": 170000}
{"episode": 684.0, "episode_reward": 962.1, "eval_time": 28.32774329185486, "mean_episode_reward": 962.1, "best_episode_reward": 992.0, "step": 171000}
{"episode": 688.0, "episode_reward": 965.8, "eval_time": 28.352401733398438, "mean_episode_reward": 965.8, "best_episode_reward": 997.0, "step": 172000}
{"episode": 692.0, "episode_reward": 972.0, "eval_time": 28.40865707397461, "mean_episode_reward": 972.0, "best_episode_reward": 999.0, "step": 173000}
{"episode": 696.0, "episode_reward": 957.4, "eval_time": 28.329814672470093, "mean_episode_reward": 957.4, "best_episode_reward": 991.0, "step": 174000}
{"episode": 700.0, "episode_reward": 972.4, "eval_time": 28.434065341949463, "mean_episode_reward": 972.4, "best_episode_reward": 1000.0, "step": 175000}
{"episode": 704.0, "episode_reward": 962.5, "eval_time": 28.775476694107056, "mean_episode_reward": 962.5, "best_episode_reward": 996.0, "step": 176000}
{"episode": 708.0, "episode_reward": 946.4, "eval_time": 28.49261236190796, "mean_episode_reward": 946.4, "best_episode_reward": 993.0, "step": 177000}
{"episode": 712.0, "episode_reward": 964.2, "eval_time": 28.44400382041931, "mean_episode_reward": 964.2, "best_episode_reward": 996.0, "step": 178000}
{"episode": 716.0, "episode_reward": 968.5, "eval_time": 29.366934776306152, "mean_episode_reward": 968.5, "best_episode_reward": 998.0, "step": 179000}
{"episode": 720.0, "episode_reward": 976.1, "eval_time": 28.356258153915405, "mean_episode_reward": 976.1, "best_episode_reward": 1000.0, "step": 180000}
{"episode": 724.0, "episode_reward": 964.6, "eval_time": 28.423144578933716, "mean_episode_reward": 964.6, "best_episode_reward": 997.0, "step": 181000}
{"episode": 728.0, "episode_reward": 972.6, "eval_time": 28.48929214477539, "mean_episode_reward": 972.6, "best_episode_reward": 997.0, "step": 182000}
{"episode": 732.0, "episode_reward": 962.0, "eval_time": 28.601022481918335, "mean_episode_reward": 962.0, "best_episode_reward": 992.0, "step": 183000}
{"episode": 736.0, "episode_reward": 958.2, "eval_time": 28.49463939666748, "mean_episode_reward": 958.2, "best_episode_reward": 993.0, "step": 184000}
{"episode": 740.0, "episode_reward": 969.0, "eval_time": 28.35629653930664, "mean_episode_reward": 969.0, "best_episode_reward": 991.0, "step": 185000}
{"episode": 744.0, "episode_reward": 963.2, "eval_time": 28.590927362442017, "mean_episode_reward": 963.2, "best_episode_reward": 988.0, "step": 186000}
{"episode": 748.0, "episode_reward": 963.8, "eval_time": 28.403257608413696, "mean_episode_reward": 963.8, "best_episode_reward": 990.0, "step": 187000}
{"episode": 752.0, "episode_reward": 947.7, "eval_time": 28.3991379737854, "mean_episode_reward": 947.7, "best_episode_reward": 992.0, "step": 188000}
{"episode": 756.0, "episode_reward": 957.0, "eval_time": 28.445562601089478, "mean_episode_reward": 957.0, "best_episode_reward": 991.0, "step": 189000}
{"episode": 760.0, "episode_reward": 962.6, "eval_time": 28.396337032318115, "mean_episode_reward": 962.6, "best_episode_reward": 993.0, "step": 190000}
{"episode": 764.0, "episode_reward": 963.4, "eval_time": 28.35402512550354, "mean_episode_reward": 963.4, "best_episode_reward": 1000.0, "step": 191000}
{"episode": 768.0, "episode_reward": 966.0, "eval_time": 28.41003942489624, "mean_episode_reward": 966.0, "best_episode_reward": 997.0, "step": 192000}
{"episode": 772.0, "episode_reward": 971.7, "eval_time": 29.107475996017456, "mean_episode_reward": 971.7, "best_episode_reward": 993.0, "step": 193000}
{"episode": 776.0, "episode_reward": 986.4, "eval_time": 28.53396201133728, "mean_episode_reward": 986.4, "best_episode_reward": 996.0, "step": 194000}
{"episode": 780.0, "episode_reward": 967.1, "eval_time": 28.49299716949463, "mean_episode_reward": 967.1, "best_episode_reward": 992.0, "step": 195000}
{"episode": 784.0, "episode_reward": 977.1, "eval_time": 28.434844970703125, "mean_episode_reward": 977.1, "best_episode_reward": 993.0, "step": 196000}
{"episode": 788.0, "episode_reward": 965.5, "eval_time": 28.40769863128662, "mean_episode_reward": 965.5, "best_episode_reward": 989.0, "step": 197000}
{"episode": 792.0, "episode_reward": 968.5, "eval_time": 28.447936058044434, "mean_episode_reward": 968.5, "best_episode_reward": 1000.0, "step": 198000}
{"episode": 796.0, "episode_reward": 967.9, "eval_time": 28.381422519683838, "mean_episode_reward": 967.9, "best_episode_reward": 992.0, "step": 199000}
{"episode": 800.0, "episode_reward": 966.9, "eval_time": 28.39247226715088, "mean_episode_reward": 966.9, "best_episode_reward": 994.0, "step": 200000}
{"episode": 804.0, "episode_reward": 977.1, "eval_time": 28.382519960403442, "mean_episode_reward": 977.1, "best_episode_reward": 996.0, "step": 201000}
{"episode": 808.0, "episode_reward": 949.6, "eval_time": 28.457130670547485, "mean_episode_reward": 949.6, "best_episode_reward": 992.0, "step": 202000}
{"episode": 812.0, "episode_reward": 977.0, "eval_time": 28.40294337272644, "mean_episode_reward": 977.0, "best_episode_reward": 999.0, "step": 203000}
{"episode": 816.0, "episode_reward": 962.7, "eval_time": 28.330129384994507, "mean_episode_reward": 962.7, "best_episode_reward": 994.0, "step": 204000}
{"episode": 820.0, "episode_reward": 970.9, "eval_time": 28.413133144378662, "mean_episode_reward": 970.9, "best_episode_reward": 1000.0, "step": 205000}
{"episode": 824.0, "episode_reward": 957.8, "eval_time": 27.943779945373535, "mean_episode_reward": 957.8, "best_episode_reward": 992.0, "step": 206000}
{"episode": 828.0, "episode_reward": 962.7, "eval_time": 29.06941246986389, "mean_episode_reward": 962.7, "best_episode_reward": 990.0, "step": 207000}
{"episode": 832.0, "episode_reward": 971.1, "eval_time": 28.693299770355225, "mean_episode_reward": 971.1, "best_episode_reward": 997.0, "step": 208000}
{"episode": 836.0, "episode_reward": 980.3, "eval_time": 28.37296414375305, "mean_episode_reward": 980.3, "best_episode_reward": 1000.0, "step": 209000}
{"episode": 840.0, "episode_reward": 945.4, "eval_time": 29.44692349433899, "mean_episode_reward": 945.4, "best_episode_reward": 998.0, "step": 210000}
{"episode": 844.0, "episode_reward": 957.0, "eval_time": 29.712387561798096, "mean_episode_reward": 957.0, "best_episode_reward": 993.0, "step": 211000}
{"episode": 848.0, "episode_reward": 974.1, "eval_time": 28.401687145233154, "mean_episode_reward": 974.1, "best_episode_reward": 1000.0, "step": 212000}
{"episode": 852.0, "episode_reward": 967.2, "eval_time": 28.47093677520752, "mean_episode_reward": 967.2, "best_episode_reward": 995.0, "step": 213000}
{"episode": 856.0, "episode_reward": 969.1, "eval_time": 28.51648235321045, "mean_episode_reward": 969.1, "best_episode_reward": 1000.0, "step": 214000}
{"episode": 860.0, "episode_reward": 978.1, "eval_time": 28.41426944732666, "mean_episode_reward": 978.1, "best_episode_reward": 992.0, "step": 215000}
{"episode": 864.0, "episode_reward": 971.0, "eval_time": 28.424225091934204, "mean_episode_reward": 971.0, "best_episode_reward": 998.0, "step": 216000}
{"episode": 868.0, "episode_reward": 969.3, "eval_time": 28.42326855659485, "mean_episode_reward": 969.3, "best_episode_reward": 999.0, "step": 217000}
{"episode": 872.0, "episode_reward": 965.2, "eval_time": 29.635059595108032, "mean_episode_reward": 965.2, "best_episode_reward": 997.0, "step": 218000}
{"episode": 876.0, "episode_reward": 971.8, "eval_time": 28.25355863571167, "mean_episode_reward": 971.8, "best_episode_reward": 1000.0, "step": 219000}
{"episode": 880.0, "episode_reward": 966.4, "eval_time": 29.78730297088623, "mean_episode_reward": 966.4, "best_episode_reward": 989.0, "step": 220000}
{"episode": 884.0, "episode_reward": 956.2, "eval_time": 28.421249628067017, "mean_episode_reward": 956.2, "best_episode_reward": 991.0, "step": 221000}
{"episode": 888.0, "episode_reward": 962.0, "eval_time": 28.604756832122803, "mean_episode_reward": 962.0, "best_episode_reward": 996.0, "step": 222000}
{"episode": 892.0, "episode_reward": 968.7, "eval_time": 28.522204637527466, "mean_episode_reward": 968.7, "best_episode_reward": 992.0, "step": 223000}
{"episode": 896.0, "episode_reward": 966.0, "eval_time": 28.429767847061157, "mean_episode_reward": 966.0, "best_episode_reward": 986.0, "step": 224000}
{"episode": 900.0, "episode_reward": 946.4, "eval_time": 29.057868480682373, "mean_episode_reward": 946.4, "best_episode_reward": 999.0, "step": 225000}
{"episode": 904.0, "episode_reward": 979.3, "eval_time": 28.542365074157715, "mean_episode_reward": 979.3, "best_episode_reward": 994.0, "step": 226000}
{"episode": 908.0, "episode_reward": 974.6, "eval_time": 28.388118267059326, "mean_episode_reward": 974.6, "best_episode_reward": 997.0, "step": 227000}
{"episode": 912.0, "episode_reward": 966.5, "eval_time": 28.40449285507202, "mean_episode_reward": 966.5, "best_episode_reward": 1000.0, "step": 228000}
{"episode": 916.0, "episode_reward": 968.7, "eval_time": 28.49759578704834, "mean_episode_reward": 968.7, "best_episode_reward": 992.0, "step": 229000}
{"episode": 920.0, "episode_reward": 967.7, "eval_time": 29.434351921081543, "mean_episode_reward": 967.7, "best_episode_reward": 999.0, "step": 230000}
{"episode": 924.0, "episode_reward": 967.3, "eval_time": 29.445323705673218, "mean_episode_reward": 967.3, "best_episode_reward": 992.0, "step": 231000}
{"episode": 928.0, "episode_reward": 966.8, "eval_time": 28.66337275505066, "mean_episode_reward": 966.8, "best_episode_reward": 1000.0, "step": 232000}
{"episode": 932.0, "episode_reward": 958.8, "eval_time": 28.409485578536987, "mean_episode_reward": 958.8, "best_episode_reward": 996.0, "step": 233000}
{"episode": 936.0, "episode_reward": 976.5, "eval_time": 28.33052396774292, "mean_episode_reward": 976.5, "best_episode_reward": 997.0, "step": 234000}
{"episode": 940.0, "episode_reward": 966.2, "eval_time": 29.66855239868164, "mean_episode_reward": 966.2, "best_episode_reward": 993.0, "step": 235000}
{"episode": 944.0, "episode_reward": 978.8, "eval_time": 29.384708881378174, "mean_episode_reward": 978.8, "best_episode_reward": 1000.0, "step": 236000}
{"episode": 948.0, "episode_reward": 983.2, "eval_time": 29.63533926010132, "mean_episode_reward": 983.2, "best_episode_reward": 1000.0, "step": 237000}
{"episode": 952.0, "episode_reward": 969.1, "eval_time": 29.878793239593506, "mean_episode_reward": 969.1, "best_episode_reward": 991.0, "step": 238000}
{"episode": 956.0, "episode_reward": 947.1, "eval_time": 29.175029516220093, "mean_episode_reward": 947.1, "best_episode_reward": 991.0, "step": 239000}
{"episode": 960.0, "episode_reward": 850.2, "eval_time": 29.523080825805664, "mean_episode_reward": 850.2, "best_episode_reward": 1000.0, "step": 240000}
{"episode": 964.0, "episode_reward": 937.4, "eval_time": 29.724578142166138, "mean_episode_reward": 937.4, "best_episode_reward": 992.0, "step": 241000}
{"episode": 968.0, "episode_reward": 982.4, "eval_time": 28.545385360717773, "mean_episode_reward": 982.4, "best_episode_reward": 996.0, "step": 242000}
{"episode": 972.0, "episode_reward": 971.2, "eval_time": 28.749619245529175, "mean_episode_reward": 971.2, "best_episode_reward": 993.0, "step": 243000}
{"episode": 976.0, "episode_reward": 962.5, "eval_time": 28.523590564727783, "mean_episode_reward": 962.5, "best_episode_reward": 985.0, "step": 244000}
{"episode": 980.0, "episode_reward": 964.7, "eval_time": 28.2083637714386, "mean_episode_reward": 964.7, "best_episode_reward": 989.0, "step": 245000}
{"episode": 984.0, "episode_reward": 950.7, "eval_time": 29.585674285888672, "mean_episode_reward": 950.7, "best_episode_reward": 993.0, "step": 246000}
{"episode": 988.0, "episode_reward": 963.4, "eval_time": 28.572553157806396, "mean_episode_reward": 963.4, "best_episode_reward": 997.0, "step": 247000}
{"episode": 992.0, "episode_reward": 975.8, "eval_time": 29.488364219665527, "mean_episode_reward": 975.8, "best_episode_reward": 997.0, "step": 248000}
{"episode": 996.0, "episode_reward": 970.7, "eval_time": 28.5767343044281, "mean_episode_reward": 970.7, "best_episode_reward": 991.0, "step": 249000}
{"episode": 1000.0, "episode_reward": 974.5, "eval_time": 29.646763563156128, "mean_episode_reward": 974.5, "best_episode_reward": 998.0, "step": 250000}
{"episode": 1004.0, "episode_reward": 972.7, "eval_time": 28.441795825958252, "mean_episode_reward": 972.7, "best_episode_reward": 991.0, "step": 251000}
{"episode": 1008.0, "episode_reward": 963.1, "eval_time": 29.63919425010681, "mean_episode_reward": 963.1, "best_episode_reward": 989.0, "step": 252000}
{"episode": 1012.0, "episode_reward": 966.8, "eval_time": 29.351382732391357, "mean_episode_reward": 966.8, "best_episode_reward": 993.0, "step": 253000}
{"episode": 1016.0, "episode_reward": 975.2, "eval_time": 29.53014326095581, "mean_episode_reward": 975.2, "best_episode_reward": 992.0, "step": 254000}
{"episode": 1020.0, "episode_reward": 975.1, "eval_time": 28.514414310455322, "mean_episode_reward": 975.1, "best_episode_reward": 993.0, "step": 255000}
{"episode": 1024.0, "episode_reward": 975.5, "eval_time": 28.551903009414673, "mean_episode_reward": 975.5, "best_episode_reward": 992.0, "step": 256000}
{"episode": 1028.0, "episode_reward": 967.4, "eval_time": 28.523255825042725, "mean_episode_reward": 967.4, "best_episode_reward": 995.0, "step": 257000}
{"episode": 1032.0, "episode_reward": 977.6, "eval_time": 28.58535075187683, "mean_episode_reward": 977.6, "best_episode_reward": 996.0, "step": 258000}
{"episode": 1036.0, "episode_reward": 966.4, "eval_time": 29.561347723007202, "mean_episode_reward": 966.4, "best_episode_reward": 993.0, "step": 259000}
{"episode": 1040.0, "episode_reward": 974.0, "eval_time": 29.4898362159729, "mean_episode_reward": 974.0, "best_episode_reward": 993.0, "step": 260000}
{"episode": 1044.0, "episode_reward": 978.4, "eval_time": 29.65467643737793, "mean_episode_reward": 978.4, "best_episode_reward": 993.0, "step": 261000}
{"episode": 1048.0, "episode_reward": 955.5, "eval_time": 29.574947595596313, "mean_episode_reward": 955.5, "best_episode_reward": 992.0, "step": 262000}
{"episode": 1052.0, "episode_reward": 962.4, "eval_time": 29.481738090515137, "mean_episode_reward": 962.4, "best_episode_reward": 998.0, "step": 263000}
{"episode": 1056.0, "episode_reward": 970.0, "eval_time": 29.673115015029907, "mean_episode_reward": 970.0, "best_episode_reward": 998.0, "step": 264000}
{"episode": 1060.0, "episode_reward": 970.3, "eval_time": 28.521379947662354, "mean_episode_reward": 970.3, "best_episode_reward": 998.0, "step": 265000}
{"episode": 1064.0, "episode_reward": 983.9, "eval_time": 28.673912525177002, "mean_episode_reward": 983.9, "best_episode_reward": 1000.0, "step": 266000}
{"episode": 1068.0, "episode_reward": 982.9, "eval_time": 28.428377151489258, "mean_episode_reward": 982.9, "best_episode_reward": 995.0, "step": 267000}
{"episode": 1072.0, "episode_reward": 968.3, "eval_time": 28.45652151107788, "mean_episode_reward": 968.3, "best_episode_reward": 1000.0, "step": 268000}
{"episode": 1076.0, "episode_reward": 976.6, "eval_time": 29.480387926101685, "mean_episode_reward": 976.6, "best_episode_reward": 994.0, "step": 269000}
{"episode": 1080.0, "episode_reward": 965.4, "eval_time": 28.47178888320923, "mean_episode_reward": 965.4, "best_episode_reward": 1000.0, "step": 270000}
{"episode": 1084.0, "episode_reward": 975.2, "eval_time": 29.63741111755371, "mean_episode_reward": 975.2, "best_episode_reward": 993.0, "step": 271000}
{"episode": 1088.0, "episode_reward": 979.1, "eval_time": 28.457191228866577, "mean_episode_reward": 979.1, "best_episode_reward": 996.0, "step": 272000}
{"episode": 1092.0, "episode_reward": 976.1, "eval_time": 28.43398094177246, "mean_episode_reward": 976.1, "best_episode_reward": 1000.0, "step": 273000}
{"episode": 1096.0, "episode_reward": 976.8, "eval_time": 29.63727831840515, "mean_episode_reward": 976.8, "best_episode_reward": 992.0, "step": 274000}
{"episode": 1100.0, "episode_reward": 977.6, "eval_time": 29.4122953414917, "mean_episode_reward": 977.6, "best_episode_reward": 999.0, "step": 275000}
{"episode": 1104.0, "episode_reward": 972.3, "eval_time": 28.578627824783325, "mean_episode_reward": 972.3, "best_episode_reward": 995.0, "step": 276000}
{"episode": 1108.0, "episode_reward": 968.8, "eval_time": 29.57881236076355, "mean_episode_reward": 968.8, "best_episode_reward": 991.0, "step": 277000}
{"episode": 1112.0, "episode_reward": 976.6, "eval_time": 28.561084985733032, "mean_episode_reward": 976.6, "best_episode_reward": 997.0, "step": 278000}
{"episode": 1116.0, "episode_reward": 962.7, "eval_time": 28.097124338150024, "mean_episode_reward": 962.7, "best_episode_reward": 992.0, "step": 279000}
{"episode": 1120.0, "episode_reward": 970.1, "eval_time": 27.809226512908936, "mean_episode_reward": 970.1, "best_episode_reward": 999.0, "step": 280000}
{"episode": 1124.0, "episode_reward": 969.1, "eval_time": 27.911973476409912, "mean_episode_reward": 969.1, "best_episode_reward": 996.0, "step": 281000}
{"episode": 1128.0, "episode_reward": 969.5, "eval_time": 28.089308977127075, "mean_episode_reward": 969.5, "best_episode_reward": 992.0, "step": 282000}
{"episode": 1132.0, "episode_reward": 968.4, "eval_time": 28.176504135131836, "mean_episode_reward": 968.4, "best_episode_reward": 997.0, "step": 283000}
{"episode": 1136.0, "episode_reward": 973.2, "eval_time": 28.92330265045166, "mean_episode_reward": 973.2, "best_episode_reward": 997.0, "step": 284000}
{"episode": 1140.0, "episode_reward": 963.9, "eval_time": 29.15565061569214, "mean_episode_reward": 963.9, "best_episode_reward": 997.0, "step": 285000}
{"episode": 1144.0, "episode_reward": 963.2, "eval_time": 29.569545030593872, "mean_episode_reward": 963.2, "best_episode_reward": 996.0, "step": 286000}
{"episode": 1148.0, "episode_reward": 955.2, "eval_time": 28.378572463989258, "mean_episode_reward": 955.2, "best_episode_reward": 994.0, "step": 287000}
{"episode": 1152.0, "episode_reward": 950.5, "eval_time": 29.77129030227661, "mean_episode_reward": 950.5, "best_episode_reward": 991.0, "step": 288000}
{"episode": 1156.0, "episode_reward": 970.5, "eval_time": 29.636492252349854, "mean_episode_reward": 970.5, "best_episode_reward": 997.0, "step": 289000}
{"episode": 1160.0, "episode_reward": 962.8, "eval_time": 28.525129795074463, "mean_episode_reward": 962.8, "best_episode_reward": 992.0, "step": 290000}
{"episode": 1164.0, "episode_reward": 965.7, "eval_time": 28.518925428390503, "mean_episode_reward": 965.7, "best_episode_reward": 999.0, "step": 291000}
{"episode": 1168.0, "episode_reward": 943.3, "eval_time": 28.281726360321045, "mean_episode_reward": 943.3, "best_episode_reward": 1000.0, "step": 292000}
{"episode": 1172.0, "episode_reward": 980.7, "eval_time": 28.202779054641724, "mean_episode_reward": 980.7, "best_episode_reward": 998.0, "step": 293000}
{"episode": 1176.0, "episode_reward": 976.0, "eval_time": 28.30532431602478, "mean_episode_reward": 976.0, "best_episode_reward": 997.0, "step": 294000}
{"episode": 1180.0, "episode_reward": 971.0, "eval_time": 28.4604229927063, "mean_episode_reward": 971.0, "best_episode_reward": 1000.0, "step": 295000}
{"episode": 1184.0, "episode_reward": 969.6, "eval_time": 29.604662656784058, "mean_episode_reward": 969.6, "best_episode_reward": 991.0, "step": 296000}
{"episode": 1188.0, "episode_reward": 961.0, "eval_time": 29.163044452667236, "mean_episode_reward": 961.0, "best_episode_reward": 992.0, "step": 297000}
{"episode": 1192.0, "episode_reward": 938.6, "eval_time": 29.29121994972229, "mean_episode_reward": 938.6, "best_episode_reward": 987.0, "step": 298000}
{"episode": 1196.0, "episode_reward": 940.2, "eval_time": 28.54900550842285, "mean_episode_reward": 940.2, "best_episode_reward": 990.0, "step": 299000}
{"episode": 1200.0, "episode_reward": 971.4, "eval_time": 29.711472988128662, "mean_episode_reward": 971.4, "best_episode_reward": 992.0, "step": 300000}
{"episode": 1204.0, "episode_reward": 926.1, "eval_time": 28.399822235107422, "mean_episode_reward": 926.1, "best_episode_reward": 991.0, "step": 301000}
{"episode": 1208.0, "episode_reward": 975.2, "eval_time": 28.366271257400513, "mean_episode_reward": 975.2, "best_episode_reward": 998.0, "step": 302000}
{"episode": 1212.0, "episode_reward": 978.9, "eval_time": 29.106110095977783, "mean_episode_reward": 978.9, "best_episode_reward": 996.0, "step": 303000}
{"episode": 1216.0, "episode_reward": 975.3, "eval_time": 28.501736640930176, "mean_episode_reward": 975.3, "best_episode_reward": 1000.0, "step": 304000}
{"episode": 1220.0, "episode_reward": 966.3, "eval_time": 28.41133999824524, "mean_episode_reward": 966.3, "best_episode_reward": 992.0, "step": 305000}
{"episode": 1224.0, "episode_reward": 980.7, "eval_time": 28.30779457092285, "mean_episode_reward": 980.7, "best_episode_reward": 997.0, "step": 306000}
{"episode": 1228.0, "episode_reward": 931.7, "eval_time": 28.26712131500244, "mean_episode_reward": 931.7, "best_episode_reward": 992.0, "step": 307000}
{"episode": 1232.0, "episode_reward": 868.3, "eval_time": 28.406638622283936, "mean_episode_reward": 868.3, "best_episode_reward": 991.0, "step": 308000}
{"episode": 1236.0, "episode_reward": 950.2, "eval_time": 28.308963775634766, "mean_episode_reward": 950.2, "best_episode_reward": 996.0, "step": 309000}
{"episode": 1240.0, "episode_reward": 971.2, "eval_time": 29.5344877243042, "mean_episode_reward": 971.2, "best_episode_reward": 1000.0, "step": 310000}
{"episode": 1244.0, "episode_reward": 982.9, "eval_time": 29.553382635116577, "mean_episode_reward": 982.9, "best_episode_reward": 999.0, "step": 311000}
{"episode": 1248.0, "episode_reward": 950.4, "eval_time": 29.513675689697266, "mean_episode_reward": 950.4, "best_episode_reward": 996.0, "step": 312000}
{"episode": 1252.0, "episode_reward": 939.5, "eval_time": 29.34355592727661, "mean_episode_reward": 939.5, "best_episode_reward": 989.0, "step": 313000}
{"episode": 1256.0, "episode_reward": 983.0, "eval_time": 29.721030712127686, "mean_episode_reward": 983.0, "best_episode_reward": 999.0, "step": 314000}
{"episode": 1260.0, "episode_reward": 955.8, "eval_time": 29.694661378860474, "mean_episode_reward": 955.8, "best_episode_reward": 998.0, "step": 315000}
{"episode": 1264.0, "episode_reward": 936.5, "eval_time": 28.386229515075684, "mean_episode_reward": 936.5, "best_episode_reward": 991.0, "step": 316000}
{"episode": 1268.0, "episode_reward": 949.7, "eval_time": 29.38357162475586, "mean_episode_reward": 949.7, "best_episode_reward": 997.0, "step": 317000}
{"episode": 1272.0, "episode_reward": 962.2, "eval_time": 29.628289461135864, "mean_episode_reward": 962.2, "best_episode_reward": 999.0, "step": 318000}
{"episode": 1276.0, "episode_reward": 959.5, "eval_time": 28.459635019302368, "mean_episode_reward": 959.5, "best_episode_reward": 995.0, "step": 319000}
{"episode": 1280.0, "episode_reward": 978.9, "eval_time": 28.36755657196045, "mean_episode_reward": 978.9, "best_episode_reward": 1000.0, "step": 320000}
{"episode": 1284.0, "episode_reward": 982.6, "eval_time": 28.715304136276245, "mean_episode_reward": 982.6, "best_episode_reward": 997.0, "step": 321000}
{"episode": 1288.0, "episode_reward": 956.5, "eval_time": 28.454488515853882, "mean_episode_reward": 956.5, "best_episode_reward": 998.0, "step": 322000}
{"episode": 1292.0, "episode_reward": 978.6, "eval_time": 28.841535091400146, "mean_episode_reward": 978.6, "best_episode_reward": 995.0, "step": 323000}
{"episode": 1296.0, "episode_reward": 964.4, "eval_time": 29.52200937271118, "mean_episode_reward": 964.4, "best_episode_reward": 1000.0, "step": 324000}
{"episode": 1300.0, "episode_reward": 971.1, "eval_time": 29.583090782165527, "mean_episode_reward": 971.1, "best_episode_reward": 1000.0, "step": 325000}
{"episode": 1304.0, "episode_reward": 950.0, "eval_time": 28.187893629074097, "mean_episode_reward": 950.0, "best_episode_reward": 997.0, "step": 326000}
{"episode": 1308.0, "episode_reward": 970.6, "eval_time": 29.627363443374634, "mean_episode_reward": 970.6, "best_episode_reward": 991.0, "step": 327000}
{"episode": 1312.0, "episode_reward": 962.2, "eval_time": 29.08196496963501, "mean_episode_reward": 962.2, "best_episode_reward": 994.0, "step": 328000}
{"episode": 1316.0, "episode_reward": 965.2, "eval_time": 28.20997977256775, "mean_episode_reward": 965.2, "best_episode_reward": 998.0, "step": 329000}
{"episode": 1320.0, "episode_reward": 971.5, "eval_time": 29.452451944351196, "mean_episode_reward": 971.5, "best_episode_reward": 1000.0, "step": 330000}
{"episode": 1324.0, "episode_reward": 967.8, "eval_time": 28.4285671710968, "mean_episode_reward": 967.8, "best_episode_reward": 997.0, "step": 331000}
{"episode": 1328.0, "episode_reward": 965.1, "eval_time": 29.042374849319458, "mean_episode_reward": 965.1, "best_episode_reward": 992.0, "step": 332000}
{"episode": 1332.0, "episode_reward": 942.1, "eval_time": 29.579834938049316, "mean_episode_reward": 942.1, "best_episode_reward": 995.0, "step": 333000}
{"episode": 1336.0, "episode_reward": 969.8, "eval_time": 29.57746148109436, "mean_episode_reward": 969.8, "best_episode_reward": 1000.0, "step": 334000}
{"episode": 1340.0, "episode_reward": 981.6, "eval_time": 27.93183422088623, "mean_episode_reward": 981.6, "best_episode_reward": 1000.0, "step": 335000}
{"episode": 1344.0, "episode_reward": 962.5, "eval_time": 29.75624394416809, "mean_episode_reward": 962.5, "best_episode_reward": 992.0, "step": 336000}
{"episode": 1348.0, "episode_reward": 976.0, "eval_time": 29.29787588119507, "mean_episode_reward": 976.0, "best_episode_reward": 997.0, "step": 337000}
{"episode": 1352.0, "episode_reward": 954.4, "eval_time": 29.426191568374634, "mean_episode_reward": 954.4, "best_episode_reward": 996.0, "step": 338000}
{"episode": 1356.0, "episode_reward": 961.3, "eval_time": 28.53357768058777, "mean_episode_reward": 961.3, "best_episode_reward": 993.0, "step": 339000}
{"episode": 1360.0, "episode_reward": 974.4, "eval_time": 28.41924786567688, "mean_episode_reward": 974.4, "best_episode_reward": 1000.0, "step": 340000}
{"episode": 1364.0, "episode_reward": 960.1, "eval_time": 28.287192344665527, "mean_episode_reward": 960.1, "best_episode_reward": 991.0, "step": 341000}
{"episode": 1368.0, "episode_reward": 972.2, "eval_time": 28.12266707420349, "mean_episode_reward": 972.2, "best_episode_reward": 1000.0, "step": 342000}
{"episode": 1372.0, "episode_reward": 972.2, "eval_time": 28.858854055404663, "mean_episode_reward": 972.2, "best_episode_reward": 990.0, "step": 343000}
{"episode": 1376.0, "episode_reward": 973.7, "eval_time": 28.513492822647095, "mean_episode_reward": 973.7, "best_episode_reward": 994.0, "step": 344000}
{"episode": 1380.0, "episode_reward": 982.2, "eval_time": 28.48220419883728, "mean_episode_reward": 982.2, "best_episode_reward": 1000.0, "step": 345000}
{"episode": 1384.0, "episode_reward": 969.8, "eval_time": 29.636515617370605, "mean_episode_reward": 969.8, "best_episode_reward": 990.0, "step": 346000}
{"episode": 1388.0, "episode_reward": 967.9, "eval_time": 28.208077907562256, "mean_episode_reward": 967.9, "best_episode_reward": 998.0, "step": 347000}
{"episode": 1392.0, "episode_reward": 946.2, "eval_time": 29.768306255340576, "mean_episode_reward": 946.2, "best_episode_reward": 988.0, "step": 348000}
{"episode": 1396.0, "episode_reward": 972.2, "eval_time": 29.639837503433228, "mean_episode_reward": 972.2, "best_episode_reward": 993.0, "step": 349000}
{"episode": 1400.0, "episode_reward": 971.2, "eval_time": 29.44832682609558, "mean_episode_reward": 971.2, "best_episode_reward": 998.0, "step": 350000}
{"episode": 1404.0, "episode_reward": 961.8, "eval_time": 28.458202600479126, "mean_episode_reward": 961.8, "best_episode_reward": 994.0, "step": 351000}
{"episode": 1408.0, "episode_reward": 969.8, "eval_time": 29.547598838806152, "mean_episode_reward": 969.8, "best_episode_reward": 997.0, "step": 352000}
{"episode": 1412.0, "episode_reward": 960.6, "eval_time": 28.487558603286743, "mean_episode_reward": 960.6, "best_episode_reward": 1000.0, "step": 353000}
{"episode": 1416.0, "episode_reward": 965.2, "eval_time": 29.47743272781372, "mean_episode_reward": 965.2, "best_episode_reward": 992.0, "step": 354000}
{"episode": 1420.0, "episode_reward": 862.5, "eval_time": 28.791902542114258, "mean_episode_reward": 862.5, "best_episode_reward": 996.0, "step": 355000}
{"episode": 1424.0, "episode_reward": 957.5, "eval_time": 28.500515460968018, "mean_episode_reward": 957.5, "best_episode_reward": 992.0, "step": 356000}
{"episode": 1428.0, "episode_reward": 963.5, "eval_time": 28.566448211669922, "mean_episode_reward": 963.5, "best_episode_reward": 996.0, "step": 357000}
{"episode": 1432.0, "episode_reward": 964.7, "eval_time": 28.583203554153442, "mean_episode_reward": 964.7, "best_episode_reward": 998.0, "step": 358000}
{"episode": 1436.0, "episode_reward": 967.0, "eval_time": 28.50626015663147, "mean_episode_reward": 967.0, "best_episode_reward": 1000.0, "step": 359000}
{"episode": 1440.0, "episode_reward": 958.9, "eval_time": 28.651927947998047, "mean_episode_reward": 958.9, "best_episode_reward": 995.0, "step": 360000}
{"episode": 1444.0, "episode_reward": 965.2, "eval_time": 29.746756553649902, "mean_episode_reward": 965.2, "best_episode_reward": 995.0, "step": 361000}
{"episode": 1448.0, "episode_reward": 971.2, "eval_time": 28.378283739089966, "mean_episode_reward": 971.2, "best_episode_reward": 996.0, "step": 362000}
{"episode": 1452.0, "episode_reward": 972.0, "eval_time": 28.51950240135193, "mean_episode_reward": 972.0, "best_episode_reward": 994.0, "step": 363000}
{"episode": 1456.0, "episode_reward": 969.8, "eval_time": 28.787608861923218, "mean_episode_reward": 969.8, "best_episode_reward": 994.0, "step": 364000}
{"episode": 1460.0, "episode_reward": 983.5, "eval_time": 28.54128646850586, "mean_episode_reward": 983.5, "best_episode_reward": 992.0, "step": 365000}
{"episode": 1464.0, "episode_reward": 963.1, "eval_time": 29.682878494262695, "mean_episode_reward": 963.1, "best_episode_reward": 995.0, "step": 366000}
{"episode": 1468.0, "episode_reward": 979.7, "eval_time": 28.477787733078003, "mean_episode_reward": 979.7, "best_episode_reward": 997.0, "step": 367000}
{"episode": 1472.0, "episode_reward": 964.9, "eval_time": 28.403828620910645, "mean_episode_reward": 964.9, "best_episode_reward": 990.0, "step": 368000}
{"episode": 1476.0, "episode_reward": 977.8, "eval_time": 28.521356344223022, "mean_episode_reward": 977.8, "best_episode_reward": 1000.0, "step": 369000}
{"episode": 1480.0, "episode_reward": 956.2, "eval_time": 28.237356424331665, "mean_episode_reward": 956.2, "best_episode_reward": 996.0, "step": 370000}
{"episode": 1484.0, "episode_reward": 976.1, "eval_time": 28.44812273979187, "mean_episode_reward": 976.1, "best_episode_reward": 995.0, "step": 371000}
{"episode": 1488.0, "episode_reward": 972.7, "eval_time": 28.338109493255615, "mean_episode_reward": 972.7, "best_episode_reward": 995.0, "step": 372000}
{"episode": 1492.0, "episode_reward": 975.0, "eval_time": 28.06687879562378, "mean_episode_reward": 975.0, "best_episode_reward": 1000.0, "step": 373000}
{"episode": 1496.0, "episode_reward": 973.1, "eval_time": 28.328693866729736, "mean_episode_reward": 973.1, "best_episode_reward": 998.0, "step": 374000}
{"episode": 1500.0, "episode_reward": 962.8, "eval_time": 29.57566547393799, "mean_episode_reward": 962.8, "best_episode_reward": 991.0, "step": 375000}
{"episode": 1504.0, "episode_reward": 977.9, "eval_time": 28.110857009887695, "mean_episode_reward": 977.9, "best_episode_reward": 1000.0, "step": 376000}
{"episode": 1508.0, "episode_reward": 962.8, "eval_time": 29.488078117370605, "mean_episode_reward": 962.8, "best_episode_reward": 999.0, "step": 377000}
{"episode": 1512.0, "episode_reward": 945.5, "eval_time": 28.4984073638916, "mean_episode_reward": 945.5, "best_episode_reward": 991.0, "step": 378000}
{"episode": 1516.0, "episode_reward": 973.5, "eval_time": 28.255693912506104, "mean_episode_reward": 973.5, "best_episode_reward": 992.0, "step": 379000}
{"episode": 1520.0, "episode_reward": 969.5, "eval_time": 28.401108264923096, "mean_episode_reward": 969.5, "best_episode_reward": 995.0, "step": 380000}
{"episode": 1524.0, "episode_reward": 957.2, "eval_time": 28.522123336791992, "mean_episode_reward": 957.2, "best_episode_reward": 997.0, "step": 381000}
{"episode": 1528.0, "episode_reward": 984.4, "eval_time": 29.33239769935608, "mean_episode_reward": 984.4, "best_episode_reward": 998.0, "step": 382000}
{"episode": 1532.0, "episode_reward": 966.6, "eval_time": 29.50160312652588, "mean_episode_reward": 966.6, "best_episode_reward": 998.0, "step": 383000}
{"episode": 1536.0, "episode_reward": 960.2, "eval_time": 28.578592777252197, "mean_episode_reward": 960.2, "best_episode_reward": 999.0, "step": 384000}
{"episode": 1540.0, "episode_reward": 964.4, "eval_time": 28.521309852600098, "mean_episode_reward": 964.4, "best_episode_reward": 994.0, "step": 385000}
{"episode": 1544.0, "episode_reward": 968.2, "eval_time": 28.678136587142944, "mean_episode_reward": 968.2, "best_episode_reward": 992.0, "step": 386000}
{"episode": 1548.0, "episode_reward": 977.4, "eval_time": 28.571040868759155, "mean_episode_reward": 977.4, "best_episode_reward": 996.0, "step": 387000}
{"episode": 1552.0, "episode_reward": 975.2, "eval_time": 29.071223735809326, "mean_episode_reward": 975.2, "best_episode_reward": 993.0, "step": 388000}
{"episode": 1556.0, "episode_reward": 960.4, "eval_time": 28.40967631340027, "mean_episode_reward": 960.4, "best_episode_reward": 992.0, "step": 389000}
{"episode": 1560.0, "episode_reward": 972.1, "eval_time": 29.392117023468018, "mean_episode_reward": 972.1, "best_episode_reward": 992.0, "step": 390000}
{"episode": 1564.0, "episode_reward": 973.6, "eval_time": 27.952507734298706, "mean_episode_reward": 973.6, "best_episode_reward": 1000.0, "step": 391000}
{"episode": 1568.0, "episode_reward": 964.4, "eval_time": 28.06355881690979, "mean_episode_reward": 964.4, "best_episode_reward": 989.0, "step": 392000}
{"episode": 1572.0, "episode_reward": 952.8, "eval_time": 28.01361584663391, "mean_episode_reward": 952.8, "best_episode_reward": 993.0, "step": 393000}
{"episode": 1576.0, "episode_reward": 970.1, "eval_time": 27.981739044189453, "mean_episode_reward": 970.1, "best_episode_reward": 991.0, "step": 394000}
{"episode": 1580.0, "episode_reward": 964.8, "eval_time": 28.05777883529663, "mean_episode_reward": 964.8, "best_episode_reward": 991.0, "step": 395000}
{"episode": 1584.0, "episode_reward": 963.6, "eval_time": 28.02942705154419, "mean_episode_reward": 963.6, "best_episode_reward": 990.0, "step": 396000}
{"episode": 1588.0, "episode_reward": 958.6, "eval_time": 27.20982265472412, "mean_episode_reward": 958.6, "best_episode_reward": 994.0, "step": 397000}
{"episode": 1592.0, "episode_reward": 975.9, "eval_time": 27.43365454673767, "mean_episode_reward": 975.9, "best_episode_reward": 994.0, "step": 398000}
{"episode": 1596.0, "episode_reward": 980.2, "eval_time": 27.36635971069336, "mean_episode_reward": 980.2, "best_episode_reward": 994.0, "step": 399000}
{"episode": 1600.0, "episode_reward": 972.8, "eval_time": 27.24642276763916, "mean_episode_reward": 972.8, "best_episode_reward": 995.0, "step": 400000}
{"episode": 1604.0, "episode_reward": 965.3, "eval_time": 27.39277935028076, "mean_episode_reward": 965.3, "best_episode_reward": 996.0, "step": 401000}
{"episode": 1608.0, "episode_reward": 970.1, "eval_time": 27.263981580734253, "mean_episode_reward": 970.1, "best_episode_reward": 999.0, "step": 402000}
{"episode": 1612.0, "episode_reward": 977.0, "eval_time": 27.44535779953003, "mean_episode_reward": 977.0, "best_episode_reward": 996.0, "step": 403000}
{"episode": 1616.0, "episode_reward": 965.9, "eval_time": 27.44127368927002, "mean_episode_reward": 965.9, "best_episode_reward": 1000.0, "step": 404000}
{"episode": 1620.0, "episode_reward": 969.5, "eval_time": 27.428768634796143, "mean_episode_reward": 969.5, "best_episode_reward": 995.0, "step": 405000}
{"episode": 1624.0, "episode_reward": 977.6, "eval_time": 26.99066925048828, "mean_episode_reward": 977.6, "best_episode_reward": 998.0, "step": 406000}
{"episode": 1628.0, "episode_reward": 975.2, "eval_time": 27.452974319458008, "mean_episode_reward": 975.2, "best_episode_reward": 991.0, "step": 407000}
{"episode": 1632.0, "episode_reward": 941.7, "eval_time": 27.276899337768555, "mean_episode_reward": 941.7, "best_episode_reward": 997.0, "step": 408000}
{"episode": 1636.0, "episode_reward": 982.4, "eval_time": 27.32562780380249, "mean_episode_reward": 982.4, "best_episode_reward": 998.0, "step": 409000}
{"episode": 1640.0, "episode_reward": 963.6, "eval_time": 27.447251558303833, "mean_episode_reward": 963.6, "best_episode_reward": 993.0, "step": 410000}
{"episode": 1644.0, "episode_reward": 971.2, "eval_time": 27.424851179122925, "mean_episode_reward": 971.2, "best_episode_reward": 998.0, "step": 411000}
{"episode": 1648.0, "episode_reward": 966.4, "eval_time": 28.49701499938965, "mean_episode_reward": 966.4, "best_episode_reward": 992.0, "step": 412000}
{"episode": 1652.0, "episode_reward": 956.2, "eval_time": 27.94879937171936, "mean_episode_reward": 956.2, "best_episode_reward": 996.0, "step": 413000}
{"episode": 1656.0, "episode_reward": 956.6, "eval_time": 28.43014907836914, "mean_episode_reward": 956.6, "best_episode_reward": 991.0, "step": 414000}
{"episode": 1660.0, "episode_reward": 983.3, "eval_time": 27.317818880081177, "mean_episode_reward": 983.3, "best_episode_reward": 996.0, "step": 415000}
{"episode": 1664.0, "episode_reward": 960.5, "eval_time": 27.547412872314453, "mean_episode_reward": 960.5, "best_episode_reward": 991.0, "step": 416000}
{"episode": 1668.0, "episode_reward": 974.3, "eval_time": 27.24278211593628, "mean_episode_reward": 974.3, "best_episode_reward": 1000.0, "step": 417000}
{"episode": 1672.0, "episode_reward": 976.8, "eval_time": 27.344430923461914, "mean_episode_reward": 976.8, "best_episode_reward": 994.0, "step": 418000}
{"episode": 1676.0, "episode_reward": 963.5, "eval_time": 27.43609356880188, "mean_episode_reward": 963.5, "best_episode_reward": 992.0, "step": 419000}
{"episode": 1680.0, "episode_reward": 963.7, "eval_time": 27.953424215316772, "mean_episode_reward": 963.7, "best_episode_reward": 994.0, "step": 420000}
{"episode": 1684.0, "episode_reward": 965.7, "eval_time": 27.45140266418457, "mean_episode_reward": 965.7, "best_episode_reward": 991.0, "step": 421000}
{"episode": 1688.0, "episode_reward": 970.2, "eval_time": 27.05205202102661, "mean_episode_reward": 970.2, "best_episode_reward": 1000.0, "step": 422000}
{"episode": 1692.0, "episode_reward": 965.4, "eval_time": 28.488808393478394, "mean_episode_reward": 965.4, "best_episode_reward": 990.0, "step": 423000}
{"episode": 1696.0, "episode_reward": 952.7, "eval_time": 27.614686012268066, "mean_episode_reward": 952.7, "best_episode_reward": 991.0, "step": 424000}
{"episode": 1700.0, "episode_reward": 956.4, "eval_time": 27.357337713241577, "mean_episode_reward": 956.4, "best_episode_reward": 996.0, "step": 425000}
{"episode": 1704.0, "episode_reward": 967.3, "eval_time": 27.15308904647827, "mean_episode_reward": 967.3, "best_episode_reward": 993.0, "step": 426000}
{"episode": 1708.0, "episode_reward": 922.6, "eval_time": 27.087642669677734, "mean_episode_reward": 922.6, "best_episode_reward": 993.0, "step": 427000}
{"episode": 1712.0, "episode_reward": 970.4, "eval_time": 27.30545663833618, "mean_episode_reward": 970.4, "best_episode_reward": 1000.0, "step": 428000}
{"episode": 1716.0, "episode_reward": 959.4, "eval_time": 27.281723737716675, "mean_episode_reward": 959.4, "best_episode_reward": 991.0, "step": 429000}
{"episode": 1720.0, "episode_reward": 971.5, "eval_time": 27.33772921562195, "mean_episode_reward": 971.5, "best_episode_reward": 995.0, "step": 430000}
{"episode": 1724.0, "episode_reward": 982.5, "eval_time": 27.305971384048462, "mean_episode_reward": 982.5, "best_episode_reward": 1000.0, "step": 431000}
{"episode": 1728.0, "episode_reward": 973.9, "eval_time": 27.330480098724365, "mean_episode_reward": 973.9, "best_episode_reward": 995.0, "step": 432000}
{"episode": 1732.0, "episode_reward": 965.2, "eval_time": 27.371134519577026, "mean_episode_reward": 965.2, "best_episode_reward": 991.0, "step": 433000}
{"episode": 1736.0, "episode_reward": 956.7, "eval_time": 28.115418195724487, "mean_episode_reward": 956.7, "best_episode_reward": 998.0, "step": 434000}
{"episode": 1740.0, "episode_reward": 977.2, "eval_time": 28.538343906402588, "mean_episode_reward": 977.2, "best_episode_reward": 996.0, "step": 435000}
{"episode": 1744.0, "episode_reward": 974.2, "eval_time": 27.269774675369263, "mean_episode_reward": 974.2, "best_episode_reward": 996.0, "step": 436000}
{"episode": 1748.0, "episode_reward": 979.9, "eval_time": 28.231114387512207, "mean_episode_reward": 979.9, "best_episode_reward": 996.0, "step": 437000}
{"episode": 1752.0, "episode_reward": 970.9, "eval_time": 28.477535009384155, "mean_episode_reward": 970.9, "best_episode_reward": 996.0, "step": 438000}
{"episode": 1756.0, "episode_reward": 965.1, "eval_time": 27.27560567855835, "mean_episode_reward": 965.1, "best_episode_reward": 994.0, "step": 439000}
{"episode": 1760.0, "episode_reward": 954.7, "eval_time": 27.834266901016235, "mean_episode_reward": 954.7, "best_episode_reward": 992.0, "step": 440000}
{"episode": 1764.0, "episode_reward": 974.9, "eval_time": 28.380777597427368, "mean_episode_reward": 974.9, "best_episode_reward": 1000.0, "step": 441000}
{"episode": 1768.0, "episode_reward": 963.7, "eval_time": 27.005097150802612, "mean_episode_reward": 963.7, "best_episode_reward": 997.0, "step": 442000}
{"episode": 1772.0, "episode_reward": 961.6, "eval_time": 27.449991703033447, "mean_episode_reward": 961.6, "best_episode_reward": 992.0, "step": 443000}
{"episode": 1776.0, "episode_reward": 973.4, "eval_time": 27.307806968688965, "mean_episode_reward": 973.4, "best_episode_reward": 992.0, "step": 444000}
{"episode": 1780.0, "episode_reward": 966.0, "eval_time": 28.41197443008423, "mean_episode_reward": 966.0, "best_episode_reward": 992.0, "step": 445000}
{"episode": 1784.0, "episode_reward": 971.2, "eval_time": 27.35783052444458, "mean_episode_reward": 971.2, "best_episode_reward": 994.0, "step": 446000}
{"episode": 1788.0, "episode_reward": 965.9, "eval_time": 28.426379442214966, "mean_episode_reward": 965.9, "best_episode_reward": 1000.0, "step": 447000}
{"episode": 1792.0, "episode_reward": 974.5, "eval_time": 28.565502405166626, "mean_episode_reward": 974.5, "best_episode_reward": 996.0, "step": 448000}
{"episode": 1796.0, "episode_reward": 986.3, "eval_time": 27.907952308654785, "mean_episode_reward": 986.3, "best_episode_reward": 999.0, "step": 449000}
{"episode": 1800.0, "episode_reward": 971.5, "eval_time": 27.338529586791992, "mean_episode_reward": 971.5, "best_episode_reward": 992.0, "step": 450000}
{"episode": 1804.0, "episode_reward": 969.2, "eval_time": 27.136133909225464, "mean_episode_reward": 969.2, "best_episode_reward": 1000.0, "step": 451000}
{"episode": 1808.0, "episode_reward": 939.3, "eval_time": 27.43816900253296, "mean_episode_reward": 939.3, "best_episode_reward": 996.0, "step": 452000}
{"episode": 1812.0, "episode_reward": 974.3, "eval_time": 27.308674097061157, "mean_episode_reward": 974.3, "best_episode_reward": 998.0, "step": 453000}
{"episode": 1816.0, "episode_reward": 961.3, "eval_time": 28.442912340164185, "mean_episode_reward": 961.3, "best_episode_reward": 1000.0, "step": 454000}
{"episode": 1820.0, "episode_reward": 971.5, "eval_time": 28.64671778678894, "mean_episode_reward": 971.5, "best_episode_reward": 991.0, "step": 455000}
{"episode": 1824.0, "episode_reward": 945.4, "eval_time": 27.115049123764038, "mean_episode_reward": 945.4, "best_episode_reward": 991.0, "step": 456000}
{"episode": 1828.0, "episode_reward": 977.4, "eval_time": 27.449771404266357, "mean_episode_reward": 977.4, "best_episode_reward": 996.0, "step": 457000}
{"episode": 1832.0, "episode_reward": 966.2, "eval_time": 28.634721279144287, "mean_episode_reward": 966.2, "best_episode_reward": 997.0, "step": 458000}
{"episode": 1836.0, "episode_reward": 967.9, "eval_time": 28.41231417655945, "mean_episode_reward": 967.9, "best_episode_reward": 1000.0, "step": 459000}
{"episode": 1840.0, "episode_reward": 981.7, "eval_time": 27.46936559677124, "mean_episode_reward": 981.7, "best_episode_reward": 997.0, "step": 460000}
{"episode": 1844.0, "episode_reward": 969.3, "eval_time": 27.3056538105011, "mean_episode_reward": 969.3, "best_episode_reward": 994.0, "step": 461000}
{"episode": 1848.0, "episode_reward": 970.7, "eval_time": 27.318334579467773, "mean_episode_reward": 970.7, "best_episode_reward": 999.0, "step": 462000}
{"episode": 1852.0, "episode_reward": 970.1, "eval_time": 27.449931144714355, "mean_episode_reward": 970.1, "best_episode_reward": 999.0, "step": 463000}
{"episode": 1856.0, "episode_reward": 970.6, "eval_time": 28.185810089111328, "mean_episode_reward": 970.6, "best_episode_reward": 996.0, "step": 464000}
{"episode": 1860.0, "episode_reward": 968.3, "eval_time": 27.286041021347046, "mean_episode_reward": 968.3, "best_episode_reward": 991.0, "step": 465000}
{"episode": 1864.0, "episode_reward": 966.3, "eval_time": 27.43284249305725, "mean_episode_reward": 966.3, "best_episode_reward": 994.0, "step": 466000}
{"episode": 1868.0, "episode_reward": 972.8, "eval_time": 27.348416328430176, "mean_episode_reward": 972.8, "best_episode_reward": 996.0, "step": 467000}
{"episode": 1872.0, "episode_reward": 971.1, "eval_time": 27.227606058120728, "mean_episode_reward": 971.1, "best_episode_reward": 991.0, "step": 468000}
{"episode": 1876.0, "episode_reward": 963.4, "eval_time": 27.40130615234375, "mean_episode_reward": 963.4, "best_episode_reward": 991.0, "step": 469000}
{"episode": 1880.0, "episode_reward": 959.3, "eval_time": 27.205052375793457, "mean_episode_reward": 959.3, "best_episode_reward": 992.0, "step": 470000}
{"episode": 1884.0, "episode_reward": 978.7, "eval_time": 27.367132902145386, "mean_episode_reward": 978.7, "best_episode_reward": 991.0, "step": 471000}
{"episode": 1888.0, "episode_reward": 974.1, "eval_time": 28.70863151550293, "mean_episode_reward": 974.1, "best_episode_reward": 993.0, "step": 472000}
{"episode": 1892.0, "episode_reward": 969.9, "eval_time": 27.756211280822754, "mean_episode_reward": 969.9, "best_episode_reward": 999.0, "step": 473000}
{"episode": 1896.0, "episode_reward": 967.3, "eval_time": 27.2984619140625, "mean_episode_reward": 967.3, "best_episode_reward": 999.0, "step": 474000}
{"episode": 1900.0, "episode_reward": 979.2, "eval_time": 27.4815092086792, "mean_episode_reward": 979.2, "best_episode_reward": 997.0, "step": 475000}
{"episode": 1904.0, "episode_reward": 971.5, "eval_time": 28.42603874206543, "mean_episode_reward": 971.5, "best_episode_reward": 999.0, "step": 476000}
{"episode": 1908.0, "episode_reward": 947.0, "eval_time": 28.259145259857178, "mean_episode_reward": 947.0, "best_episode_reward": 991.0, "step": 477000}
{"episode": 1912.0, "episode_reward": 982.6, "eval_time": 27.269163131713867, "mean_episode_reward": 982.6, "best_episode_reward": 999.0, "step": 478000}
{"episode": 1916.0, "episode_reward": 978.9, "eval_time": 27.319597005844116, "mean_episode_reward": 978.9, "best_episode_reward": 998.0, "step": 479000}
{"episode": 1920.0, "episode_reward": 972.6, "eval_time": 27.34242868423462, "mean_episode_reward": 972.6, "best_episode_reward": 1000.0, "step": 480000}
{"episode": 1924.0, "episode_reward": 985.9, "eval_time": 28.782565355300903, "mean_episode_reward": 985.9, "best_episode_reward": 998.0, "step": 481000}
{"episode": 1928.0, "episode_reward": 975.1, "eval_time": 27.28914451599121, "mean_episode_reward": 975.1, "best_episode_reward": 994.0, "step": 482000}
{"episode": 1932.0, "episode_reward": 981.1, "eval_time": 27.41735601425171, "mean_episode_reward": 981.1, "best_episode_reward": 1000.0, "step": 483000}
{"episode": 1936.0, "episode_reward": 931.4, "eval_time": 28.621309280395508, "mean_episode_reward": 931.4, "best_episode_reward": 991.0, "step": 484000}
{"episode": 1940.0, "episode_reward": 968.6, "eval_time": 28.25423765182495, "mean_episode_reward": 968.6, "best_episode_reward": 992.0, "step": 485000}
{"episode": 1944.0, "episode_reward": 971.2, "eval_time": 28.024608612060547, "mean_episode_reward": 971.2, "best_episode_reward": 992.0, "step": 486000}
{"episode": 1948.0, "episode_reward": 971.0, "eval_time": 27.500136137008667, "mean_episode_reward": 971.0, "best_episode_reward": 991.0, "step": 487000}
{"episode": 1952.0, "episode_reward": 971.2, "eval_time": 27.393482208251953, "mean_episode_reward": 971.2, "best_episode_reward": 997.0, "step": 488000}
{"episode": 1956.0, "episode_reward": 968.7, "eval_time": 28.600212812423706, "mean_episode_reward": 968.7, "best_episode_reward": 994.0, "step": 489000}
{"episode": 1960.0, "episode_reward": 972.0, "eval_time": 27.509681701660156, "mean_episode_reward": 972.0, "best_episode_reward": 995.0, "step": 490000}
{"episode": 1964.0, "episode_reward": 959.9, "eval_time": 27.210707426071167, "mean_episode_reward": 959.9, "best_episode_reward": 997.0, "step": 491000}
{"episode": 1968.0, "episode_reward": 958.3, "eval_time": 27.354151964187622, "mean_episode_reward": 958.3, "best_episode_reward": 991.0, "step": 492000}
{"episode": 1972.0, "episode_reward": 984.1, "eval_time": 28.736696481704712, "mean_episode_reward": 984.1, "best_episode_reward": 999.0, "step": 493000}
{"episode": 1976.0, "episode_reward": 974.0, "eval_time": 27.239044904708862, "mean_episode_reward": 974.0, "best_episode_reward": 997.0, "step": 494000}
{"episode": 1980.0, "episode_reward": 979.5, "eval_time": 27.510496854782104, "mean_episode_reward": 979.5, "best_episode_reward": 992.0, "step": 495000}
{"episode": 1984.0, "episode_reward": 969.8, "eval_time": 27.422000408172607, "mean_episode_reward": 969.8, "best_episode_reward": 992.0, "step": 496000}
{"episode": 1988.0, "episode_reward": 976.6, "eval_time": 27.444610595703125, "mean_episode_reward": 976.6, "best_episode_reward": 1000.0, "step": 497000}
{"episode": 1992.0, "episode_reward": 961.6, "eval_time": 27.450575590133667, "mean_episode_reward": 961.6, "best_episode_reward": 997.0, "step": 498000}
{"episode": 1996.0, "episode_reward": 957.5, "eval_time": 27.249154567718506, "mean_episode_reward": 957.5, "best_episode_reward": 991.0, "step": 499000}
