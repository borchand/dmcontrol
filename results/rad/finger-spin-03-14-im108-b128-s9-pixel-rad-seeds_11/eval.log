{"episode": 0.0, "episode_reward": 0.0, "eval_time": 296.1365735530853, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 0}
{"episode": 2.0, "episode_reward": 0.0, "eval_time": 315.2759761810303, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 1000}
{"episode": 4.0, "episode_reward": 0.0, "eval_time": 291.3416848182678, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 2000}
{"episode": 6.0, "episode_reward": 0.0, "eval_time": 294.32030510902405, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 3000}
{"episode": 8.0, "episode_reward": 0.0, "eval_time": 305.93025302886963, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 4000}
{"episode": 10.0, "episode_reward": 0.0, "eval_time": 329.76913952827454, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 5000}
{"episode": 12.0, "episode_reward": 0.0, "eval_time": 320.2554876804352, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 6000}
{"episode": 14.0, "episode_reward": 0.5, "eval_time": 301.76694893836975, "mean_episode_reward": 0.5, "best_episode_reward": 5.0, "step": 7000}
{"episode": 16.0, "episode_reward": 1.0, "eval_time": 329.9517240524292, "mean_episode_reward": 1.0, "best_episode_reward": 10.0, "step": 8000}
{"episode": 18.0, "episode_reward": 0.8, "eval_time": 342.90761518478394, "mean_episode_reward": 0.8, "best_episode_reward": 3.0, "step": 9000}
{"episode": 20.0, "episode_reward": 3.4, "eval_time": 339.424772977829, "mean_episode_reward": 3.4, "best_episode_reward": 19.0, "step": 10000}
{"episode": 22.0, "episode_reward": 140.5, "eval_time": 356.4518213272095, "mean_episode_reward": 140.5, "best_episode_reward": 219.0, "step": 11000}
{"episode": 24.0, "episode_reward": 158.8, "eval_time": 356.56818866729736, "mean_episode_reward": 158.8, "best_episode_reward": 187.0, "step": 12000}
{"episode": 26.0, "episode_reward": 239.5, "eval_time": 341.45923352241516, "mean_episode_reward": 239.5, "best_episode_reward": 301.0, "step": 13000}
{"episode": 28.0, "episode_reward": 331.0, "eval_time": 312.49744272232056, "mean_episode_reward": 331.0, "best_episode_reward": 373.0, "step": 14000}
{"episode": 30.0, "episode_reward": 376.5, "eval_time": 339.5178875923157, "mean_episode_reward": 376.5, "best_episode_reward": 450.0, "step": 15000}
{"episode": 32.0, "episode_reward": 396.5, "eval_time": 364.43154740333557, "mean_episode_reward": 396.5, "best_episode_reward": 509.0, "step": 16000}
{"episode": 34.0, "episode_reward": 488.3, "eval_time": 351.19605922698975, "mean_episode_reward": 488.3, "best_episode_reward": 565.0, "step": 17000}
{"episode": 36.0, "episode_reward": 511.2, "eval_time": 352.7617471218109, "mean_episode_reward": 511.2, "best_episode_reward": 546.0, "step": 18000}
{"episode": 38.0, "episode_reward": 535.7, "eval_time": 359.4455690383911, "mean_episode_reward": 535.7, "best_episode_reward": 563.0, "step": 19000}
{"episode": 40.0, "episode_reward": 564.1, "eval_time": 349.9593939781189, "mean_episode_reward": 564.1, "best_episode_reward": 600.0, "step": 20000}
{"episode": 42.0, "episode_reward": 546.2, "eval_time": 397.5535624027252, "mean_episode_reward": 546.2, "best_episode_reward": 569.0, "step": 21000}
{"episode": 44.0, "episode_reward": 555.6, "eval_time": 352.5074281692505, "mean_episode_reward": 555.6, "best_episode_reward": 593.0, "step": 22000}
{"episode": 46.0, "episode_reward": 578.6, "eval_time": 338.1063859462738, "mean_episode_reward": 578.6, "best_episode_reward": 593.0, "step": 23000}
{"episode": 48.0, "episode_reward": 622.7, "eval_time": 366.9977033138275, "mean_episode_reward": 622.7, "best_episode_reward": 699.0, "step": 24000}
{"episode": 50.0, "episode_reward": 611.2, "eval_time": 322.5614323616028, "mean_episode_reward": 611.2, "best_episode_reward": 672.0, "step": 25000}
{"episode": 52.0, "episode_reward": 660.2, "eval_time": 360.2664999961853, "mean_episode_reward": 660.2, "best_episode_reward": 729.0, "step": 26000}
{"episode": 54.0, "episode_reward": 683.8, "eval_time": 369.33566188812256, "mean_episode_reward": 683.8, "best_episode_reward": 735.0, "step": 27000}
{"episode": 56.0, "episode_reward": 687.0, "eval_time": 357.3570041656494, "mean_episode_reward": 687.0, "best_episode_reward": 732.0, "step": 28000}
{"episode": 58.0, "episode_reward": 702.7, "eval_time": 356.7556629180908, "mean_episode_reward": 702.7, "best_episode_reward": 729.0, "step": 29000}
{"episode": 60.0, "episode_reward": 709.3, "eval_time": 356.784227848053, "mean_episode_reward": 709.3, "best_episode_reward": 753.0, "step": 30000}
{"episode": 62.0, "episode_reward": 685.4, "eval_time": 367.93990898132324, "mean_episode_reward": 685.4, "best_episode_reward": 710.0, "step": 31000}
{"episode": 64.0, "episode_reward": 714.6, "eval_time": 355.3796067237854, "mean_episode_reward": 714.6, "best_episode_reward": 744.0, "step": 32000}
{"episode": 66.0, "episode_reward": 730.7, "eval_time": 362.73085618019104, "mean_episode_reward": 730.7, "best_episode_reward": 749.0, "step": 33000}
{"episode": 68.0, "episode_reward": 753.4, "eval_time": 358.7466814517975, "mean_episode_reward": 753.4, "best_episode_reward": 769.0, "step": 34000}
{"episode": 70.0, "episode_reward": 732.6, "eval_time": 357.71946716308594, "mean_episode_reward": 732.6, "best_episode_reward": 750.0, "step": 35000}
{"episode": 72.0, "episode_reward": 741.5, "eval_time": 405.29232239723206, "mean_episode_reward": 741.5, "best_episode_reward": 766.0, "step": 36000}
{"episode": 74.0, "episode_reward": 779.8, "eval_time": 409.7393579483032, "mean_episode_reward": 779.8, "best_episode_reward": 798.0, "step": 37000}
{"episode": 76.0, "episode_reward": 740.4, "eval_time": 381.81316089630127, "mean_episode_reward": 740.4, "best_episode_reward": 764.0, "step": 38000}
{"episode": 78.0, "episode_reward": 770.0, "eval_time": 396.1588706970215, "mean_episode_reward": 770.0, "best_episode_reward": 784.0, "step": 39000}
{"episode": 80.0, "episode_reward": 753.3, "eval_time": 388.86858916282654, "mean_episode_reward": 753.3, "best_episode_reward": 769.0, "step": 40000}
{"episode": 82.0, "episode_reward": 778.9, "eval_time": 399.8766231536865, "mean_episode_reward": 778.9, "best_episode_reward": 804.0, "step": 41000}
{"episode": 84.0, "episode_reward": 770.8, "eval_time": 400.15913820266724, "mean_episode_reward": 770.8, "best_episode_reward": 781.0, "step": 42000}
{"episode": 86.0, "episode_reward": 679.1, "eval_time": 390.1711587905884, "mean_episode_reward": 679.1, "best_episode_reward": 789.0, "step": 43000}
{"episode": 88.0, "episode_reward": 788.2, "eval_time": 386.63528633117676, "mean_episode_reward": 788.2, "best_episode_reward": 807.0, "step": 44000}
{"episode": 90.0, "episode_reward": 783.1, "eval_time": 408.4119277000427, "mean_episode_reward": 783.1, "best_episode_reward": 794.0, "step": 45000}
{"episode": 92.0, "episode_reward": 764.6, "eval_time": 395.51365971565247, "mean_episode_reward": 764.6, "best_episode_reward": 795.0, "step": 46000}
{"episode": 94.0, "episode_reward": 789.1, "eval_time": 388.48964500427246, "mean_episode_reward": 789.1, "best_episode_reward": 800.0, "step": 47000}
{"episode": 96.0, "episode_reward": 807.8, "eval_time": 366.9648416042328, "mean_episode_reward": 807.8, "best_episode_reward": 826.0, "step": 48000}
{"episode": 98.0, "episode_reward": 805.3, "eval_time": 360.919278383255, "mean_episode_reward": 805.3, "best_episode_reward": 824.0, "step": 49000}
{"episode": 100.0, "episode_reward": 805.4, "eval_time": 365.520676612854, "mean_episode_reward": 805.4, "best_episode_reward": 826.0, "step": 50000}
{"episode": 102.0, "episode_reward": 819.4, "eval_time": 331.81559681892395, "mean_episode_reward": 819.4, "best_episode_reward": 850.0, "step": 51000}
{"episode": 104.0, "episode_reward": 808.1, "eval_time": 341.10382056236267, "mean_episode_reward": 808.1, "best_episode_reward": 836.0, "step": 52000}
{"episode": 106.0, "episode_reward": 821.1, "eval_time": 350.16344833374023, "mean_episode_reward": 821.1, "best_episode_reward": 838.0, "step": 53000}
{"episode": 108.0, "episode_reward": 819.2, "eval_time": 358.2829442024231, "mean_episode_reward": 819.2, "best_episode_reward": 848.0, "step": 54000}
{"episode": 110.0, "episode_reward": 815.3, "eval_time": 347.4273672103882, "mean_episode_reward": 815.3, "best_episode_reward": 845.0, "step": 55000}
{"episode": 112.0, "episode_reward": 823.2, "eval_time": 345.39698600769043, "mean_episode_reward": 823.2, "best_episode_reward": 849.0, "step": 56000}
{"episode": 114.0, "episode_reward": 826.2, "eval_time": 344.5956778526306, "mean_episode_reward": 826.2, "best_episode_reward": 845.0, "step": 57000}
{"episode": 116.0, "episode_reward": 827.4, "eval_time": 343.86779022216797, "mean_episode_reward": 827.4, "best_episode_reward": 844.0, "step": 58000}
{"episode": 118.0, "episode_reward": 812.4, "eval_time": 348.96296405792236, "mean_episode_reward": 812.4, "best_episode_reward": 830.0, "step": 59000}
{"episode": 120.0, "episode_reward": 821.2, "eval_time": 348.07944321632385, "mean_episode_reward": 821.2, "best_episode_reward": 837.0, "step": 60000}
{"episode": 122.0, "episode_reward": 820.2, "eval_time": 328.2254033088684, "mean_episode_reward": 820.2, "best_episode_reward": 840.0, "step": 61000}
{"episode": 124.0, "episode_reward": 849.3, "eval_time": 342.027574300766, "mean_episode_reward": 849.3, "best_episode_reward": 861.0, "step": 62000}
{"episode": 126.0, "episode_reward": 842.4, "eval_time": 343.959020614624, "mean_episode_reward": 842.4, "best_episode_reward": 860.0, "step": 63000}
{"episode": 128.0, "episode_reward": 844.8, "eval_time": 343.4871623516083, "mean_episode_reward": 844.8, "best_episode_reward": 862.0, "step": 64000}
{"episode": 130.0, "episode_reward": 839.7, "eval_time": 347.9956040382385, "mean_episode_reward": 839.7, "best_episode_reward": 855.0, "step": 65000}
{"episode": 132.0, "episode_reward": 833.8, "eval_time": 350.3181209564209, "mean_episode_reward": 833.8, "best_episode_reward": 851.0, "step": 66000}
{"episode": 134.0, "episode_reward": 845.3, "eval_time": 354.4176867008209, "mean_episode_reward": 845.3, "best_episode_reward": 857.0, "step": 67000}
{"episode": 136.0, "episode_reward": 826.8, "eval_time": 358.86157155036926, "mean_episode_reward": 826.8, "best_episode_reward": 840.0, "step": 68000}
{"episode": 138.0, "episode_reward": 831.8, "eval_time": 353.48129177093506, "mean_episode_reward": 831.8, "best_episode_reward": 852.0, "step": 69000}
{"episode": 140.0, "episode_reward": 845.9, "eval_time": 359.2064001560211, "mean_episode_reward": 845.9, "best_episode_reward": 860.0, "step": 70000}
{"episode": 142.0, "episode_reward": 836.6, "eval_time": 352.33590364456177, "mean_episode_reward": 836.6, "best_episode_reward": 859.0, "step": 71000}
{"episode": 144.0, "episode_reward": 851.5, "eval_time": 353.159467458725, "mean_episode_reward": 851.5, "best_episode_reward": 864.0, "step": 72000}
{"episode": 146.0, "episode_reward": 839.8, "eval_time": 341.8400366306305, "mean_episode_reward": 839.8, "best_episode_reward": 856.0, "step": 73000}
{"episode": 148.0, "episode_reward": 838.5, "eval_time": 342.9640598297119, "mean_episode_reward": 838.5, "best_episode_reward": 848.0, "step": 74000}
{"episode": 150.0, "episode_reward": 824.1, "eval_time": 362.7762236595154, "mean_episode_reward": 824.1, "best_episode_reward": 848.0, "step": 75000}
{"episode": 152.0, "episode_reward": 844.8, "eval_time": 359.5075533390045, "mean_episode_reward": 844.8, "best_episode_reward": 852.0, "step": 76000}
{"episode": 154.0, "episode_reward": 842.9, "eval_time": 385.27757477760315, "mean_episode_reward": 842.9, "best_episode_reward": 863.0, "step": 77000}
{"episode": 156.0, "episode_reward": 850.3, "eval_time": 349.65122747421265, "mean_episode_reward": 850.3, "best_episode_reward": 863.0, "step": 78000}
{"episode": 158.0, "episode_reward": 841.9, "eval_time": 354.3355402946472, "mean_episode_reward": 841.9, "best_episode_reward": 863.0, "step": 79000}
{"episode": 160.0, "episode_reward": 850.3, "eval_time": 342.89963960647583, "mean_episode_reward": 850.3, "best_episode_reward": 860.0, "step": 80000}
{"episode": 162.0, "episode_reward": 853.5, "eval_time": 353.902996301651, "mean_episode_reward": 853.5, "best_episode_reward": 867.0, "step": 81000}
{"episode": 164.0, "episode_reward": 846.4, "eval_time": 352.78798604011536, "mean_episode_reward": 846.4, "best_episode_reward": 877.0, "step": 82000}
{"episode": 166.0, "episode_reward": 840.7, "eval_time": 351.5065121650696, "mean_episode_reward": 840.7, "best_episode_reward": 865.0, "step": 83000}
{"episode": 168.0, "episode_reward": 856.7, "eval_time": 356.5446879863739, "mean_episode_reward": 856.7, "best_episode_reward": 866.0, "step": 84000}
{"episode": 170.0, "episode_reward": 851.5, "eval_time": 344.45167326927185, "mean_episode_reward": 851.5, "best_episode_reward": 870.0, "step": 85000}
{"episode": 172.0, "episode_reward": 851.9, "eval_time": 360.25158643722534, "mean_episode_reward": 851.9, "best_episode_reward": 865.0, "step": 86000}
{"episode": 174.0, "episode_reward": 869.6, "eval_time": 341.1016170978546, "mean_episode_reward": 869.6, "best_episode_reward": 877.0, "step": 87000}
{"episode": 176.0, "episode_reward": 824.5, "eval_time": 352.7193696498871, "mean_episode_reward": 824.5, "best_episode_reward": 832.0, "step": 88000}
{"episode": 178.0, "episode_reward": 862.0, "eval_time": 343.69985365867615, "mean_episode_reward": 862.0, "best_episode_reward": 871.0, "step": 89000}
{"episode": 180.0, "episode_reward": 846.9, "eval_time": 347.1703987121582, "mean_episode_reward": 846.9, "best_episode_reward": 872.0, "step": 90000}
{"episode": 182.0, "episode_reward": 843.0, "eval_time": 354.33533000946045, "mean_episode_reward": 843.0, "best_episode_reward": 863.0, "step": 91000}
{"episode": 184.0, "episode_reward": 841.4, "eval_time": 347.422744512558, "mean_episode_reward": 841.4, "best_episode_reward": 867.0, "step": 92000}
{"episode": 186.0, "episode_reward": 851.1, "eval_time": 361.00759077072144, "mean_episode_reward": 851.1, "best_episode_reward": 861.0, "step": 93000}
{"episode": 188.0, "episode_reward": 845.7, "eval_time": 349.67692828178406, "mean_episode_reward": 845.7, "best_episode_reward": 853.0, "step": 94000}
{"episode": 190.0, "episode_reward": 856.2, "eval_time": 357.2216558456421, "mean_episode_reward": 856.2, "best_episode_reward": 867.0, "step": 95000}
{"episode": 192.0, "episode_reward": 849.4, "eval_time": 353.3556213378906, "mean_episode_reward": 849.4, "best_episode_reward": 871.0, "step": 96000}
{"episode": 194.0, "episode_reward": 860.8, "eval_time": 350.73578333854675, "mean_episode_reward": 860.8, "best_episode_reward": 880.0, "step": 97000}
{"episode": 196.0, "episode_reward": 837.0, "eval_time": 354.8435490131378, "mean_episode_reward": 837.0, "best_episode_reward": 843.0, "step": 98000}
{"episode": 198.0, "episode_reward": 855.4, "eval_time": 350.0107831954956, "mean_episode_reward": 855.4, "best_episode_reward": 872.0, "step": 99000}
{"episode": 200.0, "episode_reward": 859.2, "eval_time": 355.73155665397644, "mean_episode_reward": 859.2, "best_episode_reward": 869.0, "step": 100000}
{"episode": 202.0, "episode_reward": 855.2, "eval_time": 348.9170181751251, "mean_episode_reward": 855.2, "best_episode_reward": 863.0, "step": 101000}
{"episode": 204.0, "episode_reward": 871.2, "eval_time": 337.68664813041687, "mean_episode_reward": 871.2, "best_episode_reward": 885.0, "step": 102000}
{"episode": 206.0, "episode_reward": 892.9, "eval_time": 348.3398554325104, "mean_episode_reward": 892.9, "best_episode_reward": 934.0, "step": 103000}
{"episode": 208.0, "episode_reward": 851.8, "eval_time": 358.953581571579, "mean_episode_reward": 851.8, "best_episode_reward": 867.0, "step": 104000}
{"episode": 210.0, "episode_reward": 861.8, "eval_time": 349.63537979125977, "mean_episode_reward": 861.8, "best_episode_reward": 881.0, "step": 105000}
{"episode": 212.0, "episode_reward": 861.5, "eval_time": 337.7884783744812, "mean_episode_reward": 861.5, "best_episode_reward": 880.0, "step": 106000}
{"episode": 214.0, "episode_reward": 841.2, "eval_time": 341.20192289352417, "mean_episode_reward": 841.2, "best_episode_reward": 858.0, "step": 107000}
{"episode": 216.0, "episode_reward": 866.0, "eval_time": 351.75032925605774, "mean_episode_reward": 866.0, "best_episode_reward": 886.0, "step": 108000}
{"episode": 218.0, "episode_reward": 872.5, "eval_time": 365.96715092658997, "mean_episode_reward": 872.5, "best_episode_reward": 884.0, "step": 109000}
{"episode": 220.0, "episode_reward": 770.6, "eval_time": 347.00772857666016, "mean_episode_reward": 770.6, "best_episode_reward": 866.0, "step": 110000}
{"episode": 222.0, "episode_reward": 851.9, "eval_time": 377.80051350593567, "mean_episode_reward": 851.9, "best_episode_reward": 866.0, "step": 111000}
{"episode": 224.0, "episode_reward": 863.4, "eval_time": 338.94560384750366, "mean_episode_reward": 863.4, "best_episode_reward": 876.0, "step": 112000}
{"episode": 226.0, "episode_reward": 871.0, "eval_time": 365.69158601760864, "mean_episode_reward": 871.0, "best_episode_reward": 880.0, "step": 113000}
{"episode": 228.0, "episode_reward": 861.2, "eval_time": 374.58655309677124, "mean_episode_reward": 861.2, "best_episode_reward": 874.0, "step": 114000}
{"episode": 230.0, "episode_reward": 862.8, "eval_time": 386.6756956577301, "mean_episode_reward": 862.8, "best_episode_reward": 872.0, "step": 115000}
{"episode": 232.0, "episode_reward": 834.5, "eval_time": 355.9763150215149, "mean_episode_reward": 834.5, "best_episode_reward": 861.0, "step": 116000}
{"episode": 234.0, "episode_reward": 869.5, "eval_time": 347.63225269317627, "mean_episode_reward": 869.5, "best_episode_reward": 882.0, "step": 117000}
{"episode": 236.0, "episode_reward": 862.9, "eval_time": 345.86922907829285, "mean_episode_reward": 862.9, "best_episode_reward": 874.0, "step": 118000}
{"episode": 238.0, "episode_reward": 869.3, "eval_time": 366.7485103607178, "mean_episode_reward": 869.3, "best_episode_reward": 882.0, "step": 119000}
{"episode": 240.0, "episode_reward": 857.8, "eval_time": 358.42762899398804, "mean_episode_reward": 857.8, "best_episode_reward": 876.0, "step": 120000}
{"episode": 242.0, "episode_reward": 863.2, "eval_time": 345.3562729358673, "mean_episode_reward": 863.2, "best_episode_reward": 879.0, "step": 121000}
{"episode": 244.0, "episode_reward": 856.3, "eval_time": 354.57077383995056, "mean_episode_reward": 856.3, "best_episode_reward": 881.0, "step": 122000}
{"episode": 246.0, "episode_reward": 869.4, "eval_time": 344.10159134864807, "mean_episode_reward": 869.4, "best_episode_reward": 894.0, "step": 123000}
{"episode": 248.0, "episode_reward": 869.4, "eval_time": 336.1526916027069, "mean_episode_reward": 869.4, "best_episode_reward": 882.0, "step": 124000}
{"episode": 250.0, "episode_reward": 878.1, "eval_time": 350.37172174453735, "mean_episode_reward": 878.1, "best_episode_reward": 892.0, "step": 125000}
{"episode": 252.0, "episode_reward": 876.1, "eval_time": 355.54967403411865, "mean_episode_reward": 876.1, "best_episode_reward": 893.0, "step": 126000}
{"episode": 254.0, "episode_reward": 874.8, "eval_time": 349.15760469436646, "mean_episode_reward": 874.8, "best_episode_reward": 899.0, "step": 127000}
{"episode": 256.0, "episode_reward": 871.8, "eval_time": 356.7474184036255, "mean_episode_reward": 871.8, "best_episode_reward": 891.0, "step": 128000}
{"episode": 258.0, "episode_reward": 884.4, "eval_time": 350.0792224407196, "mean_episode_reward": 884.4, "best_episode_reward": 898.0, "step": 129000}
{"episode": 260.0, "episode_reward": 873.2, "eval_time": 347.19557094573975, "mean_episode_reward": 873.2, "best_episode_reward": 901.0, "step": 130000}
{"episode": 262.0, "episode_reward": 887.9, "eval_time": 348.48088788986206, "mean_episode_reward": 887.9, "best_episode_reward": 904.0, "step": 131000}
{"episode": 264.0, "episode_reward": 892.6, "eval_time": 343.2069752216339, "mean_episode_reward": 892.6, "best_episode_reward": 911.0, "step": 132000}
{"episode": 266.0, "episode_reward": 902.6, "eval_time": 344.20607566833496, "mean_episode_reward": 902.6, "best_episode_reward": 924.0, "step": 133000}
{"episode": 268.0, "episode_reward": 792.6, "eval_time": 360.3254382610321, "mean_episode_reward": 792.6, "best_episode_reward": 903.0, "step": 134000}
{"episode": 270.0, "episode_reward": 881.4, "eval_time": 378.8876736164093, "mean_episode_reward": 881.4, "best_episode_reward": 904.0, "step": 135000}
{"episode": 272.0, "episode_reward": 885.9, "eval_time": 388.91120767593384, "mean_episode_reward": 885.9, "best_episode_reward": 906.0, "step": 136000}
{"episode": 274.0, "episode_reward": 870.8, "eval_time": 363.2517228126526, "mean_episode_reward": 870.8, "best_episode_reward": 892.0, "step": 137000}
{"episode": 276.0, "episode_reward": 882.0, "eval_time": 385.62368059158325, "mean_episode_reward": 882.0, "best_episode_reward": 908.0, "step": 138000}
{"episode": 278.0, "episode_reward": 874.7, "eval_time": 361.7100820541382, "mean_episode_reward": 874.7, "best_episode_reward": 892.0, "step": 139000}
{"episode": 280.0, "episode_reward": 799.7, "eval_time": 398.35299277305603, "mean_episode_reward": 799.7, "best_episode_reward": 902.0, "step": 140000}
{"episode": 282.0, "episode_reward": 801.8, "eval_time": 364.1516783237457, "mean_episode_reward": 801.8, "best_episode_reward": 900.0, "step": 141000}
{"episode": 284.0, "episode_reward": 879.1, "eval_time": 365.3910791873932, "mean_episode_reward": 879.1, "best_episode_reward": 899.0, "step": 142000}
{"episode": 286.0, "episode_reward": 869.3, "eval_time": 345.065203666687, "mean_episode_reward": 869.3, "best_episode_reward": 891.0, "step": 143000}
{"episode": 288.0, "episode_reward": 804.3, "eval_time": 358.07535672187805, "mean_episode_reward": 804.3, "best_episode_reward": 905.0, "step": 144000}
{"episode": 290.0, "episode_reward": 887.4, "eval_time": 352.6912953853607, "mean_episode_reward": 887.4, "best_episode_reward": 909.0, "step": 145000}
{"episode": 292.0, "episode_reward": 895.8, "eval_time": 346.4795124530792, "mean_episode_reward": 895.8, "best_episode_reward": 915.0, "step": 146000}
{"episode": 294.0, "episode_reward": 891.9, "eval_time": 356.7691776752472, "mean_episode_reward": 891.9, "best_episode_reward": 912.0, "step": 147000}
{"episode": 296.0, "episode_reward": 820.0, "eval_time": 356.94766640663147, "mean_episode_reward": 820.0, "best_episode_reward": 928.0, "step": 148000}
{"episode": 298.0, "episode_reward": 887.9, "eval_time": 360.73036670684814, "mean_episode_reward": 887.9, "best_episode_reward": 909.0, "step": 149000}
{"episode": 300.0, "episode_reward": 879.6, "eval_time": 357.63955426216125, "mean_episode_reward": 879.6, "best_episode_reward": 896.0, "step": 150000}
{"episode": 302.0, "episode_reward": 891.0, "eval_time": 353.34702038764954, "mean_episode_reward": 891.0, "best_episode_reward": 918.0, "step": 151000}
{"episode": 304.0, "episode_reward": 914.7, "eval_time": 360.06101512908936, "mean_episode_reward": 914.7, "best_episode_reward": 944.0, "step": 152000}
{"episode": 306.0, "episode_reward": 880.8, "eval_time": 344.6772840023041, "mean_episode_reward": 880.8, "best_episode_reward": 899.0, "step": 153000}
{"episode": 308.0, "episode_reward": 913.2, "eval_time": 342.61080861091614, "mean_episode_reward": 913.2, "best_episode_reward": 928.0, "step": 154000}
{"episode": 310.0, "episode_reward": 898.9, "eval_time": 359.8829481601715, "mean_episode_reward": 898.9, "best_episode_reward": 908.0, "step": 155000}
{"episode": 312.0, "episode_reward": 896.8, "eval_time": 352.5597183704376, "mean_episode_reward": 896.8, "best_episode_reward": 923.0, "step": 156000}
{"episode": 314.0, "episode_reward": 824.4, "eval_time": 351.5136253833771, "mean_episode_reward": 824.4, "best_episode_reward": 937.0, "step": 157000}
{"episode": 316.0, "episode_reward": 883.1, "eval_time": 328.7247807979584, "mean_episode_reward": 883.1, "best_episode_reward": 901.0, "step": 158000}
{"episode": 318.0, "episode_reward": 899.9, "eval_time": 356.4956307411194, "mean_episode_reward": 899.9, "best_episode_reward": 912.0, "step": 159000}
{"episode": 320.0, "episode_reward": 907.2, "eval_time": 337.9218761920929, "mean_episode_reward": 907.2, "best_episode_reward": 916.0, "step": 160000}
{"episode": 322.0, "episode_reward": 900.7, "eval_time": 345.6664249897003, "mean_episode_reward": 900.7, "best_episode_reward": 923.0, "step": 161000}
{"episode": 324.0, "episode_reward": 913.1, "eval_time": 355.6050193309784, "mean_episode_reward": 913.1, "best_episode_reward": 928.0, "step": 162000}
{"episode": 326.0, "episode_reward": 909.8, "eval_time": 347.52379393577576, "mean_episode_reward": 909.8, "best_episode_reward": 920.0, "step": 163000}
{"episode": 328.0, "episode_reward": 903.4, "eval_time": 350.8263466358185, "mean_episode_reward": 903.4, "best_episode_reward": 914.0, "step": 164000}
{"episode": 330.0, "episode_reward": 915.6, "eval_time": 354.27254700660706, "mean_episode_reward": 915.6, "best_episode_reward": 931.0, "step": 165000}
{"episode": 332.0, "episode_reward": 903.7, "eval_time": 366.4380977153778, "mean_episode_reward": 903.7, "best_episode_reward": 920.0, "step": 166000}
{"episode": 334.0, "episode_reward": 898.0, "eval_time": 380.28225016593933, "mean_episode_reward": 898.0, "best_episode_reward": 915.0, "step": 167000}
{"episode": 336.0, "episode_reward": 908.6, "eval_time": 385.7995731830597, "mean_episode_reward": 908.6, "best_episode_reward": 926.0, "step": 168000}
{"episode": 338.0, "episode_reward": 918.6, "eval_time": 400.42535853385925, "mean_episode_reward": 918.6, "best_episode_reward": 934.0, "step": 169000}
{"episode": 340.0, "episode_reward": 917.8, "eval_time": 398.36758279800415, "mean_episode_reward": 917.8, "best_episode_reward": 932.0, "step": 170000}
{"episode": 342.0, "episode_reward": 930.4, "eval_time": 416.97877979278564, "mean_episode_reward": 930.4, "best_episode_reward": 940.0, "step": 171000}
{"episode": 344.0, "episode_reward": 903.0, "eval_time": 428.70748686790466, "mean_episode_reward": 903.0, "best_episode_reward": 914.0, "step": 172000}
{"episode": 346.0, "episode_reward": 911.2, "eval_time": 427.3115837574005, "mean_episode_reward": 911.2, "best_episode_reward": 927.0, "step": 173000}
{"episode": 348.0, "episode_reward": 911.5, "eval_time": 422.79765224456787, "mean_episode_reward": 911.5, "best_episode_reward": 922.0, "step": 174000}
{"episode": 350.0, "episode_reward": 902.4, "eval_time": 393.1475863456726, "mean_episode_reward": 902.4, "best_episode_reward": 917.0, "step": 175000}
{"episode": 352.0, "episode_reward": 927.4, "eval_time": 375.2356758117676, "mean_episode_reward": 927.4, "best_episode_reward": 940.0, "step": 176000}
{"episode": 354.0, "episode_reward": 943.0, "eval_time": 365.31006956100464, "mean_episode_reward": 943.0, "best_episode_reward": 960.0, "step": 177000}
{"episode": 356.0, "episode_reward": 943.8, "eval_time": 359.4546711444855, "mean_episode_reward": 943.8, "best_episode_reward": 949.0, "step": 178000}
{"episode": 358.0, "episode_reward": 932.9, "eval_time": 364.5580084323883, "mean_episode_reward": 932.9, "best_episode_reward": 945.0, "step": 179000}
{"episode": 360.0, "episode_reward": 924.2, "eval_time": 375.3734812736511, "mean_episode_reward": 924.2, "best_episode_reward": 935.0, "step": 180000}
{"episode": 362.0, "episode_reward": 940.4, "eval_time": 384.90355610847473, "mean_episode_reward": 940.4, "best_episode_reward": 956.0, "step": 181000}
{"episode": 364.0, "episode_reward": 942.7, "eval_time": 366.96762704849243, "mean_episode_reward": 942.7, "best_episode_reward": 957.0, "step": 182000}
{"episode": 366.0, "episode_reward": 916.0, "eval_time": 378.4554636478424, "mean_episode_reward": 916.0, "best_episode_reward": 928.0, "step": 183000}
{"episode": 368.0, "episode_reward": 949.7, "eval_time": 384.7239775657654, "mean_episode_reward": 949.7, "best_episode_reward": 957.0, "step": 184000}
{"episode": 370.0, "episode_reward": 943.9, "eval_time": 377.14709401130676, "mean_episode_reward": 943.9, "best_episode_reward": 964.0, "step": 185000}
{"episode": 372.0, "episode_reward": 945.5, "eval_time": 362.813059091568, "mean_episode_reward": 945.5, "best_episode_reward": 955.0, "step": 186000}
{"episode": 374.0, "episode_reward": 960.5, "eval_time": 371.53166151046753, "mean_episode_reward": 960.5, "best_episode_reward": 970.0, "step": 187000}
{"episode": 376.0, "episode_reward": 937.9, "eval_time": 371.74785590171814, "mean_episode_reward": 937.9, "best_episode_reward": 950.0, "step": 188000}
{"episode": 378.0, "episode_reward": 946.8, "eval_time": 377.6086964607239, "mean_episode_reward": 946.8, "best_episode_reward": 955.0, "step": 189000}
{"episode": 380.0, "episode_reward": 945.2, "eval_time": 393.6183867454529, "mean_episode_reward": 945.2, "best_episode_reward": 952.0, "step": 190000}
{"episode": 382.0, "episode_reward": 946.0, "eval_time": 388.9375238418579, "mean_episode_reward": 946.0, "best_episode_reward": 956.0, "step": 191000}
{"episode": 384.0, "episode_reward": 942.1, "eval_time": 391.73641872406006, "mean_episode_reward": 942.1, "best_episode_reward": 958.0, "step": 192000}
{"episode": 386.0, "episode_reward": 941.4, "eval_time": 373.0125849246979, "mean_episode_reward": 941.4, "best_episode_reward": 966.0, "step": 193000}
{"episode": 388.0, "episode_reward": 946.9, "eval_time": 382.15732526779175, "mean_episode_reward": 946.9, "best_episode_reward": 955.0, "step": 194000}
{"episode": 390.0, "episode_reward": 943.5, "eval_time": 390.2283613681793, "mean_episode_reward": 943.5, "best_episode_reward": 950.0, "step": 195000}
{"episode": 392.0, "episode_reward": 937.8, "eval_time": 368.5556571483612, "mean_episode_reward": 937.8, "best_episode_reward": 952.0, "step": 196000}
{"episode": 394.0, "episode_reward": 944.3, "eval_time": 385.1567130088806, "mean_episode_reward": 944.3, "best_episode_reward": 954.0, "step": 197000}
{"episode": 396.0, "episode_reward": 953.4, "eval_time": 354.35236167907715, "mean_episode_reward": 953.4, "best_episode_reward": 961.0, "step": 198000}
{"episode": 398.0, "episode_reward": 952.9, "eval_time": 380.3393874168396, "mean_episode_reward": 952.9, "best_episode_reward": 975.0, "step": 199000}
{"episode": 400.0, "episode_reward": 940.1, "eval_time": 373.7035462856293, "mean_episode_reward": 940.1, "best_episode_reward": 955.0, "step": 200000}
{"episode": 402.0, "episode_reward": 933.1, "eval_time": 389.9352333545685, "mean_episode_reward": 933.1, "best_episode_reward": 948.0, "step": 201000}
{"episode": 404.0, "episode_reward": 943.1, "eval_time": 364.1955909729004, "mean_episode_reward": 943.1, "best_episode_reward": 951.0, "step": 202000}
{"episode": 406.0, "episode_reward": 947.3, "eval_time": 384.4579644203186, "mean_episode_reward": 947.3, "best_episode_reward": 961.0, "step": 203000}
{"episode": 408.0, "episode_reward": 955.1, "eval_time": 388.5399761199951, "mean_episode_reward": 955.1, "best_episode_reward": 982.0, "step": 204000}
{"episode": 410.0, "episode_reward": 945.0, "eval_time": 374.6874854564667, "mean_episode_reward": 945.0, "best_episode_reward": 952.0, "step": 205000}
{"episode": 412.0, "episode_reward": 939.6, "eval_time": 380.111111164093, "mean_episode_reward": 939.6, "best_episode_reward": 952.0, "step": 206000}
{"episode": 414.0, "episode_reward": 949.3, "eval_time": 370.9232585430145, "mean_episode_reward": 949.3, "best_episode_reward": 968.0, "step": 207000}
{"episode": 416.0, "episode_reward": 943.1, "eval_time": 370.2677597999573, "mean_episode_reward": 943.1, "best_episode_reward": 956.0, "step": 208000}
{"episode": 418.0, "episode_reward": 945.5, "eval_time": 372.73426723480225, "mean_episode_reward": 945.5, "best_episode_reward": 961.0, "step": 209000}
{"episode": 420.0, "episode_reward": 941.6, "eval_time": 386.86565136909485, "mean_episode_reward": 941.6, "best_episode_reward": 951.0, "step": 210000}
{"episode": 422.0, "episode_reward": 934.9, "eval_time": 378.18784165382385, "mean_episode_reward": 934.9, "best_episode_reward": 950.0, "step": 211000}
{"episode": 424.0, "episode_reward": 935.2, "eval_time": 376.9533905982971, "mean_episode_reward": 935.2, "best_episode_reward": 948.0, "step": 212000}
{"episode": 426.0, "episode_reward": 946.8, "eval_time": 384.7074685096741, "mean_episode_reward": 946.8, "best_episode_reward": 955.0, "step": 213000}
{"episode": 428.0, "episode_reward": 939.2, "eval_time": 360.17599654197693, "mean_episode_reward": 939.2, "best_episode_reward": 955.0, "step": 214000}
{"episode": 430.0, "episode_reward": 947.0, "eval_time": 392.9492280483246, "mean_episode_reward": 947.0, "best_episode_reward": 960.0, "step": 215000}
{"episode": 432.0, "episode_reward": 941.8, "eval_time": 390.09368348121643, "mean_episode_reward": 941.8, "best_episode_reward": 954.0, "step": 216000}
{"episode": 434.0, "episode_reward": 941.5, "eval_time": 371.54310727119446, "mean_episode_reward": 941.5, "best_episode_reward": 955.0, "step": 217000}
{"episode": 436.0, "episode_reward": 950.6, "eval_time": 397.58308696746826, "mean_episode_reward": 950.6, "best_episode_reward": 964.0, "step": 218000}
{"episode": 438.0, "episode_reward": 945.6, "eval_time": 374.0501310825348, "mean_episode_reward": 945.6, "best_episode_reward": 954.0, "step": 219000}
{"episode": 440.0, "episode_reward": 946.2, "eval_time": 385.9236764907837, "mean_episode_reward": 946.2, "best_episode_reward": 956.0, "step": 220000}
{"episode": 442.0, "episode_reward": 947.2, "eval_time": 396.5747127532959, "mean_episode_reward": 947.2, "best_episode_reward": 953.0, "step": 221000}
{"episode": 444.0, "episode_reward": 947.3, "eval_time": 398.68358063697815, "mean_episode_reward": 947.3, "best_episode_reward": 961.0, "step": 222000}
{"episode": 446.0, "episode_reward": 939.7, "eval_time": 373.2778272628784, "mean_episode_reward": 939.7, "best_episode_reward": 952.0, "step": 223000}
{"episode": 448.0, "episode_reward": 953.9, "eval_time": 383.8916018009186, "mean_episode_reward": 953.9, "best_episode_reward": 968.0, "step": 224000}
{"episode": 450.0, "episode_reward": 946.3, "eval_time": 375.69037795066833, "mean_episode_reward": 946.3, "best_episode_reward": 959.0, "step": 225000}
{"episode": 452.0, "episode_reward": 973.7, "eval_time": 372.7308626174927, "mean_episode_reward": 973.7, "best_episode_reward": 987.0, "step": 226000}
{"episode": 454.0, "episode_reward": 982.3, "eval_time": 369.1363215446472, "mean_episode_reward": 982.3, "best_episode_reward": 994.0, "step": 227000}
{"episode": 456.0, "episode_reward": 945.5, "eval_time": 366.54212164878845, "mean_episode_reward": 945.5, "best_episode_reward": 952.0, "step": 228000}
{"episode": 458.0, "episode_reward": 942.8, "eval_time": 368.1958622932434, "mean_episode_reward": 942.8, "best_episode_reward": 950.0, "step": 229000}
{"episode": 460.0, "episode_reward": 950.7, "eval_time": 371.67958521842957, "mean_episode_reward": 950.7, "best_episode_reward": 957.0, "step": 230000}
{"episode": 462.0, "episode_reward": 980.5, "eval_time": 365.88638710975647, "mean_episode_reward": 980.5, "best_episode_reward": 986.0, "step": 231000}
{"episode": 464.0, "episode_reward": 942.6, "eval_time": 386.227694272995, "mean_episode_reward": 942.6, "best_episode_reward": 950.0, "step": 232000}
{"episode": 466.0, "episode_reward": 941.5, "eval_time": 377.8194718360901, "mean_episode_reward": 941.5, "best_episode_reward": 951.0, "step": 233000}
{"episode": 468.0, "episode_reward": 957.1, "eval_time": 392.7219703197479, "mean_episode_reward": 957.1, "best_episode_reward": 971.0, "step": 234000}
{"episode": 470.0, "episode_reward": 967.6, "eval_time": 369.2237105369568, "mean_episode_reward": 967.6, "best_episode_reward": 983.0, "step": 235000}
{"episode": 472.0, "episode_reward": 974.8, "eval_time": 375.4577832221985, "mean_episode_reward": 974.8, "best_episode_reward": 984.0, "step": 236000}
{"episode": 474.0, "episode_reward": 982.1, "eval_time": 383.695499420166, "mean_episode_reward": 982.1, "best_episode_reward": 987.0, "step": 237000}
{"episode": 476.0, "episode_reward": 952.6, "eval_time": 374.08222484588623, "mean_episode_reward": 952.6, "best_episode_reward": 961.0, "step": 238000}
{"episode": 478.0, "episode_reward": 980.9, "eval_time": 368.1283597946167, "mean_episode_reward": 980.9, "best_episode_reward": 987.0, "step": 239000}
{"episode": 480.0, "episode_reward": 887.4, "eval_time": 361.371595621109, "mean_episode_reward": 887.4, "best_episode_reward": 996.0, "step": 240000}
{"episode": 482.0, "episode_reward": 986.2, "eval_time": 378.01887130737305, "mean_episode_reward": 986.2, "best_episode_reward": 989.0, "step": 241000}
{"episode": 484.0, "episode_reward": 986.4, "eval_time": 377.2310628890991, "mean_episode_reward": 986.4, "best_episode_reward": 998.0, "step": 242000}
{"episode": 486.0, "episode_reward": 982.5, "eval_time": 393.427209854126, "mean_episode_reward": 982.5, "best_episode_reward": 995.0, "step": 243000}
{"episode": 488.0, "episode_reward": 989.0, "eval_time": 382.1514005661011, "mean_episode_reward": 989.0, "best_episode_reward": 997.0, "step": 244000}
{"episode": 490.0, "episode_reward": 984.0, "eval_time": 378.9348678588867, "mean_episode_reward": 984.0, "best_episode_reward": 994.0, "step": 245000}
{"episode": 492.0, "episode_reward": 984.1, "eval_time": 372.1346318721771, "mean_episode_reward": 984.1, "best_episode_reward": 992.0, "step": 246000}
{"episode": 494.0, "episode_reward": 964.5, "eval_time": 368.8376111984253, "mean_episode_reward": 964.5, "best_episode_reward": 976.0, "step": 247000}
{"episode": 496.0, "episode_reward": 976.8, "eval_time": 380.64478158950806, "mean_episode_reward": 976.8, "best_episode_reward": 995.0, "step": 248000}
{"episode": 498.0, "episode_reward": 965.5, "eval_time": 350.4113576412201, "mean_episode_reward": 965.5, "best_episode_reward": 983.0, "step": 249000}
{"episode": 500.0, "episode_reward": 957.0, "eval_time": 370.81938910484314, "mean_episode_reward": 957.0, "best_episode_reward": 966.0, "step": 250000}
{"episode": 502.0, "episode_reward": 965.2, "eval_time": 368.54413652420044, "mean_episode_reward": 965.2, "best_episode_reward": 975.0, "step": 251000}
{"episode": 504.0, "episode_reward": 983.3, "eval_time": 362.6435959339142, "mean_episode_reward": 983.3, "best_episode_reward": 991.0, "step": 252000}
{"episode": 506.0, "episode_reward": 978.4, "eval_time": 370.7302715778351, "mean_episode_reward": 978.4, "best_episode_reward": 991.0, "step": 253000}
{"episode": 508.0, "episode_reward": 982.8, "eval_time": 366.7875783443451, "mean_episode_reward": 982.8, "best_episode_reward": 992.0, "step": 254000}
{"episode": 510.0, "episode_reward": 985.3, "eval_time": 382.3162999153137, "mean_episode_reward": 985.3, "best_episode_reward": 993.0, "step": 255000}
{"episode": 512.0, "episode_reward": 954.2, "eval_time": 382.0720920562744, "mean_episode_reward": 954.2, "best_episode_reward": 969.0, "step": 256000}
{"episode": 514.0, "episode_reward": 983.5, "eval_time": 401.63164615631104, "mean_episode_reward": 983.5, "best_episode_reward": 993.0, "step": 257000}
{"episode": 516.0, "episode_reward": 983.1, "eval_time": 401.96759939193726, "mean_episode_reward": 983.1, "best_episode_reward": 992.0, "step": 258000}
{"episode": 518.0, "episode_reward": 973.4, "eval_time": 384.09697580337524, "mean_episode_reward": 973.4, "best_episode_reward": 983.0, "step": 259000}
{"episode": 520.0, "episode_reward": 986.2, "eval_time": 404.79163575172424, "mean_episode_reward": 986.2, "best_episode_reward": 995.0, "step": 260000}
{"episode": 522.0, "episode_reward": 981.9, "eval_time": 393.1636164188385, "mean_episode_reward": 981.9, "best_episode_reward": 992.0, "step": 261000}
{"episode": 524.0, "episode_reward": 982.6, "eval_time": 401.67128896713257, "mean_episode_reward": 982.6, "best_episode_reward": 996.0, "step": 262000}
{"episode": 526.0, "episode_reward": 986.5, "eval_time": 382.47141456604004, "mean_episode_reward": 986.5, "best_episode_reward": 998.0, "step": 263000}
{"episode": 528.0, "episode_reward": 979.9, "eval_time": 380.17945408821106, "mean_episode_reward": 979.9, "best_episode_reward": 991.0, "step": 264000}
{"episode": 530.0, "episode_reward": 971.2, "eval_time": 373.87151169776917, "mean_episode_reward": 971.2, "best_episode_reward": 986.0, "step": 265000}
{"episode": 532.0, "episode_reward": 974.0, "eval_time": 380.3048565387726, "mean_episode_reward": 974.0, "best_episode_reward": 985.0, "step": 266000}
{"episode": 534.0, "episode_reward": 985.0, "eval_time": 362.8810541629791, "mean_episode_reward": 985.0, "best_episode_reward": 993.0, "step": 267000}
{"episode": 536.0, "episode_reward": 981.7, "eval_time": 378.3542170524597, "mean_episode_reward": 981.7, "best_episode_reward": 994.0, "step": 268000}
{"episode": 538.0, "episode_reward": 974.9, "eval_time": 370.3555634021759, "mean_episode_reward": 974.9, "best_episode_reward": 985.0, "step": 269000}
{"episode": 540.0, "episode_reward": 986.9, "eval_time": 383.7238938808441, "mean_episode_reward": 986.9, "best_episode_reward": 991.0, "step": 270000}
{"episode": 542.0, "episode_reward": 982.6, "eval_time": 378.51165747642517, "mean_episode_reward": 982.6, "best_episode_reward": 993.0, "step": 271000}
{"episode": 544.0, "episode_reward": 980.1, "eval_time": 384.2996416091919, "mean_episode_reward": 980.1, "best_episode_reward": 993.0, "step": 272000}
{"episode": 546.0, "episode_reward": 982.6, "eval_time": 376.43719458580017, "mean_episode_reward": 982.6, "best_episode_reward": 990.0, "step": 273000}
{"episode": 548.0, "episode_reward": 983.7, "eval_time": 377.63316464424133, "mean_episode_reward": 983.7, "best_episode_reward": 989.0, "step": 274000}
{"episode": 550.0, "episode_reward": 976.9, "eval_time": 379.72036504745483, "mean_episode_reward": 976.9, "best_episode_reward": 993.0, "step": 275000}
{"episode": 552.0, "episode_reward": 978.0, "eval_time": 361.78729486465454, "mean_episode_reward": 978.0, "best_episode_reward": 988.0, "step": 276000}
{"episode": 554.0, "episode_reward": 984.3, "eval_time": 375.4715578556061, "mean_episode_reward": 984.3, "best_episode_reward": 994.0, "step": 277000}
{"episode": 556.0, "episode_reward": 983.6, "eval_time": 372.5752058029175, "mean_episode_reward": 983.6, "best_episode_reward": 994.0, "step": 278000}
{"episode": 558.0, "episode_reward": 981.2, "eval_time": 374.28388571739197, "mean_episode_reward": 981.2, "best_episode_reward": 994.0, "step": 279000}
{"episode": 560.0, "episode_reward": 983.3, "eval_time": 381.3630745410919, "mean_episode_reward": 983.3, "best_episode_reward": 992.0, "step": 280000}
{"episode": 562.0, "episode_reward": 981.6, "eval_time": 377.943763256073, "mean_episode_reward": 981.6, "best_episode_reward": 995.0, "step": 281000}
{"episode": 564.0, "episode_reward": 983.8, "eval_time": 379.0796172618866, "mean_episode_reward": 983.8, "best_episode_reward": 994.0, "step": 282000}
{"episode": 566.0, "episode_reward": 981.4, "eval_time": 369.5357382297516, "mean_episode_reward": 981.4, "best_episode_reward": 993.0, "step": 283000}
{"episode": 568.0, "episode_reward": 982.8, "eval_time": 381.1196446418762, "mean_episode_reward": 982.8, "best_episode_reward": 997.0, "step": 284000}
{"episode": 570.0, "episode_reward": 984.2, "eval_time": 377.0677156448364, "mean_episode_reward": 984.2, "best_episode_reward": 993.0, "step": 285000}
{"episode": 572.0, "episode_reward": 982.7, "eval_time": 382.0693917274475, "mean_episode_reward": 982.7, "best_episode_reward": 992.0, "step": 286000}
{"episode": 574.0, "episode_reward": 986.4, "eval_time": 375.4824552536011, "mean_episode_reward": 986.4, "best_episode_reward": 996.0, "step": 287000}
{"episode": 576.0, "episode_reward": 883.9, "eval_time": 364.4128074645996, "mean_episode_reward": 883.9, "best_episode_reward": 992.0, "step": 288000}
{"episode": 578.0, "episode_reward": 970.3, "eval_time": 381.37154245376587, "mean_episode_reward": 970.3, "best_episode_reward": 985.0, "step": 289000}
{"episode": 580.0, "episode_reward": 988.8, "eval_time": 361.22781682014465, "mean_episode_reward": 988.8, "best_episode_reward": 994.0, "step": 290000}
{"episode": 582.0, "episode_reward": 971.2, "eval_time": 375.12140583992004, "mean_episode_reward": 971.2, "best_episode_reward": 983.0, "step": 291000}
{"episode": 584.0, "episode_reward": 983.3, "eval_time": 375.93563628196716, "mean_episode_reward": 983.3, "best_episode_reward": 989.0, "step": 292000}
{"episode": 586.0, "episode_reward": 986.0, "eval_time": 372.810494184494, "mean_episode_reward": 986.0, "best_episode_reward": 996.0, "step": 293000}
{"episode": 588.0, "episode_reward": 980.8, "eval_time": 393.8074231147766, "mean_episode_reward": 980.8, "best_episode_reward": 995.0, "step": 294000}
{"episode": 590.0, "episode_reward": 981.5, "eval_time": 369.47164964675903, "mean_episode_reward": 981.5, "best_episode_reward": 994.0, "step": 295000}
{"episode": 592.0, "episode_reward": 985.2, "eval_time": 377.3051390647888, "mean_episode_reward": 985.2, "best_episode_reward": 996.0, "step": 296000}
{"episode": 594.0, "episode_reward": 982.4, "eval_time": 373.95022678375244, "mean_episode_reward": 982.4, "best_episode_reward": 993.0, "step": 297000}
{"episode": 596.0, "episode_reward": 983.1, "eval_time": 390.40751361846924, "mean_episode_reward": 983.1, "best_episode_reward": 989.0, "step": 298000}
{"episode": 598.0, "episode_reward": 982.3, "eval_time": 373.81976652145386, "mean_episode_reward": 982.3, "best_episode_reward": 994.0, "step": 299000}
{"episode": 600.0, "episode_reward": 980.7, "eval_time": 399.35882353782654, "mean_episode_reward": 980.7, "best_episode_reward": 988.0, "step": 300000}
{"episode": 602.0, "episode_reward": 985.2, "eval_time": 399.5473976135254, "mean_episode_reward": 985.2, "best_episode_reward": 992.0, "step": 301000}
{"episode": 604.0, "episode_reward": 975.6, "eval_time": 409.5674147605896, "mean_episode_reward": 975.6, "best_episode_reward": 991.0, "step": 302000}
{"episode": 606.0, "episode_reward": 987.3, "eval_time": 380.03544306755066, "mean_episode_reward": 987.3, "best_episode_reward": 996.0, "step": 303000}
{"episode": 608.0, "episode_reward": 975.0, "eval_time": 372.8642477989197, "mean_episode_reward": 975.0, "best_episode_reward": 993.0, "step": 304000}
{"episode": 610.0, "episode_reward": 979.5, "eval_time": 381.3752410411835, "mean_episode_reward": 979.5, "best_episode_reward": 993.0, "step": 305000}
{"episode": 612.0, "episode_reward": 983.9, "eval_time": 378.2417929172516, "mean_episode_reward": 983.9, "best_episode_reward": 993.0, "step": 306000}
{"episode": 614.0, "episode_reward": 981.2, "eval_time": 384.7716426849365, "mean_episode_reward": 981.2, "best_episode_reward": 997.0, "step": 307000}
{"episode": 616.0, "episode_reward": 986.0, "eval_time": 378.23914790153503, "mean_episode_reward": 986.0, "best_episode_reward": 994.0, "step": 308000}
{"episode": 618.0, "episode_reward": 983.0, "eval_time": 363.4271399974823, "mean_episode_reward": 983.0, "best_episode_reward": 992.0, "step": 309000}
{"episode": 620.0, "episode_reward": 983.1, "eval_time": 374.5995466709137, "mean_episode_reward": 983.1, "best_episode_reward": 995.0, "step": 310000}
{"episode": 622.0, "episode_reward": 983.5, "eval_time": 373.2227692604065, "mean_episode_reward": 983.5, "best_episode_reward": 994.0, "step": 311000}
{"episode": 624.0, "episode_reward": 980.1, "eval_time": 399.9507703781128, "mean_episode_reward": 980.1, "best_episode_reward": 992.0, "step": 312000}
{"episode": 626.0, "episode_reward": 980.7, "eval_time": 376.0837047100067, "mean_episode_reward": 980.7, "best_episode_reward": 994.0, "step": 313000}
{"episode": 628.0, "episode_reward": 981.1, "eval_time": 391.47200560569763, "mean_episode_reward": 981.1, "best_episode_reward": 990.0, "step": 314000}
{"episode": 630.0, "episode_reward": 983.6, "eval_time": 380.6796500682831, "mean_episode_reward": 983.6, "best_episode_reward": 990.0, "step": 315000}
{"episode": 632.0, "episode_reward": 988.3, "eval_time": 383.36296486854553, "mean_episode_reward": 988.3, "best_episode_reward": 998.0, "step": 316000}
{"episode": 634.0, "episode_reward": 984.6, "eval_time": 375.47235083580017, "mean_episode_reward": 984.6, "best_episode_reward": 992.0, "step": 317000}
{"episode": 636.0, "episode_reward": 984.8, "eval_time": 369.1106231212616, "mean_episode_reward": 984.8, "best_episode_reward": 994.0, "step": 318000}
{"episode": 638.0, "episode_reward": 981.2, "eval_time": 359.80524706840515, "mean_episode_reward": 981.2, "best_episode_reward": 990.0, "step": 319000}
{"episode": 640.0, "episode_reward": 984.1, "eval_time": 359.11026334762573, "mean_episode_reward": 984.1, "best_episode_reward": 994.0, "step": 320000}
{"episode": 642.0, "episode_reward": 980.3, "eval_time": 363.1635973453522, "mean_episode_reward": 980.3, "best_episode_reward": 988.0, "step": 321000}
{"episode": 644.0, "episode_reward": 985.5, "eval_time": 366.8512177467346, "mean_episode_reward": 985.5, "best_episode_reward": 992.0, "step": 322000}
{"episode": 646.0, "episode_reward": 980.5, "eval_time": 360.91562056541443, "mean_episode_reward": 980.5, "best_episode_reward": 990.0, "step": 323000}
{"episode": 648.0, "episode_reward": 983.8, "eval_time": 351.5796401500702, "mean_episode_reward": 983.8, "best_episode_reward": 991.0, "step": 324000}
{"episode": 650.0, "episode_reward": 982.0, "eval_time": 367.49935007095337, "mean_episode_reward": 982.0, "best_episode_reward": 991.0, "step": 325000}
{"episode": 652.0, "episode_reward": 974.4, "eval_time": 365.7403371334076, "mean_episode_reward": 974.4, "best_episode_reward": 986.0, "step": 326000}
{"episode": 654.0, "episode_reward": 985.4, "eval_time": 353.9329614639282, "mean_episode_reward": 985.4, "best_episode_reward": 994.0, "step": 327000}
{"episode": 656.0, "episode_reward": 985.8, "eval_time": 360.6821665763855, "mean_episode_reward": 985.8, "best_episode_reward": 994.0, "step": 328000}
{"episode": 658.0, "episode_reward": 982.6, "eval_time": 358.2357850074768, "mean_episode_reward": 982.6, "best_episode_reward": 993.0, "step": 329000}
{"episode": 660.0, "episode_reward": 979.3, "eval_time": 379.5794463157654, "mean_episode_reward": 979.3, "best_episode_reward": 992.0, "step": 330000}
{"episode": 662.0, "episode_reward": 984.0, "eval_time": 367.41331911087036, "mean_episode_reward": 984.0, "best_episode_reward": 994.0, "step": 331000}
{"episode": 664.0, "episode_reward": 978.1, "eval_time": 384.2819118499756, "mean_episode_reward": 978.1, "best_episode_reward": 988.0, "step": 332000}
{"episode": 666.0, "episode_reward": 983.3, "eval_time": 378.91962909698486, "mean_episode_reward": 983.3, "best_episode_reward": 994.0, "step": 333000}
{"episode": 668.0, "episode_reward": 979.9, "eval_time": 381.6040451526642, "mean_episode_reward": 979.9, "best_episode_reward": 993.0, "step": 334000}
{"episode": 670.0, "episode_reward": 985.1, "eval_time": 398.8326370716095, "mean_episode_reward": 985.1, "best_episode_reward": 994.0, "step": 335000}
{"episode": 672.0, "episode_reward": 978.1, "eval_time": 389.76521706581116, "mean_episode_reward": 978.1, "best_episode_reward": 989.0, "step": 336000}
{"episode": 674.0, "episode_reward": 982.9, "eval_time": 395.55168175697327, "mean_episode_reward": 982.9, "best_episode_reward": 993.0, "step": 337000}
{"episode": 676.0, "episode_reward": 981.9, "eval_time": 393.5959722995758, "mean_episode_reward": 981.9, "best_episode_reward": 996.0, "step": 338000}
{"episode": 678.0, "episode_reward": 979.3, "eval_time": 394.33172702789307, "mean_episode_reward": 979.3, "best_episode_reward": 997.0, "step": 339000}
{"episode": 680.0, "episode_reward": 979.3, "eval_time": 376.99694895744324, "mean_episode_reward": 979.3, "best_episode_reward": 989.0, "step": 340000}
{"episode": 682.0, "episode_reward": 882.1, "eval_time": 363.4993441104889, "mean_episode_reward": 882.1, "best_episode_reward": 990.0, "step": 341000}
{"episode": 684.0, "episode_reward": 986.1, "eval_time": 361.70361256599426, "mean_episode_reward": 986.1, "best_episode_reward": 995.0, "step": 342000}
{"episode": 686.0, "episode_reward": 982.2, "eval_time": 361.71099400520325, "mean_episode_reward": 982.2, "best_episode_reward": 988.0, "step": 343000}
{"episode": 688.0, "episode_reward": 987.1, "eval_time": 360.34880208969116, "mean_episode_reward": 987.1, "best_episode_reward": 996.0, "step": 344000}
{"episode": 690.0, "episode_reward": 985.4, "eval_time": 374.48366236686707, "mean_episode_reward": 985.4, "best_episode_reward": 994.0, "step": 345000}
{"episode": 692.0, "episode_reward": 985.1, "eval_time": 363.42028999328613, "mean_episode_reward": 985.1, "best_episode_reward": 994.0, "step": 346000}
{"episode": 694.0, "episode_reward": 982.1, "eval_time": 368.61376452445984, "mean_episode_reward": 982.1, "best_episode_reward": 989.0, "step": 347000}
{"episode": 696.0, "episode_reward": 985.1, "eval_time": 370.7618112564087, "mean_episode_reward": 985.1, "best_episode_reward": 994.0, "step": 348000}
{"episode": 698.0, "episode_reward": 988.5, "eval_time": 369.70812225341797, "mean_episode_reward": 988.5, "best_episode_reward": 996.0, "step": 349000}
{"episode": 700.0, "episode_reward": 983.2, "eval_time": 357.54771661758423, "mean_episode_reward": 983.2, "best_episode_reward": 996.0, "step": 350000}
{"episode": 702.0, "episode_reward": 983.9, "eval_time": 379.4556260108948, "mean_episode_reward": 983.9, "best_episode_reward": 992.0, "step": 351000}
{"episode": 704.0, "episode_reward": 986.4, "eval_time": 360.5524435043335, "mean_episode_reward": 986.4, "best_episode_reward": 995.0, "step": 352000}
{"episode": 706.0, "episode_reward": 984.4, "eval_time": 363.1117858886719, "mean_episode_reward": 984.4, "best_episode_reward": 992.0, "step": 353000}
{"episode": 708.0, "episode_reward": 985.2, "eval_time": 342.67567324638367, "mean_episode_reward": 985.2, "best_episode_reward": 995.0, "step": 354000}
{"episode": 710.0, "episode_reward": 981.8, "eval_time": 305.0009140968323, "mean_episode_reward": 981.8, "best_episode_reward": 993.0, "step": 355000}
{"episode": 712.0, "episode_reward": 974.4, "eval_time": 240.24558544158936, "mean_episode_reward": 974.4, "best_episode_reward": 987.0, "step": 356000}
{"episode": 714.0, "episode_reward": 980.6, "eval_time": 228.29000234603882, "mean_episode_reward": 980.6, "best_episode_reward": 989.0, "step": 357000}
{"episode": 716.0, "episode_reward": 985.1, "eval_time": 222.17221355438232, "mean_episode_reward": 985.1, "best_episode_reward": 994.0, "step": 358000}
{"episode": 718.0, "episode_reward": 978.1, "eval_time": 230.71465706825256, "mean_episode_reward": 978.1, "best_episode_reward": 992.0, "step": 359000}
{"episode": 720.0, "episode_reward": 983.6, "eval_time": 164.77821922302246, "mean_episode_reward": 983.6, "best_episode_reward": 993.0, "step": 360000}
{"episode": 722.0, "episode_reward": 974.0, "eval_time": 165.87230372428894, "mean_episode_reward": 974.0, "best_episode_reward": 987.0, "step": 361000}
{"episode": 724.0, "episode_reward": 985.6, "eval_time": 167.32194566726685, "mean_episode_reward": 985.6, "best_episode_reward": 989.0, "step": 362000}
{"episode": 726.0, "episode_reward": 982.7, "eval_time": 167.5302209854126, "mean_episode_reward": 982.7, "best_episode_reward": 992.0, "step": 363000}
{"episode": 728.0, "episode_reward": 984.2, "eval_time": 167.82675337791443, "mean_episode_reward": 984.2, "best_episode_reward": 992.0, "step": 364000}
{"episode": 730.0, "episode_reward": 982.7, "eval_time": 167.30847024917603, "mean_episode_reward": 982.7, "best_episode_reward": 994.0, "step": 365000}
{"episode": 732.0, "episode_reward": 983.3, "eval_time": 165.4451630115509, "mean_episode_reward": 983.3, "best_episode_reward": 995.0, "step": 366000}
{"episode": 734.0, "episode_reward": 981.7, "eval_time": 164.37681531906128, "mean_episode_reward": 981.7, "best_episode_reward": 990.0, "step": 367000}
{"episode": 736.0, "episode_reward": 981.0, "eval_time": 164.77683901786804, "mean_episode_reward": 981.0, "best_episode_reward": 996.0, "step": 368000}
{"episode": 738.0, "episode_reward": 983.5, "eval_time": 164.67858219146729, "mean_episode_reward": 983.5, "best_episode_reward": 995.0, "step": 369000}
{"episode": 740.0, "episode_reward": 987.4, "eval_time": 164.22232937812805, "mean_episode_reward": 987.4, "best_episode_reward": 994.0, "step": 370000}
{"episode": 742.0, "episode_reward": 983.2, "eval_time": 164.80032896995544, "mean_episode_reward": 983.2, "best_episode_reward": 990.0, "step": 371000}
{"episode": 744.0, "episode_reward": 980.8, "eval_time": 162.38634872436523, "mean_episode_reward": 980.8, "best_episode_reward": 993.0, "step": 372000}
{"episode": 746.0, "episode_reward": 982.3, "eval_time": 164.36160516738892, "mean_episode_reward": 982.3, "best_episode_reward": 990.0, "step": 373000}
{"episode": 748.0, "episode_reward": 983.9, "eval_time": 165.2985155582428, "mean_episode_reward": 983.9, "best_episode_reward": 992.0, "step": 374000}
{"episode": 750.0, "episode_reward": 881.7, "eval_time": 164.69026827812195, "mean_episode_reward": 881.7, "best_episode_reward": 987.0, "step": 375000}
{"episode": 752.0, "episode_reward": 986.7, "eval_time": 164.09719014167786, "mean_episode_reward": 986.7, "best_episode_reward": 994.0, "step": 376000}
{"episode": 754.0, "episode_reward": 985.4, "eval_time": 165.04671549797058, "mean_episode_reward": 985.4, "best_episode_reward": 990.0, "step": 377000}
{"episode": 756.0, "episode_reward": 985.6, "eval_time": 164.6579134464264, "mean_episode_reward": 985.6, "best_episode_reward": 998.0, "step": 378000}
{"episode": 758.0, "episode_reward": 986.0, "eval_time": 164.50067925453186, "mean_episode_reward": 986.0, "best_episode_reward": 996.0, "step": 379000}
{"episode": 760.0, "episode_reward": 982.5, "eval_time": 164.25540447235107, "mean_episode_reward": 982.5, "best_episode_reward": 994.0, "step": 380000}
{"episode": 762.0, "episode_reward": 980.2, "eval_time": 164.29866480827332, "mean_episode_reward": 980.2, "best_episode_reward": 994.0, "step": 381000}
{"episode": 764.0, "episode_reward": 971.2, "eval_time": 162.47475910186768, "mean_episode_reward": 971.2, "best_episode_reward": 979.0, "step": 382000}
{"episode": 766.0, "episode_reward": 887.3, "eval_time": 144.32092547416687, "mean_episode_reward": 887.3, "best_episode_reward": 994.0, "step": 383000}
{"episode": 768.0, "episode_reward": 985.8, "eval_time": 162.11396884918213, "mean_episode_reward": 985.8, "best_episode_reward": 994.0, "step": 384000}
{"episode": 770.0, "episode_reward": 984.0, "eval_time": 165.6137340068817, "mean_episode_reward": 984.0, "best_episode_reward": 992.0, "step": 385000}
{"episode": 772.0, "episode_reward": 984.3, "eval_time": 164.2196798324585, "mean_episode_reward": 984.3, "best_episode_reward": 992.0, "step": 386000}
{"episode": 774.0, "episode_reward": 986.1, "eval_time": 164.59708046913147, "mean_episode_reward": 986.1, "best_episode_reward": 995.0, "step": 387000}
{"episode": 776.0, "episode_reward": 985.1, "eval_time": 164.38092756271362, "mean_episode_reward": 985.1, "best_episode_reward": 992.0, "step": 388000}
{"episode": 778.0, "episode_reward": 985.5, "eval_time": 164.39484357833862, "mean_episode_reward": 985.5, "best_episode_reward": 995.0, "step": 389000}
{"episode": 780.0, "episode_reward": 984.1, "eval_time": 163.8334197998047, "mean_episode_reward": 984.1, "best_episode_reward": 994.0, "step": 390000}
{"episode": 782.0, "episode_reward": 984.4, "eval_time": 165.31744980812073, "mean_episode_reward": 984.4, "best_episode_reward": 992.0, "step": 391000}
{"episode": 784.0, "episode_reward": 978.2, "eval_time": 164.34572410583496, "mean_episode_reward": 978.2, "best_episode_reward": 990.0, "step": 392000}
{"episode": 786.0, "episode_reward": 983.9, "eval_time": 164.20472645759583, "mean_episode_reward": 983.9, "best_episode_reward": 990.0, "step": 393000}
{"episode": 788.0, "episode_reward": 981.7, "eval_time": 164.79109406471252, "mean_episode_reward": 981.7, "best_episode_reward": 994.0, "step": 394000}
{"episode": 790.0, "episode_reward": 982.7, "eval_time": 162.6660566329956, "mean_episode_reward": 982.7, "best_episode_reward": 989.0, "step": 395000}
{"episode": 792.0, "episode_reward": 987.2, "eval_time": 163.7131953239441, "mean_episode_reward": 987.2, "best_episode_reward": 994.0, "step": 396000}
{"episode": 794.0, "episode_reward": 988.2, "eval_time": 164.63031673431396, "mean_episode_reward": 988.2, "best_episode_reward": 998.0, "step": 397000}
{"episode": 796.0, "episode_reward": 986.2, "eval_time": 164.79382348060608, "mean_episode_reward": 986.2, "best_episode_reward": 992.0, "step": 398000}
{"episode": 798.0, "episode_reward": 989.1, "eval_time": 164.52760815620422, "mean_episode_reward": 989.1, "best_episode_reward": 995.0, "step": 399000}
{"episode": 800.0, "episode_reward": 979.1, "eval_time": 164.96471858024597, "mean_episode_reward": 979.1, "best_episode_reward": 992.0, "step": 400000}
{"episode": 802.0, "episode_reward": 981.8, "eval_time": 165.31397557258606, "mean_episode_reward": 981.8, "best_episode_reward": 990.0, "step": 401000}
{"episode": 804.0, "episode_reward": 990.8, "eval_time": 165.69553971290588, "mean_episode_reward": 990.8, "best_episode_reward": 997.0, "step": 402000}
{"episode": 806.0, "episode_reward": 987.3, "eval_time": 165.40850973129272, "mean_episode_reward": 987.3, "best_episode_reward": 994.0, "step": 403000}
{"episode": 808.0, "episode_reward": 986.6, "eval_time": 163.96479535102844, "mean_episode_reward": 986.6, "best_episode_reward": 994.0, "step": 404000}
{"episode": 810.0, "episode_reward": 982.0, "eval_time": 165.0125150680542, "mean_episode_reward": 982.0, "best_episode_reward": 992.0, "step": 405000}
{"episode": 812.0, "episode_reward": 985.6, "eval_time": 164.61026096343994, "mean_episode_reward": 985.6, "best_episode_reward": 995.0, "step": 406000}
{"episode": 814.0, "episode_reward": 982.1, "eval_time": 164.6196014881134, "mean_episode_reward": 982.1, "best_episode_reward": 995.0, "step": 407000}
{"episode": 816.0, "episode_reward": 984.3, "eval_time": 165.7750587463379, "mean_episode_reward": 984.3, "best_episode_reward": 997.0, "step": 408000}
{"episode": 818.0, "episode_reward": 881.8, "eval_time": 164.22055315971375, "mean_episode_reward": 881.8, "best_episode_reward": 993.0, "step": 409000}
{"episode": 820.0, "episode_reward": 984.4, "eval_time": 163.62799978256226, "mean_episode_reward": 984.4, "best_episode_reward": 992.0, "step": 410000}
{"episode": 822.0, "episode_reward": 985.0, "eval_time": 164.66073846817017, "mean_episode_reward": 985.0, "best_episode_reward": 992.0, "step": 411000}
{"episode": 824.0, "episode_reward": 986.3, "eval_time": 165.01649832725525, "mean_episode_reward": 986.3, "best_episode_reward": 995.0, "step": 412000}
{"episode": 826.0, "episode_reward": 987.3, "eval_time": 165.13348007202148, "mean_episode_reward": 987.3, "best_episode_reward": 996.0, "step": 413000}
{"episode": 828.0, "episode_reward": 982.4, "eval_time": 170.1025869846344, "mean_episode_reward": 982.4, "best_episode_reward": 994.0, "step": 414000}
{"episode": 830.0, "episode_reward": 985.4, "eval_time": 206.58393049240112, "mean_episode_reward": 985.4, "best_episode_reward": 994.0, "step": 415000}
{"episode": 832.0, "episode_reward": 991.1, "eval_time": 221.9385907649994, "mean_episode_reward": 991.1, "best_episode_reward": 997.0, "step": 416000}
{"episode": 834.0, "episode_reward": 889.2, "eval_time": 218.16760444641113, "mean_episode_reward": 889.2, "best_episode_reward": 996.0, "step": 417000}
{"episode": 836.0, "episode_reward": 980.8, "eval_time": 218.85208106040955, "mean_episode_reward": 980.8, "best_episode_reward": 994.0, "step": 418000}
{"episode": 838.0, "episode_reward": 984.9, "eval_time": 217.5251762866974, "mean_episode_reward": 984.9, "best_episode_reward": 992.0, "step": 419000}
{"episode": 840.0, "episode_reward": 980.1, "eval_time": 217.29514122009277, "mean_episode_reward": 980.1, "best_episode_reward": 990.0, "step": 420000}
{"episode": 842.0, "episode_reward": 989.7, "eval_time": 219.4614179134369, "mean_episode_reward": 989.7, "best_episode_reward": 998.0, "step": 421000}
{"episode": 844.0, "episode_reward": 984.0, "eval_time": 219.28104281425476, "mean_episode_reward": 984.0, "best_episode_reward": 992.0, "step": 422000}
{"episode": 846.0, "episode_reward": 981.8, "eval_time": 216.32691884040833, "mean_episode_reward": 981.8, "best_episode_reward": 993.0, "step": 423000}
{"episode": 848.0, "episode_reward": 785.1, "eval_time": 215.61879229545593, "mean_episode_reward": 785.1, "best_episode_reward": 991.0, "step": 424000}
{"episode": 850.0, "episode_reward": 886.6, "eval_time": 216.01551985740662, "mean_episode_reward": 886.6, "best_episode_reward": 997.0, "step": 425000}
{"episode": 852.0, "episode_reward": 982.9, "eval_time": 217.63626265525818, "mean_episode_reward": 982.9, "best_episode_reward": 998.0, "step": 426000}
{"episode": 854.0, "episode_reward": 886.1, "eval_time": 212.88256907463074, "mean_episode_reward": 886.1, "best_episode_reward": 993.0, "step": 427000}
{"episode": 856.0, "episode_reward": 983.0, "eval_time": 216.13464832305908, "mean_episode_reward": 983.0, "best_episode_reward": 989.0, "step": 428000}
{"episode": 858.0, "episode_reward": 986.7, "eval_time": 217.59257221221924, "mean_episode_reward": 986.7, "best_episode_reward": 994.0, "step": 429000}
{"episode": 860.0, "episode_reward": 985.6, "eval_time": 218.12106442451477, "mean_episode_reward": 985.6, "best_episode_reward": 993.0, "step": 430000}
{"episode": 862.0, "episode_reward": 983.8, "eval_time": 218.53961563110352, "mean_episode_reward": 983.8, "best_episode_reward": 990.0, "step": 431000}
{"episode": 864.0, "episode_reward": 987.4, "eval_time": 219.08120369911194, "mean_episode_reward": 987.4, "best_episode_reward": 993.0, "step": 432000}
{"episode": 866.0, "episode_reward": 984.2, "eval_time": 220.67713737487793, "mean_episode_reward": 984.2, "best_episode_reward": 993.0, "step": 433000}
{"episode": 868.0, "episode_reward": 984.8, "eval_time": 223.14279699325562, "mean_episode_reward": 984.8, "best_episode_reward": 996.0, "step": 434000}
{"episode": 870.0, "episode_reward": 982.7, "eval_time": 218.24370217323303, "mean_episode_reward": 982.7, "best_episode_reward": 995.0, "step": 435000}
{"episode": 872.0, "episode_reward": 985.4, "eval_time": 219.661523103714, "mean_episode_reward": 985.4, "best_episode_reward": 992.0, "step": 436000}
{"episode": 874.0, "episode_reward": 985.8, "eval_time": 214.5655539035797, "mean_episode_reward": 985.8, "best_episode_reward": 994.0, "step": 437000}
{"episode": 876.0, "episode_reward": 985.1, "eval_time": 217.71566486358643, "mean_episode_reward": 985.1, "best_episode_reward": 995.0, "step": 438000}
{"episode": 878.0, "episode_reward": 985.8, "eval_time": 216.30015993118286, "mean_episode_reward": 985.8, "best_episode_reward": 995.0, "step": 439000}
{"episode": 880.0, "episode_reward": 985.6, "eval_time": 217.66294479370117, "mean_episode_reward": 985.6, "best_episode_reward": 993.0, "step": 440000}
{"episode": 882.0, "episode_reward": 970.1, "eval_time": 217.45306515693665, "mean_episode_reward": 970.1, "best_episode_reward": 994.0, "step": 441000}
{"episode": 884.0, "episode_reward": 985.8, "eval_time": 219.91979598999023, "mean_episode_reward": 985.8, "best_episode_reward": 991.0, "step": 442000}
{"episode": 886.0, "episode_reward": 985.9, "eval_time": 216.15257048606873, "mean_episode_reward": 985.9, "best_episode_reward": 992.0, "step": 443000}
{"episode": 888.0, "episode_reward": 982.7, "eval_time": 217.700918674469, "mean_episode_reward": 982.7, "best_episode_reward": 993.0, "step": 444000}
{"episode": 890.0, "episode_reward": 983.1, "eval_time": 215.69943499565125, "mean_episode_reward": 983.1, "best_episode_reward": 990.0, "step": 445000}
{"episode": 892.0, "episode_reward": 883.9, "eval_time": 217.88192200660706, "mean_episode_reward": 883.9, "best_episode_reward": 996.0, "step": 446000}
{"episode": 894.0, "episode_reward": 985.5, "eval_time": 226.11915469169617, "mean_episode_reward": 985.5, "best_episode_reward": 994.0, "step": 447000}
{"episode": 896.0, "episode_reward": 984.6, "eval_time": 208.67297267913818, "mean_episode_reward": 984.6, "best_episode_reward": 995.0, "step": 448000}
{"episode": 898.0, "episode_reward": 984.1, "eval_time": 219.87788724899292, "mean_episode_reward": 984.1, "best_episode_reward": 992.0, "step": 449000}
{"episode": 900.0, "episode_reward": 988.5, "eval_time": 219.04170966148376, "mean_episode_reward": 988.5, "best_episode_reward": 995.0, "step": 450000}
{"episode": 902.0, "episode_reward": 886.7, "eval_time": 214.19929242134094, "mean_episode_reward": 886.7, "best_episode_reward": 993.0, "step": 451000}
{"episode": 904.0, "episode_reward": 986.4, "eval_time": 218.93815398216248, "mean_episode_reward": 986.4, "best_episode_reward": 994.0, "step": 452000}
{"episode": 906.0, "episode_reward": 983.1, "eval_time": 219.2830991744995, "mean_episode_reward": 983.1, "best_episode_reward": 992.0, "step": 453000}
{"episode": 908.0, "episode_reward": 983.4, "eval_time": 219.5474090576172, "mean_episode_reward": 983.4, "best_episode_reward": 992.0, "step": 454000}
{"episode": 910.0, "episode_reward": 978.1, "eval_time": 213.98114728927612, "mean_episode_reward": 978.1, "best_episode_reward": 990.0, "step": 455000}
{"episode": 912.0, "episode_reward": 983.4, "eval_time": 219.21981859207153, "mean_episode_reward": 983.4, "best_episode_reward": 996.0, "step": 456000}
{"episode": 914.0, "episode_reward": 984.9, "eval_time": 211.5293653011322, "mean_episode_reward": 984.9, "best_episode_reward": 997.0, "step": 457000}
{"episode": 916.0, "episode_reward": 985.9, "eval_time": 215.5677878856659, "mean_episode_reward": 985.9, "best_episode_reward": 995.0, "step": 458000}
{"episode": 918.0, "episode_reward": 981.6, "eval_time": 218.8353590965271, "mean_episode_reward": 981.6, "best_episode_reward": 998.0, "step": 459000}
{"episode": 920.0, "episode_reward": 985.1, "eval_time": 222.45954513549805, "mean_episode_reward": 985.1, "best_episode_reward": 992.0, "step": 460000}
{"episode": 922.0, "episode_reward": 984.6, "eval_time": 219.83123517036438, "mean_episode_reward": 984.6, "best_episode_reward": 993.0, "step": 461000}
{"episode": 924.0, "episode_reward": 984.5, "eval_time": 219.56289792060852, "mean_episode_reward": 984.5, "best_episode_reward": 998.0, "step": 462000}
{"episode": 926.0, "episode_reward": 986.5, "eval_time": 223.03794288635254, "mean_episode_reward": 986.5, "best_episode_reward": 994.0, "step": 463000}
{"episode": 928.0, "episode_reward": 884.4, "eval_time": 222.37706208229065, "mean_episode_reward": 884.4, "best_episode_reward": 992.0, "step": 464000}
{"episode": 930.0, "episode_reward": 987.1, "eval_time": 221.24795842170715, "mean_episode_reward": 987.1, "best_episode_reward": 991.0, "step": 465000}
{"episode": 932.0, "episode_reward": 982.9, "eval_time": 216.85289907455444, "mean_episode_reward": 982.9, "best_episode_reward": 996.0, "step": 466000}
{"episode": 934.0, "episode_reward": 984.7, "eval_time": 187.75690174102783, "mean_episode_reward": 984.7, "best_episode_reward": 994.0, "step": 467000}
{"episode": 936.0, "episode_reward": 984.9, "eval_time": 219.4782829284668, "mean_episode_reward": 984.9, "best_episode_reward": 995.0, "step": 468000}
{"episode": 938.0, "episode_reward": 982.6, "eval_time": 220.27248334884644, "mean_episode_reward": 982.6, "best_episode_reward": 997.0, "step": 469000}
{"episode": 940.0, "episode_reward": 886.3, "eval_time": 217.07907342910767, "mean_episode_reward": 886.3, "best_episode_reward": 992.0, "step": 470000}
{"episode": 942.0, "episode_reward": 985.4, "eval_time": 217.5127248764038, "mean_episode_reward": 985.4, "best_episode_reward": 994.0, "step": 471000}
{"episode": 944.0, "episode_reward": 987.8, "eval_time": 220.96481704711914, "mean_episode_reward": 987.8, "best_episode_reward": 997.0, "step": 472000}
{"episode": 946.0, "episode_reward": 978.3, "eval_time": 218.40040183067322, "mean_episode_reward": 978.3, "best_episode_reward": 992.0, "step": 473000}
{"episode": 948.0, "episode_reward": 980.1, "eval_time": 221.58791971206665, "mean_episode_reward": 980.1, "best_episode_reward": 992.0, "step": 474000}
{"episode": 950.0, "episode_reward": 983.3, "eval_time": 217.38893795013428, "mean_episode_reward": 983.3, "best_episode_reward": 994.0, "step": 475000}
{"episode": 952.0, "episode_reward": 984.9, "eval_time": 218.65068197250366, "mean_episode_reward": 984.9, "best_episode_reward": 992.0, "step": 476000}
{"episode": 954.0, "episode_reward": 987.4, "eval_time": 219.15263724327087, "mean_episode_reward": 987.4, "best_episode_reward": 993.0, "step": 477000}
{"episode": 956.0, "episode_reward": 984.8, "eval_time": 218.94029307365417, "mean_episode_reward": 984.8, "best_episode_reward": 993.0, "step": 478000}
{"episode": 958.0, "episode_reward": 981.6, "eval_time": 218.92721939086914, "mean_episode_reward": 981.6, "best_episode_reward": 994.0, "step": 479000}
{"episode": 960.0, "episode_reward": 984.1, "eval_time": 220.85129928588867, "mean_episode_reward": 984.1, "best_episode_reward": 994.0, "step": 480000}
{"episode": 962.0, "episode_reward": 983.6, "eval_time": 217.31359457969666, "mean_episode_reward": 983.6, "best_episode_reward": 994.0, "step": 481000}
{"episode": 964.0, "episode_reward": 888.9, "eval_time": 217.44357419013977, "mean_episode_reward": 888.9, "best_episode_reward": 994.0, "step": 482000}
{"episode": 966.0, "episode_reward": 984.9, "eval_time": 217.77433466911316, "mean_episode_reward": 984.9, "best_episode_reward": 990.0, "step": 483000}
{"episode": 968.0, "episode_reward": 984.9, "eval_time": 217.69896125793457, "mean_episode_reward": 984.9, "best_episode_reward": 997.0, "step": 484000}
{"episode": 970.0, "episode_reward": 989.7, "eval_time": 216.50487804412842, "mean_episode_reward": 989.7, "best_episode_reward": 992.0, "step": 485000}
{"episode": 972.0, "episode_reward": 984.1, "eval_time": 194.8374330997467, "mean_episode_reward": 984.1, "best_episode_reward": 992.0, "step": 486000}
{"episode": 974.0, "episode_reward": 983.6, "eval_time": 219.7822630405426, "mean_episode_reward": 983.6, "best_episode_reward": 995.0, "step": 487000}
{"episode": 976.0, "episode_reward": 985.4, "eval_time": 219.65433430671692, "mean_episode_reward": 985.4, "best_episode_reward": 995.0, "step": 488000}
{"episode": 978.0, "episode_reward": 985.5, "eval_time": 215.7939097881317, "mean_episode_reward": 985.5, "best_episode_reward": 995.0, "step": 489000}
{"episode": 980.0, "episode_reward": 981.4, "eval_time": 219.2416913509369, "mean_episode_reward": 981.4, "best_episode_reward": 995.0, "step": 490000}
{"episode": 982.0, "episode_reward": 987.2, "eval_time": 222.37841415405273, "mean_episode_reward": 987.2, "best_episode_reward": 995.0, "step": 491000}
{"episode": 984.0, "episode_reward": 983.2, "eval_time": 218.41255903244019, "mean_episode_reward": 983.2, "best_episode_reward": 994.0, "step": 492000}
{"episode": 986.0, "episode_reward": 968.3, "eval_time": 216.56502842903137, "mean_episode_reward": 968.3, "best_episode_reward": 992.0, "step": 493000}
{"episode": 988.0, "episode_reward": 981.6, "eval_time": 220.06607151031494, "mean_episode_reward": 981.6, "best_episode_reward": 989.0, "step": 494000}
{"episode": 990.0, "episode_reward": 985.0, "eval_time": 216.57114005088806, "mean_episode_reward": 985.0, "best_episode_reward": 998.0, "step": 495000}
{"episode": 992.0, "episode_reward": 970.7, "eval_time": 212.75139665603638, "mean_episode_reward": 970.7, "best_episode_reward": 982.0, "step": 496000}
{"episode": 994.0, "episode_reward": 984.7, "eval_time": 214.9714047908783, "mean_episode_reward": 984.7, "best_episode_reward": 994.0, "step": 497000}
{"episode": 996.0, "episode_reward": 979.7, "eval_time": 211.84145212173462, "mean_episode_reward": 979.7, "best_episode_reward": 988.0, "step": 498000}
{"episode": 998.0, "episode_reward": 986.4, "eval_time": 168.71568202972412, "mean_episode_reward": 986.4, "best_episode_reward": 995.0, "step": 499000}
