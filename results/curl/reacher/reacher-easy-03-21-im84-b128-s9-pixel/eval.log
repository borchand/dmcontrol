{"episode": 0.0, "episode_reward": 41.9, "eval_time": 30.927610158920288, "mean_episode_reward": 41.9, "best_episode_reward": 178.0, "step": 0}
{"episode": 4.0, "episode_reward": 76.8, "eval_time": 30.724153757095337, "mean_episode_reward": 76.8, "best_episode_reward": 274.0, "step": 1000}
{"episode": 8.0, "episode_reward": 4.2, "eval_time": 30.566627264022827, "mean_episode_reward": 4.2, "best_episode_reward": 18.0, "step": 2000}
{"episode": 12.0, "episode_reward": 316.1, "eval_time": 30.429269075393677, "mean_episode_reward": 316.1, "best_episode_reward": 931.0, "step": 3000}
{"episode": 16.0, "episode_reward": 279.6, "eval_time": 30.653943061828613, "mean_episode_reward": 279.6, "best_episode_reward": 982.0, "step": 4000}
{"episode": 20.0, "episode_reward": 312.0, "eval_time": 30.649869680404663, "mean_episode_reward": 312.0, "best_episode_reward": 985.0, "step": 5000}
{"episode": 24.0, "episode_reward": 356.4, "eval_time": 30.542895317077637, "mean_episode_reward": 356.4, "best_episode_reward": 978.0, "step": 6000}
{"episode": 28.0, "episode_reward": 195.6, "eval_time": 30.69601535797119, "mean_episode_reward": 195.6, "best_episode_reward": 981.0, "step": 7000}
{"episode": 32.0, "episode_reward": 330.2, "eval_time": 30.465179443359375, "mean_episode_reward": 330.2, "best_episode_reward": 969.0, "step": 8000}
{"episode": 36.0, "episode_reward": 403.3, "eval_time": 30.61138105392456, "mean_episode_reward": 403.3, "best_episode_reward": 984.0, "step": 9000}
{"episode": 40.0, "episode_reward": 505.4, "eval_time": 30.615291118621826, "mean_episode_reward": 505.4, "best_episode_reward": 978.0, "step": 10000}
{"episode": 44.0, "episode_reward": 252.9, "eval_time": 30.51972007751465, "mean_episode_reward": 252.9, "best_episode_reward": 985.0, "step": 11000}
{"episode": 48.0, "episode_reward": 599.2, "eval_time": 30.628242015838623, "mean_episode_reward": 599.2, "best_episode_reward": 980.0, "step": 12000}
{"episode": 52.0, "episode_reward": 752.6, "eval_time": 30.666706562042236, "mean_episode_reward": 752.6, "best_episode_reward": 986.0, "step": 13000}
{"episode": 56.0, "episode_reward": 390.7, "eval_time": 30.60489273071289, "mean_episode_reward": 390.7, "best_episode_reward": 966.0, "step": 14000}
{"episode": 60.0, "episode_reward": 606.9, "eval_time": 30.77012872695923, "mean_episode_reward": 606.9, "best_episode_reward": 989.0, "step": 15000}
{"episode": 64.0, "episode_reward": 688.5, "eval_time": 30.433743715286255, "mean_episode_reward": 688.5, "best_episode_reward": 1000.0, "step": 16000}
{"episode": 68.0, "episode_reward": 580.2, "eval_time": 30.615070819854736, "mean_episode_reward": 580.2, "best_episode_reward": 991.0, "step": 17000}
{"episode": 72.0, "episode_reward": 291.3, "eval_time": 30.644200563430786, "mean_episode_reward": 291.3, "best_episode_reward": 974.0, "step": 18000}
{"episode": 76.0, "episode_reward": 578.2, "eval_time": 30.541267156600952, "mean_episode_reward": 578.2, "best_episode_reward": 984.0, "step": 19000}
{"episode": 80.0, "episode_reward": 369.4, "eval_time": 30.488774299621582, "mean_episode_reward": 369.4, "best_episode_reward": 978.0, "step": 20000}
{"episode": 84.0, "episode_reward": 616.9, "eval_time": 30.61084246635437, "mean_episode_reward": 616.9, "best_episode_reward": 986.0, "step": 21000}
{"episode": 88.0, "episode_reward": 696.1, "eval_time": 30.50685477256775, "mean_episode_reward": 696.1, "best_episode_reward": 1000.0, "step": 22000}
{"episode": 92.0, "episode_reward": 486.9, "eval_time": 30.662259340286255, "mean_episode_reward": 486.9, "best_episode_reward": 988.0, "step": 23000}
{"episode": 96.0, "episode_reward": 585.3, "eval_time": 30.659014225006104, "mean_episode_reward": 585.3, "best_episode_reward": 970.0, "step": 24000}
{"episode": 100.0, "episode_reward": 740.2, "eval_time": 30.439459800720215, "mean_episode_reward": 740.2, "best_episode_reward": 984.0, "step": 25000}
{"episode": 104.0, "episode_reward": 594.9, "eval_time": 30.557722806930542, "mean_episode_reward": 594.9, "best_episode_reward": 986.0, "step": 26000}
{"episode": 108.0, "episode_reward": 680.3, "eval_time": 30.615031242370605, "mean_episode_reward": 680.3, "best_episode_reward": 975.0, "step": 27000}
{"episode": 112.0, "episode_reward": 847.3, "eval_time": 30.48239541053772, "mean_episode_reward": 847.3, "best_episode_reward": 991.0, "step": 28000}
{"episode": 116.0, "episode_reward": 761.4, "eval_time": 30.647174835205078, "mean_episode_reward": 761.4, "best_episode_reward": 997.0, "step": 29000}
{"episode": 120.0, "episode_reward": 678.3, "eval_time": 30.661241054534912, "mean_episode_reward": 678.3, "best_episode_reward": 994.0, "step": 30000}
{"episode": 124.0, "episode_reward": 583.1, "eval_time": 30.531684160232544, "mean_episode_reward": 583.1, "best_episode_reward": 998.0, "step": 31000}
{"episode": 128.0, "episode_reward": 695.8, "eval_time": 30.602863550186157, "mean_episode_reward": 695.8, "best_episode_reward": 993.0, "step": 32000}
{"episode": 132.0, "episode_reward": 679.2, "eval_time": 30.522204160690308, "mean_episode_reward": 679.2, "best_episode_reward": 997.0, "step": 33000}
{"episode": 136.0, "episode_reward": 494.1, "eval_time": 30.561903476715088, "mean_episode_reward": 494.1, "best_episode_reward": 1000.0, "step": 34000}
{"episode": 140.0, "episode_reward": 672.3, "eval_time": 30.653088569641113, "mean_episode_reward": 672.3, "best_episode_reward": 1000.0, "step": 35000}
{"episode": 144.0, "episode_reward": 843.4, "eval_time": 30.417996406555176, "mean_episode_reward": 843.4, "best_episode_reward": 997.0, "step": 36000}
{"episode": 148.0, "episode_reward": 681.8, "eval_time": 30.55222749710083, "mean_episode_reward": 681.8, "best_episode_reward": 1000.0, "step": 37000}
{"episode": 152.0, "episode_reward": 647.0, "eval_time": 30.512099504470825, "mean_episode_reward": 647.0, "best_episode_reward": 975.0, "step": 38000}
{"episode": 156.0, "episode_reward": 855.7, "eval_time": 30.45759654045105, "mean_episode_reward": 855.7, "best_episode_reward": 995.0, "step": 39000}
{"episode": 160.0, "episode_reward": 596.1, "eval_time": 30.547730684280396, "mean_episode_reward": 596.1, "best_episode_reward": 982.0, "step": 40000}
{"episode": 164.0, "episode_reward": 577.4, "eval_time": 30.631993770599365, "mean_episode_reward": 577.4, "best_episode_reward": 979.0, "step": 41000}
{"episode": 168.0, "episode_reward": 884.7, "eval_time": 30.517457008361816, "mean_episode_reward": 884.7, "best_episode_reward": 1000.0, "step": 42000}
{"episode": 172.0, "episode_reward": 803.7, "eval_time": 30.657851696014404, "mean_episode_reward": 803.7, "best_episode_reward": 970.0, "step": 43000}
{"episode": 176.0, "episode_reward": 863.6, "eval_time": 30.621097326278687, "mean_episode_reward": 863.6, "best_episode_reward": 998.0, "step": 44000}
{"episode": 180.0, "episode_reward": 649.2, "eval_time": 30.564183473587036, "mean_episode_reward": 649.2, "best_episode_reward": 989.0, "step": 45000}
{"episode": 184.0, "episode_reward": 966.5, "eval_time": 30.556264877319336, "mean_episode_reward": 966.5, "best_episode_reward": 1000.0, "step": 46000}
{"episode": 188.0, "episode_reward": 760.9, "eval_time": 30.56418752670288, "mean_episode_reward": 760.9, "best_episode_reward": 972.0, "step": 47000}
{"episode": 192.0, "episode_reward": 866.1, "eval_time": 30.60390305519104, "mean_episode_reward": 866.1, "best_episode_reward": 1000.0, "step": 48000}
{"episode": 196.0, "episode_reward": 837.1, "eval_time": 30.581979751586914, "mean_episode_reward": 837.1, "best_episode_reward": 998.0, "step": 49000}
{"episode": 200.0, "episode_reward": 778.6, "eval_time": 30.620831727981567, "mean_episode_reward": 778.6, "best_episode_reward": 994.0, "step": 50000}
{"episode": 204.0, "episode_reward": 512.8, "eval_time": 30.626431226730347, "mean_episode_reward": 512.8, "best_episode_reward": 1000.0, "step": 51000}
{"episode": 208.0, "episode_reward": 804.5, "eval_time": 30.703070163726807, "mean_episode_reward": 804.5, "best_episode_reward": 1000.0, "step": 52000}
{"episode": 212.0, "episode_reward": 966.0, "eval_time": 30.603359699249268, "mean_episode_reward": 966.0, "best_episode_reward": 1000.0, "step": 53000}
{"episode": 216.0, "episode_reward": 781.6, "eval_time": 30.736534357070923, "mean_episode_reward": 781.6, "best_episode_reward": 995.0, "step": 54000}
{"episode": 220.0, "episode_reward": 827.3, "eval_time": 30.553844928741455, "mean_episode_reward": 827.3, "best_episode_reward": 996.0, "step": 55000}
{"episode": 224.0, "episode_reward": 878.0, "eval_time": 30.67125654220581, "mean_episode_reward": 878.0, "best_episode_reward": 993.0, "step": 56000}
{"episode": 228.0, "episode_reward": 754.6, "eval_time": 30.63324475288391, "mean_episode_reward": 754.6, "best_episode_reward": 969.0, "step": 57000}
{"episode": 232.0, "episode_reward": 950.0, "eval_time": 30.719149827957153, "mean_episode_reward": 950.0, "best_episode_reward": 999.0, "step": 58000}
{"episode": 236.0, "episode_reward": 801.0, "eval_time": 30.67515516281128, "mean_episode_reward": 801.0, "best_episode_reward": 1000.0, "step": 59000}
{"episode": 240.0, "episode_reward": 763.5, "eval_time": 30.598740816116333, "mean_episode_reward": 763.5, "best_episode_reward": 998.0, "step": 60000}
{"episode": 244.0, "episode_reward": 963.6, "eval_time": 30.67328667640686, "mean_episode_reward": 963.6, "best_episode_reward": 994.0, "step": 61000}
{"episode": 248.0, "episode_reward": 836.3, "eval_time": 30.726351022720337, "mean_episode_reward": 836.3, "best_episode_reward": 1000.0, "step": 62000}
{"episode": 252.0, "episode_reward": 796.7, "eval_time": 30.55284547805786, "mean_episode_reward": 796.7, "best_episode_reward": 989.0, "step": 63000}
{"episode": 256.0, "episode_reward": 921.5, "eval_time": 30.754101991653442, "mean_episode_reward": 921.5, "best_episode_reward": 1000.0, "step": 64000}
{"episode": 260.0, "episode_reward": 885.1, "eval_time": 30.764296054840088, "mean_episode_reward": 885.1, "best_episode_reward": 1000.0, "step": 65000}
{"episode": 264.0, "episode_reward": 867.9, "eval_time": 30.57203722000122, "mean_episode_reward": 867.9, "best_episode_reward": 997.0, "step": 66000}
{"episode": 268.0, "episode_reward": 865.5, "eval_time": 30.91067385673523, "mean_episode_reward": 865.5, "best_episode_reward": 990.0, "step": 67000}
{"episode": 272.0, "episode_reward": 837.2, "eval_time": 30.805363416671753, "mean_episode_reward": 837.2, "best_episode_reward": 991.0, "step": 68000}
{"episode": 276.0, "episode_reward": 909.6, "eval_time": 30.609726190567017, "mean_episode_reward": 909.6, "best_episode_reward": 984.0, "step": 69000}
{"episode": 280.0, "episode_reward": 875.8, "eval_time": 30.83676838874817, "mean_episode_reward": 875.8, "best_episode_reward": 997.0, "step": 70000}
{"episode": 284.0, "episode_reward": 843.5, "eval_time": 30.6775381565094, "mean_episode_reward": 843.5, "best_episode_reward": 1000.0, "step": 71000}
{"episode": 288.0, "episode_reward": 965.9, "eval_time": 30.73542022705078, "mean_episode_reward": 965.9, "best_episode_reward": 987.0, "step": 72000}
{"episode": 292.0, "episode_reward": 874.9, "eval_time": 30.825522899627686, "mean_episode_reward": 874.9, "best_episode_reward": 996.0, "step": 73000}
{"episode": 296.0, "episode_reward": 872.4, "eval_time": 30.640548944473267, "mean_episode_reward": 872.4, "best_episode_reward": 998.0, "step": 74000}
{"episode": 300.0, "episode_reward": 877.2, "eval_time": 30.676011323928833, "mean_episode_reward": 877.2, "best_episode_reward": 1000.0, "step": 75000}
{"episode": 304.0, "episode_reward": 970.9, "eval_time": 30.809027433395386, "mean_episode_reward": 970.9, "best_episode_reward": 998.0, "step": 76000}
{"episode": 308.0, "episode_reward": 970.9, "eval_time": 30.71392297744751, "mean_episode_reward": 970.9, "best_episode_reward": 990.0, "step": 77000}
{"episode": 312.0, "episode_reward": 976.5, "eval_time": 30.810031175613403, "mean_episode_reward": 976.5, "best_episode_reward": 1000.0, "step": 78000}
{"episode": 316.0, "episode_reward": 946.0, "eval_time": 30.907692670822144, "mean_episode_reward": 946.0, "best_episode_reward": 980.0, "step": 79000}
{"episode": 320.0, "episode_reward": 973.8, "eval_time": 30.64874029159546, "mean_episode_reward": 973.8, "best_episode_reward": 994.0, "step": 80000}
{"episode": 324.0, "episode_reward": 785.0, "eval_time": 30.731985092163086, "mean_episode_reward": 785.0, "best_episode_reward": 981.0, "step": 81000}
{"episode": 328.0, "episode_reward": 771.7, "eval_time": 30.87321186065674, "mean_episode_reward": 771.7, "best_episode_reward": 990.0, "step": 82000}
{"episode": 332.0, "episode_reward": 946.2, "eval_time": 30.62274670600891, "mean_episode_reward": 946.2, "best_episode_reward": 997.0, "step": 83000}
{"episode": 336.0, "episode_reward": 869.4, "eval_time": 30.72652816772461, "mean_episode_reward": 869.4, "best_episode_reward": 983.0, "step": 84000}
{"episode": 340.0, "episode_reward": 958.2, "eval_time": 30.68889880180359, "mean_episode_reward": 958.2, "best_episode_reward": 982.0, "step": 85000}
{"episode": 344.0, "episode_reward": 875.7, "eval_time": 30.70233917236328, "mean_episode_reward": 875.7, "best_episode_reward": 992.0, "step": 86000}
{"episode": 348.0, "episode_reward": 821.5, "eval_time": 30.769207239151, "mean_episode_reward": 821.5, "best_episode_reward": 1000.0, "step": 87000}
{"episode": 352.0, "episode_reward": 972.8, "eval_time": 30.760629177093506, "mean_episode_reward": 972.8, "best_episode_reward": 986.0, "step": 88000}
{"episode": 356.0, "episode_reward": 965.8, "eval_time": 30.651830911636353, "mean_episode_reward": 965.8, "best_episode_reward": 993.0, "step": 89000}
{"episode": 360.0, "episode_reward": 827.0, "eval_time": 30.804861783981323, "mean_episode_reward": 827.0, "best_episode_reward": 985.0, "step": 90000}
{"episode": 364.0, "episode_reward": 873.2, "eval_time": 30.676568508148193, "mean_episode_reward": 873.2, "best_episode_reward": 993.0, "step": 91000}
{"episode": 368.0, "episode_reward": 952.0, "eval_time": 30.59734320640564, "mean_episode_reward": 952.0, "best_episode_reward": 979.0, "step": 92000}
{"episode": 372.0, "episode_reward": 920.6, "eval_time": 30.826311588287354, "mean_episode_reward": 920.6, "best_episode_reward": 990.0, "step": 93000}
{"episode": 376.0, "episode_reward": 940.7, "eval_time": 30.593809127807617, "mean_episode_reward": 940.7, "best_episode_reward": 991.0, "step": 94000}
{"episode": 380.0, "episode_reward": 825.5, "eval_time": 30.659086227416992, "mean_episode_reward": 825.5, "best_episode_reward": 988.0, "step": 95000}
{"episode": 384.0, "episode_reward": 966.3, "eval_time": 30.912758111953735, "mean_episode_reward": 966.3, "best_episode_reward": 1000.0, "step": 96000}
{"episode": 388.0, "episode_reward": 806.2, "eval_time": 30.569793462753296, "mean_episode_reward": 806.2, "best_episode_reward": 1000.0, "step": 97000}
{"episode": 392.0, "episode_reward": 965.0, "eval_time": 30.570542335510254, "mean_episode_reward": 965.0, "best_episode_reward": 994.0, "step": 98000}
{"episode": 396.0, "episode_reward": 910.9, "eval_time": 30.838537454605103, "mean_episode_reward": 910.9, "best_episode_reward": 998.0, "step": 99000}
{"episode": 400.0, "episode_reward": 968.1, "eval_time": 30.581890106201172, "mean_episode_reward": 968.1, "best_episode_reward": 988.0, "step": 100000}
{"episode": 404.0, "episode_reward": 962.8, "eval_time": 30.673651933670044, "mean_episode_reward": 962.8, "best_episode_reward": 984.0, "step": 101000}
{"episode": 408.0, "episode_reward": 971.7, "eval_time": 30.6716046333313, "mean_episode_reward": 971.7, "best_episode_reward": 989.0, "step": 102000}
{"episode": 412.0, "episode_reward": 972.6, "eval_time": 30.6060311794281, "mean_episode_reward": 972.6, "best_episode_reward": 988.0, "step": 103000}
{"episode": 416.0, "episode_reward": 770.5, "eval_time": 30.693440675735474, "mean_episode_reward": 770.5, "best_episode_reward": 974.0, "step": 104000}
{"episode": 420.0, "episode_reward": 872.0, "eval_time": 30.596038579940796, "mean_episode_reward": 872.0, "best_episode_reward": 987.0, "step": 105000}
{"episode": 424.0, "episode_reward": 980.7, "eval_time": 30.560585975646973, "mean_episode_reward": 980.7, "best_episode_reward": 1000.0, "step": 106000}
{"episode": 428.0, "episode_reward": 946.1, "eval_time": 30.570488691329956, "mean_episode_reward": 946.1, "best_episode_reward": 999.0, "step": 107000}
{"episode": 432.0, "episode_reward": 978.2, "eval_time": 30.637404203414917, "mean_episode_reward": 978.2, "best_episode_reward": 997.0, "step": 108000}
{"episode": 436.0, "episode_reward": 965.8, "eval_time": 30.650039672851562, "mean_episode_reward": 965.8, "best_episode_reward": 991.0, "step": 109000}
{"episode": 440.0, "episode_reward": 768.2, "eval_time": 30.71354389190674, "mean_episode_reward": 768.2, "best_episode_reward": 984.0, "step": 110000}
{"episode": 444.0, "episode_reward": 966.8, "eval_time": 30.60501527786255, "mean_episode_reward": 966.8, "best_episode_reward": 987.0, "step": 111000}
{"episode": 448.0, "episode_reward": 872.5, "eval_time": 30.593692541122437, "mean_episode_reward": 872.5, "best_episode_reward": 1000.0, "step": 112000}
{"episode": 452.0, "episode_reward": 898.0, "eval_time": 30.576846837997437, "mean_episode_reward": 898.0, "best_episode_reward": 997.0, "step": 113000}
{"episode": 456.0, "episode_reward": 962.2, "eval_time": 30.476600170135498, "mean_episode_reward": 962.2, "best_episode_reward": 996.0, "step": 114000}
{"episode": 460.0, "episode_reward": 966.3, "eval_time": 30.518053770065308, "mean_episode_reward": 966.3, "best_episode_reward": 988.0, "step": 115000}
{"episode": 464.0, "episode_reward": 965.5, "eval_time": 30.624738454818726, "mean_episode_reward": 965.5, "best_episode_reward": 998.0, "step": 116000}
{"episode": 468.0, "episode_reward": 978.0, "eval_time": 30.629818439483643, "mean_episode_reward": 978.0, "best_episode_reward": 993.0, "step": 117000}
{"episode": 472.0, "episode_reward": 978.9, "eval_time": 30.600892543792725, "mean_episode_reward": 978.9, "best_episode_reward": 999.0, "step": 118000}
{"episode": 476.0, "episode_reward": 868.1, "eval_time": 30.586066246032715, "mean_episode_reward": 868.1, "best_episode_reward": 997.0, "step": 119000}
{"episode": 480.0, "episode_reward": 926.1, "eval_time": 30.47862148284912, "mean_episode_reward": 926.1, "best_episode_reward": 990.0, "step": 120000}
{"episode": 484.0, "episode_reward": 968.9, "eval_time": 30.648305416107178, "mean_episode_reward": 968.9, "best_episode_reward": 995.0, "step": 121000}
{"episode": 488.0, "episode_reward": 983.2, "eval_time": 30.607450246810913, "mean_episode_reward": 983.2, "best_episode_reward": 1000.0, "step": 122000}
{"episode": 492.0, "episode_reward": 966.1, "eval_time": 30.538174629211426, "mean_episode_reward": 966.1, "best_episode_reward": 990.0, "step": 123000}
{"episode": 496.0, "episode_reward": 957.6, "eval_time": 30.575279474258423, "mean_episode_reward": 957.6, "best_episode_reward": 989.0, "step": 124000}
{"episode": 500.0, "episode_reward": 974.0, "eval_time": 30.468071699142456, "mean_episode_reward": 974.0, "best_episode_reward": 1000.0, "step": 125000}
{"episode": 504.0, "episode_reward": 977.3, "eval_time": 30.465832233428955, "mean_episode_reward": 977.3, "best_episode_reward": 1000.0, "step": 126000}
{"episode": 508.0, "episode_reward": 881.9, "eval_time": 30.593051433563232, "mean_episode_reward": 881.9, "best_episode_reward": 999.0, "step": 127000}
{"episode": 512.0, "episode_reward": 797.0, "eval_time": 30.446104049682617, "mean_episode_reward": 797.0, "best_episode_reward": 998.0, "step": 128000}
{"episode": 516.0, "episode_reward": 972.6, "eval_time": 30.558107376098633, "mean_episode_reward": 972.6, "best_episode_reward": 979.0, "step": 129000}
{"episode": 520.0, "episode_reward": 953.0, "eval_time": 30.526228666305542, "mean_episode_reward": 953.0, "best_episode_reward": 978.0, "step": 130000}
{"episode": 524.0, "episode_reward": 877.1, "eval_time": 30.59842610359192, "mean_episode_reward": 877.1, "best_episode_reward": 1000.0, "step": 131000}
{"episode": 528.0, "episode_reward": 982.2, "eval_time": 30.58702564239502, "mean_episode_reward": 982.2, "best_episode_reward": 998.0, "step": 132000}
{"episode": 532.0, "episode_reward": 983.0, "eval_time": 30.50967764854431, "mean_episode_reward": 983.0, "best_episode_reward": 1000.0, "step": 133000}
{"episode": 536.0, "episode_reward": 979.6, "eval_time": 30.544109106063843, "mean_episode_reward": 979.6, "best_episode_reward": 990.0, "step": 134000}
{"episode": 540.0, "episode_reward": 971.5, "eval_time": 30.589736461639404, "mean_episode_reward": 971.5, "best_episode_reward": 994.0, "step": 135000}
{"episode": 544.0, "episode_reward": 971.8, "eval_time": 30.548942804336548, "mean_episode_reward": 971.8, "best_episode_reward": 997.0, "step": 136000}
{"episode": 548.0, "episode_reward": 811.4, "eval_time": 30.53883194923401, "mean_episode_reward": 811.4, "best_episode_reward": 988.0, "step": 137000}
{"episode": 552.0, "episode_reward": 872.9, "eval_time": 30.65376615524292, "mean_episode_reward": 872.9, "best_episode_reward": 994.0, "step": 138000}
{"episode": 556.0, "episode_reward": 980.8, "eval_time": 30.455243825912476, "mean_episode_reward": 980.8, "best_episode_reward": 999.0, "step": 139000}
{"episode": 560.0, "episode_reward": 975.3, "eval_time": 30.52112889289856, "mean_episode_reward": 975.3, "best_episode_reward": 1000.0, "step": 140000}
{"episode": 564.0, "episode_reward": 975.3, "eval_time": 30.56118941307068, "mean_episode_reward": 975.3, "best_episode_reward": 996.0, "step": 141000}
{"episode": 568.0, "episode_reward": 870.6, "eval_time": 30.390462160110474, "mean_episode_reward": 870.6, "best_episode_reward": 992.0, "step": 142000}
{"episode": 572.0, "episode_reward": 977.7, "eval_time": 30.184925079345703, "mean_episode_reward": 977.7, "best_episode_reward": 994.0, "step": 143000}
{"episode": 576.0, "episode_reward": 970.9, "eval_time": 30.119698524475098, "mean_episode_reward": 970.9, "best_episode_reward": 998.0, "step": 144000}
{"episode": 580.0, "episode_reward": 772.7, "eval_time": 30.117413997650146, "mean_episode_reward": 772.7, "best_episode_reward": 988.0, "step": 145000}
{"episode": 584.0, "episode_reward": 970.3, "eval_time": 30.135066509246826, "mean_episode_reward": 970.3, "best_episode_reward": 996.0, "step": 146000}
{"episode": 588.0, "episode_reward": 932.3, "eval_time": 30.188982486724854, "mean_episode_reward": 932.3, "best_episode_reward": 990.0, "step": 147000}
{"episode": 592.0, "episode_reward": 963.0, "eval_time": 30.131617784500122, "mean_episode_reward": 963.0, "best_episode_reward": 985.0, "step": 148000}
{"episode": 596.0, "episode_reward": 974.6, "eval_time": 30.121434688568115, "mean_episode_reward": 974.6, "best_episode_reward": 990.0, "step": 149000}
{"episode": 600.0, "episode_reward": 979.2, "eval_time": 30.104790925979614, "mean_episode_reward": 979.2, "best_episode_reward": 1000.0, "step": 150000}
{"episode": 604.0, "episode_reward": 976.0, "eval_time": 30.072513341903687, "mean_episode_reward": 976.0, "best_episode_reward": 1000.0, "step": 151000}
{"episode": 608.0, "episode_reward": 976.3, "eval_time": 30.188365697860718, "mean_episode_reward": 976.3, "best_episode_reward": 998.0, "step": 152000}
{"episode": 612.0, "episode_reward": 973.5, "eval_time": 30.096656799316406, "mean_episode_reward": 973.5, "best_episode_reward": 998.0, "step": 153000}
{"episode": 616.0, "episode_reward": 886.2, "eval_time": 30.042102575302124, "mean_episode_reward": 886.2, "best_episode_reward": 1000.0, "step": 154000}
{"episode": 620.0, "episode_reward": 943.4, "eval_time": 30.264628171920776, "mean_episode_reward": 943.4, "best_episode_reward": 995.0, "step": 155000}
{"episode": 624.0, "episode_reward": 967.6, "eval_time": 29.77762198448181, "mean_episode_reward": 967.6, "best_episode_reward": 997.0, "step": 156000}
{"episode": 628.0, "episode_reward": 981.1, "eval_time": 29.475691556930542, "mean_episode_reward": 981.1, "best_episode_reward": 1000.0, "step": 157000}
{"episode": 632.0, "episode_reward": 967.8, "eval_time": 29.69060468673706, "mean_episode_reward": 967.8, "best_episode_reward": 996.0, "step": 158000}
{"episode": 636.0, "episode_reward": 968.9, "eval_time": 29.500977039337158, "mean_episode_reward": 968.9, "best_episode_reward": 988.0, "step": 159000}
{"episode": 640.0, "episode_reward": 976.2, "eval_time": 29.50295853614807, "mean_episode_reward": 976.2, "best_episode_reward": 987.0, "step": 160000}
{"episode": 644.0, "episode_reward": 873.8, "eval_time": 29.511451721191406, "mean_episode_reward": 873.8, "best_episode_reward": 986.0, "step": 161000}
{"episode": 648.0, "episode_reward": 880.9, "eval_time": 29.508920669555664, "mean_episode_reward": 880.9, "best_episode_reward": 1000.0, "step": 162000}
{"episode": 652.0, "episode_reward": 964.9, "eval_time": 29.478433847427368, "mean_episode_reward": 964.9, "best_episode_reward": 990.0, "step": 163000}
{"episode": 656.0, "episode_reward": 982.8, "eval_time": 29.653871774673462, "mean_episode_reward": 982.8, "best_episode_reward": 1000.0, "step": 164000}
{"episode": 660.0, "episode_reward": 969.8, "eval_time": 29.574101448059082, "mean_episode_reward": 969.8, "best_episode_reward": 991.0, "step": 165000}
{"episode": 664.0, "episode_reward": 970.5, "eval_time": 29.53575611114502, "mean_episode_reward": 970.5, "best_episode_reward": 999.0, "step": 166000}
{"episode": 668.0, "episode_reward": 973.5, "eval_time": 29.611011743545532, "mean_episode_reward": 973.5, "best_episode_reward": 986.0, "step": 167000}
{"episode": 672.0, "episode_reward": 971.3, "eval_time": 29.48236656188965, "mean_episode_reward": 971.3, "best_episode_reward": 984.0, "step": 168000}
{"episode": 676.0, "episode_reward": 969.5, "eval_time": 29.475494861602783, "mean_episode_reward": 969.5, "best_episode_reward": 987.0, "step": 169000}
{"episode": 680.0, "episode_reward": 980.1, "eval_time": 29.624463319778442, "mean_episode_reward": 980.1, "best_episode_reward": 1000.0, "step": 170000}
{"episode": 684.0, "episode_reward": 869.0, "eval_time": 29.51039958000183, "mean_episode_reward": 869.0, "best_episode_reward": 989.0, "step": 171000}
{"episode": 688.0, "episode_reward": 894.1, "eval_time": 29.533642292022705, "mean_episode_reward": 894.1, "best_episode_reward": 993.0, "step": 172000}
{"episode": 692.0, "episode_reward": 880.9, "eval_time": 29.649856090545654, "mean_episode_reward": 880.9, "best_episode_reward": 994.0, "step": 173000}
{"episode": 696.0, "episode_reward": 976.5, "eval_time": 29.457737684249878, "mean_episode_reward": 976.5, "best_episode_reward": 996.0, "step": 174000}
{"episode": 700.0, "episode_reward": 875.9, "eval_time": 29.61643671989441, "mean_episode_reward": 875.9, "best_episode_reward": 1000.0, "step": 175000}
{"episode": 704.0, "episode_reward": 868.3, "eval_time": 29.56249451637268, "mean_episode_reward": 868.3, "best_episode_reward": 1000.0, "step": 176000}
{"episode": 708.0, "episode_reward": 771.0, "eval_time": 29.52454924583435, "mean_episode_reward": 771.0, "best_episode_reward": 986.0, "step": 177000}
{"episode": 712.0, "episode_reward": 869.0, "eval_time": 29.569680213928223, "mean_episode_reward": 869.0, "best_episode_reward": 983.0, "step": 178000}
{"episode": 716.0, "episode_reward": 884.9, "eval_time": 29.58913493156433, "mean_episode_reward": 884.9, "best_episode_reward": 989.0, "step": 179000}
{"episode": 720.0, "episode_reward": 953.6, "eval_time": 29.55940318107605, "mean_episode_reward": 953.6, "best_episode_reward": 997.0, "step": 180000}
{"episode": 724.0, "episode_reward": 974.5, "eval_time": 29.720866918563843, "mean_episode_reward": 974.5, "best_episode_reward": 994.0, "step": 181000}
{"episode": 728.0, "episode_reward": 920.0, "eval_time": 29.78386116027832, "mean_episode_reward": 920.0, "best_episode_reward": 1000.0, "step": 182000}
{"episode": 732.0, "episode_reward": 941.0, "eval_time": 29.725152254104614, "mean_episode_reward": 941.0, "best_episode_reward": 991.0, "step": 183000}
{"episode": 736.0, "episode_reward": 975.4, "eval_time": 29.67858076095581, "mean_episode_reward": 975.4, "best_episode_reward": 994.0, "step": 184000}
{"episode": 740.0, "episode_reward": 981.5, "eval_time": 29.70857548713684, "mean_episode_reward": 981.5, "best_episode_reward": 999.0, "step": 185000}
{"episode": 744.0, "episode_reward": 967.9, "eval_time": 29.67893099784851, "mean_episode_reward": 967.9, "best_episode_reward": 994.0, "step": 186000}
{"episode": 748.0, "episode_reward": 971.4, "eval_time": 29.685381174087524, "mean_episode_reward": 971.4, "best_episode_reward": 994.0, "step": 187000}
{"episode": 752.0, "episode_reward": 968.8, "eval_time": 29.709794998168945, "mean_episode_reward": 968.8, "best_episode_reward": 986.0, "step": 188000}
{"episode": 756.0, "episode_reward": 980.3, "eval_time": 29.732816219329834, "mean_episode_reward": 980.3, "best_episode_reward": 1000.0, "step": 189000}
{"episode": 760.0, "episode_reward": 869.0, "eval_time": 29.75557041168213, "mean_episode_reward": 869.0, "best_episode_reward": 1000.0, "step": 190000}
{"episode": 764.0, "episode_reward": 964.7, "eval_time": 29.688695669174194, "mean_episode_reward": 964.7, "best_episode_reward": 996.0, "step": 191000}
{"episode": 768.0, "episode_reward": 976.1, "eval_time": 29.757518529891968, "mean_episode_reward": 976.1, "best_episode_reward": 989.0, "step": 192000}
{"episode": 772.0, "episode_reward": 977.3, "eval_time": 29.69999861717224, "mean_episode_reward": 977.3, "best_episode_reward": 1000.0, "step": 193000}
{"episode": 776.0, "episode_reward": 967.3, "eval_time": 29.67121648788452, "mean_episode_reward": 967.3, "best_episode_reward": 996.0, "step": 194000}
{"episode": 780.0, "episode_reward": 979.5, "eval_time": 29.633299112319946, "mean_episode_reward": 979.5, "best_episode_reward": 996.0, "step": 195000}
{"episode": 784.0, "episode_reward": 980.0, "eval_time": 29.760009765625, "mean_episode_reward": 980.0, "best_episode_reward": 1000.0, "step": 196000}
{"episode": 788.0, "episode_reward": 876.8, "eval_time": 29.71337127685547, "mean_episode_reward": 876.8, "best_episode_reward": 997.0, "step": 197000}
{"episode": 792.0, "episode_reward": 971.0, "eval_time": 29.714306116104126, "mean_episode_reward": 971.0, "best_episode_reward": 1000.0, "step": 198000}
{"episode": 796.0, "episode_reward": 976.2, "eval_time": 29.72837233543396, "mean_episode_reward": 976.2, "best_episode_reward": 991.0, "step": 199000}
{"episode": 800.0, "episode_reward": 929.6, "eval_time": 29.200150966644287, "mean_episode_reward": 929.6, "best_episode_reward": 990.0, "step": 200000}
{"episode": 804.0, "episode_reward": 883.6, "eval_time": 29.080673694610596, "mean_episode_reward": 883.6, "best_episode_reward": 1000.0, "step": 201000}
{"episode": 808.0, "episode_reward": 974.7, "eval_time": 29.175363779067993, "mean_episode_reward": 974.7, "best_episode_reward": 992.0, "step": 202000}
{"episode": 812.0, "episode_reward": 970.2, "eval_time": 29.06461501121521, "mean_episode_reward": 970.2, "best_episode_reward": 998.0, "step": 203000}
{"episode": 816.0, "episode_reward": 977.7, "eval_time": 29.04239797592163, "mean_episode_reward": 977.7, "best_episode_reward": 987.0, "step": 204000}
{"episode": 820.0, "episode_reward": 973.9, "eval_time": 29.06216073036194, "mean_episode_reward": 973.9, "best_episode_reward": 997.0, "step": 205000}
{"episode": 824.0, "episode_reward": 968.8, "eval_time": 29.054413318634033, "mean_episode_reward": 968.8, "best_episode_reward": 990.0, "step": 206000}
{"episode": 828.0, "episode_reward": 971.6, "eval_time": 29.089807748794556, "mean_episode_reward": 971.6, "best_episode_reward": 987.0, "step": 207000}
{"episode": 832.0, "episode_reward": 981.2, "eval_time": 29.120504140853882, "mean_episode_reward": 981.2, "best_episode_reward": 1000.0, "step": 208000}
{"episode": 836.0, "episode_reward": 856.1, "eval_time": 29.077176332473755, "mean_episode_reward": 856.1, "best_episode_reward": 984.0, "step": 209000}
{"episode": 840.0, "episode_reward": 976.8, "eval_time": 29.074170112609863, "mean_episode_reward": 976.8, "best_episode_reward": 998.0, "step": 210000}
{"episode": 844.0, "episode_reward": 952.8, "eval_time": 29.081445693969727, "mean_episode_reward": 952.8, "best_episode_reward": 993.0, "step": 211000}
{"episode": 848.0, "episode_reward": 979.3, "eval_time": 29.144613027572632, "mean_episode_reward": 979.3, "best_episode_reward": 993.0, "step": 212000}
{"episode": 852.0, "episode_reward": 964.8, "eval_time": 29.12000846862793, "mean_episode_reward": 964.8, "best_episode_reward": 1000.0, "step": 213000}
{"episode": 856.0, "episode_reward": 967.6, "eval_time": 29.1116464138031, "mean_episode_reward": 967.6, "best_episode_reward": 988.0, "step": 214000}
{"episode": 860.0, "episode_reward": 969.1, "eval_time": 29.087334632873535, "mean_episode_reward": 969.1, "best_episode_reward": 992.0, "step": 215000}
{"episode": 864.0, "episode_reward": 977.3, "eval_time": 29.095565795898438, "mean_episode_reward": 977.3, "best_episode_reward": 994.0, "step": 216000}
{"episode": 868.0, "episode_reward": 961.7, "eval_time": 29.089911937713623, "mean_episode_reward": 961.7, "best_episode_reward": 987.0, "step": 217000}
{"episode": 872.0, "episode_reward": 972.1, "eval_time": 29.099709272384644, "mean_episode_reward": 972.1, "best_episode_reward": 984.0, "step": 218000}
{"episode": 876.0, "episode_reward": 974.0, "eval_time": 29.10568118095398, "mean_episode_reward": 974.0, "best_episode_reward": 988.0, "step": 219000}
{"episode": 880.0, "episode_reward": 876.7, "eval_time": 29.132331371307373, "mean_episode_reward": 876.7, "best_episode_reward": 996.0, "step": 220000}
{"episode": 884.0, "episode_reward": 869.9, "eval_time": 29.13353705406189, "mean_episode_reward": 869.9, "best_episode_reward": 1000.0, "step": 221000}
{"episode": 888.0, "episode_reward": 971.6, "eval_time": 29.147974491119385, "mean_episode_reward": 971.6, "best_episode_reward": 996.0, "step": 222000}
{"episode": 892.0, "episode_reward": 971.3, "eval_time": 29.11338973045349, "mean_episode_reward": 971.3, "best_episode_reward": 992.0, "step": 223000}
{"episode": 896.0, "episode_reward": 969.4, "eval_time": 29.106114149093628, "mean_episode_reward": 969.4, "best_episode_reward": 990.0, "step": 224000}
{"episode": 900.0, "episode_reward": 976.2, "eval_time": 29.12121033668518, "mean_episode_reward": 976.2, "best_episode_reward": 991.0, "step": 225000}
{"episode": 904.0, "episode_reward": 969.7, "eval_time": 29.10631012916565, "mean_episode_reward": 969.7, "best_episode_reward": 994.0, "step": 226000}
{"episode": 908.0, "episode_reward": 975.3, "eval_time": 29.102712392807007, "mean_episode_reward": 975.3, "best_episode_reward": 994.0, "step": 227000}
{"episode": 912.0, "episode_reward": 977.5, "eval_time": 29.116735458374023, "mean_episode_reward": 977.5, "best_episode_reward": 1000.0, "step": 228000}
{"episode": 916.0, "episode_reward": 970.8, "eval_time": 29.104926109313965, "mean_episode_reward": 970.8, "best_episode_reward": 994.0, "step": 229000}
{"episode": 920.0, "episode_reward": 977.1, "eval_time": 29.117848873138428, "mean_episode_reward": 977.1, "best_episode_reward": 1000.0, "step": 230000}
{"episode": 924.0, "episode_reward": 985.5, "eval_time": 29.060310125350952, "mean_episode_reward": 985.5, "best_episode_reward": 1000.0, "step": 231000}
{"episode": 928.0, "episode_reward": 794.6, "eval_time": 29.087448596954346, "mean_episode_reward": 794.6, "best_episode_reward": 982.0, "step": 232000}
{"episode": 932.0, "episode_reward": 866.3, "eval_time": 29.117600202560425, "mean_episode_reward": 866.3, "best_episode_reward": 977.0, "step": 233000}
{"episode": 936.0, "episode_reward": 976.3, "eval_time": 29.051222801208496, "mean_episode_reward": 976.3, "best_episode_reward": 990.0, "step": 234000}
{"episode": 940.0, "episode_reward": 968.0, "eval_time": 29.07154607772827, "mean_episode_reward": 968.0, "best_episode_reward": 993.0, "step": 235000}
{"episode": 944.0, "episode_reward": 977.4, "eval_time": 29.10931944847107, "mean_episode_reward": 977.4, "best_episode_reward": 997.0, "step": 236000}
{"episode": 948.0, "episode_reward": 965.2, "eval_time": 29.00075936317444, "mean_episode_reward": 965.2, "best_episode_reward": 989.0, "step": 237000}
{"episode": 952.0, "episode_reward": 971.9, "eval_time": 29.14315414428711, "mean_episode_reward": 971.9, "best_episode_reward": 1000.0, "step": 238000}
{"episode": 956.0, "episode_reward": 931.0, "eval_time": 29.172346830368042, "mean_episode_reward": 931.0, "best_episode_reward": 992.0, "step": 239000}
{"episode": 960.0, "episode_reward": 970.9, "eval_time": 29.124410390853882, "mean_episode_reward": 970.9, "best_episode_reward": 998.0, "step": 240000}
{"episode": 964.0, "episode_reward": 978.1, "eval_time": 29.089349031448364, "mean_episode_reward": 978.1, "best_episode_reward": 1000.0, "step": 241000}
{"episode": 968.0, "episode_reward": 979.8, "eval_time": 29.19398260116577, "mean_episode_reward": 979.8, "best_episode_reward": 1000.0, "step": 242000}
{"episode": 972.0, "episode_reward": 967.3, "eval_time": 29.015313863754272, "mean_episode_reward": 967.3, "best_episode_reward": 987.0, "step": 243000}
{"episode": 976.0, "episode_reward": 971.8, "eval_time": 29.093100547790527, "mean_episode_reward": 971.8, "best_episode_reward": 990.0, "step": 244000}
{"episode": 980.0, "episode_reward": 967.5, "eval_time": 29.121631145477295, "mean_episode_reward": 967.5, "best_episode_reward": 989.0, "step": 245000}
{"episode": 984.0, "episode_reward": 974.0, "eval_time": 28.983922958374023, "mean_episode_reward": 974.0, "best_episode_reward": 999.0, "step": 246000}
{"episode": 988.0, "episode_reward": 980.7, "eval_time": 29.10616159439087, "mean_episode_reward": 980.7, "best_episode_reward": 1000.0, "step": 247000}
{"episode": 992.0, "episode_reward": 972.2, "eval_time": 29.127681493759155, "mean_episode_reward": 972.2, "best_episode_reward": 985.0, "step": 248000}
{"episode": 996.0, "episode_reward": 975.6, "eval_time": 29.06281805038452, "mean_episode_reward": 975.6, "best_episode_reward": 992.0, "step": 249000}
{"episode": 1000.0, "episode_reward": 975.6, "eval_time": 29.04843306541443, "mean_episode_reward": 975.6, "best_episode_reward": 982.0, "step": 250000}
{"episode": 1004.0, "episode_reward": 961.6, "eval_time": 29.120834827423096, "mean_episode_reward": 961.6, "best_episode_reward": 996.0, "step": 251000}
{"episode": 1008.0, "episode_reward": 978.0, "eval_time": 29.119731903076172, "mean_episode_reward": 978.0, "best_episode_reward": 999.0, "step": 252000}
{"episode": 1012.0, "episode_reward": 956.6, "eval_time": 29.148130893707275, "mean_episode_reward": 956.6, "best_episode_reward": 997.0, "step": 253000}
{"episode": 1016.0, "episode_reward": 969.0, "eval_time": 29.073167085647583, "mean_episode_reward": 969.0, "best_episode_reward": 998.0, "step": 254000}
{"episode": 1020.0, "episode_reward": 768.1, "eval_time": 29.121203184127808, "mean_episode_reward": 768.1, "best_episode_reward": 1000.0, "step": 255000}
{"episode": 1024.0, "episode_reward": 782.4, "eval_time": 29.04362201690674, "mean_episode_reward": 782.4, "best_episode_reward": 990.0, "step": 256000}
{"episode": 1028.0, "episode_reward": 977.2, "eval_time": 29.035783529281616, "mean_episode_reward": 977.2, "best_episode_reward": 998.0, "step": 257000}
{"episode": 1032.0, "episode_reward": 976.2, "eval_time": 29.135639190673828, "mean_episode_reward": 976.2, "best_episode_reward": 990.0, "step": 258000}
{"episode": 1036.0, "episode_reward": 975.0, "eval_time": 29.127756118774414, "mean_episode_reward": 975.0, "best_episode_reward": 998.0, "step": 259000}
{"episode": 1040.0, "episode_reward": 972.9, "eval_time": 29.031440496444702, "mean_episode_reward": 972.9, "best_episode_reward": 1000.0, "step": 260000}
{"episode": 1044.0, "episode_reward": 977.9, "eval_time": 29.101582050323486, "mean_episode_reward": 977.9, "best_episode_reward": 1000.0, "step": 261000}
{"episode": 1048.0, "episode_reward": 980.1, "eval_time": 29.186132669448853, "mean_episode_reward": 980.1, "best_episode_reward": 998.0, "step": 262000}
{"episode": 1052.0, "episode_reward": 883.6, "eval_time": 29.075745820999146, "mean_episode_reward": 883.6, "best_episode_reward": 1000.0, "step": 263000}
{"episode": 1056.0, "episode_reward": 977.3, "eval_time": 29.05508065223694, "mean_episode_reward": 977.3, "best_episode_reward": 986.0, "step": 264000}
{"episode": 1060.0, "episode_reward": 972.0, "eval_time": 29.208701610565186, "mean_episode_reward": 972.0, "best_episode_reward": 991.0, "step": 265000}
{"episode": 1064.0, "episode_reward": 969.3, "eval_time": 29.109642267227173, "mean_episode_reward": 969.3, "best_episode_reward": 1000.0, "step": 266000}
{"episode": 1068.0, "episode_reward": 977.3, "eval_time": 29.127054691314697, "mean_episode_reward": 977.3, "best_episode_reward": 998.0, "step": 267000}
{"episode": 1072.0, "episode_reward": 873.7, "eval_time": 29.14397692680359, "mean_episode_reward": 873.7, "best_episode_reward": 994.0, "step": 268000}
{"episode": 1076.0, "episode_reward": 976.8, "eval_time": 29.048637866973877, "mean_episode_reward": 976.8, "best_episode_reward": 1000.0, "step": 269000}
{"episode": 1080.0, "episode_reward": 877.9, "eval_time": 29.086556911468506, "mean_episode_reward": 877.9, "best_episode_reward": 994.0, "step": 270000}
{"episode": 1084.0, "episode_reward": 971.5, "eval_time": 29.163212060928345, "mean_episode_reward": 971.5, "best_episode_reward": 989.0, "step": 271000}
{"episode": 1088.0, "episode_reward": 978.7, "eval_time": 29.058892488479614, "mean_episode_reward": 978.7, "best_episode_reward": 1000.0, "step": 272000}
{"episode": 1092.0, "episode_reward": 977.3, "eval_time": 29.09885811805725, "mean_episode_reward": 977.3, "best_episode_reward": 988.0, "step": 273000}
{"episode": 1096.0, "episode_reward": 912.4, "eval_time": 29.15218162536621, "mean_episode_reward": 912.4, "best_episode_reward": 997.0, "step": 274000}
{"episode": 1100.0, "episode_reward": 957.1, "eval_time": 29.03747296333313, "mean_episode_reward": 957.1, "best_episode_reward": 994.0, "step": 275000}
{"episode": 1104.0, "episode_reward": 970.4, "eval_time": 29.191357135772705, "mean_episode_reward": 970.4, "best_episode_reward": 996.0, "step": 276000}
{"episode": 1108.0, "episode_reward": 973.5, "eval_time": 29.09689950942993, "mean_episode_reward": 973.5, "best_episode_reward": 993.0, "step": 277000}
{"episode": 1112.0, "episode_reward": 972.9, "eval_time": 29.061372756958008, "mean_episode_reward": 972.9, "best_episode_reward": 990.0, "step": 278000}
{"episode": 1116.0, "episode_reward": 879.3, "eval_time": 29.18262815475464, "mean_episode_reward": 879.3, "best_episode_reward": 1000.0, "step": 279000}
{"episode": 1120.0, "episode_reward": 973.8, "eval_time": 29.1694176197052, "mean_episode_reward": 973.8, "best_episode_reward": 992.0, "step": 280000}
{"episode": 1124.0, "episode_reward": 975.1, "eval_time": 29.032032012939453, "mean_episode_reward": 975.1, "best_episode_reward": 1000.0, "step": 281000}
{"episode": 1128.0, "episode_reward": 969.3, "eval_time": 29.1583309173584, "mean_episode_reward": 969.3, "best_episode_reward": 1000.0, "step": 282000}
{"episode": 1132.0, "episode_reward": 967.3, "eval_time": 29.15879201889038, "mean_episode_reward": 967.3, "best_episode_reward": 976.0, "step": 283000}
{"episode": 1136.0, "episode_reward": 975.8, "eval_time": 29.04159164428711, "mean_episode_reward": 975.8, "best_episode_reward": 991.0, "step": 284000}
{"episode": 1140.0, "episode_reward": 865.3, "eval_time": 29.05011534690857, "mean_episode_reward": 865.3, "best_episode_reward": 983.0, "step": 285000}
{"episode": 1144.0, "episode_reward": 700.9, "eval_time": 29.137823343276978, "mean_episode_reward": 700.9, "best_episode_reward": 992.0, "step": 286000}
{"episode": 1148.0, "episode_reward": 859.3, "eval_time": 29.15135407447815, "mean_episode_reward": 859.3, "best_episode_reward": 1000.0, "step": 287000}
{"episode": 1152.0, "episode_reward": 975.8, "eval_time": 29.049651861190796, "mean_episode_reward": 975.8, "best_episode_reward": 991.0, "step": 288000}
{"episode": 1156.0, "episode_reward": 947.2, "eval_time": 29.08272624015808, "mean_episode_reward": 947.2, "best_episode_reward": 1000.0, "step": 289000}
{"episode": 1160.0, "episode_reward": 974.1, "eval_time": 29.084113597869873, "mean_episode_reward": 974.1, "best_episode_reward": 995.0, "step": 290000}
{"episode": 1164.0, "episode_reward": 885.1, "eval_time": 29.10567855834961, "mean_episode_reward": 885.1, "best_episode_reward": 1000.0, "step": 291000}
{"episode": 1168.0, "episode_reward": 781.4, "eval_time": 29.10542345046997, "mean_episode_reward": 781.4, "best_episode_reward": 996.0, "step": 292000}
{"episode": 1172.0, "episode_reward": 981.5, "eval_time": 29.083751916885376, "mean_episode_reward": 981.5, "best_episode_reward": 994.0, "step": 293000}
{"episode": 1176.0, "episode_reward": 875.4, "eval_time": 29.058547496795654, "mean_episode_reward": 875.4, "best_episode_reward": 986.0, "step": 294000}
{"episode": 1180.0, "episode_reward": 972.5, "eval_time": 29.090941429138184, "mean_episode_reward": 972.5, "best_episode_reward": 1000.0, "step": 295000}
{"episode": 1184.0, "episode_reward": 982.5, "eval_time": 29.202224254608154, "mean_episode_reward": 982.5, "best_episode_reward": 993.0, "step": 296000}
{"episode": 1188.0, "episode_reward": 885.3, "eval_time": 29.11835479736328, "mean_episode_reward": 885.3, "best_episode_reward": 995.0, "step": 297000}
{"episode": 1192.0, "episode_reward": 978.7, "eval_time": 29.388466835021973, "mean_episode_reward": 978.7, "best_episode_reward": 1000.0, "step": 298000}
{"episode": 1196.0, "episode_reward": 959.0, "eval_time": 29.123477697372437, "mean_episode_reward": 959.0, "best_episode_reward": 999.0, "step": 299000}
{"episode": 1200.0, "episode_reward": 971.9, "eval_time": 29.11528491973877, "mean_episode_reward": 971.9, "best_episode_reward": 994.0, "step": 300000}
{"episode": 1204.0, "episode_reward": 979.1, "eval_time": 29.25127601623535, "mean_episode_reward": 979.1, "best_episode_reward": 1000.0, "step": 301000}
{"episode": 1208.0, "episode_reward": 877.7, "eval_time": 29.14027214050293, "mean_episode_reward": 877.7, "best_episode_reward": 994.0, "step": 302000}
{"episode": 1212.0, "episode_reward": 972.9, "eval_time": 29.088833570480347, "mean_episode_reward": 972.9, "best_episode_reward": 997.0, "step": 303000}
{"episode": 1216.0, "episode_reward": 974.3, "eval_time": 29.206771850585938, "mean_episode_reward": 974.3, "best_episode_reward": 1000.0, "step": 304000}
{"episode": 1220.0, "episode_reward": 875.0, "eval_time": 29.148343801498413, "mean_episode_reward": 875.0, "best_episode_reward": 1000.0, "step": 305000}
{"episode": 1224.0, "episode_reward": 975.3, "eval_time": 29.09979271888733, "mean_episode_reward": 975.3, "best_episode_reward": 992.0, "step": 306000}
{"episode": 1228.0, "episode_reward": 972.1, "eval_time": 29.174954175949097, "mean_episode_reward": 972.1, "best_episode_reward": 986.0, "step": 307000}
{"episode": 1232.0, "episode_reward": 955.7, "eval_time": 29.124362230300903, "mean_episode_reward": 955.7, "best_episode_reward": 997.0, "step": 308000}
{"episode": 1236.0, "episode_reward": 975.1, "eval_time": 29.106384754180908, "mean_episode_reward": 975.1, "best_episode_reward": 1000.0, "step": 309000}
{"episode": 1240.0, "episode_reward": 892.0, "eval_time": 29.125160932540894, "mean_episode_reward": 892.0, "best_episode_reward": 998.0, "step": 310000}
{"episode": 1244.0, "episode_reward": 945.9, "eval_time": 29.18178963661194, "mean_episode_reward": 945.9, "best_episode_reward": 992.0, "step": 311000}
{"episode": 1248.0, "episode_reward": 970.7, "eval_time": 29.061031579971313, "mean_episode_reward": 970.7, "best_episode_reward": 983.0, "step": 312000}
{"episode": 1252.0, "episode_reward": 975.7, "eval_time": 29.105397701263428, "mean_episode_reward": 975.7, "best_episode_reward": 993.0, "step": 313000}
{"episode": 1256.0, "episode_reward": 861.1, "eval_time": 29.062322854995728, "mean_episode_reward": 861.1, "best_episode_reward": 991.0, "step": 314000}
{"episode": 1260.0, "episode_reward": 981.7, "eval_time": 29.09079670906067, "mean_episode_reward": 981.7, "best_episode_reward": 1000.0, "step": 315000}
{"episode": 1264.0, "episode_reward": 888.5, "eval_time": 29.085896492004395, "mean_episode_reward": 888.5, "best_episode_reward": 1000.0, "step": 316000}
{"episode": 1268.0, "episode_reward": 954.5, "eval_time": 29.10358214378357, "mean_episode_reward": 954.5, "best_episode_reward": 996.0, "step": 317000}
{"episode": 1272.0, "episode_reward": 966.9, "eval_time": 29.052446603775024, "mean_episode_reward": 966.9, "best_episode_reward": 989.0, "step": 318000}
{"episode": 1276.0, "episode_reward": 946.2, "eval_time": 29.13960576057434, "mean_episode_reward": 946.2, "best_episode_reward": 981.0, "step": 319000}
{"episode": 1280.0, "episode_reward": 975.7, "eval_time": 29.014381885528564, "mean_episode_reward": 975.7, "best_episode_reward": 1000.0, "step": 320000}
{"episode": 1284.0, "episode_reward": 968.7, "eval_time": 29.276842832565308, "mean_episode_reward": 968.7, "best_episode_reward": 985.0, "step": 321000}
{"episode": 1288.0, "episode_reward": 977.2, "eval_time": 29.08272075653076, "mean_episode_reward": 977.2, "best_episode_reward": 991.0, "step": 322000}
{"episode": 1292.0, "episode_reward": 876.3, "eval_time": 29.19371247291565, "mean_episode_reward": 876.3, "best_episode_reward": 991.0, "step": 323000}
{"episode": 1296.0, "episode_reward": 878.5, "eval_time": 29.109604597091675, "mean_episode_reward": 878.5, "best_episode_reward": 990.0, "step": 324000}
{"episode": 1300.0, "episode_reward": 878.6, "eval_time": 29.172855854034424, "mean_episode_reward": 878.6, "best_episode_reward": 994.0, "step": 325000}
{"episode": 1304.0, "episode_reward": 975.9, "eval_time": 29.146589756011963, "mean_episode_reward": 975.9, "best_episode_reward": 991.0, "step": 326000}
{"episode": 1308.0, "episode_reward": 970.1, "eval_time": 29.129076957702637, "mean_episode_reward": 970.1, "best_episode_reward": 990.0, "step": 327000}
{"episode": 1312.0, "episode_reward": 967.7, "eval_time": 29.192439317703247, "mean_episode_reward": 967.7, "best_episode_reward": 992.0, "step": 328000}
{"episode": 1316.0, "episode_reward": 959.8, "eval_time": 29.164494514465332, "mean_episode_reward": 959.8, "best_episode_reward": 995.0, "step": 329000}
{"episode": 1320.0, "episode_reward": 976.7, "eval_time": 29.111228704452515, "mean_episode_reward": 976.7, "best_episode_reward": 1000.0, "step": 330000}
{"episode": 1324.0, "episode_reward": 949.5, "eval_time": 29.214198350906372, "mean_episode_reward": 949.5, "best_episode_reward": 992.0, "step": 331000}
{"episode": 1328.0, "episode_reward": 876.3, "eval_time": 29.17073345184326, "mean_episode_reward": 876.3, "best_episode_reward": 1000.0, "step": 332000}
{"episode": 1332.0, "episode_reward": 963.8, "eval_time": 29.17848014831543, "mean_episode_reward": 963.8, "best_episode_reward": 988.0, "step": 333000}
{"episode": 1336.0, "episode_reward": 974.7, "eval_time": 29.181748151779175, "mean_episode_reward": 974.7, "best_episode_reward": 1000.0, "step": 334000}
{"episode": 1340.0, "episode_reward": 971.2, "eval_time": 29.212236404418945, "mean_episode_reward": 971.2, "best_episode_reward": 991.0, "step": 335000}
{"episode": 1344.0, "episode_reward": 978.7, "eval_time": 29.213325023651123, "mean_episode_reward": 978.7, "best_episode_reward": 993.0, "step": 336000}
{"episode": 1348.0, "episode_reward": 976.1, "eval_time": 29.223639488220215, "mean_episode_reward": 976.1, "best_episode_reward": 999.0, "step": 337000}
{"episode": 1352.0, "episode_reward": 979.9, "eval_time": 29.18155288696289, "mean_episode_reward": 979.9, "best_episode_reward": 993.0, "step": 338000}
{"episode": 1356.0, "episode_reward": 968.4, "eval_time": 29.14660143852234, "mean_episode_reward": 968.4, "best_episode_reward": 986.0, "step": 339000}
{"episode": 1360.0, "episode_reward": 974.0, "eval_time": 29.234403371810913, "mean_episode_reward": 974.0, "best_episode_reward": 997.0, "step": 340000}
{"episode": 1364.0, "episode_reward": 819.8, "eval_time": 29.204896450042725, "mean_episode_reward": 819.8, "best_episode_reward": 985.0, "step": 341000}
{"episode": 1368.0, "episode_reward": 964.1, "eval_time": 29.0839204788208, "mean_episode_reward": 964.1, "best_episode_reward": 994.0, "step": 342000}
{"episode": 1372.0, "episode_reward": 802.7, "eval_time": 29.22449278831482, "mean_episode_reward": 802.7, "best_episode_reward": 992.0, "step": 343000}
{"episode": 1376.0, "episode_reward": 948.4, "eval_time": 29.225120782852173, "mean_episode_reward": 948.4, "best_episode_reward": 996.0, "step": 344000}
{"episode": 1380.0, "episode_reward": 967.0, "eval_time": 29.16489863395691, "mean_episode_reward": 967.0, "best_episode_reward": 993.0, "step": 345000}
{"episode": 1384.0, "episode_reward": 874.2, "eval_time": 29.163220405578613, "mean_episode_reward": 874.2, "best_episode_reward": 991.0, "step": 346000}
{"episode": 1388.0, "episode_reward": 956.2, "eval_time": 29.219125986099243, "mean_episode_reward": 956.2, "best_episode_reward": 1000.0, "step": 347000}
{"episode": 1392.0, "episode_reward": 965.5, "eval_time": 29.220195293426514, "mean_episode_reward": 965.5, "best_episode_reward": 993.0, "step": 348000}
{"episode": 1396.0, "episode_reward": 878.6, "eval_time": 29.170768976211548, "mean_episode_reward": 878.6, "best_episode_reward": 986.0, "step": 349000}
{"episode": 1400.0, "episode_reward": 956.5, "eval_time": 29.240234851837158, "mean_episode_reward": 956.5, "best_episode_reward": 999.0, "step": 350000}
{"episode": 1404.0, "episode_reward": 976.4, "eval_time": 29.161906242370605, "mean_episode_reward": 976.4, "best_episode_reward": 993.0, "step": 351000}
{"episode": 1408.0, "episode_reward": 859.8, "eval_time": 29.18803834915161, "mean_episode_reward": 859.8, "best_episode_reward": 1000.0, "step": 352000}
{"episode": 1412.0, "episode_reward": 976.1, "eval_time": 29.2048077583313, "mean_episode_reward": 976.1, "best_episode_reward": 999.0, "step": 353000}
{"episode": 1416.0, "episode_reward": 969.6, "eval_time": 29.197325229644775, "mean_episode_reward": 969.6, "best_episode_reward": 986.0, "step": 354000}
{"episode": 1420.0, "episode_reward": 967.7, "eval_time": 29.2192964553833, "mean_episode_reward": 967.7, "best_episode_reward": 994.0, "step": 355000}
{"episode": 1424.0, "episode_reward": 869.6, "eval_time": 29.158706426620483, "mean_episode_reward": 869.6, "best_episode_reward": 996.0, "step": 356000}
{"episode": 1428.0, "episode_reward": 979.0, "eval_time": 29.181954860687256, "mean_episode_reward": 979.0, "best_episode_reward": 991.0, "step": 357000}
{"episode": 1432.0, "episode_reward": 975.3, "eval_time": 29.263787746429443, "mean_episode_reward": 975.3, "best_episode_reward": 996.0, "step": 358000}
{"episode": 1436.0, "episode_reward": 976.4, "eval_time": 29.205430507659912, "mean_episode_reward": 976.4, "best_episode_reward": 1000.0, "step": 359000}
{"episode": 1440.0, "episode_reward": 975.5, "eval_time": 29.25132989883423, "mean_episode_reward": 975.5, "best_episode_reward": 1000.0, "step": 360000}
{"episode": 1444.0, "episode_reward": 979.2, "eval_time": 29.28681182861328, "mean_episode_reward": 979.2, "best_episode_reward": 996.0, "step": 361000}
{"episode": 1448.0, "episode_reward": 947.6, "eval_time": 29.233447551727295, "mean_episode_reward": 947.6, "best_episode_reward": 1000.0, "step": 362000}
{"episode": 1452.0, "episode_reward": 972.0, "eval_time": 29.120929718017578, "mean_episode_reward": 972.0, "best_episode_reward": 1000.0, "step": 363000}
{"episode": 1456.0, "episode_reward": 981.8, "eval_time": 29.16299271583557, "mean_episode_reward": 981.8, "best_episode_reward": 1000.0, "step": 364000}
{"episode": 1460.0, "episode_reward": 978.2, "eval_time": 29.174760818481445, "mean_episode_reward": 978.2, "best_episode_reward": 997.0, "step": 365000}
{"episode": 1464.0, "episode_reward": 875.1, "eval_time": 29.15498661994934, "mean_episode_reward": 875.1, "best_episode_reward": 1000.0, "step": 366000}
{"episode": 1468.0, "episode_reward": 972.8, "eval_time": 29.20072650909424, "mean_episode_reward": 972.8, "best_episode_reward": 990.0, "step": 367000}
{"episode": 1472.0, "episode_reward": 975.1, "eval_time": 29.206960201263428, "mean_episode_reward": 975.1, "best_episode_reward": 987.0, "step": 368000}
{"episode": 1476.0, "episode_reward": 974.3, "eval_time": 29.256404876708984, "mean_episode_reward": 974.3, "best_episode_reward": 1000.0, "step": 369000}
{"episode": 1480.0, "episode_reward": 972.2, "eval_time": 29.20883846282959, "mean_episode_reward": 972.2, "best_episode_reward": 1000.0, "step": 370000}
{"episode": 1484.0, "episode_reward": 977.3, "eval_time": 29.24545407295227, "mean_episode_reward": 977.3, "best_episode_reward": 997.0, "step": 371000}
{"episode": 1488.0, "episode_reward": 979.5, "eval_time": 29.1697416305542, "mean_episode_reward": 979.5, "best_episode_reward": 1000.0, "step": 372000}
{"episode": 1492.0, "episode_reward": 888.5, "eval_time": 29.206550121307373, "mean_episode_reward": 888.5, "best_episode_reward": 1000.0, "step": 373000}
{"episode": 1496.0, "episode_reward": 979.7, "eval_time": 29.20721197128296, "mean_episode_reward": 979.7, "best_episode_reward": 995.0, "step": 374000}
{"episode": 1500.0, "episode_reward": 973.0, "eval_time": 29.22555685043335, "mean_episode_reward": 973.0, "best_episode_reward": 993.0, "step": 375000}
{"episode": 1504.0, "episode_reward": 969.2, "eval_time": 29.238710403442383, "mean_episode_reward": 969.2, "best_episode_reward": 995.0, "step": 376000}
{"episode": 1508.0, "episode_reward": 961.2, "eval_time": 29.246963500976562, "mean_episode_reward": 961.2, "best_episode_reward": 977.0, "step": 377000}
{"episode": 1512.0, "episode_reward": 970.2, "eval_time": 29.249703645706177, "mean_episode_reward": 970.2, "best_episode_reward": 987.0, "step": 378000}
{"episode": 1516.0, "episode_reward": 879.9, "eval_time": 29.25478434562683, "mean_episode_reward": 879.9, "best_episode_reward": 977.0, "step": 379000}
{"episode": 1520.0, "episode_reward": 970.0, "eval_time": 29.175305128097534, "mean_episode_reward": 970.0, "best_episode_reward": 988.0, "step": 380000}
{"episode": 1524.0, "episode_reward": 976.7, "eval_time": 29.14661192893982, "mean_episode_reward": 976.7, "best_episode_reward": 997.0, "step": 381000}
{"episode": 1528.0, "episode_reward": 971.1, "eval_time": 29.224793434143066, "mean_episode_reward": 971.1, "best_episode_reward": 983.0, "step": 382000}
{"episode": 1532.0, "episode_reward": 970.1, "eval_time": 29.17694401741028, "mean_episode_reward": 970.1, "best_episode_reward": 1000.0, "step": 383000}
{"episode": 1536.0, "episode_reward": 977.8, "eval_time": 29.268629550933838, "mean_episode_reward": 977.8, "best_episode_reward": 1000.0, "step": 384000}
{"episode": 1540.0, "episode_reward": 979.6, "eval_time": 29.198338508605957, "mean_episode_reward": 979.6, "best_episode_reward": 1000.0, "step": 385000}
{"episode": 1544.0, "episode_reward": 974.1, "eval_time": 29.18076229095459, "mean_episode_reward": 974.1, "best_episode_reward": 995.0, "step": 386000}
{"episode": 1548.0, "episode_reward": 972.7, "eval_time": 29.16898488998413, "mean_episode_reward": 972.7, "best_episode_reward": 993.0, "step": 387000}
{"episode": 1552.0, "episode_reward": 961.6, "eval_time": 29.225741863250732, "mean_episode_reward": 961.6, "best_episode_reward": 1000.0, "step": 388000}
{"episode": 1556.0, "episode_reward": 978.7, "eval_time": 29.248638153076172, "mean_episode_reward": 978.7, "best_episode_reward": 999.0, "step": 389000}
{"episode": 1560.0, "episode_reward": 970.4, "eval_time": 29.305684804916382, "mean_episode_reward": 970.4, "best_episode_reward": 996.0, "step": 390000}
{"episode": 1564.0, "episode_reward": 977.2, "eval_time": 29.2792067527771, "mean_episode_reward": 977.2, "best_episode_reward": 998.0, "step": 391000}
{"episode": 1568.0, "episode_reward": 973.8, "eval_time": 29.1966712474823, "mean_episode_reward": 973.8, "best_episode_reward": 1000.0, "step": 392000}
{"episode": 1572.0, "episode_reward": 973.0, "eval_time": 29.271263122558594, "mean_episode_reward": 973.0, "best_episode_reward": 995.0, "step": 393000}
{"episode": 1576.0, "episode_reward": 976.4, "eval_time": 29.183112144470215, "mean_episode_reward": 976.4, "best_episode_reward": 992.0, "step": 394000}
{"episode": 1580.0, "episode_reward": 971.6, "eval_time": 29.318346977233887, "mean_episode_reward": 971.6, "best_episode_reward": 997.0, "step": 395000}
{"episode": 1584.0, "episode_reward": 879.3, "eval_time": 29.281651496887207, "mean_episode_reward": 879.3, "best_episode_reward": 1000.0, "step": 396000}
{"episode": 1588.0, "episode_reward": 982.1, "eval_time": 29.182084560394287, "mean_episode_reward": 982.1, "best_episode_reward": 1000.0, "step": 397000}
{"episode": 1592.0, "episode_reward": 973.9, "eval_time": 29.344881296157837, "mean_episode_reward": 973.9, "best_episode_reward": 988.0, "step": 398000}
{"episode": 1596.0, "episode_reward": 967.1, "eval_time": 29.215698957443237, "mean_episode_reward": 967.1, "best_episode_reward": 993.0, "step": 399000}
{"episode": 1600.0, "episode_reward": 964.3, "eval_time": 29.16377878189087, "mean_episode_reward": 964.3, "best_episode_reward": 993.0, "step": 400000}
{"episode": 1604.0, "episode_reward": 971.9, "eval_time": 29.26732587814331, "mean_episode_reward": 971.9, "best_episode_reward": 1000.0, "step": 401000}
{"episode": 1608.0, "episode_reward": 977.3, "eval_time": 29.19249200820923, "mean_episode_reward": 977.3, "best_episode_reward": 996.0, "step": 402000}
{"episode": 1612.0, "episode_reward": 968.4, "eval_time": 29.240793228149414, "mean_episode_reward": 968.4, "best_episode_reward": 1000.0, "step": 403000}
{"episode": 1616.0, "episode_reward": 979.2, "eval_time": 29.152604341506958, "mean_episode_reward": 979.2, "best_episode_reward": 1000.0, "step": 404000}
{"episode": 1620.0, "episode_reward": 971.6, "eval_time": 29.223722219467163, "mean_episode_reward": 971.6, "best_episode_reward": 1000.0, "step": 405000}
{"episode": 1624.0, "episode_reward": 951.7, "eval_time": 29.17789602279663, "mean_episode_reward": 951.7, "best_episode_reward": 991.0, "step": 406000}
{"episode": 1628.0, "episode_reward": 984.3, "eval_time": 29.304206609725952, "mean_episode_reward": 984.3, "best_episode_reward": 1000.0, "step": 407000}
{"episode": 1632.0, "episode_reward": 972.1, "eval_time": 29.15100622177124, "mean_episode_reward": 972.1, "best_episode_reward": 999.0, "step": 408000}
{"episode": 1636.0, "episode_reward": 891.5, "eval_time": 29.20691418647766, "mean_episode_reward": 891.5, "best_episode_reward": 986.0, "step": 409000}
{"episode": 1640.0, "episode_reward": 968.9, "eval_time": 29.28972554206848, "mean_episode_reward": 968.9, "best_episode_reward": 989.0, "step": 410000}
{"episode": 1644.0, "episode_reward": 970.5, "eval_time": 29.161695957183838, "mean_episode_reward": 970.5, "best_episode_reward": 987.0, "step": 411000}
{"episode": 1648.0, "episode_reward": 968.8, "eval_time": 29.202880859375, "mean_episode_reward": 968.8, "best_episode_reward": 997.0, "step": 412000}
{"episode": 1652.0, "episode_reward": 969.8, "eval_time": 29.233089923858643, "mean_episode_reward": 969.8, "best_episode_reward": 998.0, "step": 413000}
{"episode": 1656.0, "episode_reward": 879.9, "eval_time": 29.154737949371338, "mean_episode_reward": 879.9, "best_episode_reward": 986.0, "step": 414000}
{"episode": 1660.0, "episode_reward": 972.4, "eval_time": 29.229052543640137, "mean_episode_reward": 972.4, "best_episode_reward": 989.0, "step": 415000}
{"episode": 1664.0, "episode_reward": 977.6, "eval_time": 29.29287075996399, "mean_episode_reward": 977.6, "best_episode_reward": 991.0, "step": 416000}
{"episode": 1668.0, "episode_reward": 933.1, "eval_time": 29.122516870498657, "mean_episode_reward": 933.1, "best_episode_reward": 998.0, "step": 417000}
{"episode": 1672.0, "episode_reward": 973.1, "eval_time": 29.220165252685547, "mean_episode_reward": 973.1, "best_episode_reward": 996.0, "step": 418000}
{"episode": 1676.0, "episode_reward": 976.4, "eval_time": 29.25787615776062, "mean_episode_reward": 976.4, "best_episode_reward": 993.0, "step": 419000}
{"episode": 1680.0, "episode_reward": 949.2, "eval_time": 29.190747499465942, "mean_episode_reward": 949.2, "best_episode_reward": 1000.0, "step": 420000}
{"episode": 1684.0, "episode_reward": 980.0, "eval_time": 29.276543378829956, "mean_episode_reward": 980.0, "best_episode_reward": 998.0, "step": 421000}
{"episode": 1688.0, "episode_reward": 934.4, "eval_time": 29.211095809936523, "mean_episode_reward": 934.4, "best_episode_reward": 995.0, "step": 422000}
{"episode": 1692.0, "episode_reward": 973.6, "eval_time": 29.129467010498047, "mean_episode_reward": 973.6, "best_episode_reward": 986.0, "step": 423000}
{"episode": 1696.0, "episode_reward": 794.6, "eval_time": 29.209679126739502, "mean_episode_reward": 794.6, "best_episode_reward": 985.0, "step": 424000}
{"episode": 1700.0, "episode_reward": 972.6, "eval_time": 29.101152420043945, "mean_episode_reward": 972.6, "best_episode_reward": 985.0, "step": 425000}
{"episode": 1704.0, "episode_reward": 972.2, "eval_time": 29.09501028060913, "mean_episode_reward": 972.2, "best_episode_reward": 997.0, "step": 426000}
{"episode": 1708.0, "episode_reward": 936.6, "eval_time": 29.20064616203308, "mean_episode_reward": 936.6, "best_episode_reward": 982.0, "step": 427000}
{"episode": 1712.0, "episode_reward": 974.2, "eval_time": 29.08077836036682, "mean_episode_reward": 974.2, "best_episode_reward": 1000.0, "step": 428000}
{"episode": 1716.0, "episode_reward": 948.1, "eval_time": 29.112034797668457, "mean_episode_reward": 948.1, "best_episode_reward": 1000.0, "step": 429000}
{"episode": 1720.0, "episode_reward": 977.0, "eval_time": 29.23081135749817, "mean_episode_reward": 977.0, "best_episode_reward": 996.0, "step": 430000}
{"episode": 1724.0, "episode_reward": 956.1, "eval_time": 29.13443160057068, "mean_episode_reward": 956.1, "best_episode_reward": 992.0, "step": 431000}
{"episode": 1728.0, "episode_reward": 876.6, "eval_time": 29.10576295852661, "mean_episode_reward": 876.6, "best_episode_reward": 1000.0, "step": 432000}
{"episode": 1732.0, "episode_reward": 928.3, "eval_time": 29.10522222518921, "mean_episode_reward": 928.3, "best_episode_reward": 1000.0, "step": 433000}
{"episode": 1736.0, "episode_reward": 975.4, "eval_time": 29.05744194984436, "mean_episode_reward": 975.4, "best_episode_reward": 991.0, "step": 434000}
{"episode": 1740.0, "episode_reward": 977.5, "eval_time": 29.017815828323364, "mean_episode_reward": 977.5, "best_episode_reward": 1000.0, "step": 435000}
{"episode": 1744.0, "episode_reward": 976.2, "eval_time": 29.124110221862793, "mean_episode_reward": 976.2, "best_episode_reward": 990.0, "step": 436000}
{"episode": 1748.0, "episode_reward": 980.3, "eval_time": 29.029435634613037, "mean_episode_reward": 980.3, "best_episode_reward": 1000.0, "step": 437000}
{"episode": 1752.0, "episode_reward": 976.4, "eval_time": 29.12951421737671, "mean_episode_reward": 976.4, "best_episode_reward": 1000.0, "step": 438000}
{"episode": 1756.0, "episode_reward": 964.2, "eval_time": 29.021342992782593, "mean_episode_reward": 964.2, "best_episode_reward": 990.0, "step": 439000}
{"episode": 1760.0, "episode_reward": 968.4, "eval_time": 28.986886262893677, "mean_episode_reward": 968.4, "best_episode_reward": 987.0, "step": 440000}
{"episode": 1764.0, "episode_reward": 884.8, "eval_time": 29.110463857650757, "mean_episode_reward": 884.8, "best_episode_reward": 1000.0, "step": 441000}
{"episode": 1768.0, "episode_reward": 874.9, "eval_time": 29.073713541030884, "mean_episode_reward": 874.9, "best_episode_reward": 994.0, "step": 442000}
{"episode": 1772.0, "episode_reward": 973.0, "eval_time": 29.00967526435852, "mean_episode_reward": 973.0, "best_episode_reward": 996.0, "step": 443000}
{"episode": 1776.0, "episode_reward": 879.5, "eval_time": 29.109363555908203, "mean_episode_reward": 879.5, "best_episode_reward": 1000.0, "step": 444000}
{"episode": 1780.0, "episode_reward": 884.0, "eval_time": 29.117369174957275, "mean_episode_reward": 884.0, "best_episode_reward": 1000.0, "step": 445000}
{"episode": 1784.0, "episode_reward": 876.8, "eval_time": 29.171735286712646, "mean_episode_reward": 876.8, "best_episode_reward": 992.0, "step": 446000}
{"episode": 1788.0, "episode_reward": 874.3, "eval_time": 29.074079990386963, "mean_episode_reward": 874.3, "best_episode_reward": 985.0, "step": 447000}
{"episode": 1792.0, "episode_reward": 976.3, "eval_time": 29.10450553894043, "mean_episode_reward": 976.3, "best_episode_reward": 995.0, "step": 448000}
{"episode": 1796.0, "episode_reward": 972.1, "eval_time": 29.16084885597229, "mean_episode_reward": 972.1, "best_episode_reward": 991.0, "step": 449000}
{"episode": 1800.0, "episode_reward": 972.5, "eval_time": 29.128639698028564, "mean_episode_reward": 972.5, "best_episode_reward": 986.0, "step": 450000}
{"episode": 1804.0, "episode_reward": 981.8, "eval_time": 29.063769817352295, "mean_episode_reward": 981.8, "best_episode_reward": 1000.0, "step": 451000}
{"episode": 1808.0, "episode_reward": 845.1, "eval_time": 29.063343048095703, "mean_episode_reward": 845.1, "best_episode_reward": 1000.0, "step": 452000}
{"episode": 1812.0, "episode_reward": 976.2, "eval_time": 29.079883098602295, "mean_episode_reward": 976.2, "best_episode_reward": 990.0, "step": 453000}
{"episode": 1816.0, "episode_reward": 975.2, "eval_time": 29.079026460647583, "mean_episode_reward": 975.2, "best_episode_reward": 999.0, "step": 454000}
{"episode": 1820.0, "episode_reward": 968.4, "eval_time": 29.07996964454651, "mean_episode_reward": 968.4, "best_episode_reward": 990.0, "step": 455000}
{"episode": 1824.0, "episode_reward": 982.1, "eval_time": 29.12933611869812, "mean_episode_reward": 982.1, "best_episode_reward": 992.0, "step": 456000}
{"episode": 1828.0, "episode_reward": 880.6, "eval_time": 29.013701677322388, "mean_episode_reward": 880.6, "best_episode_reward": 994.0, "step": 457000}
{"episode": 1832.0, "episode_reward": 967.3, "eval_time": 29.10675287246704, "mean_episode_reward": 967.3, "best_episode_reward": 994.0, "step": 458000}
{"episode": 1836.0, "episode_reward": 969.4, "eval_time": 29.08853316307068, "mean_episode_reward": 969.4, "best_episode_reward": 990.0, "step": 459000}
{"episode": 1840.0, "episode_reward": 878.5, "eval_time": 29.019975662231445, "mean_episode_reward": 878.5, "best_episode_reward": 996.0, "step": 460000}
{"episode": 1844.0, "episode_reward": 768.1, "eval_time": 29.10582208633423, "mean_episode_reward": 768.1, "best_episode_reward": 1000.0, "step": 461000}
{"episode": 1848.0, "episode_reward": 955.9, "eval_time": 29.068374633789062, "mean_episode_reward": 955.9, "best_episode_reward": 999.0, "step": 462000}
{"episode": 1852.0, "episode_reward": 974.8, "eval_time": 28.9139142036438, "mean_episode_reward": 974.8, "best_episode_reward": 1000.0, "step": 463000}
{"episode": 1856.0, "episode_reward": 944.2, "eval_time": 29.004601001739502, "mean_episode_reward": 944.2, "best_episode_reward": 1000.0, "step": 464000}
{"episode": 1860.0, "episode_reward": 922.7, "eval_time": 29.093817234039307, "mean_episode_reward": 922.7, "best_episode_reward": 1000.0, "step": 465000}
{"episode": 1864.0, "episode_reward": 933.5, "eval_time": 28.947259426116943, "mean_episode_reward": 933.5, "best_episode_reward": 994.0, "step": 466000}
{"episode": 1868.0, "episode_reward": 923.6, "eval_time": 29.059794902801514, "mean_episode_reward": 923.6, "best_episode_reward": 994.0, "step": 467000}
{"episode": 1872.0, "episode_reward": 972.9, "eval_time": 29.1135036945343, "mean_episode_reward": 972.9, "best_episode_reward": 993.0, "step": 468000}
{"episode": 1876.0, "episode_reward": 924.9, "eval_time": 29.08139991760254, "mean_episode_reward": 924.9, "best_episode_reward": 987.0, "step": 469000}
{"episode": 1880.0, "episode_reward": 874.0, "eval_time": 29.12202262878418, "mean_episode_reward": 874.0, "best_episode_reward": 991.0, "step": 470000}
{"episode": 1884.0, "episode_reward": 900.7, "eval_time": 29.16724944114685, "mean_episode_reward": 900.7, "best_episode_reward": 996.0, "step": 471000}
{"episode": 1888.0, "episode_reward": 973.1, "eval_time": 29.50558829307556, "mean_episode_reward": 973.1, "best_episode_reward": 992.0, "step": 472000}
{"episode": 1892.0, "episode_reward": 978.5, "eval_time": 29.486878156661987, "mean_episode_reward": 978.5, "best_episode_reward": 1000.0, "step": 473000}
{"episode": 1896.0, "episode_reward": 933.6, "eval_time": 29.6468346118927, "mean_episode_reward": 933.6, "best_episode_reward": 1000.0, "step": 474000}
{"episode": 1900.0, "episode_reward": 952.1, "eval_time": 29.45133876800537, "mean_episode_reward": 952.1, "best_episode_reward": 994.0, "step": 475000}
{"episode": 1904.0, "episode_reward": 958.6, "eval_time": 29.556880950927734, "mean_episode_reward": 958.6, "best_episode_reward": 988.0, "step": 476000}
{"episode": 1908.0, "episode_reward": 806.8, "eval_time": 29.611659288406372, "mean_episode_reward": 806.8, "best_episode_reward": 990.0, "step": 477000}
{"episode": 1912.0, "episode_reward": 980.9, "eval_time": 29.474576711654663, "mean_episode_reward": 980.9, "best_episode_reward": 1000.0, "step": 478000}
{"episode": 1916.0, "episode_reward": 971.4, "eval_time": 29.682865619659424, "mean_episode_reward": 971.4, "best_episode_reward": 994.0, "step": 479000}
{"episode": 1920.0, "episode_reward": 972.7, "eval_time": 29.6574547290802, "mean_episode_reward": 972.7, "best_episode_reward": 1000.0, "step": 480000}
{"episode": 1924.0, "episode_reward": 879.3, "eval_time": 29.522823095321655, "mean_episode_reward": 879.3, "best_episode_reward": 996.0, "step": 481000}
{"episode": 1928.0, "episode_reward": 952.1, "eval_time": 29.570206880569458, "mean_episode_reward": 952.1, "best_episode_reward": 995.0, "step": 482000}
{"episode": 1932.0, "episode_reward": 958.9, "eval_time": 29.619954109191895, "mean_episode_reward": 958.9, "best_episode_reward": 994.0, "step": 483000}
{"episode": 1936.0, "episode_reward": 979.3, "eval_time": 29.432079553604126, "mean_episode_reward": 979.3, "best_episode_reward": 998.0, "step": 484000}
{"episode": 1940.0, "episode_reward": 972.0, "eval_time": 29.60569477081299, "mean_episode_reward": 972.0, "best_episode_reward": 1000.0, "step": 485000}
{"episode": 1944.0, "episode_reward": 962.5, "eval_time": 29.519310235977173, "mean_episode_reward": 962.5, "best_episode_reward": 993.0, "step": 486000}
{"episode": 1948.0, "episode_reward": 978.7, "eval_time": 29.497660398483276, "mean_episode_reward": 978.7, "best_episode_reward": 1000.0, "step": 487000}
{"episode": 1952.0, "episode_reward": 903.1, "eval_time": 29.56305694580078, "mean_episode_reward": 903.1, "best_episode_reward": 997.0, "step": 488000}
{"episode": 1956.0, "episode_reward": 948.2, "eval_time": 29.536805391311646, "mean_episode_reward": 948.2, "best_episode_reward": 999.0, "step": 489000}
{"episode": 1960.0, "episode_reward": 973.6, "eval_time": 29.482372283935547, "mean_episode_reward": 973.6, "best_episode_reward": 993.0, "step": 490000}
{"episode": 1964.0, "episode_reward": 974.2, "eval_time": 29.495718002319336, "mean_episode_reward": 974.2, "best_episode_reward": 993.0, "step": 491000}
{"episode": 1968.0, "episode_reward": 974.4, "eval_time": 29.589497327804565, "mean_episode_reward": 974.4, "best_episode_reward": 997.0, "step": 492000}
{"episode": 1972.0, "episode_reward": 941.2, "eval_time": 29.47018027305603, "mean_episode_reward": 941.2, "best_episode_reward": 994.0, "step": 493000}
{"episode": 1976.0, "episode_reward": 820.1, "eval_time": 29.516562700271606, "mean_episode_reward": 820.1, "best_episode_reward": 989.0, "step": 494000}
{"episode": 1980.0, "episode_reward": 968.0, "eval_time": 29.498830795288086, "mean_episode_reward": 968.0, "best_episode_reward": 1000.0, "step": 495000}
{"episode": 1984.0, "episode_reward": 933.9, "eval_time": 29.54250478744507, "mean_episode_reward": 933.9, "best_episode_reward": 1000.0, "step": 496000}
{"episode": 1988.0, "episode_reward": 878.1, "eval_time": 29.525548934936523, "mean_episode_reward": 878.1, "best_episode_reward": 992.0, "step": 497000}
{"episode": 1992.0, "episode_reward": 968.7, "eval_time": 29.513875246047974, "mean_episode_reward": 968.7, "best_episode_reward": 998.0, "step": 498000}
{"episode": 1996.0, "episode_reward": 884.4, "eval_time": 29.447144985198975, "mean_episode_reward": 884.4, "best_episode_reward": 1000.0, "step": 499000}
