{"episode": 0.0, "episode_reward": 95.4, "eval_time": 29.67669939994812, "mean_episode_reward": 95.4, "best_episode_reward": 344.0, "step": 0}
{"episode": 4.0, "episode_reward": 6.6, "eval_time": 29.015825271606445, "mean_episode_reward": 6.6, "best_episode_reward": 66.0, "step": 1000}
{"episode": 8.0, "episode_reward": 104.9, "eval_time": 29.09193515777588, "mean_episode_reward": 104.9, "best_episode_reward": 947.0, "step": 2000}
{"episode": 12.0, "episode_reward": 105.3, "eval_time": 29.034074544906616, "mean_episode_reward": 105.3, "best_episode_reward": 509.0, "step": 3000}
{"episode": 16.0, "episode_reward": 101.3, "eval_time": 29.06372594833374, "mean_episode_reward": 101.3, "best_episode_reward": 941.0, "step": 4000}
{"episode": 20.0, "episode_reward": 87.8, "eval_time": 29.07546591758728, "mean_episode_reward": 87.8, "best_episode_reward": 848.0, "step": 5000}
{"episode": 24.0, "episode_reward": 153.4, "eval_time": 29.058971166610718, "mean_episode_reward": 153.4, "best_episode_reward": 822.0, "step": 6000}
{"episode": 28.0, "episode_reward": 101.4, "eval_time": 29.095463752746582, "mean_episode_reward": 101.4, "best_episode_reward": 995.0, "step": 7000}
{"episode": 32.0, "episode_reward": 102.3, "eval_time": 29.030970811843872, "mean_episode_reward": 102.3, "best_episode_reward": 963.0, "step": 8000}
{"episode": 36.0, "episode_reward": 93.0, "eval_time": 29.077472448349, "mean_episode_reward": 93.0, "best_episode_reward": 911.0, "step": 9000}
{"episode": 40.0, "episode_reward": 172.9, "eval_time": 29.082114219665527, "mean_episode_reward": 172.9, "best_episode_reward": 980.0, "step": 10000}
{"episode": 44.0, "episode_reward": 296.6, "eval_time": 29.067564249038696, "mean_episode_reward": 296.6, "best_episode_reward": 972.0, "step": 11000}
{"episode": 48.0, "episode_reward": 95.6, "eval_time": 29.05368709564209, "mean_episode_reward": 95.6, "best_episode_reward": 622.0, "step": 12000}
{"episode": 52.0, "episode_reward": 234.7, "eval_time": 29.068713188171387, "mean_episode_reward": 234.7, "best_episode_reward": 941.0, "step": 13000}
{"episode": 56.0, "episode_reward": 299.4, "eval_time": 29.111475706100464, "mean_episode_reward": 299.4, "best_episode_reward": 925.0, "step": 14000}
{"episode": 60.0, "episode_reward": 123.8, "eval_time": 29.08958411216736, "mean_episode_reward": 123.8, "best_episode_reward": 949.0, "step": 15000}
{"episode": 64.0, "episode_reward": 152.4, "eval_time": 29.13662552833557, "mean_episode_reward": 152.4, "best_episode_reward": 754.0, "step": 16000}
{"episode": 68.0, "episode_reward": 236.6, "eval_time": 29.072587966918945, "mean_episode_reward": 236.6, "best_episode_reward": 929.0, "step": 17000}
{"episode": 72.0, "episode_reward": 446.5, "eval_time": 29.079617023468018, "mean_episode_reward": 446.5, "best_episode_reward": 983.0, "step": 18000}
{"episode": 76.0, "episode_reward": 354.7, "eval_time": 29.116498947143555, "mean_episode_reward": 354.7, "best_episode_reward": 989.0, "step": 19000}
{"episode": 80.0, "episode_reward": 548.5, "eval_time": 29.083863258361816, "mean_episode_reward": 548.5, "best_episode_reward": 994.0, "step": 20000}
{"episode": 84.0, "episode_reward": 316.4, "eval_time": 29.062036514282227, "mean_episode_reward": 316.4, "best_episode_reward": 949.0, "step": 21000}
{"episode": 88.0, "episode_reward": 385.6, "eval_time": 29.08202314376831, "mean_episode_reward": 385.6, "best_episode_reward": 993.0, "step": 22000}
{"episode": 92.0, "episode_reward": 582.0, "eval_time": 29.123246431350708, "mean_episode_reward": 582.0, "best_episode_reward": 997.0, "step": 23000}
{"episode": 96.0, "episode_reward": 363.1, "eval_time": 29.131309747695923, "mean_episode_reward": 363.1, "best_episode_reward": 991.0, "step": 24000}
{"episode": 100.0, "episode_reward": 729.9, "eval_time": 29.102892637252808, "mean_episode_reward": 729.9, "best_episode_reward": 975.0, "step": 25000}
{"episode": 104.0, "episode_reward": 289.9, "eval_time": 29.08261227607727, "mean_episode_reward": 289.9, "best_episode_reward": 1000.0, "step": 26000}
{"episode": 108.0, "episode_reward": 342.2, "eval_time": 29.10567045211792, "mean_episode_reward": 342.2, "best_episode_reward": 950.0, "step": 27000}
{"episode": 112.0, "episode_reward": 377.5, "eval_time": 29.093260526657104, "mean_episode_reward": 377.5, "best_episode_reward": 993.0, "step": 28000}
{"episode": 116.0, "episode_reward": 366.5, "eval_time": 29.111486434936523, "mean_episode_reward": 366.5, "best_episode_reward": 984.0, "step": 29000}
{"episode": 120.0, "episode_reward": 334.2, "eval_time": 29.050730228424072, "mean_episode_reward": 334.2, "best_episode_reward": 1000.0, "step": 30000}
{"episode": 124.0, "episode_reward": 259.1, "eval_time": 29.066710710525513, "mean_episode_reward": 259.1, "best_episode_reward": 958.0, "step": 31000}
{"episode": 128.0, "episode_reward": 657.0, "eval_time": 29.104207515716553, "mean_episode_reward": 657.0, "best_episode_reward": 997.0, "step": 32000}
{"episode": 132.0, "episode_reward": 591.3, "eval_time": 29.145954132080078, "mean_episode_reward": 591.3, "best_episode_reward": 988.0, "step": 33000}
{"episode": 136.0, "episode_reward": 630.4, "eval_time": 29.198836088180542, "mean_episode_reward": 630.4, "best_episode_reward": 998.0, "step": 34000}
{"episode": 140.0, "episode_reward": 591.8, "eval_time": 29.066813707351685, "mean_episode_reward": 591.8, "best_episode_reward": 989.0, "step": 35000}
{"episode": 144.0, "episode_reward": 530.9, "eval_time": 29.09478759765625, "mean_episode_reward": 530.9, "best_episode_reward": 978.0, "step": 36000}
{"episode": 148.0, "episode_reward": 630.6, "eval_time": 29.13579797744751, "mean_episode_reward": 630.6, "best_episode_reward": 995.0, "step": 37000}
{"episode": 152.0, "episode_reward": 781.4, "eval_time": 29.076843976974487, "mean_episode_reward": 781.4, "best_episode_reward": 994.0, "step": 38000}
{"episode": 156.0, "episode_reward": 577.9, "eval_time": 29.085334300994873, "mean_episode_reward": 577.9, "best_episode_reward": 1000.0, "step": 39000}
{"episode": 160.0, "episode_reward": 482.1, "eval_time": 29.07761526107788, "mean_episode_reward": 482.1, "best_episode_reward": 1000.0, "step": 40000}
{"episode": 164.0, "episode_reward": 559.8, "eval_time": 29.103869438171387, "mean_episode_reward": 559.8, "best_episode_reward": 1000.0, "step": 41000}
{"episode": 168.0, "episode_reward": 937.6, "eval_time": 29.053845405578613, "mean_episode_reward": 937.6, "best_episode_reward": 980.0, "step": 42000}
{"episode": 172.0, "episode_reward": 419.7, "eval_time": 29.11597776412964, "mean_episode_reward": 419.7, "best_episode_reward": 991.0, "step": 43000}
{"episode": 176.0, "episode_reward": 825.7, "eval_time": 29.16637420654297, "mean_episode_reward": 825.7, "best_episode_reward": 977.0, "step": 44000}
{"episode": 180.0, "episode_reward": 580.2, "eval_time": 29.010345697402954, "mean_episode_reward": 580.2, "best_episode_reward": 974.0, "step": 45000}
{"episode": 184.0, "episode_reward": 638.8, "eval_time": 29.118714332580566, "mean_episode_reward": 638.8, "best_episode_reward": 987.0, "step": 46000}
{"episode": 188.0, "episode_reward": 483.5, "eval_time": 29.12417197227478, "mean_episode_reward": 483.5, "best_episode_reward": 980.0, "step": 47000}
{"episode": 192.0, "episode_reward": 746.3, "eval_time": 29.111851453781128, "mean_episode_reward": 746.3, "best_episode_reward": 993.0, "step": 48000}
{"episode": 196.0, "episode_reward": 250.6, "eval_time": 29.13906240463257, "mean_episode_reward": 250.6, "best_episode_reward": 950.0, "step": 49000}
{"episode": 200.0, "episode_reward": 785.6, "eval_time": 29.150960445404053, "mean_episode_reward": 785.6, "best_episode_reward": 987.0, "step": 50000}
{"episode": 204.0, "episode_reward": 789.1, "eval_time": 29.078462839126587, "mean_episode_reward": 789.1, "best_episode_reward": 983.0, "step": 51000}
{"episode": 208.0, "episode_reward": 561.6, "eval_time": 29.089395761489868, "mean_episode_reward": 561.6, "best_episode_reward": 977.0, "step": 52000}
{"episode": 212.0, "episode_reward": 667.7, "eval_time": 29.090996980667114, "mean_episode_reward": 667.7, "best_episode_reward": 976.0, "step": 53000}
{"episode": 216.0, "episode_reward": 776.6, "eval_time": 29.08260679244995, "mean_episode_reward": 776.6, "best_episode_reward": 973.0, "step": 54000}
{"episode": 220.0, "episode_reward": 756.9, "eval_time": 29.07671046257019, "mean_episode_reward": 756.9, "best_episode_reward": 989.0, "step": 55000}
{"episode": 224.0, "episode_reward": 678.0, "eval_time": 29.07863426208496, "mean_episode_reward": 678.0, "best_episode_reward": 1000.0, "step": 56000}
{"episode": 228.0, "episode_reward": 940.7, "eval_time": 29.069976806640625, "mean_episode_reward": 940.7, "best_episode_reward": 1000.0, "step": 57000}
{"episode": 232.0, "episode_reward": 839.0, "eval_time": 29.095000982284546, "mean_episode_reward": 839.0, "best_episode_reward": 972.0, "step": 58000}
{"episode": 236.0, "episode_reward": 923.5, "eval_time": 29.1978120803833, "mean_episode_reward": 923.5, "best_episode_reward": 985.0, "step": 59000}
{"episode": 240.0, "episode_reward": 673.8, "eval_time": 29.105189323425293, "mean_episode_reward": 673.8, "best_episode_reward": 1000.0, "step": 60000}
{"episode": 244.0, "episode_reward": 928.3, "eval_time": 29.122180700302124, "mean_episode_reward": 928.3, "best_episode_reward": 987.0, "step": 61000}
{"episode": 248.0, "episode_reward": 734.4, "eval_time": 29.101058959960938, "mean_episode_reward": 734.4, "best_episode_reward": 996.0, "step": 62000}
{"episode": 252.0, "episode_reward": 830.6, "eval_time": 29.14928102493286, "mean_episode_reward": 830.6, "best_episode_reward": 992.0, "step": 63000}
{"episode": 256.0, "episode_reward": 764.7, "eval_time": 29.1375572681427, "mean_episode_reward": 764.7, "best_episode_reward": 993.0, "step": 64000}
{"episode": 260.0, "episode_reward": 791.0, "eval_time": 29.069747924804688, "mean_episode_reward": 791.0, "best_episode_reward": 988.0, "step": 65000}
{"episode": 264.0, "episode_reward": 829.8, "eval_time": 29.042061805725098, "mean_episode_reward": 829.8, "best_episode_reward": 999.0, "step": 66000}
{"episode": 268.0, "episode_reward": 785.2, "eval_time": 29.04270362854004, "mean_episode_reward": 785.2, "best_episode_reward": 994.0, "step": 67000}
{"episode": 272.0, "episode_reward": 966.6, "eval_time": 29.09537982940674, "mean_episode_reward": 966.6, "best_episode_reward": 997.0, "step": 68000}
{"episode": 276.0, "episode_reward": 837.1, "eval_time": 29.12016010284424, "mean_episode_reward": 837.1, "best_episode_reward": 982.0, "step": 69000}
{"episode": 280.0, "episode_reward": 775.8, "eval_time": 29.11788558959961, "mean_episode_reward": 775.8, "best_episode_reward": 986.0, "step": 70000}
{"episode": 284.0, "episode_reward": 882.8, "eval_time": 29.13852286338806, "mean_episode_reward": 882.8, "best_episode_reward": 1000.0, "step": 71000}
{"episode": 288.0, "episode_reward": 655.1, "eval_time": 29.07969903945923, "mean_episode_reward": 655.1, "best_episode_reward": 969.0, "step": 72000}
{"episode": 292.0, "episode_reward": 778.6, "eval_time": 29.08626675605774, "mean_episode_reward": 778.6, "best_episode_reward": 1000.0, "step": 73000}
{"episode": 296.0, "episode_reward": 728.6, "eval_time": 29.12972140312195, "mean_episode_reward": 728.6, "best_episode_reward": 1000.0, "step": 74000}
{"episode": 300.0, "episode_reward": 883.6, "eval_time": 29.0669162273407, "mean_episode_reward": 883.6, "best_episode_reward": 985.0, "step": 75000}
{"episode": 304.0, "episode_reward": 966.5, "eval_time": 29.11012554168701, "mean_episode_reward": 966.5, "best_episode_reward": 997.0, "step": 76000}
{"episode": 308.0, "episode_reward": 848.0, "eval_time": 29.052812099456787, "mean_episode_reward": 848.0, "best_episode_reward": 997.0, "step": 77000}
{"episode": 312.0, "episode_reward": 960.1, "eval_time": 29.131041049957275, "mean_episode_reward": 960.1, "best_episode_reward": 991.0, "step": 78000}
{"episode": 316.0, "episode_reward": 796.9, "eval_time": 29.104109048843384, "mean_episode_reward": 796.9, "best_episode_reward": 987.0, "step": 79000}
{"episode": 320.0, "episode_reward": 961.9, "eval_time": 29.115867137908936, "mean_episode_reward": 961.9, "best_episode_reward": 1000.0, "step": 80000}
{"episode": 324.0, "episode_reward": 964.1, "eval_time": 29.11379599571228, "mean_episode_reward": 964.1, "best_episode_reward": 999.0, "step": 81000}
{"episode": 328.0, "episode_reward": 783.1, "eval_time": 29.15766406059265, "mean_episode_reward": 783.1, "best_episode_reward": 994.0, "step": 82000}
{"episode": 332.0, "episode_reward": 760.8, "eval_time": 29.11117649078369, "mean_episode_reward": 760.8, "best_episode_reward": 997.0, "step": 83000}
{"episode": 336.0, "episode_reward": 927.6, "eval_time": 29.106359720230103, "mean_episode_reward": 927.6, "best_episode_reward": 1000.0, "step": 84000}
{"episode": 340.0, "episode_reward": 779.1, "eval_time": 29.12367081642151, "mean_episode_reward": 779.1, "best_episode_reward": 989.0, "step": 85000}
{"episode": 344.0, "episode_reward": 848.2, "eval_time": 29.100464820861816, "mean_episode_reward": 848.2, "best_episode_reward": 996.0, "step": 86000}
{"episode": 348.0, "episode_reward": 862.7, "eval_time": 29.174946069717407, "mean_episode_reward": 862.7, "best_episode_reward": 987.0, "step": 87000}
{"episode": 352.0, "episode_reward": 767.9, "eval_time": 29.12531304359436, "mean_episode_reward": 767.9, "best_episode_reward": 982.0, "step": 88000}
{"episode": 356.0, "episode_reward": 875.8, "eval_time": 29.166080713272095, "mean_episode_reward": 875.8, "best_episode_reward": 985.0, "step": 89000}
{"episode": 360.0, "episode_reward": 875.5, "eval_time": 29.12199831008911, "mean_episode_reward": 875.5, "best_episode_reward": 985.0, "step": 90000}
{"episode": 364.0, "episode_reward": 751.4, "eval_time": 29.069911241531372, "mean_episode_reward": 751.4, "best_episode_reward": 1000.0, "step": 91000}
{"episode": 368.0, "episode_reward": 858.9, "eval_time": 29.15122413635254, "mean_episode_reward": 858.9, "best_episode_reward": 997.0, "step": 92000}
{"episode": 372.0, "episode_reward": 942.2, "eval_time": 29.12965202331543, "mean_episode_reward": 942.2, "best_episode_reward": 977.0, "step": 93000}
{"episode": 376.0, "episode_reward": 801.2, "eval_time": 29.102823972702026, "mean_episode_reward": 801.2, "best_episode_reward": 1000.0, "step": 94000}
{"episode": 380.0, "episode_reward": 969.6, "eval_time": 29.155481576919556, "mean_episode_reward": 969.6, "best_episode_reward": 994.0, "step": 95000}
{"episode": 384.0, "episode_reward": 928.4, "eval_time": 29.03518319129944, "mean_episode_reward": 928.4, "best_episode_reward": 987.0, "step": 96000}
{"episode": 388.0, "episode_reward": 970.8, "eval_time": 29.07300305366516, "mean_episode_reward": 970.8, "best_episode_reward": 989.0, "step": 97000}
{"episode": 392.0, "episode_reward": 915.7, "eval_time": 29.1122465133667, "mean_episode_reward": 915.7, "best_episode_reward": 1000.0, "step": 98000}
{"episode": 396.0, "episode_reward": 961.9, "eval_time": 29.131999254226685, "mean_episode_reward": 961.9, "best_episode_reward": 999.0, "step": 99000}
{"episode": 400.0, "episode_reward": 843.3, "eval_time": 29.18548893928528, "mean_episode_reward": 843.3, "best_episode_reward": 1000.0, "step": 100000}
{"episode": 404.0, "episode_reward": 768.6, "eval_time": 29.096708297729492, "mean_episode_reward": 768.6, "best_episode_reward": 991.0, "step": 101000}
{"episode": 408.0, "episode_reward": 968.5, "eval_time": 29.097203731536865, "mean_episode_reward": 968.5, "best_episode_reward": 1000.0, "step": 102000}
{"episode": 412.0, "episode_reward": 935.8, "eval_time": 29.132057666778564, "mean_episode_reward": 935.8, "best_episode_reward": 995.0, "step": 103000}
{"episode": 416.0, "episode_reward": 857.2, "eval_time": 29.082756519317627, "mean_episode_reward": 857.2, "best_episode_reward": 1000.0, "step": 104000}
{"episode": 420.0, "episode_reward": 967.2, "eval_time": 29.180727005004883, "mean_episode_reward": 967.2, "best_episode_reward": 990.0, "step": 105000}
{"episode": 424.0, "episode_reward": 932.4, "eval_time": 29.122398614883423, "mean_episode_reward": 932.4, "best_episode_reward": 994.0, "step": 106000}
{"episode": 428.0, "episode_reward": 974.4, "eval_time": 29.139928579330444, "mean_episode_reward": 974.4, "best_episode_reward": 1000.0, "step": 107000}
{"episode": 432.0, "episode_reward": 830.3, "eval_time": 29.151099920272827, "mean_episode_reward": 830.3, "best_episode_reward": 991.0, "step": 108000}
{"episode": 436.0, "episode_reward": 955.2, "eval_time": 29.163424968719482, "mean_episode_reward": 955.2, "best_episode_reward": 996.0, "step": 109000}
{"episode": 440.0, "episode_reward": 889.3, "eval_time": 29.167296886444092, "mean_episode_reward": 889.3, "best_episode_reward": 998.0, "step": 110000}
{"episode": 444.0, "episode_reward": 879.0, "eval_time": 29.150760412216187, "mean_episode_reward": 879.0, "best_episode_reward": 1000.0, "step": 111000}
{"episode": 448.0, "episode_reward": 969.3, "eval_time": 29.17987823486328, "mean_episode_reward": 969.3, "best_episode_reward": 991.0, "step": 112000}
{"episode": 452.0, "episode_reward": 960.8, "eval_time": 29.08234667778015, "mean_episode_reward": 960.8, "best_episode_reward": 983.0, "step": 113000}
{"episode": 456.0, "episode_reward": 937.3, "eval_time": 29.064813137054443, "mean_episode_reward": 937.3, "best_episode_reward": 987.0, "step": 114000}
{"episode": 460.0, "episode_reward": 966.6, "eval_time": 29.091656923294067, "mean_episode_reward": 966.6, "best_episode_reward": 987.0, "step": 115000}
{"episode": 464.0, "episode_reward": 974.0, "eval_time": 29.147610902786255, "mean_episode_reward": 974.0, "best_episode_reward": 989.0, "step": 116000}
{"episode": 468.0, "episode_reward": 970.9, "eval_time": 29.175020456314087, "mean_episode_reward": 970.9, "best_episode_reward": 991.0, "step": 117000}
{"episode": 472.0, "episode_reward": 889.2, "eval_time": 29.125002145767212, "mean_episode_reward": 889.2, "best_episode_reward": 996.0, "step": 118000}
{"episode": 476.0, "episode_reward": 966.7, "eval_time": 29.093456506729126, "mean_episode_reward": 966.7, "best_episode_reward": 980.0, "step": 119000}
{"episode": 480.0, "episode_reward": 793.3, "eval_time": 29.19123411178589, "mean_episode_reward": 793.3, "best_episode_reward": 994.0, "step": 120000}
{"episode": 484.0, "episode_reward": 969.8, "eval_time": 29.08945870399475, "mean_episode_reward": 969.8, "best_episode_reward": 996.0, "step": 121000}
{"episode": 488.0, "episode_reward": 956.1, "eval_time": 29.153752326965332, "mean_episode_reward": 956.1, "best_episode_reward": 977.0, "step": 122000}
{"episode": 492.0, "episode_reward": 805.7, "eval_time": 29.12277841567993, "mean_episode_reward": 805.7, "best_episode_reward": 984.0, "step": 123000}
{"episode": 496.0, "episode_reward": 736.9, "eval_time": 29.139134645462036, "mean_episode_reward": 736.9, "best_episode_reward": 975.0, "step": 124000}
{"episode": 500.0, "episode_reward": 878.8, "eval_time": 29.02767562866211, "mean_episode_reward": 878.8, "best_episode_reward": 992.0, "step": 125000}
{"episode": 504.0, "episode_reward": 868.7, "eval_time": 29.149601697921753, "mean_episode_reward": 868.7, "best_episode_reward": 999.0, "step": 126000}
{"episode": 508.0, "episode_reward": 876.2, "eval_time": 29.11992859840393, "mean_episode_reward": 876.2, "best_episode_reward": 999.0, "step": 127000}
{"episode": 512.0, "episode_reward": 967.1, "eval_time": 29.16682457923889, "mean_episode_reward": 967.1, "best_episode_reward": 990.0, "step": 128000}
{"episode": 516.0, "episode_reward": 867.4, "eval_time": 29.09415626525879, "mean_episode_reward": 867.4, "best_episode_reward": 985.0, "step": 129000}
{"episode": 520.0, "episode_reward": 954.2, "eval_time": 29.07092523574829, "mean_episode_reward": 954.2, "best_episode_reward": 998.0, "step": 130000}
{"episode": 524.0, "episode_reward": 874.8, "eval_time": 29.13884735107422, "mean_episode_reward": 874.8, "best_episode_reward": 991.0, "step": 131000}
{"episode": 528.0, "episode_reward": 803.9, "eval_time": 29.11639642715454, "mean_episode_reward": 803.9, "best_episode_reward": 994.0, "step": 132000}
{"episode": 532.0, "episode_reward": 863.2, "eval_time": 29.070253610610962, "mean_episode_reward": 863.2, "best_episode_reward": 1000.0, "step": 133000}
{"episode": 536.0, "episode_reward": 786.7, "eval_time": 29.087880849838257, "mean_episode_reward": 786.7, "best_episode_reward": 1000.0, "step": 134000}
{"episode": 540.0, "episode_reward": 972.5, "eval_time": 29.118867874145508, "mean_episode_reward": 972.5, "best_episode_reward": 994.0, "step": 135000}
{"episode": 544.0, "episode_reward": 912.9, "eval_time": 29.35690951347351, "mean_episode_reward": 912.9, "best_episode_reward": 996.0, "step": 136000}
{"episode": 548.0, "episode_reward": 950.5, "eval_time": 29.098782300949097, "mean_episode_reward": 950.5, "best_episode_reward": 985.0, "step": 137000}
{"episode": 552.0, "episode_reward": 966.4, "eval_time": 29.129486322402954, "mean_episode_reward": 966.4, "best_episode_reward": 996.0, "step": 138000}
{"episode": 556.0, "episode_reward": 972.7, "eval_time": 29.107853174209595, "mean_episode_reward": 972.7, "best_episode_reward": 997.0, "step": 139000}
{"episode": 560.0, "episode_reward": 960.7, "eval_time": 29.073792457580566, "mean_episode_reward": 960.7, "best_episode_reward": 986.0, "step": 140000}
{"episode": 564.0, "episode_reward": 972.1, "eval_time": 29.21003246307373, "mean_episode_reward": 972.1, "best_episode_reward": 991.0, "step": 141000}
{"episode": 568.0, "episode_reward": 970.1, "eval_time": 29.315962314605713, "mean_episode_reward": 970.1, "best_episode_reward": 999.0, "step": 142000}
{"episode": 572.0, "episode_reward": 951.1, "eval_time": 29.129480361938477, "mean_episode_reward": 951.1, "best_episode_reward": 986.0, "step": 143000}
{"episode": 576.0, "episode_reward": 976.6, "eval_time": 29.27070665359497, "mean_episode_reward": 976.6, "best_episode_reward": 1000.0, "step": 144000}
{"episode": 580.0, "episode_reward": 879.0, "eval_time": 29.224931001663208, "mean_episode_reward": 879.0, "best_episode_reward": 994.0, "step": 145000}
{"episode": 584.0, "episode_reward": 653.8, "eval_time": 29.157027006149292, "mean_episode_reward": 653.8, "best_episode_reward": 985.0, "step": 146000}
{"episode": 588.0, "episode_reward": 869.4, "eval_time": 29.28845500946045, "mean_episode_reward": 869.4, "best_episode_reward": 997.0, "step": 147000}
{"episode": 592.0, "episode_reward": 868.3, "eval_time": 29.20667791366577, "mean_episode_reward": 868.3, "best_episode_reward": 1000.0, "step": 148000}
{"episode": 596.0, "episode_reward": 873.7, "eval_time": 29.130398273468018, "mean_episode_reward": 873.7, "best_episode_reward": 993.0, "step": 149000}
{"episode": 600.0, "episode_reward": 964.7, "eval_time": 29.23929238319397, "mean_episode_reward": 964.7, "best_episode_reward": 987.0, "step": 150000}
{"episode": 604.0, "episode_reward": 672.2, "eval_time": 29.184698581695557, "mean_episode_reward": 672.2, "best_episode_reward": 1000.0, "step": 151000}
{"episode": 608.0, "episode_reward": 869.4, "eval_time": 29.198127508163452, "mean_episode_reward": 869.4, "best_episode_reward": 998.0, "step": 152000}
{"episode": 612.0, "episode_reward": 865.9, "eval_time": 29.271082639694214, "mean_episode_reward": 865.9, "best_episode_reward": 984.0, "step": 153000}
{"episode": 616.0, "episode_reward": 778.6, "eval_time": 29.300163507461548, "mean_episode_reward": 778.6, "best_episode_reward": 997.0, "step": 154000}
{"episode": 620.0, "episode_reward": 974.1, "eval_time": 29.224870681762695, "mean_episode_reward": 974.1, "best_episode_reward": 1000.0, "step": 155000}
{"episode": 624.0, "episode_reward": 967.2, "eval_time": 29.208740949630737, "mean_episode_reward": 967.2, "best_episode_reward": 996.0, "step": 156000}
{"episode": 628.0, "episode_reward": 951.3, "eval_time": 29.26569652557373, "mean_episode_reward": 951.3, "best_episode_reward": 990.0, "step": 157000}
{"episode": 632.0, "episode_reward": 967.1, "eval_time": 29.273940801620483, "mean_episode_reward": 967.1, "best_episode_reward": 994.0, "step": 158000}
{"episode": 636.0, "episode_reward": 971.9, "eval_time": 29.4492666721344, "mean_episode_reward": 971.9, "best_episode_reward": 988.0, "step": 159000}
{"episode": 640.0, "episode_reward": 777.8, "eval_time": 29.653698921203613, "mean_episode_reward": 777.8, "best_episode_reward": 993.0, "step": 160000}
{"episode": 644.0, "episode_reward": 902.0, "eval_time": 29.247633934020996, "mean_episode_reward": 902.0, "best_episode_reward": 1000.0, "step": 161000}
{"episode": 648.0, "episode_reward": 966.4, "eval_time": 29.370256185531616, "mean_episode_reward": 966.4, "best_episode_reward": 996.0, "step": 162000}
{"episode": 652.0, "episode_reward": 873.2, "eval_time": 29.77563786506653, "mean_episode_reward": 873.2, "best_episode_reward": 996.0, "step": 163000}
{"episode": 656.0, "episode_reward": 726.8, "eval_time": 29.68066954612732, "mean_episode_reward": 726.8, "best_episode_reward": 992.0, "step": 164000}
{"episode": 660.0, "episode_reward": 968.4, "eval_time": 29.72377061843872, "mean_episode_reward": 968.4, "best_episode_reward": 985.0, "step": 165000}
{"episode": 664.0, "episode_reward": 961.7, "eval_time": 29.68458652496338, "mean_episode_reward": 961.7, "best_episode_reward": 997.0, "step": 166000}
{"episode": 668.0, "episode_reward": 777.9, "eval_time": 29.761667728424072, "mean_episode_reward": 777.9, "best_episode_reward": 983.0, "step": 167000}
{"episode": 672.0, "episode_reward": 872.4, "eval_time": 29.74372887611389, "mean_episode_reward": 872.4, "best_episode_reward": 1000.0, "step": 168000}
{"episode": 676.0, "episode_reward": 968.0, "eval_time": 29.73441433906555, "mean_episode_reward": 968.0, "best_episode_reward": 994.0, "step": 169000}
{"episode": 680.0, "episode_reward": 885.9, "eval_time": 29.716485500335693, "mean_episode_reward": 885.9, "best_episode_reward": 1000.0, "step": 170000}
{"episode": 684.0, "episode_reward": 967.1, "eval_time": 29.74324870109558, "mean_episode_reward": 967.1, "best_episode_reward": 997.0, "step": 171000}
{"episode": 688.0, "episode_reward": 968.4, "eval_time": 29.584269762039185, "mean_episode_reward": 968.4, "best_episode_reward": 991.0, "step": 172000}
{"episode": 692.0, "episode_reward": 876.2, "eval_time": 29.657347679138184, "mean_episode_reward": 876.2, "best_episode_reward": 991.0, "step": 173000}
{"episode": 696.0, "episode_reward": 883.6, "eval_time": 29.670597314834595, "mean_episode_reward": 883.6, "best_episode_reward": 998.0, "step": 174000}
{"episode": 700.0, "episode_reward": 876.2, "eval_time": 29.678905487060547, "mean_episode_reward": 876.2, "best_episode_reward": 996.0, "step": 175000}
{"episode": 704.0, "episode_reward": 820.8, "eval_time": 29.61202573776245, "mean_episode_reward": 820.8, "best_episode_reward": 1000.0, "step": 176000}
{"episode": 708.0, "episode_reward": 775.0, "eval_time": 29.633915185928345, "mean_episode_reward": 775.0, "best_episode_reward": 999.0, "step": 177000}
{"episode": 712.0, "episode_reward": 880.6, "eval_time": 29.634382963180542, "mean_episode_reward": 880.6, "best_episode_reward": 1000.0, "step": 178000}
{"episode": 716.0, "episode_reward": 827.1, "eval_time": 29.773199558258057, "mean_episode_reward": 827.1, "best_episode_reward": 1000.0, "step": 179000}
{"episode": 720.0, "episode_reward": 882.2, "eval_time": 29.753151893615723, "mean_episode_reward": 882.2, "best_episode_reward": 996.0, "step": 180000}
{"episode": 724.0, "episode_reward": 834.5, "eval_time": 29.769991159439087, "mean_episode_reward": 834.5, "best_episode_reward": 979.0, "step": 181000}
{"episode": 728.0, "episode_reward": 861.5, "eval_time": 29.708208799362183, "mean_episode_reward": 861.5, "best_episode_reward": 1000.0, "step": 182000}
{"episode": 732.0, "episode_reward": 970.3, "eval_time": 29.71847414970398, "mean_episode_reward": 970.3, "best_episode_reward": 998.0, "step": 183000}
{"episode": 736.0, "episode_reward": 877.3, "eval_time": 29.87196135520935, "mean_episode_reward": 877.3, "best_episode_reward": 980.0, "step": 184000}
{"episode": 740.0, "episode_reward": 881.2, "eval_time": 29.420665979385376, "mean_episode_reward": 881.2, "best_episode_reward": 990.0, "step": 185000}
{"episode": 744.0, "episode_reward": 958.2, "eval_time": 29.3971951007843, "mean_episode_reward": 958.2, "best_episode_reward": 997.0, "step": 186000}
{"episode": 748.0, "episode_reward": 763.7, "eval_time": 29.36636757850647, "mean_episode_reward": 763.7, "best_episode_reward": 986.0, "step": 187000}
{"episode": 752.0, "episode_reward": 772.5, "eval_time": 29.2224600315094, "mean_episode_reward": 772.5, "best_episode_reward": 1000.0, "step": 188000}
{"episode": 756.0, "episode_reward": 879.1, "eval_time": 29.291003942489624, "mean_episode_reward": 879.1, "best_episode_reward": 1000.0, "step": 189000}
{"episode": 760.0, "episode_reward": 981.4, "eval_time": 29.26075530052185, "mean_episode_reward": 981.4, "best_episode_reward": 996.0, "step": 190000}
{"episode": 764.0, "episode_reward": 977.6, "eval_time": 29.788123607635498, "mean_episode_reward": 977.6, "best_episode_reward": 1000.0, "step": 191000}
{"episode": 768.0, "episode_reward": 971.2, "eval_time": 29.655742168426514, "mean_episode_reward": 971.2, "best_episode_reward": 990.0, "step": 192000}
{"episode": 772.0, "episode_reward": 982.8, "eval_time": 29.875242948532104, "mean_episode_reward": 982.8, "best_episode_reward": 1000.0, "step": 193000}
{"episode": 776.0, "episode_reward": 889.0, "eval_time": 29.243664026260376, "mean_episode_reward": 889.0, "best_episode_reward": 1000.0, "step": 194000}
{"episode": 780.0, "episode_reward": 987.3, "eval_time": 29.420201301574707, "mean_episode_reward": 987.3, "best_episode_reward": 998.0, "step": 195000}
{"episode": 784.0, "episode_reward": 794.8, "eval_time": 29.197845458984375, "mean_episode_reward": 794.8, "best_episode_reward": 999.0, "step": 196000}
{"episode": 788.0, "episode_reward": 982.5, "eval_time": 29.29485321044922, "mean_episode_reward": 982.5, "best_episode_reward": 993.0, "step": 197000}
{"episode": 792.0, "episode_reward": 783.9, "eval_time": 29.209688901901245, "mean_episode_reward": 783.9, "best_episode_reward": 998.0, "step": 198000}
{"episode": 796.0, "episode_reward": 735.8, "eval_time": 29.210419416427612, "mean_episode_reward": 735.8, "best_episode_reward": 993.0, "step": 199000}
{"episode": 800.0, "episode_reward": 871.6, "eval_time": 29.21110510826111, "mean_episode_reward": 871.6, "best_episode_reward": 1000.0, "step": 200000}
{"episode": 804.0, "episode_reward": 973.9, "eval_time": 29.183388471603394, "mean_episode_reward": 973.9, "best_episode_reward": 996.0, "step": 201000}
{"episode": 808.0, "episode_reward": 948.0, "eval_time": 29.289458751678467, "mean_episode_reward": 948.0, "best_episode_reward": 991.0, "step": 202000}
{"episode": 812.0, "episode_reward": 973.4, "eval_time": 29.30598473548889, "mean_episode_reward": 973.4, "best_episode_reward": 1000.0, "step": 203000}
{"episode": 816.0, "episode_reward": 866.1, "eval_time": 29.32771944999695, "mean_episode_reward": 866.1, "best_episode_reward": 1000.0, "step": 204000}
{"episode": 820.0, "episode_reward": 980.4, "eval_time": 29.20646858215332, "mean_episode_reward": 980.4, "best_episode_reward": 1000.0, "step": 205000}
{"episode": 824.0, "episode_reward": 981.6, "eval_time": 29.262179613113403, "mean_episode_reward": 981.6, "best_episode_reward": 1000.0, "step": 206000}
{"episode": 828.0, "episode_reward": 964.0, "eval_time": 29.369426488876343, "mean_episode_reward": 964.0, "best_episode_reward": 999.0, "step": 207000}
{"episode": 832.0, "episode_reward": 976.8, "eval_time": 29.320443868637085, "mean_episode_reward": 976.8, "best_episode_reward": 996.0, "step": 208000}
{"episode": 836.0, "episode_reward": 877.1, "eval_time": 29.31124210357666, "mean_episode_reward": 877.1, "best_episode_reward": 1000.0, "step": 209000}
{"episode": 840.0, "episode_reward": 877.8, "eval_time": 29.41209077835083, "mean_episode_reward": 877.8, "best_episode_reward": 991.0, "step": 210000}
{"episode": 844.0, "episode_reward": 961.3, "eval_time": 29.293946981430054, "mean_episode_reward": 961.3, "best_episode_reward": 999.0, "step": 211000}
{"episode": 848.0, "episode_reward": 927.0, "eval_time": 29.354944229125977, "mean_episode_reward": 927.0, "best_episode_reward": 999.0, "step": 212000}
{"episode": 852.0, "episode_reward": 984.0, "eval_time": 29.183196306228638, "mean_episode_reward": 984.0, "best_episode_reward": 1000.0, "step": 213000}
{"episode": 856.0, "episode_reward": 781.1, "eval_time": 29.434672355651855, "mean_episode_reward": 781.1, "best_episode_reward": 1000.0, "step": 214000}
{"episode": 860.0, "episode_reward": 878.7, "eval_time": 29.414273500442505, "mean_episode_reward": 878.7, "best_episode_reward": 993.0, "step": 215000}
{"episode": 864.0, "episode_reward": 974.4, "eval_time": 29.37007164955139, "mean_episode_reward": 974.4, "best_episode_reward": 997.0, "step": 216000}
{"episode": 868.0, "episode_reward": 872.3, "eval_time": 29.387373685836792, "mean_episode_reward": 872.3, "best_episode_reward": 999.0, "step": 217000}
{"episode": 872.0, "episode_reward": 979.0, "eval_time": 29.37451195716858, "mean_episode_reward": 979.0, "best_episode_reward": 998.0, "step": 218000}
{"episode": 876.0, "episode_reward": 880.0, "eval_time": 29.284784078598022, "mean_episode_reward": 880.0, "best_episode_reward": 1000.0, "step": 219000}
{"episode": 880.0, "episode_reward": 957.1, "eval_time": 29.393932342529297, "mean_episode_reward": 957.1, "best_episode_reward": 993.0, "step": 220000}
{"episode": 884.0, "episode_reward": 957.4, "eval_time": 29.33649516105652, "mean_episode_reward": 957.4, "best_episode_reward": 991.0, "step": 221000}
{"episode": 888.0, "episode_reward": 965.3, "eval_time": 29.383456707000732, "mean_episode_reward": 965.3, "best_episode_reward": 996.0, "step": 222000}
{"episode": 892.0, "episode_reward": 963.8, "eval_time": 29.28335428237915, "mean_episode_reward": 963.8, "best_episode_reward": 990.0, "step": 223000}
{"episode": 896.0, "episode_reward": 969.8, "eval_time": 29.364486694335938, "mean_episode_reward": 969.8, "best_episode_reward": 1000.0, "step": 224000}
{"episode": 900.0, "episode_reward": 976.4, "eval_time": 29.219780921936035, "mean_episode_reward": 976.4, "best_episode_reward": 1000.0, "step": 225000}
{"episode": 904.0, "episode_reward": 859.9, "eval_time": 29.32202649116516, "mean_episode_reward": 859.9, "best_episode_reward": 999.0, "step": 226000}
{"episode": 908.0, "episode_reward": 972.8, "eval_time": 29.308233499526978, "mean_episode_reward": 972.8, "best_episode_reward": 987.0, "step": 227000}
{"episode": 912.0, "episode_reward": 972.8, "eval_time": 29.411401510238647, "mean_episode_reward": 972.8, "best_episode_reward": 1000.0, "step": 228000}
{"episode": 916.0, "episode_reward": 973.1, "eval_time": 29.286407709121704, "mean_episode_reward": 973.1, "best_episode_reward": 996.0, "step": 229000}
{"episode": 920.0, "episode_reward": 876.5, "eval_time": 29.307302474975586, "mean_episode_reward": 876.5, "best_episode_reward": 992.0, "step": 230000}
{"episode": 924.0, "episode_reward": 870.2, "eval_time": 29.353142499923706, "mean_episode_reward": 870.2, "best_episode_reward": 999.0, "step": 231000}
{"episode": 928.0, "episode_reward": 982.7, "eval_time": 29.350608825683594, "mean_episode_reward": 982.7, "best_episode_reward": 997.0, "step": 232000}
{"episode": 932.0, "episode_reward": 961.4, "eval_time": 29.397417783737183, "mean_episode_reward": 961.4, "best_episode_reward": 986.0, "step": 233000}
{"episode": 936.0, "episode_reward": 969.0, "eval_time": 29.31604766845703, "mean_episode_reward": 969.0, "best_episode_reward": 998.0, "step": 234000}
{"episode": 940.0, "episode_reward": 868.3, "eval_time": 29.375355005264282, "mean_episode_reward": 868.3, "best_episode_reward": 999.0, "step": 235000}
{"episode": 944.0, "episode_reward": 983.0, "eval_time": 29.319993495941162, "mean_episode_reward": 983.0, "best_episode_reward": 1000.0, "step": 236000}
{"episode": 948.0, "episode_reward": 977.9, "eval_time": 29.3940269947052, "mean_episode_reward": 977.9, "best_episode_reward": 1000.0, "step": 237000}
{"episode": 952.0, "episode_reward": 882.8, "eval_time": 29.365724086761475, "mean_episode_reward": 882.8, "best_episode_reward": 1000.0, "step": 238000}
{"episode": 956.0, "episode_reward": 830.1, "eval_time": 29.340406894683838, "mean_episode_reward": 830.1, "best_episode_reward": 993.0, "step": 239000}
{"episode": 960.0, "episode_reward": 879.5, "eval_time": 29.398623943328857, "mean_episode_reward": 879.5, "best_episode_reward": 991.0, "step": 240000}
{"episode": 964.0, "episode_reward": 776.6, "eval_time": 29.338454484939575, "mean_episode_reward": 776.6, "best_episode_reward": 994.0, "step": 241000}
{"episode": 968.0, "episode_reward": 883.0, "eval_time": 29.3446102142334, "mean_episode_reward": 883.0, "best_episode_reward": 997.0, "step": 242000}
{"episode": 972.0, "episode_reward": 973.5, "eval_time": 29.444761037826538, "mean_episode_reward": 973.5, "best_episode_reward": 1000.0, "step": 243000}
{"episode": 976.0, "episode_reward": 851.8, "eval_time": 29.321394205093384, "mean_episode_reward": 851.8, "best_episode_reward": 994.0, "step": 244000}
{"episode": 980.0, "episode_reward": 970.8, "eval_time": 29.31033706665039, "mean_episode_reward": 970.8, "best_episode_reward": 1000.0, "step": 245000}
{"episode": 984.0, "episode_reward": 977.0, "eval_time": 29.325315952301025, "mean_episode_reward": 977.0, "best_episode_reward": 1000.0, "step": 246000}
{"episode": 988.0, "episode_reward": 972.2, "eval_time": 29.364590406417847, "mean_episode_reward": 972.2, "best_episode_reward": 1000.0, "step": 247000}
{"episode": 992.0, "episode_reward": 974.2, "eval_time": 29.29741144180298, "mean_episode_reward": 974.2, "best_episode_reward": 1000.0, "step": 248000}
{"episode": 996.0, "episode_reward": 974.3, "eval_time": 29.32032871246338, "mean_episode_reward": 974.3, "best_episode_reward": 1000.0, "step": 249000}
{"episode": 1000.0, "episode_reward": 967.2, "eval_time": 29.37496829032898, "mean_episode_reward": 967.2, "best_episode_reward": 984.0, "step": 250000}
{"episode": 1004.0, "episode_reward": 883.4, "eval_time": 29.379158973693848, "mean_episode_reward": 883.4, "best_episode_reward": 1000.0, "step": 251000}
{"episode": 1008.0, "episode_reward": 977.5, "eval_time": 29.308776378631592, "mean_episode_reward": 977.5, "best_episode_reward": 990.0, "step": 252000}
{"episode": 1012.0, "episode_reward": 956.4, "eval_time": 29.341776609420776, "mean_episode_reward": 956.4, "best_episode_reward": 990.0, "step": 253000}
{"episode": 1016.0, "episode_reward": 979.4, "eval_time": 29.362338304519653, "mean_episode_reward": 979.4, "best_episode_reward": 992.0, "step": 254000}
{"episode": 1020.0, "episode_reward": 980.1, "eval_time": 29.34106206893921, "mean_episode_reward": 980.1, "best_episode_reward": 996.0, "step": 255000}
{"episode": 1024.0, "episode_reward": 985.5, "eval_time": 29.35832405090332, "mean_episode_reward": 985.5, "best_episode_reward": 999.0, "step": 256000}
{"episode": 1028.0, "episode_reward": 923.7, "eval_time": 29.324634790420532, "mean_episode_reward": 923.7, "best_episode_reward": 993.0, "step": 257000}
{"episode": 1032.0, "episode_reward": 864.3, "eval_time": 29.339296579360962, "mean_episode_reward": 864.3, "best_episode_reward": 986.0, "step": 258000}
{"episode": 1036.0, "episode_reward": 970.4, "eval_time": 29.338627576828003, "mean_episode_reward": 970.4, "best_episode_reward": 1000.0, "step": 259000}
{"episode": 1040.0, "episode_reward": 979.2, "eval_time": 29.295778036117554, "mean_episode_reward": 979.2, "best_episode_reward": 1000.0, "step": 260000}
{"episode": 1044.0, "episode_reward": 968.2, "eval_time": 29.296707153320312, "mean_episode_reward": 968.2, "best_episode_reward": 988.0, "step": 261000}
{"episode": 1048.0, "episode_reward": 971.8, "eval_time": 29.403154373168945, "mean_episode_reward": 971.8, "best_episode_reward": 1000.0, "step": 262000}
{"episode": 1052.0, "episode_reward": 932.9, "eval_time": 29.321207523345947, "mean_episode_reward": 932.9, "best_episode_reward": 998.0, "step": 263000}
{"episode": 1056.0, "episode_reward": 808.3, "eval_time": 29.2726571559906, "mean_episode_reward": 808.3, "best_episode_reward": 998.0, "step": 264000}
{"episode": 1060.0, "episode_reward": 963.0, "eval_time": 29.359116792678833, "mean_episode_reward": 963.0, "best_episode_reward": 995.0, "step": 265000}
{"episode": 1064.0, "episode_reward": 983.2, "eval_time": 29.383907556533813, "mean_episode_reward": 983.2, "best_episode_reward": 1000.0, "step": 266000}
{"episode": 1068.0, "episode_reward": 949.0, "eval_time": 29.335270404815674, "mean_episode_reward": 949.0, "best_episode_reward": 987.0, "step": 267000}
{"episode": 1072.0, "episode_reward": 927.6, "eval_time": 29.329599618911743, "mean_episode_reward": 927.6, "best_episode_reward": 996.0, "step": 268000}
{"episode": 1076.0, "episode_reward": 974.0, "eval_time": 29.294800281524658, "mean_episode_reward": 974.0, "best_episode_reward": 993.0, "step": 269000}
{"episode": 1080.0, "episode_reward": 983.0, "eval_time": 29.307818174362183, "mean_episode_reward": 983.0, "best_episode_reward": 1000.0, "step": 270000}
{"episode": 1084.0, "episode_reward": 957.8, "eval_time": 29.388171434402466, "mean_episode_reward": 957.8, "best_episode_reward": 997.0, "step": 271000}
{"episode": 1088.0, "episode_reward": 967.8, "eval_time": 29.35648798942566, "mean_episode_reward": 967.8, "best_episode_reward": 997.0, "step": 272000}
{"episode": 1092.0, "episode_reward": 976.5, "eval_time": 29.454574823379517, "mean_episode_reward": 976.5, "best_episode_reward": 984.0, "step": 273000}
{"episode": 1096.0, "episode_reward": 831.3, "eval_time": 29.32679271697998, "mean_episode_reward": 831.3, "best_episode_reward": 1000.0, "step": 274000}
{"episode": 1100.0, "episode_reward": 876.6, "eval_time": 29.346543312072754, "mean_episode_reward": 876.6, "best_episode_reward": 980.0, "step": 275000}
{"episode": 1104.0, "episode_reward": 976.0, "eval_time": 29.319310903549194, "mean_episode_reward": 976.0, "best_episode_reward": 988.0, "step": 276000}
{"episode": 1108.0, "episode_reward": 960.8, "eval_time": 29.313721418380737, "mean_episode_reward": 960.8, "best_episode_reward": 994.0, "step": 277000}
{"episode": 1112.0, "episode_reward": 875.4, "eval_time": 29.729506015777588, "mean_episode_reward": 875.4, "best_episode_reward": 990.0, "step": 278000}
{"episode": 1116.0, "episode_reward": 976.8, "eval_time": 30.634681463241577, "mean_episode_reward": 976.8, "best_episode_reward": 989.0, "step": 279000}
{"episode": 1120.0, "episode_reward": 873.0, "eval_time": 30.19416832923889, "mean_episode_reward": 873.0, "best_episode_reward": 993.0, "step": 280000}
{"episode": 1124.0, "episode_reward": 973.0, "eval_time": 29.315651655197144, "mean_episode_reward": 973.0, "best_episode_reward": 989.0, "step": 281000}
{"episode": 1128.0, "episode_reward": 976.0, "eval_time": 29.38207983970642, "mean_episode_reward": 976.0, "best_episode_reward": 999.0, "step": 282000}
{"episode": 1132.0, "episode_reward": 944.9, "eval_time": 29.37318706512451, "mean_episode_reward": 944.9, "best_episode_reward": 1000.0, "step": 283000}
{"episode": 1136.0, "episode_reward": 941.8, "eval_time": 29.3243088722229, "mean_episode_reward": 941.8, "best_episode_reward": 989.0, "step": 284000}
{"episode": 1140.0, "episode_reward": 973.3, "eval_time": 29.35239839553833, "mean_episode_reward": 973.3, "best_episode_reward": 990.0, "step": 285000}
{"episode": 1144.0, "episode_reward": 964.4, "eval_time": 29.418048620224, "mean_episode_reward": 964.4, "best_episode_reward": 1000.0, "step": 286000}
{"episode": 1148.0, "episode_reward": 979.1, "eval_time": 29.919564962387085, "mean_episode_reward": 979.1, "best_episode_reward": 1000.0, "step": 287000}
{"episode": 1152.0, "episode_reward": 973.7, "eval_time": 30.551531314849854, "mean_episode_reward": 973.7, "best_episode_reward": 988.0, "step": 288000}
{"episode": 1156.0, "episode_reward": 968.9, "eval_time": 30.561547994613647, "mean_episode_reward": 968.9, "best_episode_reward": 976.0, "step": 289000}
{"episode": 1160.0, "episode_reward": 980.0, "eval_time": 30.551554441452026, "mean_episode_reward": 980.0, "best_episode_reward": 1000.0, "step": 290000}
{"episode": 1164.0, "episode_reward": 975.5, "eval_time": 30.55302095413208, "mean_episode_reward": 975.5, "best_episode_reward": 1000.0, "step": 291000}
{"episode": 1168.0, "episode_reward": 886.1, "eval_time": 30.540095567703247, "mean_episode_reward": 886.1, "best_episode_reward": 1000.0, "step": 292000}
{"episode": 1172.0, "episode_reward": 969.6, "eval_time": 30.605980157852173, "mean_episode_reward": 969.6, "best_episode_reward": 995.0, "step": 293000}
{"episode": 1176.0, "episode_reward": 980.8, "eval_time": 30.53114914894104, "mean_episode_reward": 980.8, "best_episode_reward": 1000.0, "step": 294000}
{"episode": 1180.0, "episode_reward": 979.9, "eval_time": 30.554689645767212, "mean_episode_reward": 979.9, "best_episode_reward": 997.0, "step": 295000}
{"episode": 1184.0, "episode_reward": 974.0, "eval_time": 30.514338493347168, "mean_episode_reward": 974.0, "best_episode_reward": 1000.0, "step": 296000}
{"episode": 1188.0, "episode_reward": 976.6, "eval_time": 30.553261280059814, "mean_episode_reward": 976.6, "best_episode_reward": 997.0, "step": 297000}
{"episode": 1192.0, "episode_reward": 892.6, "eval_time": 30.524577617645264, "mean_episode_reward": 892.6, "best_episode_reward": 1000.0, "step": 298000}
{"episode": 1196.0, "episode_reward": 972.2, "eval_time": 30.537421226501465, "mean_episode_reward": 972.2, "best_episode_reward": 1000.0, "step": 299000}
{"episode": 1200.0, "episode_reward": 972.0, "eval_time": 30.58789587020874, "mean_episode_reward": 972.0, "best_episode_reward": 1000.0, "step": 300000}
{"episode": 1204.0, "episode_reward": 877.3, "eval_time": 30.491334676742554, "mean_episode_reward": 877.3, "best_episode_reward": 995.0, "step": 301000}
{"episode": 1208.0, "episode_reward": 977.6, "eval_time": 30.47896122932434, "mean_episode_reward": 977.6, "best_episode_reward": 1000.0, "step": 302000}
{"episode": 1212.0, "episode_reward": 880.3, "eval_time": 30.558658599853516, "mean_episode_reward": 880.3, "best_episode_reward": 995.0, "step": 303000}
{"episode": 1216.0, "episode_reward": 978.1, "eval_time": 30.56521964073181, "mean_episode_reward": 978.1, "best_episode_reward": 1000.0, "step": 304000}
{"episode": 1220.0, "episode_reward": 965.8, "eval_time": 30.48437738418579, "mean_episode_reward": 965.8, "best_episode_reward": 988.0, "step": 305000}
{"episode": 1224.0, "episode_reward": 970.8, "eval_time": 30.514110803604126, "mean_episode_reward": 970.8, "best_episode_reward": 996.0, "step": 306000}
{"episode": 1228.0, "episode_reward": 964.7, "eval_time": 30.615609407424927, "mean_episode_reward": 964.7, "best_episode_reward": 1000.0, "step": 307000}
{"episode": 1232.0, "episode_reward": 972.6, "eval_time": 30.472310781478882, "mean_episode_reward": 972.6, "best_episode_reward": 1000.0, "step": 308000}
{"episode": 1236.0, "episode_reward": 864.3, "eval_time": 30.529396295547485, "mean_episode_reward": 864.3, "best_episode_reward": 985.0, "step": 309000}
{"episode": 1240.0, "episode_reward": 964.4, "eval_time": 30.559722423553467, "mean_episode_reward": 964.4, "best_episode_reward": 990.0, "step": 310000}
{"episode": 1244.0, "episode_reward": 972.8, "eval_time": 30.60620617866516, "mean_episode_reward": 972.8, "best_episode_reward": 993.0, "step": 311000}
{"episode": 1248.0, "episode_reward": 885.7, "eval_time": 30.50622272491455, "mean_episode_reward": 885.7, "best_episode_reward": 1000.0, "step": 312000}
{"episode": 1252.0, "episode_reward": 945.1, "eval_time": 30.622902631759644, "mean_episode_reward": 945.1, "best_episode_reward": 996.0, "step": 313000}
{"episode": 1256.0, "episode_reward": 968.0, "eval_time": 30.476858854293823, "mean_episode_reward": 968.0, "best_episode_reward": 1000.0, "step": 314000}
{"episode": 1260.0, "episode_reward": 967.6, "eval_time": 30.535163402557373, "mean_episode_reward": 967.6, "best_episode_reward": 1000.0, "step": 315000}
{"episode": 1264.0, "episode_reward": 981.1, "eval_time": 30.579463481903076, "mean_episode_reward": 981.1, "best_episode_reward": 992.0, "step": 316000}
{"episode": 1268.0, "episode_reward": 881.7, "eval_time": 30.533152103424072, "mean_episode_reward": 881.7, "best_episode_reward": 1000.0, "step": 317000}
{"episode": 1272.0, "episode_reward": 963.5, "eval_time": 30.595112800598145, "mean_episode_reward": 963.5, "best_episode_reward": 991.0, "step": 318000}
{"episode": 1276.0, "episode_reward": 968.3, "eval_time": 30.566227912902832, "mean_episode_reward": 968.3, "best_episode_reward": 992.0, "step": 319000}
{"episode": 1280.0, "episode_reward": 886.7, "eval_time": 30.54975390434265, "mean_episode_reward": 886.7, "best_episode_reward": 1000.0, "step": 320000}
{"episode": 1284.0, "episode_reward": 966.9, "eval_time": 30.511736392974854, "mean_episode_reward": 966.9, "best_episode_reward": 1000.0, "step": 321000}
{"episode": 1288.0, "episode_reward": 901.7, "eval_time": 30.641790628433228, "mean_episode_reward": 901.7, "best_episode_reward": 1000.0, "step": 322000}
{"episode": 1292.0, "episode_reward": 881.1, "eval_time": 30.59465503692627, "mean_episode_reward": 881.1, "best_episode_reward": 994.0, "step": 323000}
{"episode": 1296.0, "episode_reward": 970.9, "eval_time": 30.588611602783203, "mean_episode_reward": 970.9, "best_episode_reward": 1000.0, "step": 324000}
{"episode": 1300.0, "episode_reward": 965.9, "eval_time": 30.622123956680298, "mean_episode_reward": 965.9, "best_episode_reward": 993.0, "step": 325000}
{"episode": 1304.0, "episode_reward": 966.0, "eval_time": 30.74911069869995, "mean_episode_reward": 966.0, "best_episode_reward": 1000.0, "step": 326000}
{"episode": 1308.0, "episode_reward": 973.6, "eval_time": 31.159011125564575, "mean_episode_reward": 973.6, "best_episode_reward": 1000.0, "step": 327000}
{"episode": 1312.0, "episode_reward": 984.9, "eval_time": 31.074989557266235, "mean_episode_reward": 984.9, "best_episode_reward": 1000.0, "step": 328000}
{"episode": 1316.0, "episode_reward": 985.2, "eval_time": 31.19083023071289, "mean_episode_reward": 985.2, "best_episode_reward": 1000.0, "step": 329000}
{"episode": 1320.0, "episode_reward": 975.9, "eval_time": 31.170547485351562, "mean_episode_reward": 975.9, "best_episode_reward": 1000.0, "step": 330000}
{"episode": 1324.0, "episode_reward": 930.1, "eval_time": 31.221062660217285, "mean_episode_reward": 930.1, "best_episode_reward": 988.0, "step": 331000}
{"episode": 1328.0, "episode_reward": 984.3, "eval_time": 31.190021514892578, "mean_episode_reward": 984.3, "best_episode_reward": 996.0, "step": 332000}
{"episode": 1332.0, "episode_reward": 971.3, "eval_time": 31.039694786071777, "mean_episode_reward": 971.3, "best_episode_reward": 985.0, "step": 333000}
{"episode": 1336.0, "episode_reward": 981.1, "eval_time": 31.02694845199585, "mean_episode_reward": 981.1, "best_episode_reward": 1000.0, "step": 334000}
{"episode": 1340.0, "episode_reward": 977.2, "eval_time": 31.104233741760254, "mean_episode_reward": 977.2, "best_episode_reward": 1000.0, "step": 335000}
{"episode": 1344.0, "episode_reward": 889.9, "eval_time": 31.07976746559143, "mean_episode_reward": 889.9, "best_episode_reward": 1000.0, "step": 336000}
{"episode": 1348.0, "episode_reward": 968.0, "eval_time": 31.065176010131836, "mean_episode_reward": 968.0, "best_episode_reward": 980.0, "step": 337000}
{"episode": 1352.0, "episode_reward": 974.0, "eval_time": 31.170835256576538, "mean_episode_reward": 974.0, "best_episode_reward": 999.0, "step": 338000}
{"episode": 1356.0, "episode_reward": 980.8, "eval_time": 31.0965359210968, "mean_episode_reward": 980.8, "best_episode_reward": 999.0, "step": 339000}
{"episode": 1360.0, "episode_reward": 970.3, "eval_time": 31.08539366722107, "mean_episode_reward": 970.3, "best_episode_reward": 1000.0, "step": 340000}
{"episode": 1364.0, "episode_reward": 789.8, "eval_time": 31.106072425842285, "mean_episode_reward": 789.8, "best_episode_reward": 1000.0, "step": 341000}
{"episode": 1368.0, "episode_reward": 971.4, "eval_time": 31.081969022750854, "mean_episode_reward": 971.4, "best_episode_reward": 995.0, "step": 342000}
{"episode": 1372.0, "episode_reward": 963.1, "eval_time": 31.141034603118896, "mean_episode_reward": 963.1, "best_episode_reward": 1000.0, "step": 343000}
{"episode": 1376.0, "episode_reward": 974.1, "eval_time": 30.986984252929688, "mean_episode_reward": 974.1, "best_episode_reward": 1000.0, "step": 344000}
{"episode": 1380.0, "episode_reward": 918.0, "eval_time": 31.104162216186523, "mean_episode_reward": 918.0, "best_episode_reward": 995.0, "step": 345000}
{"episode": 1384.0, "episode_reward": 980.4, "eval_time": 31.058506965637207, "mean_episode_reward": 980.4, "best_episode_reward": 1000.0, "step": 346000}
{"episode": 1388.0, "episode_reward": 874.8, "eval_time": 31.16149115562439, "mean_episode_reward": 874.8, "best_episode_reward": 1000.0, "step": 347000}
{"episode": 1392.0, "episode_reward": 825.0, "eval_time": 31.10862708091736, "mean_episode_reward": 825.0, "best_episode_reward": 1000.0, "step": 348000}
{"episode": 1396.0, "episode_reward": 784.3, "eval_time": 31.11498498916626, "mean_episode_reward": 784.3, "best_episode_reward": 995.0, "step": 349000}
{"episode": 1400.0, "episode_reward": 886.8, "eval_time": 31.096396684646606, "mean_episode_reward": 886.8, "best_episode_reward": 983.0, "step": 350000}
{"episode": 1404.0, "episode_reward": 917.2, "eval_time": 31.09213900566101, "mean_episode_reward": 917.2, "best_episode_reward": 989.0, "step": 351000}
{"episode": 1408.0, "episode_reward": 940.7, "eval_time": 31.229008436203003, "mean_episode_reward": 940.7, "best_episode_reward": 983.0, "step": 352000}
{"episode": 1412.0, "episode_reward": 873.7, "eval_time": 31.060385704040527, "mean_episode_reward": 873.7, "best_episode_reward": 997.0, "step": 353000}
{"episode": 1416.0, "episode_reward": 779.7, "eval_time": 31.03241753578186, "mean_episode_reward": 779.7, "best_episode_reward": 992.0, "step": 354000}
{"episode": 1420.0, "episode_reward": 953.5, "eval_time": 31.074311017990112, "mean_episode_reward": 953.5, "best_episode_reward": 989.0, "step": 355000}
{"episode": 1424.0, "episode_reward": 641.1, "eval_time": 31.08428144454956, "mean_episode_reward": 641.1, "best_episode_reward": 1000.0, "step": 356000}
{"episode": 1428.0, "episode_reward": 985.8, "eval_time": 31.01191258430481, "mean_episode_reward": 985.8, "best_episode_reward": 1000.0, "step": 357000}
{"episode": 1432.0, "episode_reward": 956.9, "eval_time": 31.073585510253906, "mean_episode_reward": 956.9, "best_episode_reward": 997.0, "step": 358000}
{"episode": 1436.0, "episode_reward": 887.6, "eval_time": 31.0910165309906, "mean_episode_reward": 887.6, "best_episode_reward": 1000.0, "step": 359000}
{"episode": 1440.0, "episode_reward": 977.8, "eval_time": 31.070462465286255, "mean_episode_reward": 977.8, "best_episode_reward": 999.0, "step": 360000}
{"episode": 1444.0, "episode_reward": 967.5, "eval_time": 31.058297395706177, "mean_episode_reward": 967.5, "best_episode_reward": 994.0, "step": 361000}
{"episode": 1448.0, "episode_reward": 977.0, "eval_time": 31.085898637771606, "mean_episode_reward": 977.0, "best_episode_reward": 998.0, "step": 362000}
{"episode": 1452.0, "episode_reward": 884.1, "eval_time": 31.01868224143982, "mean_episode_reward": 884.1, "best_episode_reward": 989.0, "step": 363000}
{"episode": 1456.0, "episode_reward": 776.3, "eval_time": 30.863407373428345, "mean_episode_reward": 776.3, "best_episode_reward": 984.0, "step": 364000}
{"episode": 1460.0, "episode_reward": 979.2, "eval_time": 31.01434874534607, "mean_episode_reward": 979.2, "best_episode_reward": 1000.0, "step": 365000}
{"episode": 1464.0, "episode_reward": 967.4, "eval_time": 30.939935207366943, "mean_episode_reward": 967.4, "best_episode_reward": 993.0, "step": 366000}
{"episode": 1468.0, "episode_reward": 969.4, "eval_time": 30.979753732681274, "mean_episode_reward": 969.4, "best_episode_reward": 1000.0, "step": 367000}
{"episode": 1472.0, "episode_reward": 788.1, "eval_time": 30.982963800430298, "mean_episode_reward": 788.1, "best_episode_reward": 992.0, "step": 368000}
{"episode": 1476.0, "episode_reward": 971.1, "eval_time": 30.975680351257324, "mean_episode_reward": 971.1, "best_episode_reward": 983.0, "step": 369000}
{"episode": 1480.0, "episode_reward": 884.3, "eval_time": 30.994739770889282, "mean_episode_reward": 884.3, "best_episode_reward": 992.0, "step": 370000}
{"episode": 1484.0, "episode_reward": 986.0, "eval_time": 30.929865837097168, "mean_episode_reward": 986.0, "best_episode_reward": 1000.0, "step": 371000}
{"episode": 1488.0, "episode_reward": 983.7, "eval_time": 30.964539527893066, "mean_episode_reward": 983.7, "best_episode_reward": 995.0, "step": 372000}
{"episode": 1492.0, "episode_reward": 949.1, "eval_time": 31.030083656311035, "mean_episode_reward": 949.1, "best_episode_reward": 989.0, "step": 373000}
{"episode": 1496.0, "episode_reward": 969.5, "eval_time": 30.861729621887207, "mean_episode_reward": 969.5, "best_episode_reward": 1000.0, "step": 374000}
{"episode": 1500.0, "episode_reward": 962.9, "eval_time": 31.150471210479736, "mean_episode_reward": 962.9, "best_episode_reward": 1000.0, "step": 375000}
{"episode": 1504.0, "episode_reward": 973.9, "eval_time": 30.955655574798584, "mean_episode_reward": 973.9, "best_episode_reward": 991.0, "step": 376000}
{"episode": 1508.0, "episode_reward": 973.4, "eval_time": 30.842490434646606, "mean_episode_reward": 973.4, "best_episode_reward": 1000.0, "step": 377000}
{"episode": 1512.0, "episode_reward": 963.1, "eval_time": 31.036176681518555, "mean_episode_reward": 963.1, "best_episode_reward": 991.0, "step": 378000}
{"episode": 1516.0, "episode_reward": 877.6, "eval_time": 30.992006301879883, "mean_episode_reward": 877.6, "best_episode_reward": 998.0, "step": 379000}
{"episode": 1520.0, "episode_reward": 956.5, "eval_time": 31.151890754699707, "mean_episode_reward": 956.5, "best_episode_reward": 989.0, "step": 380000}
{"episode": 1524.0, "episode_reward": 981.6, "eval_time": 31.163684129714966, "mean_episode_reward": 981.6, "best_episode_reward": 1000.0, "step": 381000}
{"episode": 1528.0, "episode_reward": 984.1, "eval_time": 31.129894733428955, "mean_episode_reward": 984.1, "best_episode_reward": 1000.0, "step": 382000}
{"episode": 1532.0, "episode_reward": 961.5, "eval_time": 31.086645126342773, "mean_episode_reward": 961.5, "best_episode_reward": 1000.0, "step": 383000}
{"episode": 1536.0, "episode_reward": 978.0, "eval_time": 31.176536083221436, "mean_episode_reward": 978.0, "best_episode_reward": 997.0, "step": 384000}
{"episode": 1540.0, "episode_reward": 864.2, "eval_time": 31.05824851989746, "mean_episode_reward": 864.2, "best_episode_reward": 991.0, "step": 385000}
{"episode": 1544.0, "episode_reward": 977.4, "eval_time": 31.152446746826172, "mean_episode_reward": 977.4, "best_episode_reward": 1000.0, "step": 386000}
{"episode": 1548.0, "episode_reward": 911.5, "eval_time": 31.177916765213013, "mean_episode_reward": 911.5, "best_episode_reward": 1000.0, "step": 387000}
{"episode": 1552.0, "episode_reward": 975.8, "eval_time": 31.126429557800293, "mean_episode_reward": 975.8, "best_episode_reward": 1000.0, "step": 388000}
{"episode": 1556.0, "episode_reward": 972.0, "eval_time": 31.087522983551025, "mean_episode_reward": 972.0, "best_episode_reward": 991.0, "step": 389000}
{"episode": 1560.0, "episode_reward": 976.3, "eval_time": 31.06526756286621, "mean_episode_reward": 976.3, "best_episode_reward": 990.0, "step": 390000}
{"episode": 1564.0, "episode_reward": 886.3, "eval_time": 31.064127683639526, "mean_episode_reward": 886.3, "best_episode_reward": 993.0, "step": 391000}
{"episode": 1568.0, "episode_reward": 923.4, "eval_time": 31.054648876190186, "mean_episode_reward": 923.4, "best_episode_reward": 994.0, "step": 392000}
{"episode": 1572.0, "episode_reward": 891.9, "eval_time": 31.02748465538025, "mean_episode_reward": 891.9, "best_episode_reward": 998.0, "step": 393000}
{"episode": 1576.0, "episode_reward": 983.5, "eval_time": 31.173945426940918, "mean_episode_reward": 983.5, "best_episode_reward": 1000.0, "step": 394000}
{"episode": 1580.0, "episode_reward": 963.8, "eval_time": 31.220166444778442, "mean_episode_reward": 963.8, "best_episode_reward": 998.0, "step": 395000}
{"episode": 1584.0, "episode_reward": 982.5, "eval_time": 31.139776945114136, "mean_episode_reward": 982.5, "best_episode_reward": 997.0, "step": 396000}
{"episode": 1588.0, "episode_reward": 895.8, "eval_time": 31.02505350112915, "mean_episode_reward": 895.8, "best_episode_reward": 1000.0, "step": 397000}
{"episode": 1592.0, "episode_reward": 980.8, "eval_time": 31.167278289794922, "mean_episode_reward": 980.8, "best_episode_reward": 994.0, "step": 398000}
{"episode": 1596.0, "episode_reward": 889.9, "eval_time": 31.111982822418213, "mean_episode_reward": 889.9, "best_episode_reward": 989.0, "step": 399000}
{"episode": 1600.0, "episode_reward": 832.4, "eval_time": 31.142712116241455, "mean_episode_reward": 832.4, "best_episode_reward": 996.0, "step": 400000}
{"episode": 1604.0, "episode_reward": 973.9, "eval_time": 31.086474418640137, "mean_episode_reward": 973.9, "best_episode_reward": 984.0, "step": 401000}
{"episode": 1608.0, "episode_reward": 982.7, "eval_time": 31.119143962860107, "mean_episode_reward": 982.7, "best_episode_reward": 993.0, "step": 402000}
{"episode": 1612.0, "episode_reward": 872.1, "eval_time": 31.034223079681396, "mean_episode_reward": 872.1, "best_episode_reward": 1000.0, "step": 403000}
{"episode": 1616.0, "episode_reward": 980.4, "eval_time": 31.13258957862854, "mean_episode_reward": 980.4, "best_episode_reward": 994.0, "step": 404000}
{"episode": 1620.0, "episode_reward": 884.5, "eval_time": 31.109206676483154, "mean_episode_reward": 884.5, "best_episode_reward": 1000.0, "step": 405000}
{"episode": 1624.0, "episode_reward": 885.3, "eval_time": 31.17099165916443, "mean_episode_reward": 885.3, "best_episode_reward": 1000.0, "step": 406000}
{"episode": 1628.0, "episode_reward": 847.1, "eval_time": 31.080103635787964, "mean_episode_reward": 847.1, "best_episode_reward": 997.0, "step": 407000}
{"episode": 1632.0, "episode_reward": 892.1, "eval_time": 31.229012966156006, "mean_episode_reward": 892.1, "best_episode_reward": 1000.0, "step": 408000}
{"episode": 1636.0, "episode_reward": 883.5, "eval_time": 31.0402512550354, "mean_episode_reward": 883.5, "best_episode_reward": 997.0, "step": 409000}
{"episode": 1640.0, "episode_reward": 785.1, "eval_time": 31.042147874832153, "mean_episode_reward": 785.1, "best_episode_reward": 1000.0, "step": 410000}
{"episode": 1644.0, "episode_reward": 964.2, "eval_time": 31.144882917404175, "mean_episode_reward": 964.2, "best_episode_reward": 994.0, "step": 411000}
{"episode": 1648.0, "episode_reward": 960.3, "eval_time": 31.17219638824463, "mean_episode_reward": 960.3, "best_episode_reward": 988.0, "step": 412000}
{"episode": 1652.0, "episode_reward": 874.7, "eval_time": 31.096293926239014, "mean_episode_reward": 874.7, "best_episode_reward": 1000.0, "step": 413000}
{"episode": 1656.0, "episode_reward": 975.2, "eval_time": 31.109952688217163, "mean_episode_reward": 975.2, "best_episode_reward": 994.0, "step": 414000}
{"episode": 1660.0, "episode_reward": 966.6, "eval_time": 31.196525812149048, "mean_episode_reward": 966.6, "best_episode_reward": 993.0, "step": 415000}
{"episode": 1664.0, "episode_reward": 984.0, "eval_time": 31.158968448638916, "mean_episode_reward": 984.0, "best_episode_reward": 1000.0, "step": 416000}
{"episode": 1668.0, "episode_reward": 982.6, "eval_time": 31.23344898223877, "mean_episode_reward": 982.6, "best_episode_reward": 997.0, "step": 417000}
{"episode": 1672.0, "episode_reward": 633.7, "eval_time": 31.125665426254272, "mean_episode_reward": 633.7, "best_episode_reward": 993.0, "step": 418000}
{"episode": 1676.0, "episode_reward": 972.7, "eval_time": 31.09285020828247, "mean_episode_reward": 972.7, "best_episode_reward": 998.0, "step": 419000}
{"episode": 1680.0, "episode_reward": 830.2, "eval_time": 31.16778802871704, "mean_episode_reward": 830.2, "best_episode_reward": 984.0, "step": 420000}
{"episode": 1684.0, "episode_reward": 980.3, "eval_time": 31.211068630218506, "mean_episode_reward": 980.3, "best_episode_reward": 1000.0, "step": 421000}
{"episode": 1688.0, "episode_reward": 935.1, "eval_time": 31.21341872215271, "mean_episode_reward": 935.1, "best_episode_reward": 1000.0, "step": 422000}
{"episode": 1692.0, "episode_reward": 899.7, "eval_time": 31.052223682403564, "mean_episode_reward": 899.7, "best_episode_reward": 995.0, "step": 423000}
{"episode": 1696.0, "episode_reward": 865.3, "eval_time": 31.126944541931152, "mean_episode_reward": 865.3, "best_episode_reward": 1000.0, "step": 424000}
{"episode": 1700.0, "episode_reward": 949.8, "eval_time": 31.159395933151245, "mean_episode_reward": 949.8, "best_episode_reward": 999.0, "step": 425000}
{"episode": 1704.0, "episode_reward": 885.3, "eval_time": 31.11402654647827, "mean_episode_reward": 885.3, "best_episode_reward": 997.0, "step": 426000}
{"episode": 1708.0, "episode_reward": 975.3, "eval_time": 31.134201288223267, "mean_episode_reward": 975.3, "best_episode_reward": 997.0, "step": 427000}
{"episode": 1712.0, "episode_reward": 883.1, "eval_time": 31.15294122695923, "mean_episode_reward": 883.1, "best_episode_reward": 991.0, "step": 428000}
{"episode": 1716.0, "episode_reward": 880.5, "eval_time": 31.097310781478882, "mean_episode_reward": 880.5, "best_episode_reward": 996.0, "step": 429000}
{"episode": 1720.0, "episode_reward": 843.6, "eval_time": 31.087534427642822, "mean_episode_reward": 843.6, "best_episode_reward": 992.0, "step": 430000}
{"episode": 1724.0, "episode_reward": 883.2, "eval_time": 31.07721757888794, "mean_episode_reward": 883.2, "best_episode_reward": 1000.0, "step": 431000}
{"episode": 1728.0, "episode_reward": 981.0, "eval_time": 30.998563766479492, "mean_episode_reward": 981.0, "best_episode_reward": 1000.0, "step": 432000}
{"episode": 1732.0, "episode_reward": 961.0, "eval_time": 31.145840883255005, "mean_episode_reward": 961.0, "best_episode_reward": 994.0, "step": 433000}
{"episode": 1736.0, "episode_reward": 973.8, "eval_time": 31.05966353416443, "mean_episode_reward": 973.8, "best_episode_reward": 1000.0, "step": 434000}
{"episode": 1740.0, "episode_reward": 871.5, "eval_time": 31.065317153930664, "mean_episode_reward": 871.5, "best_episode_reward": 988.0, "step": 435000}
{"episode": 1744.0, "episode_reward": 837.6, "eval_time": 31.058449268341064, "mean_episode_reward": 837.6, "best_episode_reward": 988.0, "step": 436000}
{"episode": 1748.0, "episode_reward": 988.7, "eval_time": 31.070030450820923, "mean_episode_reward": 988.7, "best_episode_reward": 995.0, "step": 437000}
{"episode": 1752.0, "episode_reward": 886.3, "eval_time": 31.13443160057068, "mean_episode_reward": 886.3, "best_episode_reward": 993.0, "step": 438000}
{"episode": 1756.0, "episode_reward": 875.6, "eval_time": 30.99596405029297, "mean_episode_reward": 875.6, "best_episode_reward": 991.0, "step": 439000}
{"episode": 1760.0, "episode_reward": 885.0, "eval_time": 31.064425468444824, "mean_episode_reward": 885.0, "best_episode_reward": 993.0, "step": 440000}
{"episode": 1764.0, "episode_reward": 973.2, "eval_time": 31.019850492477417, "mean_episode_reward": 973.2, "best_episode_reward": 994.0, "step": 441000}
{"episode": 1768.0, "episode_reward": 852.0, "eval_time": 31.065592288970947, "mean_episode_reward": 852.0, "best_episode_reward": 999.0, "step": 442000}
{"episode": 1772.0, "episode_reward": 972.7, "eval_time": 31.01876711845398, "mean_episode_reward": 972.7, "best_episode_reward": 997.0, "step": 443000}
{"episode": 1776.0, "episode_reward": 896.2, "eval_time": 31.084259748458862, "mean_episode_reward": 896.2, "best_episode_reward": 1000.0, "step": 444000}
{"episode": 1780.0, "episode_reward": 973.6, "eval_time": 31.003318309783936, "mean_episode_reward": 973.6, "best_episode_reward": 997.0, "step": 445000}
{"episode": 1784.0, "episode_reward": 871.4, "eval_time": 31.130977630615234, "mean_episode_reward": 871.4, "best_episode_reward": 997.0, "step": 446000}
{"episode": 1788.0, "episode_reward": 978.1, "eval_time": 31.117552995681763, "mean_episode_reward": 978.1, "best_episode_reward": 997.0, "step": 447000}
{"episode": 1792.0, "episode_reward": 977.0, "eval_time": 31.04968571662903, "mean_episode_reward": 977.0, "best_episode_reward": 988.0, "step": 448000}
{"episode": 1796.0, "episode_reward": 940.5, "eval_time": 31.04750967025757, "mean_episode_reward": 940.5, "best_episode_reward": 1000.0, "step": 449000}
{"episode": 1800.0, "episode_reward": 978.1, "eval_time": 31.00331997871399, "mean_episode_reward": 978.1, "best_episode_reward": 993.0, "step": 450000}
{"episode": 1804.0, "episode_reward": 977.6, "eval_time": 31.101524591445923, "mean_episode_reward": 977.6, "best_episode_reward": 994.0, "step": 451000}
{"episode": 1808.0, "episode_reward": 882.8, "eval_time": 30.910941123962402, "mean_episode_reward": 882.8, "best_episode_reward": 989.0, "step": 452000}
{"episode": 1812.0, "episode_reward": 981.4, "eval_time": 31.01680302619934, "mean_episode_reward": 981.4, "best_episode_reward": 997.0, "step": 453000}
{"episode": 1816.0, "episode_reward": 982.1, "eval_time": 31.000487804412842, "mean_episode_reward": 982.1, "best_episode_reward": 1000.0, "step": 454000}
{"episode": 1820.0, "episode_reward": 984.8, "eval_time": 31.128540992736816, "mean_episode_reward": 984.8, "best_episode_reward": 1000.0, "step": 455000}
{"episode": 1824.0, "episode_reward": 954.5, "eval_time": 31.047597408294678, "mean_episode_reward": 954.5, "best_episode_reward": 993.0, "step": 456000}
{"episode": 1828.0, "episode_reward": 981.1, "eval_time": 31.084908723831177, "mean_episode_reward": 981.1, "best_episode_reward": 1000.0, "step": 457000}
{"episode": 1832.0, "episode_reward": 967.6, "eval_time": 31.03491997718811, "mean_episode_reward": 967.6, "best_episode_reward": 997.0, "step": 458000}
{"episode": 1836.0, "episode_reward": 967.0, "eval_time": 31.000556230545044, "mean_episode_reward": 967.0, "best_episode_reward": 1000.0, "step": 459000}
{"episode": 1840.0, "episode_reward": 986.9, "eval_time": 31.037141799926758, "mean_episode_reward": 986.9, "best_episode_reward": 1000.0, "step": 460000}
{"episode": 1844.0, "episode_reward": 970.8, "eval_time": 31.060035228729248, "mean_episode_reward": 970.8, "best_episode_reward": 988.0, "step": 461000}
{"episode": 1848.0, "episode_reward": 978.6, "eval_time": 30.963473558425903, "mean_episode_reward": 978.6, "best_episode_reward": 1000.0, "step": 462000}
{"episode": 1852.0, "episode_reward": 982.7, "eval_time": 31.038928985595703, "mean_episode_reward": 982.7, "best_episode_reward": 1000.0, "step": 463000}
{"episode": 1856.0, "episode_reward": 944.9, "eval_time": 31.022104263305664, "mean_episode_reward": 944.9, "best_episode_reward": 990.0, "step": 464000}
{"episode": 1860.0, "episode_reward": 972.9, "eval_time": 31.015315294265747, "mean_episode_reward": 972.9, "best_episode_reward": 996.0, "step": 465000}
{"episode": 1864.0, "episode_reward": 866.8, "eval_time": 31.05326747894287, "mean_episode_reward": 866.8, "best_episode_reward": 993.0, "step": 466000}
{"episode": 1868.0, "episode_reward": 975.5, "eval_time": 31.127581119537354, "mean_episode_reward": 975.5, "best_episode_reward": 993.0, "step": 467000}
{"episode": 1872.0, "episode_reward": 871.8, "eval_time": 31.03936743736267, "mean_episode_reward": 871.8, "best_episode_reward": 1000.0, "step": 468000}
{"episode": 1876.0, "episode_reward": 990.0, "eval_time": 31.09725332260132, "mean_episode_reward": 990.0, "best_episode_reward": 1000.0, "step": 469000}
{"episode": 1880.0, "episode_reward": 983.8, "eval_time": 31.103182315826416, "mean_episode_reward": 983.8, "best_episode_reward": 1000.0, "step": 470000}
{"episode": 1884.0, "episode_reward": 966.3, "eval_time": 31.152014017105103, "mean_episode_reward": 966.3, "best_episode_reward": 992.0, "step": 471000}
{"episode": 1888.0, "episode_reward": 954.7, "eval_time": 31.11892557144165, "mean_episode_reward": 954.7, "best_episode_reward": 1000.0, "step": 472000}
{"episode": 1892.0, "episode_reward": 978.4, "eval_time": 31.142483949661255, "mean_episode_reward": 978.4, "best_episode_reward": 997.0, "step": 473000}
{"episode": 1896.0, "episode_reward": 979.8, "eval_time": 31.01125431060791, "mean_episode_reward": 979.8, "best_episode_reward": 1000.0, "step": 474000}
{"episode": 1900.0, "episode_reward": 980.4, "eval_time": 31.03944993019104, "mean_episode_reward": 980.4, "best_episode_reward": 995.0, "step": 475000}
{"episode": 1904.0, "episode_reward": 981.9, "eval_time": 31.149613857269287, "mean_episode_reward": 981.9, "best_episode_reward": 996.0, "step": 476000}
{"episode": 1908.0, "episode_reward": 883.7, "eval_time": 30.889391660690308, "mean_episode_reward": 883.7, "best_episode_reward": 992.0, "step": 477000}
{"episode": 1912.0, "episode_reward": 973.7, "eval_time": 30.954718589782715, "mean_episode_reward": 973.7, "best_episode_reward": 1000.0, "step": 478000}
{"episode": 1916.0, "episode_reward": 704.2, "eval_time": 30.92670750617981, "mean_episode_reward": 704.2, "best_episode_reward": 1000.0, "step": 479000}
{"episode": 1920.0, "episode_reward": 979.8, "eval_time": 30.94219446182251, "mean_episode_reward": 979.8, "best_episode_reward": 997.0, "step": 480000}
{"episode": 1924.0, "episode_reward": 956.2, "eval_time": 30.85018515586853, "mean_episode_reward": 956.2, "best_episode_reward": 995.0, "step": 481000}
{"episode": 1928.0, "episode_reward": 973.1, "eval_time": 30.82898259162903, "mean_episode_reward": 973.1, "best_episode_reward": 995.0, "step": 482000}
{"episode": 1932.0, "episode_reward": 985.4, "eval_time": 30.897757291793823, "mean_episode_reward": 985.4, "best_episode_reward": 999.0, "step": 483000}
{"episode": 1936.0, "episode_reward": 974.2, "eval_time": 30.85102391242981, "mean_episode_reward": 974.2, "best_episode_reward": 1000.0, "step": 484000}
{"episode": 1940.0, "episode_reward": 981.1, "eval_time": 30.89866876602173, "mean_episode_reward": 981.1, "best_episode_reward": 996.0, "step": 485000}
{"episode": 1944.0, "episode_reward": 977.1, "eval_time": 30.933037996292114, "mean_episode_reward": 977.1, "best_episode_reward": 995.0, "step": 486000}
{"episode": 1948.0, "episode_reward": 939.8, "eval_time": 30.877665758132935, "mean_episode_reward": 939.8, "best_episode_reward": 998.0, "step": 487000}
{"episode": 1952.0, "episode_reward": 983.8, "eval_time": 30.90479326248169, "mean_episode_reward": 983.8, "best_episode_reward": 994.0, "step": 488000}
{"episode": 1956.0, "episode_reward": 978.5, "eval_time": 30.8026123046875, "mean_episode_reward": 978.5, "best_episode_reward": 1000.0, "step": 489000}
{"episode": 1960.0, "episode_reward": 961.8, "eval_time": 30.909408569335938, "mean_episode_reward": 961.8, "best_episode_reward": 999.0, "step": 490000}
{"episode": 1964.0, "episode_reward": 979.4, "eval_time": 30.948891162872314, "mean_episode_reward": 979.4, "best_episode_reward": 993.0, "step": 491000}
{"episode": 1968.0, "episode_reward": 974.2, "eval_time": 30.673887968063354, "mean_episode_reward": 974.2, "best_episode_reward": 989.0, "step": 492000}
{"episode": 1972.0, "episode_reward": 976.2, "eval_time": 30.850991010665894, "mean_episode_reward": 976.2, "best_episode_reward": 999.0, "step": 493000}
{"episode": 1976.0, "episode_reward": 957.4, "eval_time": 30.917317628860474, "mean_episode_reward": 957.4, "best_episode_reward": 993.0, "step": 494000}
{"episode": 1980.0, "episode_reward": 987.1, "eval_time": 30.886170625686646, "mean_episode_reward": 987.1, "best_episode_reward": 1000.0, "step": 495000}
{"episode": 1984.0, "episode_reward": 952.2, "eval_time": 30.878080368041992, "mean_episode_reward": 952.2, "best_episode_reward": 998.0, "step": 496000}
{"episode": 1988.0, "episode_reward": 979.1, "eval_time": 30.917664527893066, "mean_episode_reward": 979.1, "best_episode_reward": 1000.0, "step": 497000}
{"episode": 1992.0, "episode_reward": 982.5, "eval_time": 30.875879049301147, "mean_episode_reward": 982.5, "best_episode_reward": 1000.0, "step": 498000}
{"episode": 1996.0, "episode_reward": 983.1, "eval_time": 30.98157787322998, "mean_episode_reward": 983.1, "best_episode_reward": 1000.0, "step": 499000}
