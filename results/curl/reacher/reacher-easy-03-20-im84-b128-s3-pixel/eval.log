{"episode": 0.0, "episode_reward": 171.1, "eval_time": 29.900551795959473, "mean_episode_reward": 171.1, "best_episode_reward": 497.0, "step": 0}
{"episode": 4.0, "episode_reward": 26.4, "eval_time": 29.191854000091553, "mean_episode_reward": 26.4, "best_episode_reward": 178.0, "step": 1000}
{"episode": 8.0, "episode_reward": 25.4, "eval_time": 29.191779613494873, "mean_episode_reward": 25.4, "best_episode_reward": 81.0, "step": 2000}
{"episode": 12.0, "episode_reward": 4.4, "eval_time": 29.233333826065063, "mean_episode_reward": 4.4, "best_episode_reward": 32.0, "step": 3000}
{"episode": 16.0, "episode_reward": 187.3, "eval_time": 29.218838453292847, "mean_episode_reward": 187.3, "best_episode_reward": 965.0, "step": 4000}
{"episode": 20.0, "episode_reward": 95.8, "eval_time": 29.192065715789795, "mean_episode_reward": 95.8, "best_episode_reward": 957.0, "step": 5000}
{"episode": 24.0, "episode_reward": 197.5, "eval_time": 29.23297953605652, "mean_episode_reward": 197.5, "best_episode_reward": 965.0, "step": 6000}
{"episode": 28.0, "episode_reward": 93.4, "eval_time": 29.297429084777832, "mean_episode_reward": 93.4, "best_episode_reward": 919.0, "step": 7000}
{"episode": 32.0, "episode_reward": 212.1, "eval_time": 29.241231679916382, "mean_episode_reward": 212.1, "best_episode_reward": 994.0, "step": 8000}
{"episode": 36.0, "episode_reward": 67.3, "eval_time": 29.200586080551147, "mean_episode_reward": 67.3, "best_episode_reward": 577.0, "step": 9000}
{"episode": 40.0, "episode_reward": 553.6, "eval_time": 29.19148874282837, "mean_episode_reward": 553.6, "best_episode_reward": 990.0, "step": 10000}
{"episode": 44.0, "episode_reward": 259.7, "eval_time": 29.20076823234558, "mean_episode_reward": 259.7, "best_episode_reward": 998.0, "step": 11000}
{"episode": 48.0, "episode_reward": 213.5, "eval_time": 29.149240016937256, "mean_episode_reward": 213.5, "best_episode_reward": 986.0, "step": 12000}
{"episode": 52.0, "episode_reward": 272.2, "eval_time": 29.185588598251343, "mean_episode_reward": 272.2, "best_episode_reward": 990.0, "step": 13000}
{"episode": 56.0, "episode_reward": 199.0, "eval_time": 29.110733032226562, "mean_episode_reward": 199.0, "best_episode_reward": 963.0, "step": 14000}
{"episode": 60.0, "episode_reward": 330.4, "eval_time": 29.16846990585327, "mean_episode_reward": 330.4, "best_episode_reward": 997.0, "step": 15000}
{"episode": 64.0, "episode_reward": 290.2, "eval_time": 29.157939195632935, "mean_episode_reward": 290.2, "best_episode_reward": 982.0, "step": 16000}
{"episode": 68.0, "episode_reward": 168.2, "eval_time": 29.193260669708252, "mean_episode_reward": 168.2, "best_episode_reward": 838.0, "step": 17000}
{"episode": 72.0, "episode_reward": 486.7, "eval_time": 29.1750168800354, "mean_episode_reward": 486.7, "best_episode_reward": 978.0, "step": 18000}
{"episode": 76.0, "episode_reward": 243.4, "eval_time": 29.224046230316162, "mean_episode_reward": 243.4, "best_episode_reward": 956.0, "step": 19000}
{"episode": 80.0, "episode_reward": 477.6, "eval_time": 29.130266666412354, "mean_episode_reward": 477.6, "best_episode_reward": 988.0, "step": 20000}
{"episode": 84.0, "episode_reward": 468.1, "eval_time": 29.106658935546875, "mean_episode_reward": 468.1, "best_episode_reward": 990.0, "step": 21000}
{"episode": 88.0, "episode_reward": 432.9, "eval_time": 29.126055002212524, "mean_episode_reward": 432.9, "best_episode_reward": 966.0, "step": 22000}
{"episode": 92.0, "episode_reward": 552.0, "eval_time": 29.182334661483765, "mean_episode_reward": 552.0, "best_episode_reward": 987.0, "step": 23000}
{"episode": 96.0, "episode_reward": 579.4, "eval_time": 29.18511438369751, "mean_episode_reward": 579.4, "best_episode_reward": 992.0, "step": 24000}
{"episode": 100.0, "episode_reward": 488.1, "eval_time": 29.17785120010376, "mean_episode_reward": 488.1, "best_episode_reward": 996.0, "step": 25000}
{"episode": 104.0, "episode_reward": 294.6, "eval_time": 29.224709272384644, "mean_episode_reward": 294.6, "best_episode_reward": 966.0, "step": 26000}
{"episode": 108.0, "episode_reward": 557.5, "eval_time": 29.141679286956787, "mean_episode_reward": 557.5, "best_episode_reward": 985.0, "step": 27000}
{"episode": 112.0, "episode_reward": 476.6, "eval_time": 29.12939977645874, "mean_episode_reward": 476.6, "best_episode_reward": 981.0, "step": 28000}
{"episode": 116.0, "episode_reward": 597.9, "eval_time": 29.20356512069702, "mean_episode_reward": 597.9, "best_episode_reward": 990.0, "step": 29000}
{"episode": 120.0, "episode_reward": 262.9, "eval_time": 29.185703992843628, "mean_episode_reward": 262.9, "best_episode_reward": 967.0, "step": 30000}
{"episode": 124.0, "episode_reward": 770.8, "eval_time": 29.162172317504883, "mean_episode_reward": 770.8, "best_episode_reward": 985.0, "step": 31000}
{"episode": 128.0, "episode_reward": 634.7, "eval_time": 29.222206592559814, "mean_episode_reward": 634.7, "best_episode_reward": 991.0, "step": 32000}
{"episode": 132.0, "episode_reward": 661.9, "eval_time": 29.193648099899292, "mean_episode_reward": 661.9, "best_episode_reward": 973.0, "step": 33000}
{"episode": 136.0, "episode_reward": 654.3, "eval_time": 29.250380516052246, "mean_episode_reward": 654.3, "best_episode_reward": 984.0, "step": 34000}
{"episode": 140.0, "episode_reward": 372.8, "eval_time": 29.156075716018677, "mean_episode_reward": 372.8, "best_episode_reward": 979.0, "step": 35000}
{"episode": 144.0, "episode_reward": 651.1, "eval_time": 29.09789729118347, "mean_episode_reward": 651.1, "best_episode_reward": 987.0, "step": 36000}
{"episode": 148.0, "episode_reward": 616.9, "eval_time": 29.189715147018433, "mean_episode_reward": 616.9, "best_episode_reward": 988.0, "step": 37000}
{"episode": 152.0, "episode_reward": 519.7, "eval_time": 29.232028007507324, "mean_episode_reward": 519.7, "best_episode_reward": 980.0, "step": 38000}
{"episode": 156.0, "episode_reward": 684.3, "eval_time": 29.203087091445923, "mean_episode_reward": 684.3, "best_episode_reward": 995.0, "step": 39000}
{"episode": 160.0, "episode_reward": 447.3, "eval_time": 29.213433980941772, "mean_episode_reward": 447.3, "best_episode_reward": 1000.0, "step": 40000}
{"episode": 164.0, "episode_reward": 713.5, "eval_time": 29.233427047729492, "mean_episode_reward": 713.5, "best_episode_reward": 983.0, "step": 41000}
{"episode": 168.0, "episode_reward": 722.4, "eval_time": 29.258288383483887, "mean_episode_reward": 722.4, "best_episode_reward": 977.0, "step": 42000}
{"episode": 172.0, "episode_reward": 496.3, "eval_time": 29.194907665252686, "mean_episode_reward": 496.3, "best_episode_reward": 986.0, "step": 43000}
{"episode": 176.0, "episode_reward": 495.7, "eval_time": 29.23142957687378, "mean_episode_reward": 495.7, "best_episode_reward": 993.0, "step": 44000}
{"episode": 180.0, "episode_reward": 601.3, "eval_time": 29.24516010284424, "mean_episode_reward": 601.3, "best_episode_reward": 994.0, "step": 45000}
{"episode": 184.0, "episode_reward": 571.9, "eval_time": 29.190267324447632, "mean_episode_reward": 571.9, "best_episode_reward": 972.0, "step": 46000}
{"episode": 188.0, "episode_reward": 508.5, "eval_time": 29.21560025215149, "mean_episode_reward": 508.5, "best_episode_reward": 970.0, "step": 47000}
{"episode": 192.0, "episode_reward": 881.4, "eval_time": 29.234447956085205, "mean_episode_reward": 881.4, "best_episode_reward": 993.0, "step": 48000}
{"episode": 196.0, "episode_reward": 843.3, "eval_time": 29.253645658493042, "mean_episode_reward": 843.3, "best_episode_reward": 997.0, "step": 49000}
{"episode": 200.0, "episode_reward": 702.8, "eval_time": 29.16292715072632, "mean_episode_reward": 702.8, "best_episode_reward": 996.0, "step": 50000}
{"episode": 204.0, "episode_reward": 774.4, "eval_time": 29.218547344207764, "mean_episode_reward": 774.4, "best_episode_reward": 991.0, "step": 51000}
{"episode": 208.0, "episode_reward": 810.5, "eval_time": 29.178088426589966, "mean_episode_reward": 810.5, "best_episode_reward": 992.0, "step": 52000}
{"episode": 212.0, "episode_reward": 833.2, "eval_time": 29.24724268913269, "mean_episode_reward": 833.2, "best_episode_reward": 978.0, "step": 53000}
{"episode": 216.0, "episode_reward": 644.0, "eval_time": 29.12350821495056, "mean_episode_reward": 644.0, "best_episode_reward": 992.0, "step": 54000}
{"episode": 220.0, "episode_reward": 690.5, "eval_time": 29.264883518218994, "mean_episode_reward": 690.5, "best_episode_reward": 976.0, "step": 55000}
{"episode": 224.0, "episode_reward": 689.8, "eval_time": 29.237159967422485, "mean_episode_reward": 689.8, "best_episode_reward": 994.0, "step": 56000}
{"episode": 228.0, "episode_reward": 503.7, "eval_time": 29.2221999168396, "mean_episode_reward": 503.7, "best_episode_reward": 987.0, "step": 57000}
{"episode": 232.0, "episode_reward": 689.1, "eval_time": 29.213379621505737, "mean_episode_reward": 689.1, "best_episode_reward": 970.0, "step": 58000}
{"episode": 236.0, "episode_reward": 932.4, "eval_time": 29.17649483680725, "mean_episode_reward": 932.4, "best_episode_reward": 991.0, "step": 59000}
{"episode": 240.0, "episode_reward": 766.7, "eval_time": 29.19747281074524, "mean_episode_reward": 766.7, "best_episode_reward": 994.0, "step": 60000}
{"episode": 244.0, "episode_reward": 789.1, "eval_time": 29.157323360443115, "mean_episode_reward": 789.1, "best_episode_reward": 973.0, "step": 61000}
{"episode": 248.0, "episode_reward": 889.2, "eval_time": 29.241339683532715, "mean_episode_reward": 889.2, "best_episode_reward": 1000.0, "step": 62000}
{"episode": 252.0, "episode_reward": 679.3, "eval_time": 29.20279359817505, "mean_episode_reward": 679.3, "best_episode_reward": 982.0, "step": 63000}
{"episode": 256.0, "episode_reward": 735.5, "eval_time": 29.263078927993774, "mean_episode_reward": 735.5, "best_episode_reward": 981.0, "step": 64000}
{"episode": 260.0, "episode_reward": 844.5, "eval_time": 29.225836753845215, "mean_episode_reward": 844.5, "best_episode_reward": 986.0, "step": 65000}
{"episode": 264.0, "episode_reward": 763.1, "eval_time": 29.237988710403442, "mean_episode_reward": 763.1, "best_episode_reward": 988.0, "step": 66000}
{"episode": 268.0, "episode_reward": 719.8, "eval_time": 29.164817333221436, "mean_episode_reward": 719.8, "best_episode_reward": 992.0, "step": 67000}
{"episode": 272.0, "episode_reward": 927.8, "eval_time": 29.254255533218384, "mean_episode_reward": 927.8, "best_episode_reward": 995.0, "step": 68000}
{"episode": 276.0, "episode_reward": 843.7, "eval_time": 29.250892162322998, "mean_episode_reward": 843.7, "best_episode_reward": 999.0, "step": 69000}
{"episode": 280.0, "episode_reward": 843.6, "eval_time": 29.26960015296936, "mean_episode_reward": 843.6, "best_episode_reward": 1000.0, "step": 70000}
{"episode": 284.0, "episode_reward": 851.6, "eval_time": 29.266611576080322, "mean_episode_reward": 851.6, "best_episode_reward": 987.0, "step": 71000}
{"episode": 288.0, "episode_reward": 769.8, "eval_time": 29.262042999267578, "mean_episode_reward": 769.8, "best_episode_reward": 996.0, "step": 72000}
{"episode": 292.0, "episode_reward": 671.4, "eval_time": 29.258180379867554, "mean_episode_reward": 671.4, "best_episode_reward": 986.0, "step": 73000}
{"episode": 296.0, "episode_reward": 872.1, "eval_time": 29.232044458389282, "mean_episode_reward": 872.1, "best_episode_reward": 999.0, "step": 74000}
{"episode": 300.0, "episode_reward": 903.0, "eval_time": 29.272478342056274, "mean_episode_reward": 903.0, "best_episode_reward": 992.0, "step": 75000}
{"episode": 304.0, "episode_reward": 785.6, "eval_time": 29.259355783462524, "mean_episode_reward": 785.6, "best_episode_reward": 1000.0, "step": 76000}
{"episode": 308.0, "episode_reward": 894.6, "eval_time": 29.313096523284912, "mean_episode_reward": 894.6, "best_episode_reward": 980.0, "step": 77000}
{"episode": 312.0, "episode_reward": 874.1, "eval_time": 29.242336988449097, "mean_episode_reward": 874.1, "best_episode_reward": 976.0, "step": 78000}
{"episode": 316.0, "episode_reward": 776.4, "eval_time": 29.255162477493286, "mean_episode_reward": 776.4, "best_episode_reward": 991.0, "step": 79000}
{"episode": 320.0, "episode_reward": 841.3, "eval_time": 29.20949673652649, "mean_episode_reward": 841.3, "best_episode_reward": 995.0, "step": 80000}
{"episode": 324.0, "episode_reward": 866.2, "eval_time": 29.21650242805481, "mean_episode_reward": 866.2, "best_episode_reward": 985.0, "step": 81000}
{"episode": 328.0, "episode_reward": 870.0, "eval_time": 29.269145965576172, "mean_episode_reward": 870.0, "best_episode_reward": 991.0, "step": 82000}
{"episode": 332.0, "episode_reward": 831.5, "eval_time": 29.226152181625366, "mean_episode_reward": 831.5, "best_episode_reward": 982.0, "step": 83000}
{"episode": 336.0, "episode_reward": 749.0, "eval_time": 29.266639947891235, "mean_episode_reward": 749.0, "best_episode_reward": 986.0, "step": 84000}
{"episode": 340.0, "episode_reward": 877.4, "eval_time": 29.244025230407715, "mean_episode_reward": 877.4, "best_episode_reward": 1000.0, "step": 85000}
{"episode": 344.0, "episode_reward": 872.4, "eval_time": 29.269038677215576, "mean_episode_reward": 872.4, "best_episode_reward": 1000.0, "step": 86000}
{"episode": 348.0, "episode_reward": 680.6, "eval_time": 29.331363916397095, "mean_episode_reward": 680.6, "best_episode_reward": 993.0, "step": 87000}
{"episode": 352.0, "episode_reward": 933.3, "eval_time": 29.257593154907227, "mean_episode_reward": 933.3, "best_episode_reward": 997.0, "step": 88000}
{"episode": 356.0, "episode_reward": 867.5, "eval_time": 29.253769397735596, "mean_episode_reward": 867.5, "best_episode_reward": 977.0, "step": 89000}
{"episode": 360.0, "episode_reward": 969.9, "eval_time": 29.28180170059204, "mean_episode_reward": 969.9, "best_episode_reward": 988.0, "step": 90000}
{"episode": 364.0, "episode_reward": 966.3, "eval_time": 29.20908284187317, "mean_episode_reward": 966.3, "best_episode_reward": 993.0, "step": 91000}
{"episode": 368.0, "episode_reward": 846.6, "eval_time": 29.24418067932129, "mean_episode_reward": 846.6, "best_episode_reward": 991.0, "step": 92000}
{"episode": 372.0, "episode_reward": 861.4, "eval_time": 29.18685030937195, "mean_episode_reward": 861.4, "best_episode_reward": 990.0, "step": 93000}
{"episode": 376.0, "episode_reward": 860.5, "eval_time": 29.246241331100464, "mean_episode_reward": 860.5, "best_episode_reward": 974.0, "step": 94000}
{"episode": 380.0, "episode_reward": 775.3, "eval_time": 29.27683687210083, "mean_episode_reward": 775.3, "best_episode_reward": 988.0, "step": 95000}
{"episode": 384.0, "episode_reward": 875.2, "eval_time": 29.26578426361084, "mean_episode_reward": 875.2, "best_episode_reward": 1000.0, "step": 96000}
{"episode": 388.0, "episode_reward": 950.7, "eval_time": 29.25999927520752, "mean_episode_reward": 950.7, "best_episode_reward": 1000.0, "step": 97000}
{"episode": 392.0, "episode_reward": 835.8, "eval_time": 29.277472734451294, "mean_episode_reward": 835.8, "best_episode_reward": 1000.0, "step": 98000}
{"episode": 396.0, "episode_reward": 963.1, "eval_time": 29.242486476898193, "mean_episode_reward": 963.1, "best_episode_reward": 992.0, "step": 99000}
{"episode": 400.0, "episode_reward": 872.8, "eval_time": 29.268352270126343, "mean_episode_reward": 872.8, "best_episode_reward": 992.0, "step": 100000}
{"episode": 404.0, "episode_reward": 955.2, "eval_time": 29.283283948898315, "mean_episode_reward": 955.2, "best_episode_reward": 988.0, "step": 101000}
{"episode": 408.0, "episode_reward": 902.2, "eval_time": 29.218921899795532, "mean_episode_reward": 902.2, "best_episode_reward": 989.0, "step": 102000}
{"episode": 412.0, "episode_reward": 969.4, "eval_time": 29.283424139022827, "mean_episode_reward": 969.4, "best_episode_reward": 995.0, "step": 103000}
{"episode": 416.0, "episode_reward": 737.5, "eval_time": 29.24488592147827, "mean_episode_reward": 737.5, "best_episode_reward": 975.0, "step": 104000}
{"episode": 420.0, "episode_reward": 875.3, "eval_time": 29.261603593826294, "mean_episode_reward": 875.3, "best_episode_reward": 998.0, "step": 105000}
{"episode": 424.0, "episode_reward": 784.8, "eval_time": 29.32587170600891, "mean_episode_reward": 784.8, "best_episode_reward": 992.0, "step": 106000}
{"episode": 428.0, "episode_reward": 955.9, "eval_time": 29.36316204071045, "mean_episode_reward": 955.9, "best_episode_reward": 989.0, "step": 107000}
{"episode": 432.0, "episode_reward": 903.2, "eval_time": 29.20937156677246, "mean_episode_reward": 903.2, "best_episode_reward": 984.0, "step": 108000}
{"episode": 436.0, "episode_reward": 965.8, "eval_time": 29.279858350753784, "mean_episode_reward": 965.8, "best_episode_reward": 990.0, "step": 109000}
{"episode": 440.0, "episode_reward": 855.7, "eval_time": 29.274922370910645, "mean_episode_reward": 855.7, "best_episode_reward": 1000.0, "step": 110000}
{"episode": 444.0, "episode_reward": 900.1, "eval_time": 29.304678440093994, "mean_episode_reward": 900.1, "best_episode_reward": 993.0, "step": 111000}
{"episode": 448.0, "episode_reward": 922.3, "eval_time": 29.281768798828125, "mean_episode_reward": 922.3, "best_episode_reward": 999.0, "step": 112000}
{"episode": 452.0, "episode_reward": 762.1, "eval_time": 29.2816641330719, "mean_episode_reward": 762.1, "best_episode_reward": 995.0, "step": 113000}
{"episode": 456.0, "episode_reward": 813.2, "eval_time": 29.368507623672485, "mean_episode_reward": 813.2, "best_episode_reward": 987.0, "step": 114000}
{"episode": 460.0, "episode_reward": 974.1, "eval_time": 29.211037397384644, "mean_episode_reward": 974.1, "best_episode_reward": 998.0, "step": 115000}
{"episode": 464.0, "episode_reward": 886.0, "eval_time": 29.335875272750854, "mean_episode_reward": 886.0, "best_episode_reward": 977.0, "step": 116000}
{"episode": 468.0, "episode_reward": 975.7, "eval_time": 29.324328184127808, "mean_episode_reward": 975.7, "best_episode_reward": 999.0, "step": 117000}
{"episode": 472.0, "episode_reward": 897.7, "eval_time": 29.28431248664856, "mean_episode_reward": 897.7, "best_episode_reward": 976.0, "step": 118000}
{"episode": 476.0, "episode_reward": 972.6, "eval_time": 29.285354137420654, "mean_episode_reward": 972.6, "best_episode_reward": 1000.0, "step": 119000}
{"episode": 480.0, "episode_reward": 969.0, "eval_time": 29.37276268005371, "mean_episode_reward": 969.0, "best_episode_reward": 999.0, "step": 120000}
{"episode": 484.0, "episode_reward": 821.6, "eval_time": 29.298749208450317, "mean_episode_reward": 821.6, "best_episode_reward": 989.0, "step": 121000}
{"episode": 488.0, "episode_reward": 876.1, "eval_time": 29.334006547927856, "mean_episode_reward": 876.1, "best_episode_reward": 992.0, "step": 122000}
{"episode": 492.0, "episode_reward": 959.5, "eval_time": 29.22819995880127, "mean_episode_reward": 959.5, "best_episode_reward": 990.0, "step": 123000}
{"episode": 496.0, "episode_reward": 873.8, "eval_time": 29.25496006011963, "mean_episode_reward": 873.8, "best_episode_reward": 984.0, "step": 124000}
{"episode": 500.0, "episode_reward": 979.3, "eval_time": 29.19223928451538, "mean_episode_reward": 979.3, "best_episode_reward": 1000.0, "step": 125000}
{"episode": 504.0, "episode_reward": 743.6, "eval_time": 29.364351749420166, "mean_episode_reward": 743.6, "best_episode_reward": 1000.0, "step": 126000}
{"episode": 508.0, "episode_reward": 794.8, "eval_time": 29.301389932632446, "mean_episode_reward": 794.8, "best_episode_reward": 1000.0, "step": 127000}
{"episode": 512.0, "episode_reward": 948.3, "eval_time": 29.2403621673584, "mean_episode_reward": 948.3, "best_episode_reward": 973.0, "step": 128000}
{"episode": 516.0, "episode_reward": 972.2, "eval_time": 29.23374319076538, "mean_episode_reward": 972.2, "best_episode_reward": 988.0, "step": 129000}
{"episode": 520.0, "episode_reward": 878.8, "eval_time": 29.222565174102783, "mean_episode_reward": 878.8, "best_episode_reward": 1000.0, "step": 130000}
{"episode": 524.0, "episode_reward": 957.8, "eval_time": 29.274330139160156, "mean_episode_reward": 957.8, "best_episode_reward": 996.0, "step": 131000}
{"episode": 528.0, "episode_reward": 983.8, "eval_time": 29.298933029174805, "mean_episode_reward": 983.8, "best_episode_reward": 1000.0, "step": 132000}
{"episode": 532.0, "episode_reward": 832.7, "eval_time": 29.33756399154663, "mean_episode_reward": 832.7, "best_episode_reward": 982.0, "step": 133000}
{"episode": 536.0, "episode_reward": 969.0, "eval_time": 29.384939193725586, "mean_episode_reward": 969.0, "best_episode_reward": 1000.0, "step": 134000}
{"episode": 540.0, "episode_reward": 970.1, "eval_time": 29.211302757263184, "mean_episode_reward": 970.1, "best_episode_reward": 991.0, "step": 135000}
{"episode": 544.0, "episode_reward": 959.7, "eval_time": 29.2398099899292, "mean_episode_reward": 959.7, "best_episode_reward": 987.0, "step": 136000}
{"episode": 548.0, "episode_reward": 965.5, "eval_time": 29.268494367599487, "mean_episode_reward": 965.5, "best_episode_reward": 997.0, "step": 137000}
{"episode": 552.0, "episode_reward": 845.5, "eval_time": 29.241852045059204, "mean_episode_reward": 845.5, "best_episode_reward": 1000.0, "step": 138000}
{"episode": 556.0, "episode_reward": 870.2, "eval_time": 29.340198516845703, "mean_episode_reward": 870.2, "best_episode_reward": 989.0, "step": 139000}
{"episode": 560.0, "episode_reward": 985.3, "eval_time": 29.23366141319275, "mean_episode_reward": 985.3, "best_episode_reward": 1000.0, "step": 140000}
{"episode": 564.0, "episode_reward": 881.1, "eval_time": 29.476433038711548, "mean_episode_reward": 881.1, "best_episode_reward": 990.0, "step": 141000}
{"episode": 568.0, "episode_reward": 959.7, "eval_time": 29.394869327545166, "mean_episode_reward": 959.7, "best_episode_reward": 989.0, "step": 142000}
{"episode": 572.0, "episode_reward": 978.3, "eval_time": 29.344984769821167, "mean_episode_reward": 978.3, "best_episode_reward": 1000.0, "step": 143000}
{"episode": 576.0, "episode_reward": 931.8, "eval_time": 29.45684838294983, "mean_episode_reward": 931.8, "best_episode_reward": 994.0, "step": 144000}
{"episode": 580.0, "episode_reward": 968.2, "eval_time": 29.429829597473145, "mean_episode_reward": 968.2, "best_episode_reward": 995.0, "step": 145000}
{"episode": 584.0, "episode_reward": 872.6, "eval_time": 29.403443098068237, "mean_episode_reward": 872.6, "best_episode_reward": 995.0, "step": 146000}
{"episode": 588.0, "episode_reward": 969.8, "eval_time": 29.397531032562256, "mean_episode_reward": 969.8, "best_episode_reward": 996.0, "step": 147000}
{"episode": 592.0, "episode_reward": 965.7, "eval_time": 29.474132776260376, "mean_episode_reward": 965.7, "best_episode_reward": 990.0, "step": 148000}
{"episode": 596.0, "episode_reward": 847.9, "eval_time": 29.463903665542603, "mean_episode_reward": 847.9, "best_episode_reward": 984.0, "step": 149000}
{"episode": 600.0, "episode_reward": 975.8, "eval_time": 29.36856770515442, "mean_episode_reward": 975.8, "best_episode_reward": 999.0, "step": 150000}
{"episode": 604.0, "episode_reward": 972.6, "eval_time": 29.514650583267212, "mean_episode_reward": 972.6, "best_episode_reward": 1000.0, "step": 151000}
{"episode": 608.0, "episode_reward": 691.4, "eval_time": 29.48691725730896, "mean_episode_reward": 691.4, "best_episode_reward": 997.0, "step": 152000}
{"episode": 612.0, "episode_reward": 972.6, "eval_time": 29.42004370689392, "mean_episode_reward": 972.6, "best_episode_reward": 992.0, "step": 153000}
{"episode": 616.0, "episode_reward": 974.3, "eval_time": 29.470274209976196, "mean_episode_reward": 974.3, "best_episode_reward": 990.0, "step": 154000}
{"episode": 620.0, "episode_reward": 651.2, "eval_time": 29.404390335083008, "mean_episode_reward": 651.2, "best_episode_reward": 995.0, "step": 155000}
{"episode": 624.0, "episode_reward": 970.4, "eval_time": 29.48948335647583, "mean_episode_reward": 970.4, "best_episode_reward": 994.0, "step": 156000}
{"episode": 628.0, "episode_reward": 911.6, "eval_time": 29.446200370788574, "mean_episode_reward": 911.6, "best_episode_reward": 985.0, "step": 157000}
{"episode": 632.0, "episode_reward": 973.0, "eval_time": 29.490323305130005, "mean_episode_reward": 973.0, "best_episode_reward": 995.0, "step": 158000}
{"episode": 636.0, "episode_reward": 967.7, "eval_time": 29.86604619026184, "mean_episode_reward": 967.7, "best_episode_reward": 987.0, "step": 159000}
{"episode": 640.0, "episode_reward": 970.5, "eval_time": 29.511362075805664, "mean_episode_reward": 970.5, "best_episode_reward": 993.0, "step": 160000}
{"episode": 644.0, "episode_reward": 790.1, "eval_time": 29.588794946670532, "mean_episode_reward": 790.1, "best_episode_reward": 999.0, "step": 161000}
{"episode": 648.0, "episode_reward": 970.9, "eval_time": 29.55907106399536, "mean_episode_reward": 970.9, "best_episode_reward": 998.0, "step": 162000}
{"episode": 652.0, "episode_reward": 867.5, "eval_time": 29.931834936141968, "mean_episode_reward": 867.5, "best_episode_reward": 982.0, "step": 163000}
{"episode": 656.0, "episode_reward": 966.1, "eval_time": 29.933039903640747, "mean_episode_reward": 966.1, "best_episode_reward": 1000.0, "step": 164000}
{"episode": 660.0, "episode_reward": 960.3, "eval_time": 29.922218799591064, "mean_episode_reward": 960.3, "best_episode_reward": 998.0, "step": 165000}
{"episode": 664.0, "episode_reward": 854.5, "eval_time": 29.945570707321167, "mean_episode_reward": 854.5, "best_episode_reward": 997.0, "step": 166000}
{"episode": 668.0, "episode_reward": 960.1, "eval_time": 29.866527795791626, "mean_episode_reward": 960.1, "best_episode_reward": 997.0, "step": 167000}
{"episode": 672.0, "episode_reward": 853.0, "eval_time": 30.01184582710266, "mean_episode_reward": 853.0, "best_episode_reward": 996.0, "step": 168000}
{"episode": 676.0, "episode_reward": 803.2, "eval_time": 29.81304931640625, "mean_episode_reward": 803.2, "best_episode_reward": 993.0, "step": 169000}
{"episode": 680.0, "episode_reward": 809.8, "eval_time": 29.882144451141357, "mean_episode_reward": 809.8, "best_episode_reward": 992.0, "step": 170000}
{"episode": 684.0, "episode_reward": 973.7, "eval_time": 29.836324453353882, "mean_episode_reward": 973.7, "best_episode_reward": 990.0, "step": 171000}
{"episode": 688.0, "episode_reward": 928.8, "eval_time": 29.876282453536987, "mean_episode_reward": 928.8, "best_episode_reward": 985.0, "step": 172000}
{"episode": 692.0, "episode_reward": 973.5, "eval_time": 29.876770496368408, "mean_episode_reward": 973.5, "best_episode_reward": 990.0, "step": 173000}
{"episode": 696.0, "episode_reward": 962.5, "eval_time": 29.88244366645813, "mean_episode_reward": 962.5, "best_episode_reward": 1000.0, "step": 174000}
{"episode": 700.0, "episode_reward": 884.4, "eval_time": 29.81652021408081, "mean_episode_reward": 884.4, "best_episode_reward": 983.0, "step": 175000}
{"episode": 704.0, "episode_reward": 859.5, "eval_time": 29.813431978225708, "mean_episode_reward": 859.5, "best_episode_reward": 983.0, "step": 176000}
{"episode": 708.0, "episode_reward": 859.4, "eval_time": 29.88725185394287, "mean_episode_reward": 859.4, "best_episode_reward": 978.0, "step": 177000}
{"episode": 712.0, "episode_reward": 778.1, "eval_time": 29.992334842681885, "mean_episode_reward": 778.1, "best_episode_reward": 1000.0, "step": 178000}
{"episode": 716.0, "episode_reward": 875.3, "eval_time": 29.835069179534912, "mean_episode_reward": 875.3, "best_episode_reward": 1000.0, "step": 179000}
{"episode": 720.0, "episode_reward": 814.6, "eval_time": 29.828681707382202, "mean_episode_reward": 814.6, "best_episode_reward": 1000.0, "step": 180000}
{"episode": 724.0, "episode_reward": 779.6, "eval_time": 29.941678762435913, "mean_episode_reward": 779.6, "best_episode_reward": 993.0, "step": 181000}
{"episode": 728.0, "episode_reward": 866.0, "eval_time": 29.784382104873657, "mean_episode_reward": 866.0, "best_episode_reward": 1000.0, "step": 182000}
{"episode": 732.0, "episode_reward": 872.4, "eval_time": 29.83882188796997, "mean_episode_reward": 872.4, "best_episode_reward": 1000.0, "step": 183000}
{"episode": 736.0, "episode_reward": 883.2, "eval_time": 29.882367849349976, "mean_episode_reward": 883.2, "best_episode_reward": 1000.0, "step": 184000}
{"episode": 740.0, "episode_reward": 973.1, "eval_time": 29.52554440498352, "mean_episode_reward": 973.1, "best_episode_reward": 993.0, "step": 185000}
{"episode": 744.0, "episode_reward": 814.8, "eval_time": 29.43539309501648, "mean_episode_reward": 814.8, "best_episode_reward": 999.0, "step": 186000}
{"episode": 748.0, "episode_reward": 810.9, "eval_time": 29.416725158691406, "mean_episode_reward": 810.9, "best_episode_reward": 994.0, "step": 187000}
{"episode": 752.0, "episode_reward": 849.6, "eval_time": 29.46768593788147, "mean_episode_reward": 849.6, "best_episode_reward": 993.0, "step": 188000}
{"episode": 756.0, "episode_reward": 976.3, "eval_time": 29.478498220443726, "mean_episode_reward": 976.3, "best_episode_reward": 991.0, "step": 189000}
{"episode": 760.0, "episode_reward": 880.0, "eval_time": 29.41501498222351, "mean_episode_reward": 880.0, "best_episode_reward": 999.0, "step": 190000}
{"episode": 764.0, "episode_reward": 853.1, "eval_time": 29.46463894844055, "mean_episode_reward": 853.1, "best_episode_reward": 994.0, "step": 191000}
{"episode": 768.0, "episode_reward": 966.0, "eval_time": 29.497854948043823, "mean_episode_reward": 966.0, "best_episode_reward": 987.0, "step": 192000}
{"episode": 772.0, "episode_reward": 878.2, "eval_time": 29.472924947738647, "mean_episode_reward": 878.2, "best_episode_reward": 1000.0, "step": 193000}
{"episode": 776.0, "episode_reward": 842.6, "eval_time": 29.461795806884766, "mean_episode_reward": 842.6, "best_episode_reward": 979.0, "step": 194000}
{"episode": 780.0, "episode_reward": 733.5, "eval_time": 30.3844153881073, "mean_episode_reward": 733.5, "best_episode_reward": 981.0, "step": 195000}
{"episode": 784.0, "episode_reward": 958.7, "eval_time": 29.456698656082153, "mean_episode_reward": 958.7, "best_episode_reward": 992.0, "step": 196000}
{"episode": 788.0, "episode_reward": 975.9, "eval_time": 29.413645029067993, "mean_episode_reward": 975.9, "best_episode_reward": 1000.0, "step": 197000}
{"episode": 792.0, "episode_reward": 958.3, "eval_time": 29.43423581123352, "mean_episode_reward": 958.3, "best_episode_reward": 998.0, "step": 198000}
{"episode": 796.0, "episode_reward": 870.8, "eval_time": 29.441871881484985, "mean_episode_reward": 870.8, "best_episode_reward": 986.0, "step": 199000}
{"episode": 800.0, "episode_reward": 866.8, "eval_time": 29.39687156677246, "mean_episode_reward": 866.8, "best_episode_reward": 1000.0, "step": 200000}
{"episode": 804.0, "episode_reward": 844.0, "eval_time": 29.44662308692932, "mean_episode_reward": 844.0, "best_episode_reward": 997.0, "step": 201000}
{"episode": 808.0, "episode_reward": 973.2, "eval_time": 29.399433851242065, "mean_episode_reward": 973.2, "best_episode_reward": 999.0, "step": 202000}
{"episode": 812.0, "episode_reward": 969.8, "eval_time": 29.394845008850098, "mean_episode_reward": 969.8, "best_episode_reward": 1000.0, "step": 203000}
{"episode": 816.0, "episode_reward": 953.6, "eval_time": 29.451552867889404, "mean_episode_reward": 953.6, "best_episode_reward": 1000.0, "step": 204000}
{"episode": 820.0, "episode_reward": 873.7, "eval_time": 29.386105060577393, "mean_episode_reward": 873.7, "best_episode_reward": 991.0, "step": 205000}
{"episode": 824.0, "episode_reward": 942.4, "eval_time": 29.32990026473999, "mean_episode_reward": 942.4, "best_episode_reward": 991.0, "step": 206000}
{"episode": 828.0, "episode_reward": 873.7, "eval_time": 29.598308324813843, "mean_episode_reward": 873.7, "best_episode_reward": 993.0, "step": 207000}
{"episode": 832.0, "episode_reward": 971.9, "eval_time": 29.52058982849121, "mean_episode_reward": 971.9, "best_episode_reward": 983.0, "step": 208000}
{"episode": 836.0, "episode_reward": 950.1, "eval_time": 29.4775710105896, "mean_episode_reward": 950.1, "best_episode_reward": 986.0, "step": 209000}
{"episode": 840.0, "episode_reward": 874.7, "eval_time": 29.61045527458191, "mean_episode_reward": 874.7, "best_episode_reward": 996.0, "step": 210000}
{"episode": 844.0, "episode_reward": 980.7, "eval_time": 29.63401222229004, "mean_episode_reward": 980.7, "best_episode_reward": 1000.0, "step": 211000}
{"episode": 848.0, "episode_reward": 978.5, "eval_time": 29.518486738204956, "mean_episode_reward": 978.5, "best_episode_reward": 1000.0, "step": 212000}
{"episode": 852.0, "episode_reward": 863.5, "eval_time": 29.50660014152527, "mean_episode_reward": 863.5, "best_episode_reward": 1000.0, "step": 213000}
{"episode": 856.0, "episode_reward": 962.9, "eval_time": 29.55860710144043, "mean_episode_reward": 962.9, "best_episode_reward": 995.0, "step": 214000}
{"episode": 860.0, "episode_reward": 881.0, "eval_time": 29.600254774093628, "mean_episode_reward": 881.0, "best_episode_reward": 995.0, "step": 215000}
{"episode": 864.0, "episode_reward": 943.0, "eval_time": 29.618463277816772, "mean_episode_reward": 943.0, "best_episode_reward": 996.0, "step": 216000}
{"episode": 868.0, "episode_reward": 830.1, "eval_time": 29.53291130065918, "mean_episode_reward": 830.1, "best_episode_reward": 988.0, "step": 217000}
{"episode": 872.0, "episode_reward": 968.5, "eval_time": 29.485065698623657, "mean_episode_reward": 968.5, "best_episode_reward": 995.0, "step": 218000}
{"episode": 876.0, "episode_reward": 957.7, "eval_time": 29.5115966796875, "mean_episode_reward": 957.7, "best_episode_reward": 1000.0, "step": 219000}
{"episode": 880.0, "episode_reward": 973.5, "eval_time": 29.564685106277466, "mean_episode_reward": 973.5, "best_episode_reward": 996.0, "step": 220000}
{"episode": 884.0, "episode_reward": 957.0, "eval_time": 29.558106660842896, "mean_episode_reward": 957.0, "best_episode_reward": 992.0, "step": 221000}
{"episode": 888.0, "episode_reward": 969.3, "eval_time": 29.556884050369263, "mean_episode_reward": 969.3, "best_episode_reward": 995.0, "step": 222000}
{"episode": 892.0, "episode_reward": 966.2, "eval_time": 29.513498306274414, "mean_episode_reward": 966.2, "best_episode_reward": 995.0, "step": 223000}
{"episode": 896.0, "episode_reward": 971.0, "eval_time": 29.583418607711792, "mean_episode_reward": 971.0, "best_episode_reward": 984.0, "step": 224000}
{"episode": 900.0, "episode_reward": 778.4, "eval_time": 29.553349256515503, "mean_episode_reward": 778.4, "best_episode_reward": 997.0, "step": 225000}
{"episode": 904.0, "episode_reward": 964.8, "eval_time": 29.5678927898407, "mean_episode_reward": 964.8, "best_episode_reward": 985.0, "step": 226000}
{"episode": 908.0, "episode_reward": 949.3, "eval_time": 29.496055841445923, "mean_episode_reward": 949.3, "best_episode_reward": 1000.0, "step": 227000}
{"episode": 912.0, "episode_reward": 977.6, "eval_time": 29.609243869781494, "mean_episode_reward": 977.6, "best_episode_reward": 997.0, "step": 228000}
{"episode": 916.0, "episode_reward": 917.7, "eval_time": 29.586642742156982, "mean_episode_reward": 917.7, "best_episode_reward": 997.0, "step": 229000}
{"episode": 920.0, "episode_reward": 881.4, "eval_time": 29.53134512901306, "mean_episode_reward": 881.4, "best_episode_reward": 1000.0, "step": 230000}
{"episode": 924.0, "episode_reward": 969.1, "eval_time": 29.532981395721436, "mean_episode_reward": 969.1, "best_episode_reward": 1000.0, "step": 231000}
{"episode": 928.0, "episode_reward": 968.3, "eval_time": 29.480774402618408, "mean_episode_reward": 968.3, "best_episode_reward": 1000.0, "step": 232000}
{"episode": 932.0, "episode_reward": 968.7, "eval_time": 29.58232569694519, "mean_episode_reward": 968.7, "best_episode_reward": 987.0, "step": 233000}
{"episode": 936.0, "episode_reward": 967.3, "eval_time": 29.58107328414917, "mean_episode_reward": 967.3, "best_episode_reward": 991.0, "step": 234000}
{"episode": 940.0, "episode_reward": 965.1, "eval_time": 29.57681941986084, "mean_episode_reward": 965.1, "best_episode_reward": 979.0, "step": 235000}
{"episode": 944.0, "episode_reward": 972.6, "eval_time": 29.557698726654053, "mean_episode_reward": 972.6, "best_episode_reward": 987.0, "step": 236000}
{"episode": 948.0, "episode_reward": 871.5, "eval_time": 29.525456190109253, "mean_episode_reward": 871.5, "best_episode_reward": 998.0, "step": 237000}
{"episode": 952.0, "episode_reward": 936.9, "eval_time": 29.674662590026855, "mean_episode_reward": 936.9, "best_episode_reward": 997.0, "step": 238000}
{"episode": 956.0, "episode_reward": 981.7, "eval_time": 29.61037826538086, "mean_episode_reward": 981.7, "best_episode_reward": 1000.0, "step": 239000}
{"episode": 960.0, "episode_reward": 974.4, "eval_time": 29.57424759864807, "mean_episode_reward": 974.4, "best_episode_reward": 1000.0, "step": 240000}
{"episode": 964.0, "episode_reward": 923.6, "eval_time": 29.627775192260742, "mean_episode_reward": 923.6, "best_episode_reward": 1000.0, "step": 241000}
{"episode": 968.0, "episode_reward": 785.7, "eval_time": 29.590916395187378, "mean_episode_reward": 785.7, "best_episode_reward": 990.0, "step": 242000}
{"episode": 972.0, "episode_reward": 775.2, "eval_time": 29.647892713546753, "mean_episode_reward": 775.2, "best_episode_reward": 992.0, "step": 243000}
{"episode": 976.0, "episode_reward": 968.1, "eval_time": 29.622036695480347, "mean_episode_reward": 968.1, "best_episode_reward": 1000.0, "step": 244000}
{"episode": 980.0, "episode_reward": 968.1, "eval_time": 29.56148672103882, "mean_episode_reward": 968.1, "best_episode_reward": 995.0, "step": 245000}
{"episode": 984.0, "episode_reward": 947.2, "eval_time": 29.584139823913574, "mean_episode_reward": 947.2, "best_episode_reward": 986.0, "step": 246000}
{"episode": 988.0, "episode_reward": 876.6, "eval_time": 29.63913655281067, "mean_episode_reward": 876.6, "best_episode_reward": 999.0, "step": 247000}
{"episode": 992.0, "episode_reward": 974.0, "eval_time": 29.50886106491089, "mean_episode_reward": 974.0, "best_episode_reward": 1000.0, "step": 248000}
{"episode": 996.0, "episode_reward": 941.2, "eval_time": 29.565673828125, "mean_episode_reward": 941.2, "best_episode_reward": 1000.0, "step": 249000}
{"episode": 1000.0, "episode_reward": 971.8, "eval_time": 29.59261155128479, "mean_episode_reward": 971.8, "best_episode_reward": 985.0, "step": 250000}
{"episode": 1004.0, "episode_reward": 975.1, "eval_time": 29.671263217926025, "mean_episode_reward": 975.1, "best_episode_reward": 994.0, "step": 251000}
{"episode": 1008.0, "episode_reward": 713.0, "eval_time": 29.52745509147644, "mean_episode_reward": 713.0, "best_episode_reward": 996.0, "step": 252000}
{"episode": 1012.0, "episode_reward": 959.4, "eval_time": 29.556492805480957, "mean_episode_reward": 959.4, "best_episode_reward": 1000.0, "step": 253000}
{"episode": 1016.0, "episode_reward": 926.8, "eval_time": 29.577167510986328, "mean_episode_reward": 926.8, "best_episode_reward": 1000.0, "step": 254000}
{"episode": 1020.0, "episode_reward": 981.0, "eval_time": 29.541492700576782, "mean_episode_reward": 981.0, "best_episode_reward": 1000.0, "step": 255000}
{"episode": 1024.0, "episode_reward": 979.3, "eval_time": 29.61045503616333, "mean_episode_reward": 979.3, "best_episode_reward": 1000.0, "step": 256000}
{"episode": 1028.0, "episode_reward": 976.8, "eval_time": 29.545137405395508, "mean_episode_reward": 976.8, "best_episode_reward": 997.0, "step": 257000}
{"episode": 1032.0, "episode_reward": 974.5, "eval_time": 29.51524782180786, "mean_episode_reward": 974.5, "best_episode_reward": 990.0, "step": 258000}
{"episode": 1036.0, "episode_reward": 973.3, "eval_time": 29.584829330444336, "mean_episode_reward": 973.3, "best_episode_reward": 1000.0, "step": 259000}
{"episode": 1040.0, "episode_reward": 980.6, "eval_time": 29.53506088256836, "mean_episode_reward": 980.6, "best_episode_reward": 995.0, "step": 260000}
{"episode": 1044.0, "episode_reward": 962.8, "eval_time": 29.573901891708374, "mean_episode_reward": 962.8, "best_episode_reward": 985.0, "step": 261000}
{"episode": 1048.0, "episode_reward": 969.6, "eval_time": 29.55781054496765, "mean_episode_reward": 969.6, "best_episode_reward": 994.0, "step": 262000}
{"episode": 1052.0, "episode_reward": 872.8, "eval_time": 29.551401615142822, "mean_episode_reward": 872.8, "best_episode_reward": 988.0, "step": 263000}
{"episode": 1056.0, "episode_reward": 976.5, "eval_time": 29.631778240203857, "mean_episode_reward": 976.5, "best_episode_reward": 1000.0, "step": 264000}
{"episode": 1060.0, "episode_reward": 965.9, "eval_time": 29.477298736572266, "mean_episode_reward": 965.9, "best_episode_reward": 993.0, "step": 265000}
{"episode": 1064.0, "episode_reward": 979.3, "eval_time": 29.534117221832275, "mean_episode_reward": 979.3, "best_episode_reward": 992.0, "step": 266000}
{"episode": 1068.0, "episode_reward": 974.7, "eval_time": 29.6566219329834, "mean_episode_reward": 974.7, "best_episode_reward": 989.0, "step": 267000}
{"episode": 1072.0, "episode_reward": 878.6, "eval_time": 29.592689752578735, "mean_episode_reward": 878.6, "best_episode_reward": 1000.0, "step": 268000}
{"episode": 1076.0, "episode_reward": 978.2, "eval_time": 29.582996368408203, "mean_episode_reward": 978.2, "best_episode_reward": 1000.0, "step": 269000}
{"episode": 1080.0, "episode_reward": 870.5, "eval_time": 29.60810089111328, "mean_episode_reward": 870.5, "best_episode_reward": 982.0, "step": 270000}
{"episode": 1084.0, "episode_reward": 969.0, "eval_time": 29.621663331985474, "mean_episode_reward": 969.0, "best_episode_reward": 991.0, "step": 271000}
{"episode": 1088.0, "episode_reward": 879.0, "eval_time": 29.613277435302734, "mean_episode_reward": 879.0, "best_episode_reward": 998.0, "step": 272000}
{"episode": 1092.0, "episode_reward": 971.3, "eval_time": 29.517816066741943, "mean_episode_reward": 971.3, "best_episode_reward": 990.0, "step": 273000}
{"episode": 1096.0, "episode_reward": 967.5, "eval_time": 29.579789876937866, "mean_episode_reward": 967.5, "best_episode_reward": 988.0, "step": 274000}
{"episode": 1100.0, "episode_reward": 968.4, "eval_time": 29.53305697441101, "mean_episode_reward": 968.4, "best_episode_reward": 986.0, "step": 275000}
{"episode": 1104.0, "episode_reward": 870.9, "eval_time": 29.64283585548401, "mean_episode_reward": 870.9, "best_episode_reward": 981.0, "step": 276000}
{"episode": 1108.0, "episode_reward": 973.7, "eval_time": 29.52437973022461, "mean_episode_reward": 973.7, "best_episode_reward": 996.0, "step": 277000}
{"episode": 1112.0, "episode_reward": 977.5, "eval_time": 30.002036333084106, "mean_episode_reward": 977.5, "best_episode_reward": 996.0, "step": 278000}
{"episode": 1116.0, "episode_reward": 885.6, "eval_time": 30.68918514251709, "mean_episode_reward": 885.6, "best_episode_reward": 992.0, "step": 279000}
{"episode": 1120.0, "episode_reward": 980.8, "eval_time": 29.49335527420044, "mean_episode_reward": 980.8, "best_episode_reward": 1000.0, "step": 280000}
{"episode": 1124.0, "episode_reward": 971.0, "eval_time": 29.624534130096436, "mean_episode_reward": 971.0, "best_episode_reward": 989.0, "step": 281000}
{"episode": 1128.0, "episode_reward": 973.9, "eval_time": 29.562456607818604, "mean_episode_reward": 973.9, "best_episode_reward": 987.0, "step": 282000}
{"episode": 1132.0, "episode_reward": 976.5, "eval_time": 29.55965805053711, "mean_episode_reward": 976.5, "best_episode_reward": 994.0, "step": 283000}
{"episode": 1136.0, "episode_reward": 973.6, "eval_time": 29.581838369369507, "mean_episode_reward": 973.6, "best_episode_reward": 1000.0, "step": 284000}
{"episode": 1140.0, "episode_reward": 965.3, "eval_time": 29.565865755081177, "mean_episode_reward": 965.3, "best_episode_reward": 991.0, "step": 285000}
{"episode": 1144.0, "episode_reward": 977.4, "eval_time": 29.46485948562622, "mean_episode_reward": 977.4, "best_episode_reward": 988.0, "step": 286000}
{"episode": 1148.0, "episode_reward": 966.3, "eval_time": 30.098188400268555, "mean_episode_reward": 966.3, "best_episode_reward": 1000.0, "step": 287000}
{"episode": 1152.0, "episode_reward": 976.7, "eval_time": 30.84170913696289, "mean_episode_reward": 976.7, "best_episode_reward": 991.0, "step": 288000}
{"episode": 1156.0, "episode_reward": 889.6, "eval_time": 30.746896505355835, "mean_episode_reward": 889.6, "best_episode_reward": 1000.0, "step": 289000}
{"episode": 1160.0, "episode_reward": 965.6, "eval_time": 30.731456756591797, "mean_episode_reward": 965.6, "best_episode_reward": 992.0, "step": 290000}
{"episode": 1164.0, "episode_reward": 961.0, "eval_time": 30.831987857818604, "mean_episode_reward": 961.0, "best_episode_reward": 1000.0, "step": 291000}
{"episode": 1168.0, "episode_reward": 864.3, "eval_time": 30.839354515075684, "mean_episode_reward": 864.3, "best_episode_reward": 994.0, "step": 292000}
{"episode": 1172.0, "episode_reward": 770.5, "eval_time": 30.763048887252808, "mean_episode_reward": 770.5, "best_episode_reward": 1000.0, "step": 293000}
{"episode": 1176.0, "episode_reward": 893.2, "eval_time": 30.863245487213135, "mean_episode_reward": 893.2, "best_episode_reward": 1000.0, "step": 294000}
{"episode": 1180.0, "episode_reward": 778.2, "eval_time": 30.740381717681885, "mean_episode_reward": 778.2, "best_episode_reward": 1000.0, "step": 295000}
{"episode": 1184.0, "episode_reward": 969.1, "eval_time": 30.82604169845581, "mean_episode_reward": 969.1, "best_episode_reward": 991.0, "step": 296000}
{"episode": 1188.0, "episode_reward": 976.2, "eval_time": 30.813292264938354, "mean_episode_reward": 976.2, "best_episode_reward": 1000.0, "step": 297000}
{"episode": 1192.0, "episode_reward": 876.2, "eval_time": 30.863701343536377, "mean_episode_reward": 876.2, "best_episode_reward": 981.0, "step": 298000}
{"episode": 1196.0, "episode_reward": 851.5, "eval_time": 30.759719133377075, "mean_episode_reward": 851.5, "best_episode_reward": 980.0, "step": 299000}
{"episode": 1200.0, "episode_reward": 876.9, "eval_time": 30.686803579330444, "mean_episode_reward": 876.9, "best_episode_reward": 995.0, "step": 300000}
{"episode": 1204.0, "episode_reward": 963.7, "eval_time": 30.824169397354126, "mean_episode_reward": 963.7, "best_episode_reward": 998.0, "step": 301000}
{"episode": 1208.0, "episode_reward": 967.8, "eval_time": 30.704997301101685, "mean_episode_reward": 967.8, "best_episode_reward": 991.0, "step": 302000}
{"episode": 1212.0, "episode_reward": 964.4, "eval_time": 30.719167947769165, "mean_episode_reward": 964.4, "best_episode_reward": 1000.0, "step": 303000}
{"episode": 1216.0, "episode_reward": 976.3, "eval_time": 30.777639389038086, "mean_episode_reward": 976.3, "best_episode_reward": 992.0, "step": 304000}
{"episode": 1220.0, "episode_reward": 931.3, "eval_time": 30.816201210021973, "mean_episode_reward": 931.3, "best_episode_reward": 995.0, "step": 305000}
{"episode": 1224.0, "episode_reward": 880.6, "eval_time": 30.801528930664062, "mean_episode_reward": 880.6, "best_episode_reward": 1000.0, "step": 306000}
{"episode": 1228.0, "episode_reward": 965.7, "eval_time": 30.753561973571777, "mean_episode_reward": 965.7, "best_episode_reward": 1000.0, "step": 307000}
{"episode": 1232.0, "episode_reward": 966.9, "eval_time": 30.691717386245728, "mean_episode_reward": 966.9, "best_episode_reward": 988.0, "step": 308000}
{"episode": 1236.0, "episode_reward": 885.0, "eval_time": 30.704936027526855, "mean_episode_reward": 885.0, "best_episode_reward": 1000.0, "step": 309000}
{"episode": 1240.0, "episode_reward": 911.9, "eval_time": 30.779783248901367, "mean_episode_reward": 911.9, "best_episode_reward": 996.0, "step": 310000}
{"episode": 1244.0, "episode_reward": 982.3, "eval_time": 30.6894314289093, "mean_episode_reward": 982.3, "best_episode_reward": 1000.0, "step": 311000}
{"episode": 1248.0, "episode_reward": 969.9, "eval_time": 30.673088312149048, "mean_episode_reward": 969.9, "best_episode_reward": 986.0, "step": 312000}
{"episode": 1252.0, "episode_reward": 851.6, "eval_time": 30.718326568603516, "mean_episode_reward": 851.6, "best_episode_reward": 1000.0, "step": 313000}
{"episode": 1256.0, "episode_reward": 936.2, "eval_time": 30.766847610473633, "mean_episode_reward": 936.2, "best_episode_reward": 990.0, "step": 314000}
{"episode": 1260.0, "episode_reward": 976.6, "eval_time": 30.65620756149292, "mean_episode_reward": 976.6, "best_episode_reward": 998.0, "step": 315000}
{"episode": 1264.0, "episode_reward": 867.2, "eval_time": 30.73340606689453, "mean_episode_reward": 867.2, "best_episode_reward": 994.0, "step": 316000}
{"episode": 1268.0, "episode_reward": 977.8, "eval_time": 30.628334999084473, "mean_episode_reward": 977.8, "best_episode_reward": 995.0, "step": 317000}
{"episode": 1272.0, "episode_reward": 975.2, "eval_time": 30.617217302322388, "mean_episode_reward": 975.2, "best_episode_reward": 999.0, "step": 318000}
{"episode": 1276.0, "episode_reward": 973.6, "eval_time": 30.589889526367188, "mean_episode_reward": 973.6, "best_episode_reward": 981.0, "step": 319000}
{"episode": 1280.0, "episode_reward": 979.4, "eval_time": 30.71837329864502, "mean_episode_reward": 979.4, "best_episode_reward": 1000.0, "step": 320000}
{"episode": 1284.0, "episode_reward": 872.9, "eval_time": 30.659597635269165, "mean_episode_reward": 872.9, "best_episode_reward": 999.0, "step": 321000}
{"episode": 1288.0, "episode_reward": 968.6, "eval_time": 30.737619400024414, "mean_episode_reward": 968.6, "best_episode_reward": 1000.0, "step": 322000}
{"episode": 1292.0, "episode_reward": 958.2, "eval_time": 30.698010683059692, "mean_episode_reward": 958.2, "best_episode_reward": 999.0, "step": 323000}
{"episode": 1296.0, "episode_reward": 955.4, "eval_time": 30.72184944152832, "mean_episode_reward": 955.4, "best_episode_reward": 992.0, "step": 324000}
{"episode": 1300.0, "episode_reward": 885.9, "eval_time": 31.097306966781616, "mean_episode_reward": 885.9, "best_episode_reward": 1000.0, "step": 325000}
{"episode": 1304.0, "episode_reward": 878.3, "eval_time": 31.28859782218933, "mean_episode_reward": 878.3, "best_episode_reward": 1000.0, "step": 326000}
{"episode": 1308.0, "episode_reward": 965.3, "eval_time": 31.371490001678467, "mean_episode_reward": 965.3, "best_episode_reward": 1000.0, "step": 327000}
{"episode": 1312.0, "episode_reward": 973.3, "eval_time": 31.452582836151123, "mean_episode_reward": 973.3, "best_episode_reward": 998.0, "step": 328000}
{"episode": 1316.0, "episode_reward": 877.4, "eval_time": 31.32295870780945, "mean_episode_reward": 877.4, "best_episode_reward": 991.0, "step": 329000}
{"episode": 1320.0, "episode_reward": 883.0, "eval_time": 31.31779384613037, "mean_episode_reward": 883.0, "best_episode_reward": 1000.0, "step": 330000}
{"episode": 1324.0, "episode_reward": 683.7, "eval_time": 31.34993052482605, "mean_episode_reward": 683.7, "best_episode_reward": 998.0, "step": 331000}
{"episode": 1328.0, "episode_reward": 952.5, "eval_time": 31.342108964920044, "mean_episode_reward": 952.5, "best_episode_reward": 996.0, "step": 332000}
{"episode": 1332.0, "episode_reward": 695.0, "eval_time": 31.367262840270996, "mean_episode_reward": 695.0, "best_episode_reward": 977.0, "step": 333000}
{"episode": 1336.0, "episode_reward": 875.4, "eval_time": 31.3370099067688, "mean_episode_reward": 875.4, "best_episode_reward": 993.0, "step": 334000}
{"episode": 1340.0, "episode_reward": 866.9, "eval_time": 31.235150814056396, "mean_episode_reward": 866.9, "best_episode_reward": 990.0, "step": 335000}
{"episode": 1344.0, "episode_reward": 960.3, "eval_time": 31.344773530960083, "mean_episode_reward": 960.3, "best_episode_reward": 1000.0, "step": 336000}
{"episode": 1348.0, "episode_reward": 910.6, "eval_time": 31.393466472625732, "mean_episode_reward": 910.6, "best_episode_reward": 996.0, "step": 337000}
{"episode": 1352.0, "episode_reward": 971.8, "eval_time": 31.351402521133423, "mean_episode_reward": 971.8, "best_episode_reward": 994.0, "step": 338000}
{"episode": 1356.0, "episode_reward": 975.0, "eval_time": 31.366341590881348, "mean_episode_reward": 975.0, "best_episode_reward": 1000.0, "step": 339000}
{"episode": 1360.0, "episode_reward": 971.1, "eval_time": 31.29742980003357, "mean_episode_reward": 971.1, "best_episode_reward": 996.0, "step": 340000}
{"episode": 1364.0, "episode_reward": 945.3, "eval_time": 31.423328399658203, "mean_episode_reward": 945.3, "best_episode_reward": 993.0, "step": 341000}
{"episode": 1368.0, "episode_reward": 967.4, "eval_time": 31.272186994552612, "mean_episode_reward": 967.4, "best_episode_reward": 1000.0, "step": 342000}
{"episode": 1372.0, "episode_reward": 983.2, "eval_time": 31.388884782791138, "mean_episode_reward": 983.2, "best_episode_reward": 995.0, "step": 343000}
{"episode": 1376.0, "episode_reward": 867.8, "eval_time": 31.290235996246338, "mean_episode_reward": 867.8, "best_episode_reward": 994.0, "step": 344000}
{"episode": 1380.0, "episode_reward": 978.0, "eval_time": 31.26127862930298, "mean_episode_reward": 978.0, "best_episode_reward": 1000.0, "step": 345000}
{"episode": 1384.0, "episode_reward": 879.2, "eval_time": 31.35344672203064, "mean_episode_reward": 879.2, "best_episode_reward": 995.0, "step": 346000}
{"episode": 1388.0, "episode_reward": 804.4, "eval_time": 31.360105514526367, "mean_episode_reward": 804.4, "best_episode_reward": 1000.0, "step": 347000}
{"episode": 1392.0, "episode_reward": 778.3, "eval_time": 31.239896059036255, "mean_episode_reward": 778.3, "best_episode_reward": 996.0, "step": 348000}
{"episode": 1396.0, "episode_reward": 869.9, "eval_time": 31.330822467803955, "mean_episode_reward": 869.9, "best_episode_reward": 992.0, "step": 349000}
{"episode": 1400.0, "episode_reward": 921.7, "eval_time": 31.39019799232483, "mean_episode_reward": 921.7, "best_episode_reward": 989.0, "step": 350000}
{"episode": 1404.0, "episode_reward": 823.6, "eval_time": 31.313207387924194, "mean_episode_reward": 823.6, "best_episode_reward": 997.0, "step": 351000}
{"episode": 1408.0, "episode_reward": 751.0, "eval_time": 31.31266164779663, "mean_episode_reward": 751.0, "best_episode_reward": 1000.0, "step": 352000}
{"episode": 1412.0, "episode_reward": 861.0, "eval_time": 31.314334392547607, "mean_episode_reward": 861.0, "best_episode_reward": 993.0, "step": 353000}
{"episode": 1416.0, "episode_reward": 883.8, "eval_time": 31.30419087409973, "mean_episode_reward": 883.8, "best_episode_reward": 997.0, "step": 354000}
{"episode": 1420.0, "episode_reward": 973.7, "eval_time": 31.26724076271057, "mean_episode_reward": 973.7, "best_episode_reward": 999.0, "step": 355000}
{"episode": 1424.0, "episode_reward": 854.8, "eval_time": 31.222694396972656, "mean_episode_reward": 854.8, "best_episode_reward": 998.0, "step": 356000}
{"episode": 1428.0, "episode_reward": 742.7, "eval_time": 31.333103895187378, "mean_episode_reward": 742.7, "best_episode_reward": 985.0, "step": 357000}
{"episode": 1432.0, "episode_reward": 968.0, "eval_time": 31.159465551376343, "mean_episode_reward": 968.0, "best_episode_reward": 985.0, "step": 358000}
{"episode": 1436.0, "episode_reward": 880.5, "eval_time": 31.310840845108032, "mean_episode_reward": 880.5, "best_episode_reward": 1000.0, "step": 359000}
{"episode": 1440.0, "episode_reward": 964.6, "eval_time": 31.244426012039185, "mean_episode_reward": 964.6, "best_episode_reward": 1000.0, "step": 360000}
{"episode": 1444.0, "episode_reward": 974.3, "eval_time": 31.272801637649536, "mean_episode_reward": 974.3, "best_episode_reward": 996.0, "step": 361000}
{"episode": 1448.0, "episode_reward": 972.7, "eval_time": 31.072139978408813, "mean_episode_reward": 972.7, "best_episode_reward": 998.0, "step": 362000}
{"episode": 1452.0, "episode_reward": 978.3, "eval_time": 31.206639528274536, "mean_episode_reward": 978.3, "best_episode_reward": 1000.0, "step": 363000}
{"episode": 1456.0, "episode_reward": 882.7, "eval_time": 31.12322735786438, "mean_episode_reward": 882.7, "best_episode_reward": 992.0, "step": 364000}
{"episode": 1460.0, "episode_reward": 977.9, "eval_time": 31.113507986068726, "mean_episode_reward": 977.9, "best_episode_reward": 998.0, "step": 365000}
{"episode": 1464.0, "episode_reward": 758.9, "eval_time": 31.042006492614746, "mean_episode_reward": 758.9, "best_episode_reward": 992.0, "step": 366000}
{"episode": 1468.0, "episode_reward": 932.4, "eval_time": 31.1155686378479, "mean_episode_reward": 932.4, "best_episode_reward": 995.0, "step": 367000}
{"episode": 1472.0, "episode_reward": 885.9, "eval_time": 31.16079354286194, "mean_episode_reward": 885.9, "best_episode_reward": 1000.0, "step": 368000}
{"episode": 1476.0, "episode_reward": 878.1, "eval_time": 31.134334564208984, "mean_episode_reward": 878.1, "best_episode_reward": 993.0, "step": 369000}
{"episode": 1480.0, "episode_reward": 873.1, "eval_time": 31.147731065750122, "mean_episode_reward": 873.1, "best_episode_reward": 991.0, "step": 370000}
{"episode": 1484.0, "episode_reward": 931.5, "eval_time": 31.204036235809326, "mean_episode_reward": 931.5, "best_episode_reward": 998.0, "step": 371000}
{"episode": 1488.0, "episode_reward": 969.7, "eval_time": 31.1868793964386, "mean_episode_reward": 969.7, "best_episode_reward": 1000.0, "step": 372000}
{"episode": 1492.0, "episode_reward": 967.7, "eval_time": 31.151706218719482, "mean_episode_reward": 967.7, "best_episode_reward": 991.0, "step": 373000}
{"episode": 1496.0, "episode_reward": 967.2, "eval_time": 31.167064666748047, "mean_episode_reward": 967.2, "best_episode_reward": 988.0, "step": 374000}
{"episode": 1500.0, "episode_reward": 975.6, "eval_time": 31.157784461975098, "mean_episode_reward": 975.6, "best_episode_reward": 1000.0, "step": 375000}
{"episode": 1504.0, "episode_reward": 930.3, "eval_time": 31.106683492660522, "mean_episode_reward": 930.3, "best_episode_reward": 996.0, "step": 376000}
{"episode": 1508.0, "episode_reward": 790.7, "eval_time": 31.051820516586304, "mean_episode_reward": 790.7, "best_episode_reward": 979.0, "step": 377000}
{"episode": 1512.0, "episode_reward": 978.3, "eval_time": 31.091742753982544, "mean_episode_reward": 978.3, "best_episode_reward": 1000.0, "step": 378000}
{"episode": 1516.0, "episode_reward": 973.5, "eval_time": 31.26073956489563, "mean_episode_reward": 973.5, "best_episode_reward": 1000.0, "step": 379000}
{"episode": 1520.0, "episode_reward": 875.3, "eval_time": 31.24610686302185, "mean_episode_reward": 875.3, "best_episode_reward": 990.0, "step": 380000}
{"episode": 1524.0, "episode_reward": 975.8, "eval_time": 31.1732017993927, "mean_episode_reward": 975.8, "best_episode_reward": 995.0, "step": 381000}
{"episode": 1528.0, "episode_reward": 978.6, "eval_time": 31.31108283996582, "mean_episode_reward": 978.6, "best_episode_reward": 997.0, "step": 382000}
{"episode": 1532.0, "episode_reward": 976.5, "eval_time": 31.327181816101074, "mean_episode_reward": 976.5, "best_episode_reward": 985.0, "step": 383000}
{"episode": 1536.0, "episode_reward": 969.9, "eval_time": 31.21575951576233, "mean_episode_reward": 969.9, "best_episode_reward": 992.0, "step": 384000}
{"episode": 1540.0, "episode_reward": 879.5, "eval_time": 31.18578863143921, "mean_episode_reward": 879.5, "best_episode_reward": 993.0, "step": 385000}
{"episode": 1544.0, "episode_reward": 876.6, "eval_time": 31.320070266723633, "mean_episode_reward": 876.6, "best_episode_reward": 996.0, "step": 386000}
{"episode": 1548.0, "episode_reward": 796.5, "eval_time": 31.310085773468018, "mean_episode_reward": 796.5, "best_episode_reward": 978.0, "step": 387000}
{"episode": 1552.0, "episode_reward": 844.6, "eval_time": 31.314091682434082, "mean_episode_reward": 844.6, "best_episode_reward": 1000.0, "step": 388000}
{"episode": 1556.0, "episode_reward": 800.2, "eval_time": 31.421712398529053, "mean_episode_reward": 800.2, "best_episode_reward": 981.0, "step": 389000}
{"episode": 1560.0, "episode_reward": 977.9, "eval_time": 31.303624391555786, "mean_episode_reward": 977.9, "best_episode_reward": 1000.0, "step": 390000}
{"episode": 1564.0, "episode_reward": 977.4, "eval_time": 31.28809428215027, "mean_episode_reward": 977.4, "best_episode_reward": 992.0, "step": 391000}
{"episode": 1568.0, "episode_reward": 961.4, "eval_time": 31.296096563339233, "mean_episode_reward": 961.4, "best_episode_reward": 991.0, "step": 392000}
{"episode": 1572.0, "episode_reward": 979.2, "eval_time": 31.29000997543335, "mean_episode_reward": 979.2, "best_episode_reward": 998.0, "step": 393000}
{"episode": 1576.0, "episode_reward": 935.3, "eval_time": 31.27289390563965, "mean_episode_reward": 935.3, "best_episode_reward": 991.0, "step": 394000}
{"episode": 1580.0, "episode_reward": 882.5, "eval_time": 31.16039729118347, "mean_episode_reward": 882.5, "best_episode_reward": 986.0, "step": 395000}
{"episode": 1584.0, "episode_reward": 886.0, "eval_time": 31.29899311065674, "mean_episode_reward": 886.0, "best_episode_reward": 997.0, "step": 396000}
{"episode": 1588.0, "episode_reward": 970.7, "eval_time": 31.248981714248657, "mean_episode_reward": 970.7, "best_episode_reward": 986.0, "step": 397000}
{"episode": 1592.0, "episode_reward": 959.6, "eval_time": 31.299081325531006, "mean_episode_reward": 959.6, "best_episode_reward": 1000.0, "step": 398000}
{"episode": 1596.0, "episode_reward": 977.4, "eval_time": 31.2235906124115, "mean_episode_reward": 977.4, "best_episode_reward": 992.0, "step": 399000}
{"episode": 1600.0, "episode_reward": 980.9, "eval_time": 31.31778883934021, "mean_episode_reward": 980.9, "best_episode_reward": 1000.0, "step": 400000}
{"episode": 1604.0, "episode_reward": 925.6, "eval_time": 31.31001901626587, "mean_episode_reward": 925.6, "best_episode_reward": 1000.0, "step": 401000}
{"episode": 1608.0, "episode_reward": 969.7, "eval_time": 31.241458415985107, "mean_episode_reward": 969.7, "best_episode_reward": 987.0, "step": 402000}
{"episode": 1612.0, "episode_reward": 839.6, "eval_time": 31.31657576560974, "mean_episode_reward": 839.6, "best_episode_reward": 998.0, "step": 403000}
{"episode": 1616.0, "episode_reward": 954.9, "eval_time": 31.160274982452393, "mean_episode_reward": 954.9, "best_episode_reward": 992.0, "step": 404000}
{"episode": 1620.0, "episode_reward": 966.9, "eval_time": 31.3045551776886, "mean_episode_reward": 966.9, "best_episode_reward": 990.0, "step": 405000}
{"episode": 1624.0, "episode_reward": 972.0, "eval_time": 31.30880904197693, "mean_episode_reward": 972.0, "best_episode_reward": 1000.0, "step": 406000}
{"episode": 1628.0, "episode_reward": 980.4, "eval_time": 31.23509669303894, "mean_episode_reward": 980.4, "best_episode_reward": 1000.0, "step": 407000}
{"episode": 1632.0, "episode_reward": 863.1, "eval_time": 31.25629949569702, "mean_episode_reward": 863.1, "best_episode_reward": 994.0, "step": 408000}
{"episode": 1636.0, "episode_reward": 960.1, "eval_time": 31.272130012512207, "mean_episode_reward": 960.1, "best_episode_reward": 990.0, "step": 409000}
{"episode": 1640.0, "episode_reward": 971.8, "eval_time": 31.1182222366333, "mean_episode_reward": 971.8, "best_episode_reward": 994.0, "step": 410000}
{"episode": 1644.0, "episode_reward": 781.9, "eval_time": 31.30165147781372, "mean_episode_reward": 781.9, "best_episode_reward": 1000.0, "step": 411000}
{"episode": 1648.0, "episode_reward": 969.0, "eval_time": 31.22484517097473, "mean_episode_reward": 969.0, "best_episode_reward": 1000.0, "step": 412000}
{"episode": 1652.0, "episode_reward": 879.1, "eval_time": 31.125088214874268, "mean_episode_reward": 879.1, "best_episode_reward": 997.0, "step": 413000}
{"episode": 1656.0, "episode_reward": 872.1, "eval_time": 31.312498331069946, "mean_episode_reward": 872.1, "best_episode_reward": 989.0, "step": 414000}
{"episode": 1660.0, "episode_reward": 915.4, "eval_time": 31.1410391330719, "mean_episode_reward": 915.4, "best_episode_reward": 994.0, "step": 415000}
{"episode": 1664.0, "episode_reward": 777.7, "eval_time": 31.147888898849487, "mean_episode_reward": 777.7, "best_episode_reward": 992.0, "step": 416000}
{"episode": 1668.0, "episode_reward": 973.3, "eval_time": 31.212555646896362, "mean_episode_reward": 973.3, "best_episode_reward": 994.0, "step": 417000}
{"episode": 1672.0, "episode_reward": 972.9, "eval_time": 31.222537755966187, "mean_episode_reward": 972.9, "best_episode_reward": 989.0, "step": 418000}
{"episode": 1676.0, "episode_reward": 977.2, "eval_time": 31.10727286338806, "mean_episode_reward": 977.2, "best_episode_reward": 1000.0, "step": 419000}
{"episode": 1680.0, "episode_reward": 942.2, "eval_time": 31.172587156295776, "mean_episode_reward": 942.2, "best_episode_reward": 991.0, "step": 420000}
{"episode": 1684.0, "episode_reward": 981.0, "eval_time": 31.284093856811523, "mean_episode_reward": 981.0, "best_episode_reward": 1000.0, "step": 421000}
{"episode": 1688.0, "episode_reward": 825.3, "eval_time": 31.178226947784424, "mean_episode_reward": 825.3, "best_episode_reward": 999.0, "step": 422000}
{"episode": 1692.0, "episode_reward": 961.7, "eval_time": 31.304593563079834, "mean_episode_reward": 961.7, "best_episode_reward": 999.0, "step": 423000}
{"episode": 1696.0, "episode_reward": 873.7, "eval_time": 31.23880696296692, "mean_episode_reward": 873.7, "best_episode_reward": 981.0, "step": 424000}
{"episode": 1700.0, "episode_reward": 978.1, "eval_time": 31.17818307876587, "mean_episode_reward": 978.1, "best_episode_reward": 998.0, "step": 425000}
{"episode": 1704.0, "episode_reward": 845.6, "eval_time": 31.284920692443848, "mean_episode_reward": 845.6, "best_episode_reward": 983.0, "step": 426000}
{"episode": 1708.0, "episode_reward": 967.0, "eval_time": 31.348862171173096, "mean_episode_reward": 967.0, "best_episode_reward": 1000.0, "step": 427000}
{"episode": 1712.0, "episode_reward": 984.8, "eval_time": 31.323180675506592, "mean_episode_reward": 984.8, "best_episode_reward": 1000.0, "step": 428000}
{"episode": 1716.0, "episode_reward": 917.6, "eval_time": 31.282347679138184, "mean_episode_reward": 917.6, "best_episode_reward": 985.0, "step": 429000}
{"episode": 1720.0, "episode_reward": 879.0, "eval_time": 31.239256143569946, "mean_episode_reward": 879.0, "best_episode_reward": 993.0, "step": 430000}
{"episode": 1724.0, "episode_reward": 871.4, "eval_time": 31.225740432739258, "mean_episode_reward": 871.4, "best_episode_reward": 987.0, "step": 431000}
{"episode": 1728.0, "episode_reward": 784.7, "eval_time": 31.33046054840088, "mean_episode_reward": 784.7, "best_episode_reward": 1000.0, "step": 432000}
{"episode": 1732.0, "episode_reward": 979.0, "eval_time": 31.193748950958252, "mean_episode_reward": 979.0, "best_episode_reward": 1000.0, "step": 433000}
{"episode": 1736.0, "episode_reward": 980.1, "eval_time": 31.321099281311035, "mean_episode_reward": 980.1, "best_episode_reward": 998.0, "step": 434000}
{"episode": 1740.0, "episode_reward": 883.1, "eval_time": 31.22399067878723, "mean_episode_reward": 883.1, "best_episode_reward": 1000.0, "step": 435000}
{"episode": 1744.0, "episode_reward": 980.0, "eval_time": 31.295093774795532, "mean_episode_reward": 980.0, "best_episode_reward": 1000.0, "step": 436000}
{"episode": 1748.0, "episode_reward": 904.4, "eval_time": 31.292295455932617, "mean_episode_reward": 904.4, "best_episode_reward": 1000.0, "step": 437000}
{"episode": 1752.0, "episode_reward": 969.5, "eval_time": 31.231117725372314, "mean_episode_reward": 969.5, "best_episode_reward": 1000.0, "step": 438000}
{"episode": 1756.0, "episode_reward": 971.1, "eval_time": 31.264593601226807, "mean_episode_reward": 971.1, "best_episode_reward": 986.0, "step": 439000}
{"episode": 1760.0, "episode_reward": 975.1, "eval_time": 31.280739784240723, "mean_episode_reward": 975.1, "best_episode_reward": 992.0, "step": 440000}
{"episode": 1764.0, "episode_reward": 967.8, "eval_time": 31.173028469085693, "mean_episode_reward": 967.8, "best_episode_reward": 1000.0, "step": 441000}
{"episode": 1768.0, "episode_reward": 971.8, "eval_time": 31.22103214263916, "mean_episode_reward": 971.8, "best_episode_reward": 993.0, "step": 442000}
{"episode": 1772.0, "episode_reward": 972.8, "eval_time": 31.254031896591187, "mean_episode_reward": 972.8, "best_episode_reward": 997.0, "step": 443000}
{"episode": 1776.0, "episode_reward": 782.4, "eval_time": 31.183651447296143, "mean_episode_reward": 782.4, "best_episode_reward": 987.0, "step": 444000}
{"episode": 1780.0, "episode_reward": 933.0, "eval_time": 31.182373523712158, "mean_episode_reward": 933.0, "best_episode_reward": 988.0, "step": 445000}
{"episode": 1784.0, "episode_reward": 978.3, "eval_time": 31.14932084083557, "mean_episode_reward": 978.3, "best_episode_reward": 994.0, "step": 446000}
{"episode": 1788.0, "episode_reward": 984.8, "eval_time": 31.201393842697144, "mean_episode_reward": 984.8, "best_episode_reward": 1000.0, "step": 447000}
{"episode": 1792.0, "episode_reward": 970.7, "eval_time": 31.121903896331787, "mean_episode_reward": 970.7, "best_episode_reward": 995.0, "step": 448000}
{"episode": 1796.0, "episode_reward": 961.7, "eval_time": 31.163634061813354, "mean_episode_reward": 961.7, "best_episode_reward": 987.0, "step": 449000}
{"episode": 1800.0, "episode_reward": 919.3, "eval_time": 31.14392113685608, "mean_episode_reward": 919.3, "best_episode_reward": 981.0, "step": 450000}
{"episode": 1804.0, "episode_reward": 982.7, "eval_time": 31.130933046340942, "mean_episode_reward": 982.7, "best_episode_reward": 1000.0, "step": 451000}
{"episode": 1808.0, "episode_reward": 986.8, "eval_time": 31.147144556045532, "mean_episode_reward": 986.8, "best_episode_reward": 1000.0, "step": 452000}
{"episode": 1812.0, "episode_reward": 897.6, "eval_time": 31.18234944343567, "mean_episode_reward": 897.6, "best_episode_reward": 990.0, "step": 453000}
{"episode": 1816.0, "episode_reward": 839.4, "eval_time": 31.07611894607544, "mean_episode_reward": 839.4, "best_episode_reward": 998.0, "step": 454000}
{"episode": 1820.0, "episode_reward": 969.4, "eval_time": 31.03994131088257, "mean_episode_reward": 969.4, "best_episode_reward": 997.0, "step": 455000}
{"episode": 1824.0, "episode_reward": 957.3, "eval_time": 31.175647497177124, "mean_episode_reward": 957.3, "best_episode_reward": 978.0, "step": 456000}
{"episode": 1828.0, "episode_reward": 884.2, "eval_time": 31.12932014465332, "mean_episode_reward": 884.2, "best_episode_reward": 1000.0, "step": 457000}
{"episode": 1832.0, "episode_reward": 809.7, "eval_time": 31.11309552192688, "mean_episode_reward": 809.7, "best_episode_reward": 1000.0, "step": 458000}
{"episode": 1836.0, "episode_reward": 969.8, "eval_time": 31.189878463745117, "mean_episode_reward": 969.8, "best_episode_reward": 1000.0, "step": 459000}
{"episode": 1840.0, "episode_reward": 975.1, "eval_time": 31.155717372894287, "mean_episode_reward": 975.1, "best_episode_reward": 993.0, "step": 460000}
{"episode": 1844.0, "episode_reward": 954.1, "eval_time": 31.117244958877563, "mean_episode_reward": 954.1, "best_episode_reward": 995.0, "step": 461000}
{"episode": 1848.0, "episode_reward": 875.4, "eval_time": 31.053670167922974, "mean_episode_reward": 875.4, "best_episode_reward": 996.0, "step": 462000}
{"episode": 1852.0, "episode_reward": 953.9, "eval_time": 31.02112913131714, "mean_episode_reward": 953.9, "best_episode_reward": 972.0, "step": 463000}
{"episode": 1856.0, "episode_reward": 880.1, "eval_time": 31.104540586471558, "mean_episode_reward": 880.1, "best_episode_reward": 1000.0, "step": 464000}
{"episode": 1860.0, "episode_reward": 961.9, "eval_time": 31.020244598388672, "mean_episode_reward": 961.9, "best_episode_reward": 1000.0, "step": 465000}
{"episode": 1864.0, "episode_reward": 974.0, "eval_time": 31.113706588745117, "mean_episode_reward": 974.0, "best_episode_reward": 990.0, "step": 466000}
{"episode": 1868.0, "episode_reward": 959.2, "eval_time": 31.019606351852417, "mean_episode_reward": 959.2, "best_episode_reward": 1000.0, "step": 467000}
{"episode": 1872.0, "episode_reward": 973.5, "eval_time": 31.164794921875, "mean_episode_reward": 973.5, "best_episode_reward": 992.0, "step": 468000}
{"episode": 1876.0, "episode_reward": 897.4, "eval_time": 31.137585163116455, "mean_episode_reward": 897.4, "best_episode_reward": 992.0, "step": 469000}
{"episode": 1880.0, "episode_reward": 982.2, "eval_time": 31.084118366241455, "mean_episode_reward": 982.2, "best_episode_reward": 999.0, "step": 470000}
{"episode": 1884.0, "episode_reward": 823.8, "eval_time": 31.166539669036865, "mean_episode_reward": 823.8, "best_episode_reward": 987.0, "step": 471000}
{"episode": 1888.0, "episode_reward": 975.2, "eval_time": 31.035924434661865, "mean_episode_reward": 975.2, "best_episode_reward": 1000.0, "step": 472000}
{"episode": 1892.0, "episode_reward": 926.6, "eval_time": 31.071707487106323, "mean_episode_reward": 926.6, "best_episode_reward": 993.0, "step": 473000}
{"episode": 1896.0, "episode_reward": 872.4, "eval_time": 31.162644386291504, "mean_episode_reward": 872.4, "best_episode_reward": 996.0, "step": 474000}
{"episode": 1900.0, "episode_reward": 972.9, "eval_time": 31.145793437957764, "mean_episode_reward": 972.9, "best_episode_reward": 1000.0, "step": 475000}
{"episode": 1904.0, "episode_reward": 861.2, "eval_time": 30.939247131347656, "mean_episode_reward": 861.2, "best_episode_reward": 992.0, "step": 476000}
{"episode": 1908.0, "episode_reward": 914.5, "eval_time": 31.065451622009277, "mean_episode_reward": 914.5, "best_episode_reward": 993.0, "step": 477000}
{"episode": 1912.0, "episode_reward": 983.7, "eval_time": 31.129809141159058, "mean_episode_reward": 983.7, "best_episode_reward": 1000.0, "step": 478000}
{"episode": 1916.0, "episode_reward": 885.7, "eval_time": 31.067254066467285, "mean_episode_reward": 885.7, "best_episode_reward": 986.0, "step": 479000}
{"episode": 1920.0, "episode_reward": 983.1, "eval_time": 30.94345235824585, "mean_episode_reward": 983.1, "best_episode_reward": 997.0, "step": 480000}
{"episode": 1924.0, "episode_reward": 971.5, "eval_time": 31.063733100891113, "mean_episode_reward": 971.5, "best_episode_reward": 988.0, "step": 481000}
{"episode": 1928.0, "episode_reward": 980.7, "eval_time": 30.99730658531189, "mean_episode_reward": 980.7, "best_episode_reward": 999.0, "step": 482000}
{"episode": 1932.0, "episode_reward": 877.7, "eval_time": 30.967642545700073, "mean_episode_reward": 877.7, "best_episode_reward": 996.0, "step": 483000}
{"episode": 1936.0, "episode_reward": 974.7, "eval_time": 31.00683331489563, "mean_episode_reward": 974.7, "best_episode_reward": 998.0, "step": 484000}
{"episode": 1940.0, "episode_reward": 968.9, "eval_time": 31.028497219085693, "mean_episode_reward": 968.9, "best_episode_reward": 1000.0, "step": 485000}
{"episode": 1944.0, "episode_reward": 832.9, "eval_time": 30.995110273361206, "mean_episode_reward": 832.9, "best_episode_reward": 994.0, "step": 486000}
{"episode": 1948.0, "episode_reward": 896.8, "eval_time": 30.96394419670105, "mean_episode_reward": 896.8, "best_episode_reward": 1000.0, "step": 487000}
{"episode": 1952.0, "episode_reward": 888.6, "eval_time": 30.953847885131836, "mean_episode_reward": 888.6, "best_episode_reward": 1000.0, "step": 488000}
{"episode": 1956.0, "episode_reward": 770.2, "eval_time": 31.06207799911499, "mean_episode_reward": 770.2, "best_episode_reward": 1000.0, "step": 489000}
{"episode": 1960.0, "episode_reward": 899.2, "eval_time": 31.068780660629272, "mean_episode_reward": 899.2, "best_episode_reward": 1000.0, "step": 490000}
{"episode": 1964.0, "episode_reward": 975.6, "eval_time": 30.95801568031311, "mean_episode_reward": 975.6, "best_episode_reward": 1000.0, "step": 491000}
{"episode": 1968.0, "episode_reward": 876.8, "eval_time": 30.894545316696167, "mean_episode_reward": 876.8, "best_episode_reward": 989.0, "step": 492000}
{"episode": 1972.0, "episode_reward": 939.0, "eval_time": 30.92211079597473, "mean_episode_reward": 939.0, "best_episode_reward": 1000.0, "step": 493000}
{"episode": 1976.0, "episode_reward": 882.4, "eval_time": 30.92967653274536, "mean_episode_reward": 882.4, "best_episode_reward": 1000.0, "step": 494000}
{"episode": 1980.0, "episode_reward": 971.0, "eval_time": 30.931193828582764, "mean_episode_reward": 971.0, "best_episode_reward": 1000.0, "step": 495000}
{"episode": 1984.0, "episode_reward": 872.1, "eval_time": 30.89557123184204, "mean_episode_reward": 872.1, "best_episode_reward": 996.0, "step": 496000}
{"episode": 1988.0, "episode_reward": 971.3, "eval_time": 30.96768021583557, "mean_episode_reward": 971.3, "best_episode_reward": 991.0, "step": 497000}
{"episode": 1992.0, "episode_reward": 931.4, "eval_time": 30.929017543792725, "mean_episode_reward": 931.4, "best_episode_reward": 988.0, "step": 498000}
{"episode": 1996.0, "episode_reward": 966.8, "eval_time": 30.653634071350098, "mean_episode_reward": 966.8, "best_episode_reward": 986.0, "step": 499000}
