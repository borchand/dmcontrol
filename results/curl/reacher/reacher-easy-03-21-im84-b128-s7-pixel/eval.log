{"episode": 0.0, "episode_reward": 87.7, "eval_time": 31.710365772247314, "mean_episode_reward": 87.7, "best_episode_reward": 412.0, "step": 0}
{"episode": 4.0, "episode_reward": 44.0, "eval_time": 31.163668394088745, "mean_episode_reward": 44.0, "best_episode_reward": 213.0, "step": 1000}
{"episode": 8.0, "episode_reward": 28.3, "eval_time": 31.273536205291748, "mean_episode_reward": 28.3, "best_episode_reward": 92.0, "step": 2000}
{"episode": 12.0, "episode_reward": 155.5, "eval_time": 31.13646125793457, "mean_episode_reward": 155.5, "best_episode_reward": 838.0, "step": 3000}
{"episode": 16.0, "episode_reward": 108.2, "eval_time": 31.232205152511597, "mean_episode_reward": 108.2, "best_episode_reward": 421.0, "step": 4000}
{"episode": 20.0, "episode_reward": 295.6, "eval_time": 31.255459308624268, "mean_episode_reward": 295.6, "best_episode_reward": 1000.0, "step": 5000}
{"episode": 24.0, "episode_reward": 379.3, "eval_time": 31.207279682159424, "mean_episode_reward": 379.3, "best_episode_reward": 976.0, "step": 6000}
{"episode": 28.0, "episode_reward": 198.5, "eval_time": 31.264037132263184, "mean_episode_reward": 198.5, "best_episode_reward": 976.0, "step": 7000}
{"episode": 32.0, "episode_reward": 183.7, "eval_time": 30.880517721176147, "mean_episode_reward": 183.7, "best_episode_reward": 958.0, "step": 8000}
{"episode": 36.0, "episode_reward": 380.8, "eval_time": 31.132320642471313, "mean_episode_reward": 380.8, "best_episode_reward": 993.0, "step": 9000}
{"episode": 40.0, "episode_reward": 304.5, "eval_time": 31.042337656021118, "mean_episode_reward": 304.5, "best_episode_reward": 986.0, "step": 10000}
{"episode": 44.0, "episode_reward": 383.8, "eval_time": 31.21384620666504, "mean_episode_reward": 383.8, "best_episode_reward": 955.0, "step": 11000}
{"episode": 48.0, "episode_reward": 368.8, "eval_time": 31.139326333999634, "mean_episode_reward": 368.8, "best_episode_reward": 968.0, "step": 12000}
{"episode": 52.0, "episode_reward": 282.7, "eval_time": 31.222744464874268, "mean_episode_reward": 282.7, "best_episode_reward": 944.0, "step": 13000}
{"episode": 56.0, "episode_reward": 294.4, "eval_time": 31.31215763092041, "mean_episode_reward": 294.4, "best_episode_reward": 973.0, "step": 14000}
{"episode": 60.0, "episode_reward": 193.8, "eval_time": 31.10830855369568, "mean_episode_reward": 193.8, "best_episode_reward": 956.0, "step": 15000}
{"episode": 64.0, "episode_reward": 376.4, "eval_time": 31.21753978729248, "mean_episode_reward": 376.4, "best_episode_reward": 956.0, "step": 16000}
{"episode": 68.0, "episode_reward": 294.9, "eval_time": 31.249818801879883, "mean_episode_reward": 294.9, "best_episode_reward": 996.0, "step": 17000}
{"episode": 72.0, "episode_reward": 822.1, "eval_time": 31.168210983276367, "mean_episode_reward": 822.1, "best_episode_reward": 982.0, "step": 18000}
{"episode": 76.0, "episode_reward": 477.2, "eval_time": 31.285977363586426, "mean_episode_reward": 477.2, "best_episode_reward": 972.0, "step": 19000}
{"episode": 80.0, "episode_reward": 521.5, "eval_time": 31.073750019073486, "mean_episode_reward": 521.5, "best_episode_reward": 992.0, "step": 20000}
{"episode": 84.0, "episode_reward": 455.2, "eval_time": 31.12538480758667, "mean_episode_reward": 455.2, "best_episode_reward": 962.0, "step": 21000}
{"episode": 88.0, "episode_reward": 855.9, "eval_time": 31.35378646850586, "mean_episode_reward": 855.9, "best_episode_reward": 1000.0, "step": 22000}
{"episode": 92.0, "episode_reward": 755.4, "eval_time": 31.187674045562744, "mean_episode_reward": 755.4, "best_episode_reward": 985.0, "step": 23000}
{"episode": 96.0, "episode_reward": 639.7, "eval_time": 31.173771619796753, "mean_episode_reward": 639.7, "best_episode_reward": 996.0, "step": 24000}
{"episode": 100.0, "episode_reward": 571.1, "eval_time": 31.27721333503723, "mean_episode_reward": 571.1, "best_episode_reward": 967.0, "step": 25000}
{"episode": 104.0, "episode_reward": 666.2, "eval_time": 31.186858654022217, "mean_episode_reward": 666.2, "best_episode_reward": 1000.0, "step": 26000}
{"episode": 108.0, "episode_reward": 668.8, "eval_time": 30.96995973587036, "mean_episode_reward": 668.8, "best_episode_reward": 1000.0, "step": 27000}
{"episode": 112.0, "episode_reward": 708.6, "eval_time": 31.200501680374146, "mean_episode_reward": 708.6, "best_episode_reward": 1000.0, "step": 28000}
{"episode": 116.0, "episode_reward": 840.4, "eval_time": 31.007732152938843, "mean_episode_reward": 840.4, "best_episode_reward": 989.0, "step": 29000}
{"episode": 120.0, "episode_reward": 937.6, "eval_time": 31.176944971084595, "mean_episode_reward": 937.6, "best_episode_reward": 1000.0, "step": 30000}
{"episode": 124.0, "episode_reward": 743.0, "eval_time": 31.10634756088257, "mean_episode_reward": 743.0, "best_episode_reward": 965.0, "step": 31000}
{"episode": 128.0, "episode_reward": 758.0, "eval_time": 30.976688385009766, "mean_episode_reward": 758.0, "best_episode_reward": 986.0, "step": 32000}
{"episode": 132.0, "episode_reward": 665.0, "eval_time": 31.137285709381104, "mean_episode_reward": 665.0, "best_episode_reward": 985.0, "step": 33000}
{"episode": 136.0, "episode_reward": 742.6, "eval_time": 31.217990398406982, "mean_episode_reward": 742.6, "best_episode_reward": 970.0, "step": 34000}
{"episode": 140.0, "episode_reward": 671.8, "eval_time": 31.126376390457153, "mean_episode_reward": 671.8, "best_episode_reward": 989.0, "step": 35000}
{"episode": 144.0, "episode_reward": 471.5, "eval_time": 31.222946643829346, "mean_episode_reward": 471.5, "best_episode_reward": 980.0, "step": 36000}
{"episode": 148.0, "episode_reward": 768.7, "eval_time": 31.172564268112183, "mean_episode_reward": 768.7, "best_episode_reward": 994.0, "step": 37000}
{"episode": 152.0, "episode_reward": 874.8, "eval_time": 31.189481496810913, "mean_episode_reward": 874.8, "best_episode_reward": 995.0, "step": 38000}
{"episode": 156.0, "episode_reward": 778.0, "eval_time": 31.187647819519043, "mean_episode_reward": 778.0, "best_episode_reward": 993.0, "step": 39000}
{"episode": 160.0, "episode_reward": 919.6, "eval_time": 31.124244689941406, "mean_episode_reward": 919.6, "best_episode_reward": 971.0, "step": 40000}
{"episode": 164.0, "episode_reward": 820.0, "eval_time": 31.07930016517639, "mean_episode_reward": 820.0, "best_episode_reward": 992.0, "step": 41000}
{"episode": 168.0, "episode_reward": 764.1, "eval_time": 31.13298726081848, "mean_episode_reward": 764.1, "best_episode_reward": 1000.0, "step": 42000}
{"episode": 172.0, "episode_reward": 754.2, "eval_time": 31.134714365005493, "mean_episode_reward": 754.2, "best_episode_reward": 988.0, "step": 43000}
{"episode": 176.0, "episode_reward": 766.9, "eval_time": 31.1239230632782, "mean_episode_reward": 766.9, "best_episode_reward": 991.0, "step": 44000}
{"episode": 180.0, "episode_reward": 655.8, "eval_time": 31.17153000831604, "mean_episode_reward": 655.8, "best_episode_reward": 986.0, "step": 45000}
{"episode": 184.0, "episode_reward": 848.2, "eval_time": 31.010093688964844, "mean_episode_reward": 848.2, "best_episode_reward": 993.0, "step": 46000}
{"episode": 188.0, "episode_reward": 767.2, "eval_time": 31.097670793533325, "mean_episode_reward": 767.2, "best_episode_reward": 985.0, "step": 47000}
{"episode": 192.0, "episode_reward": 580.7, "eval_time": 31.158963441848755, "mean_episode_reward": 580.7, "best_episode_reward": 1000.0, "step": 48000}
{"episode": 196.0, "episode_reward": 807.7, "eval_time": 31.076469659805298, "mean_episode_reward": 807.7, "best_episode_reward": 985.0, "step": 49000}
{"episode": 200.0, "episode_reward": 865.0, "eval_time": 31.065433979034424, "mean_episode_reward": 865.0, "best_episode_reward": 985.0, "step": 50000}
{"episode": 204.0, "episode_reward": 939.8, "eval_time": 31.043726682662964, "mean_episode_reward": 939.8, "best_episode_reward": 1000.0, "step": 51000}
{"episode": 208.0, "episode_reward": 878.3, "eval_time": 31.08017086982727, "mean_episode_reward": 878.3, "best_episode_reward": 1000.0, "step": 52000}
{"episode": 212.0, "episode_reward": 925.0, "eval_time": 31.252023220062256, "mean_episode_reward": 925.0, "best_episode_reward": 996.0, "step": 53000}
{"episode": 216.0, "episode_reward": 959.1, "eval_time": 31.12090563774109, "mean_episode_reward": 959.1, "best_episode_reward": 1000.0, "step": 54000}
{"episode": 220.0, "episode_reward": 967.0, "eval_time": 31.14436960220337, "mean_episode_reward": 967.0, "best_episode_reward": 996.0, "step": 55000}
{"episode": 224.0, "episode_reward": 776.2, "eval_time": 31.131280422210693, "mean_episode_reward": 776.2, "best_episode_reward": 1000.0, "step": 56000}
{"episode": 228.0, "episode_reward": 968.4, "eval_time": 31.08954954147339, "mean_episode_reward": 968.4, "best_episode_reward": 996.0, "step": 57000}
{"episode": 232.0, "episode_reward": 943.3, "eval_time": 31.246336698532104, "mean_episode_reward": 943.3, "best_episode_reward": 996.0, "step": 58000}
{"episode": 236.0, "episode_reward": 966.0, "eval_time": 31.106585025787354, "mean_episode_reward": 966.0, "best_episode_reward": 989.0, "step": 59000}
{"episode": 240.0, "episode_reward": 875.7, "eval_time": 31.078975439071655, "mean_episode_reward": 875.7, "best_episode_reward": 1000.0, "step": 60000}
{"episode": 244.0, "episode_reward": 976.3, "eval_time": 31.26418900489807, "mean_episode_reward": 976.3, "best_episode_reward": 997.0, "step": 61000}
{"episode": 248.0, "episode_reward": 970.2, "eval_time": 31.07625436782837, "mean_episode_reward": 970.2, "best_episode_reward": 1000.0, "step": 62000}
{"episode": 252.0, "episode_reward": 874.2, "eval_time": 31.02668595314026, "mean_episode_reward": 874.2, "best_episode_reward": 998.0, "step": 63000}
{"episode": 256.0, "episode_reward": 961.1, "eval_time": 31.17932653427124, "mean_episode_reward": 961.1, "best_episode_reward": 999.0, "step": 64000}
{"episode": 260.0, "episode_reward": 778.5, "eval_time": 31.001970052719116, "mean_episode_reward": 778.5, "best_episode_reward": 996.0, "step": 65000}
{"episode": 264.0, "episode_reward": 841.0, "eval_time": 31.089362144470215, "mean_episode_reward": 841.0, "best_episode_reward": 989.0, "step": 66000}
{"episode": 268.0, "episode_reward": 943.8, "eval_time": 31.14652991294861, "mean_episode_reward": 943.8, "best_episode_reward": 994.0, "step": 67000}
{"episode": 272.0, "episode_reward": 961.2, "eval_time": 31.118079900741577, "mean_episode_reward": 961.2, "best_episode_reward": 990.0, "step": 68000}
{"episode": 276.0, "episode_reward": 876.7, "eval_time": 31.2104754447937, "mean_episode_reward": 876.7, "best_episode_reward": 1000.0, "step": 69000}
{"episode": 280.0, "episode_reward": 980.1, "eval_time": 31.138660669326782, "mean_episode_reward": 980.1, "best_episode_reward": 1000.0, "step": 70000}
{"episode": 284.0, "episode_reward": 914.1, "eval_time": 31.13338589668274, "mean_episode_reward": 914.1, "best_episode_reward": 982.0, "step": 71000}
{"episode": 288.0, "episode_reward": 872.1, "eval_time": 31.26041293144226, "mean_episode_reward": 872.1, "best_episode_reward": 988.0, "step": 72000}
{"episode": 292.0, "episode_reward": 864.7, "eval_time": 31.148664712905884, "mean_episode_reward": 864.7, "best_episode_reward": 994.0, "step": 73000}
{"episode": 296.0, "episode_reward": 930.1, "eval_time": 31.116061210632324, "mean_episode_reward": 930.1, "best_episode_reward": 992.0, "step": 74000}
{"episode": 300.0, "episode_reward": 975.4, "eval_time": 31.307081699371338, "mean_episode_reward": 975.4, "best_episode_reward": 995.0, "step": 75000}
{"episode": 304.0, "episode_reward": 961.8, "eval_time": 31.108986377716064, "mean_episode_reward": 961.8, "best_episode_reward": 1000.0, "step": 76000}
{"episode": 308.0, "episode_reward": 972.3, "eval_time": 31.133096933364868, "mean_episode_reward": 972.3, "best_episode_reward": 987.0, "step": 77000}
{"episode": 312.0, "episode_reward": 966.1, "eval_time": 31.372278451919556, "mean_episode_reward": 966.1, "best_episode_reward": 991.0, "step": 78000}
{"episode": 316.0, "episode_reward": 964.4, "eval_time": 31.16508173942566, "mean_episode_reward": 964.4, "best_episode_reward": 996.0, "step": 79000}
{"episode": 320.0, "episode_reward": 966.2, "eval_time": 31.155091285705566, "mean_episode_reward": 966.2, "best_episode_reward": 1000.0, "step": 80000}
{"episode": 324.0, "episode_reward": 956.0, "eval_time": 31.2780818939209, "mean_episode_reward": 956.0, "best_episode_reward": 998.0, "step": 81000}
{"episode": 328.0, "episode_reward": 970.3, "eval_time": 31.221805572509766, "mean_episode_reward": 970.3, "best_episode_reward": 1000.0, "step": 82000}
{"episode": 332.0, "episode_reward": 867.0, "eval_time": 31.23087191581726, "mean_episode_reward": 867.0, "best_episode_reward": 994.0, "step": 83000}
{"episode": 336.0, "episode_reward": 975.0, "eval_time": 31.41770076751709, "mean_episode_reward": 975.0, "best_episode_reward": 996.0, "step": 84000}
{"episode": 340.0, "episode_reward": 880.5, "eval_time": 31.096039295196533, "mean_episode_reward": 880.5, "best_episode_reward": 981.0, "step": 85000}
{"episode": 344.0, "episode_reward": 972.3, "eval_time": 31.198530197143555, "mean_episode_reward": 972.3, "best_episode_reward": 993.0, "step": 86000}
{"episode": 348.0, "episode_reward": 923.7, "eval_time": 31.27865481376648, "mean_episode_reward": 923.7, "best_episode_reward": 979.0, "step": 87000}
{"episode": 352.0, "episode_reward": 962.9, "eval_time": 31.207621097564697, "mean_episode_reward": 962.9, "best_episode_reward": 991.0, "step": 88000}
{"episode": 356.0, "episode_reward": 967.2, "eval_time": 31.381352424621582, "mean_episode_reward": 967.2, "best_episode_reward": 1000.0, "step": 89000}
{"episode": 360.0, "episode_reward": 957.3, "eval_time": 31.3593909740448, "mean_episode_reward": 957.3, "best_episode_reward": 994.0, "step": 90000}
{"episode": 364.0, "episode_reward": 975.8, "eval_time": 31.13718819618225, "mean_episode_reward": 975.8, "best_episode_reward": 996.0, "step": 91000}
{"episode": 368.0, "episode_reward": 972.2, "eval_time": 31.348004579544067, "mean_episode_reward": 972.2, "best_episode_reward": 990.0, "step": 92000}
{"episode": 372.0, "episode_reward": 979.2, "eval_time": 31.27813220024109, "mean_episode_reward": 979.2, "best_episode_reward": 1000.0, "step": 93000}
{"episode": 376.0, "episode_reward": 934.3, "eval_time": 31.305702209472656, "mean_episode_reward": 934.3, "best_episode_reward": 989.0, "step": 94000}
{"episode": 380.0, "episode_reward": 882.2, "eval_time": 31.34182858467102, "mean_episode_reward": 882.2, "best_episode_reward": 994.0, "step": 95000}
{"episode": 384.0, "episode_reward": 966.3, "eval_time": 31.22761869430542, "mean_episode_reward": 966.3, "best_episode_reward": 1000.0, "step": 96000}
{"episode": 388.0, "episode_reward": 883.9, "eval_time": 31.269526720046997, "mean_episode_reward": 883.9, "best_episode_reward": 989.0, "step": 97000}
{"episode": 392.0, "episode_reward": 965.8, "eval_time": 31.364094734191895, "mean_episode_reward": 965.8, "best_episode_reward": 994.0, "step": 98000}
{"episode": 396.0, "episode_reward": 974.9, "eval_time": 31.314379453659058, "mean_episode_reward": 974.9, "best_episode_reward": 1000.0, "step": 99000}
{"episode": 400.0, "episode_reward": 779.4, "eval_time": 31.13511872291565, "mean_episode_reward": 779.4, "best_episode_reward": 984.0, "step": 100000}
{"episode": 404.0, "episode_reward": 970.5, "eval_time": 31.31334900856018, "mean_episode_reward": 970.5, "best_episode_reward": 1000.0, "step": 101000}
{"episode": 408.0, "episode_reward": 978.7, "eval_time": 31.144760131835938, "mean_episode_reward": 978.7, "best_episode_reward": 996.0, "step": 102000}
{"episode": 412.0, "episode_reward": 973.7, "eval_time": 31.260255575180054, "mean_episode_reward": 973.7, "best_episode_reward": 1000.0, "step": 103000}
{"episode": 416.0, "episode_reward": 969.8, "eval_time": 31.242167711257935, "mean_episode_reward": 969.8, "best_episode_reward": 988.0, "step": 104000}
{"episode": 420.0, "episode_reward": 881.5, "eval_time": 31.36908531188965, "mean_episode_reward": 881.5, "best_episode_reward": 990.0, "step": 105000}
{"episode": 424.0, "episode_reward": 971.4, "eval_time": 31.20116400718689, "mean_episode_reward": 971.4, "best_episode_reward": 993.0, "step": 106000}
{"episode": 428.0, "episode_reward": 964.8, "eval_time": 31.29158043861389, "mean_episode_reward": 964.8, "best_episode_reward": 991.0, "step": 107000}
{"episode": 432.0, "episode_reward": 963.7, "eval_time": 31.179569721221924, "mean_episode_reward": 963.7, "best_episode_reward": 1000.0, "step": 108000}
{"episode": 436.0, "episode_reward": 911.1, "eval_time": 31.22235918045044, "mean_episode_reward": 911.1, "best_episode_reward": 1000.0, "step": 109000}
{"episode": 440.0, "episode_reward": 809.9, "eval_time": 31.267505168914795, "mean_episode_reward": 809.9, "best_episode_reward": 996.0, "step": 110000}
{"episode": 444.0, "episode_reward": 981.0, "eval_time": 31.188714027404785, "mean_episode_reward": 981.0, "best_episode_reward": 998.0, "step": 111000}
{"episode": 448.0, "episode_reward": 978.4, "eval_time": 31.189708948135376, "mean_episode_reward": 978.4, "best_episode_reward": 1000.0, "step": 112000}
{"episode": 452.0, "episode_reward": 902.7, "eval_time": 31.120370388031006, "mean_episode_reward": 902.7, "best_episode_reward": 996.0, "step": 113000}
{"episode": 456.0, "episode_reward": 978.1, "eval_time": 31.307971000671387, "mean_episode_reward": 978.1, "best_episode_reward": 996.0, "step": 114000}
{"episode": 460.0, "episode_reward": 974.9, "eval_time": 31.085516691207886, "mean_episode_reward": 974.9, "best_episode_reward": 997.0, "step": 115000}
{"episode": 464.0, "episode_reward": 943.0, "eval_time": 31.302922010421753, "mean_episode_reward": 943.0, "best_episode_reward": 1000.0, "step": 116000}
{"episode": 468.0, "episode_reward": 873.1, "eval_time": 31.15864634513855, "mean_episode_reward": 873.1, "best_episode_reward": 985.0, "step": 117000}
{"episode": 472.0, "episode_reward": 973.7, "eval_time": 31.34929394721985, "mean_episode_reward": 973.7, "best_episode_reward": 998.0, "step": 118000}
{"episode": 476.0, "episode_reward": 976.8, "eval_time": 31.22061824798584, "mean_episode_reward": 976.8, "best_episode_reward": 993.0, "step": 119000}
{"episode": 480.0, "episode_reward": 966.6, "eval_time": 31.095231771469116, "mean_episode_reward": 966.6, "best_episode_reward": 996.0, "step": 120000}
{"episode": 484.0, "episode_reward": 972.0, "eval_time": 31.24174928665161, "mean_episode_reward": 972.0, "best_episode_reward": 1000.0, "step": 121000}
{"episode": 488.0, "episode_reward": 967.6, "eval_time": 31.02311873435974, "mean_episode_reward": 967.6, "best_episode_reward": 988.0, "step": 122000}
{"episode": 492.0, "episode_reward": 972.0, "eval_time": 31.048328399658203, "mean_episode_reward": 972.0, "best_episode_reward": 1000.0, "step": 123000}
{"episode": 496.0, "episode_reward": 982.5, "eval_time": 31.10701608657837, "mean_episode_reward": 982.5, "best_episode_reward": 1000.0, "step": 124000}
{"episode": 500.0, "episode_reward": 972.9, "eval_time": 31.190553665161133, "mean_episode_reward": 972.9, "best_episode_reward": 993.0, "step": 125000}
{"episode": 504.0, "episode_reward": 970.4, "eval_time": 31.067671060562134, "mean_episode_reward": 970.4, "best_episode_reward": 990.0, "step": 126000}
{"episode": 508.0, "episode_reward": 963.5, "eval_time": 31.09055233001709, "mean_episode_reward": 963.5, "best_episode_reward": 981.0, "step": 127000}
{"episode": 512.0, "episode_reward": 961.7, "eval_time": 31.181368112564087, "mean_episode_reward": 961.7, "best_episode_reward": 991.0, "step": 128000}
{"episode": 516.0, "episode_reward": 963.9, "eval_time": 31.141554355621338, "mean_episode_reward": 963.9, "best_episode_reward": 995.0, "step": 129000}
{"episode": 520.0, "episode_reward": 964.9, "eval_time": 31.07709288597107, "mean_episode_reward": 964.9, "best_episode_reward": 986.0, "step": 130000}
{"episode": 524.0, "episode_reward": 956.1, "eval_time": 31.033752918243408, "mean_episode_reward": 956.1, "best_episode_reward": 992.0, "step": 131000}
{"episode": 528.0, "episode_reward": 972.3, "eval_time": 31.089547872543335, "mean_episode_reward": 972.3, "best_episode_reward": 994.0, "step": 132000}
{"episode": 532.0, "episode_reward": 975.4, "eval_time": 31.105844020843506, "mean_episode_reward": 975.4, "best_episode_reward": 997.0, "step": 133000}
{"episode": 536.0, "episode_reward": 964.4, "eval_time": 31.006645441055298, "mean_episode_reward": 964.4, "best_episode_reward": 986.0, "step": 134000}
{"episode": 540.0, "episode_reward": 877.0, "eval_time": 31.081633806228638, "mean_episode_reward": 877.0, "best_episode_reward": 999.0, "step": 135000}
{"episode": 544.0, "episode_reward": 978.7, "eval_time": 31.055326223373413, "mean_episode_reward": 978.7, "best_episode_reward": 995.0, "step": 136000}
{"episode": 548.0, "episode_reward": 976.5, "eval_time": 31.126647233963013, "mean_episode_reward": 976.5, "best_episode_reward": 991.0, "step": 137000}
{"episode": 552.0, "episode_reward": 973.5, "eval_time": 31.11110758781433, "mean_episode_reward": 973.5, "best_episode_reward": 996.0, "step": 138000}
{"episode": 556.0, "episode_reward": 973.9, "eval_time": 31.135940074920654, "mean_episode_reward": 973.9, "best_episode_reward": 989.0, "step": 139000}
{"episode": 560.0, "episode_reward": 957.1, "eval_time": 31.05451464653015, "mean_episode_reward": 957.1, "best_episode_reward": 995.0, "step": 140000}
{"episode": 564.0, "episode_reward": 961.3, "eval_time": 31.16672420501709, "mean_episode_reward": 961.3, "best_episode_reward": 998.0, "step": 141000}
{"episode": 568.0, "episode_reward": 965.9, "eval_time": 31.08251667022705, "mean_episode_reward": 965.9, "best_episode_reward": 989.0, "step": 142000}
{"episode": 572.0, "episode_reward": 974.1, "eval_time": 30.993369340896606, "mean_episode_reward": 974.1, "best_episode_reward": 990.0, "step": 143000}
{"episode": 576.0, "episode_reward": 975.5, "eval_time": 31.08786153793335, "mean_episode_reward": 975.5, "best_episode_reward": 1000.0, "step": 144000}
{"episode": 580.0, "episode_reward": 878.3, "eval_time": 31.10409450531006, "mean_episode_reward": 878.3, "best_episode_reward": 996.0, "step": 145000}
{"episode": 584.0, "episode_reward": 980.6, "eval_time": 30.978084802627563, "mean_episode_reward": 980.6, "best_episode_reward": 997.0, "step": 146000}
{"episode": 588.0, "episode_reward": 968.0, "eval_time": 31.139235734939575, "mean_episode_reward": 968.0, "best_episode_reward": 980.0, "step": 147000}
{"episode": 592.0, "episode_reward": 867.2, "eval_time": 31.062233686447144, "mean_episode_reward": 867.2, "best_episode_reward": 998.0, "step": 148000}
{"episode": 596.0, "episode_reward": 939.5, "eval_time": 30.682135820388794, "mean_episode_reward": 939.5, "best_episode_reward": 998.0, "step": 149000}
{"episode": 600.0, "episode_reward": 966.1, "eval_time": 30.81242036819458, "mean_episode_reward": 966.1, "best_episode_reward": 986.0, "step": 150000}
{"episode": 604.0, "episode_reward": 867.6, "eval_time": 30.70231533050537, "mean_episode_reward": 867.6, "best_episode_reward": 991.0, "step": 151000}
{"episode": 608.0, "episode_reward": 973.4, "eval_time": 30.71390390396118, "mean_episode_reward": 973.4, "best_episode_reward": 995.0, "step": 152000}
{"episode": 612.0, "episode_reward": 974.4, "eval_time": 30.7824764251709, "mean_episode_reward": 974.4, "best_episode_reward": 1000.0, "step": 153000}
{"episode": 616.0, "episode_reward": 975.3, "eval_time": 30.647284030914307, "mean_episode_reward": 975.3, "best_episode_reward": 997.0, "step": 154000}
{"episode": 620.0, "episode_reward": 876.3, "eval_time": 30.662107467651367, "mean_episode_reward": 876.3, "best_episode_reward": 989.0, "step": 155000}
{"episode": 624.0, "episode_reward": 875.9, "eval_time": 30.883667945861816, "mean_episode_reward": 875.9, "best_episode_reward": 1000.0, "step": 156000}
{"episode": 628.0, "episode_reward": 972.0, "eval_time": 30.67984175682068, "mean_episode_reward": 972.0, "best_episode_reward": 995.0, "step": 157000}
{"episode": 632.0, "episode_reward": 977.5, "eval_time": 30.610392570495605, "mean_episode_reward": 977.5, "best_episode_reward": 999.0, "step": 158000}
{"episode": 636.0, "episode_reward": 969.2, "eval_time": 30.814704179763794, "mean_episode_reward": 969.2, "best_episode_reward": 985.0, "step": 159000}
{"episode": 640.0, "episode_reward": 975.6, "eval_time": 30.557530164718628, "mean_episode_reward": 975.6, "best_episode_reward": 988.0, "step": 160000}
{"episode": 644.0, "episode_reward": 965.4, "eval_time": 30.79207444190979, "mean_episode_reward": 965.4, "best_episode_reward": 1000.0, "step": 161000}
{"episode": 648.0, "episode_reward": 973.4, "eval_time": 30.22408175468445, "mean_episode_reward": 973.4, "best_episode_reward": 1000.0, "step": 162000}
{"episode": 652.0, "episode_reward": 922.4, "eval_time": 30.048643350601196, "mean_episode_reward": 922.4, "best_episode_reward": 993.0, "step": 163000}
{"episode": 656.0, "episode_reward": 878.0, "eval_time": 30.209514379501343, "mean_episode_reward": 878.0, "best_episode_reward": 996.0, "step": 164000}
{"episode": 660.0, "episode_reward": 977.6, "eval_time": 30.169928789138794, "mean_episode_reward": 977.6, "best_episode_reward": 1000.0, "step": 165000}
{"episode": 664.0, "episode_reward": 969.9, "eval_time": 30.062000036239624, "mean_episode_reward": 969.9, "best_episode_reward": 996.0, "step": 166000}
{"episode": 668.0, "episode_reward": 981.0, "eval_time": 30.11671805381775, "mean_episode_reward": 981.0, "best_episode_reward": 993.0, "step": 167000}
{"episode": 672.0, "episode_reward": 805.8, "eval_time": 30.213919639587402, "mean_episode_reward": 805.8, "best_episode_reward": 991.0, "step": 168000}
{"episode": 676.0, "episode_reward": 894.1, "eval_time": 30.093353748321533, "mean_episode_reward": 894.1, "best_episode_reward": 1000.0, "step": 169000}
{"episode": 680.0, "episode_reward": 973.4, "eval_time": 30.173255681991577, "mean_episode_reward": 973.4, "best_episode_reward": 994.0, "step": 170000}
{"episode": 684.0, "episode_reward": 980.0, "eval_time": 30.151952266693115, "mean_episode_reward": 980.0, "best_episode_reward": 1000.0, "step": 171000}
{"episode": 688.0, "episode_reward": 970.6, "eval_time": 30.12423324584961, "mean_episode_reward": 970.6, "best_episode_reward": 991.0, "step": 172000}
{"episode": 692.0, "episode_reward": 973.2, "eval_time": 30.260767459869385, "mean_episode_reward": 973.2, "best_episode_reward": 998.0, "step": 173000}
{"episode": 696.0, "episode_reward": 957.0, "eval_time": 30.1532199382782, "mean_episode_reward": 957.0, "best_episode_reward": 1000.0, "step": 174000}
{"episode": 700.0, "episode_reward": 971.4, "eval_time": 30.114853143692017, "mean_episode_reward": 971.4, "best_episode_reward": 1000.0, "step": 175000}
{"episode": 704.0, "episode_reward": 859.9, "eval_time": 30.218322277069092, "mean_episode_reward": 859.9, "best_episode_reward": 986.0, "step": 176000}
{"episode": 708.0, "episode_reward": 971.1, "eval_time": 30.26946759223938, "mean_episode_reward": 971.1, "best_episode_reward": 998.0, "step": 177000}
{"episode": 712.0, "episode_reward": 943.9, "eval_time": 30.123196363449097, "mean_episode_reward": 943.9, "best_episode_reward": 998.0, "step": 178000}
{"episode": 716.0, "episode_reward": 817.5, "eval_time": 30.2717924118042, "mean_episode_reward": 817.5, "best_episode_reward": 984.0, "step": 179000}
{"episode": 720.0, "episode_reward": 973.4, "eval_time": 30.326987743377686, "mean_episode_reward": 973.4, "best_episode_reward": 995.0, "step": 180000}
{"episode": 724.0, "episode_reward": 974.7, "eval_time": 30.21887230873108, "mean_episode_reward": 974.7, "best_episode_reward": 998.0, "step": 181000}
{"episode": 728.0, "episode_reward": 879.3, "eval_time": 30.284705877304077, "mean_episode_reward": 879.3, "best_episode_reward": 1000.0, "step": 182000}
{"episode": 732.0, "episode_reward": 968.4, "eval_time": 30.205064058303833, "mean_episode_reward": 968.4, "best_episode_reward": 1000.0, "step": 183000}
{"episode": 736.0, "episode_reward": 975.9, "eval_time": 30.130195140838623, "mean_episode_reward": 975.9, "best_episode_reward": 1000.0, "step": 184000}
{"episode": 740.0, "episode_reward": 968.6, "eval_time": 30.139241695404053, "mean_episode_reward": 968.6, "best_episode_reward": 990.0, "step": 185000}
{"episode": 744.0, "episode_reward": 968.5, "eval_time": 30.348864555358887, "mean_episode_reward": 968.5, "best_episode_reward": 1000.0, "step": 186000}
{"episode": 748.0, "episode_reward": 972.6, "eval_time": 30.331878900527954, "mean_episode_reward": 972.6, "best_episode_reward": 987.0, "step": 187000}
{"episode": 752.0, "episode_reward": 872.3, "eval_time": 30.34008288383484, "mean_episode_reward": 872.3, "best_episode_reward": 997.0, "step": 188000}
{"episode": 756.0, "episode_reward": 778.8, "eval_time": 30.386058807373047, "mean_episode_reward": 778.8, "best_episode_reward": 1000.0, "step": 189000}
{"episode": 760.0, "episode_reward": 946.6, "eval_time": 30.349863529205322, "mean_episode_reward": 946.6, "best_episode_reward": 998.0, "step": 190000}
{"episode": 764.0, "episode_reward": 972.8, "eval_time": 30.41354775428772, "mean_episode_reward": 972.8, "best_episode_reward": 996.0, "step": 191000}
{"episode": 768.0, "episode_reward": 980.3, "eval_time": 30.308340072631836, "mean_episode_reward": 980.3, "best_episode_reward": 999.0, "step": 192000}
{"episode": 772.0, "episode_reward": 875.2, "eval_time": 30.35359001159668, "mean_episode_reward": 875.2, "best_episode_reward": 989.0, "step": 193000}
{"episode": 776.0, "episode_reward": 942.4, "eval_time": 30.33021640777588, "mean_episode_reward": 942.4, "best_episode_reward": 997.0, "step": 194000}
{"episode": 780.0, "episode_reward": 967.3, "eval_time": 30.351279258728027, "mean_episode_reward": 967.3, "best_episode_reward": 992.0, "step": 195000}
{"episode": 784.0, "episode_reward": 886.4, "eval_time": 30.30670428276062, "mean_episode_reward": 886.4, "best_episode_reward": 975.0, "step": 196000}
{"episode": 788.0, "episode_reward": 977.0, "eval_time": 30.33632802963257, "mean_episode_reward": 977.0, "best_episode_reward": 994.0, "step": 197000}
{"episode": 792.0, "episode_reward": 967.3, "eval_time": 30.26919460296631, "mean_episode_reward": 967.3, "best_episode_reward": 1000.0, "step": 198000}
{"episode": 796.0, "episode_reward": 971.4, "eval_time": 30.242370128631592, "mean_episode_reward": 971.4, "best_episode_reward": 988.0, "step": 199000}
{"episode": 800.0, "episode_reward": 972.2, "eval_time": 30.413922548294067, "mean_episode_reward": 972.2, "best_episode_reward": 992.0, "step": 200000}
{"episode": 804.0, "episode_reward": 971.2, "eval_time": 30.312861919403076, "mean_episode_reward": 971.2, "best_episode_reward": 996.0, "step": 201000}
{"episode": 808.0, "episode_reward": 968.5, "eval_time": 30.273892641067505, "mean_episode_reward": 968.5, "best_episode_reward": 994.0, "step": 202000}
{"episode": 812.0, "episode_reward": 905.2, "eval_time": 30.28674578666687, "mean_episode_reward": 905.2, "best_episode_reward": 988.0, "step": 203000}
{"episode": 816.0, "episode_reward": 892.8, "eval_time": 30.301018953323364, "mean_episode_reward": 892.8, "best_episode_reward": 987.0, "step": 204000}
{"episode": 820.0, "episode_reward": 979.3, "eval_time": 30.10414147377014, "mean_episode_reward": 979.3, "best_episode_reward": 1000.0, "step": 205000}
{"episode": 824.0, "episode_reward": 870.2, "eval_time": 29.745936155319214, "mean_episode_reward": 870.2, "best_episode_reward": 989.0, "step": 206000}
{"episode": 828.0, "episode_reward": 877.2, "eval_time": 29.738182306289673, "mean_episode_reward": 877.2, "best_episode_reward": 998.0, "step": 207000}
{"episode": 832.0, "episode_reward": 792.8, "eval_time": 29.702008724212646, "mean_episode_reward": 792.8, "best_episode_reward": 993.0, "step": 208000}
{"episode": 836.0, "episode_reward": 976.4, "eval_time": 29.793956756591797, "mean_episode_reward": 976.4, "best_episode_reward": 997.0, "step": 209000}
{"episode": 840.0, "episode_reward": 969.5, "eval_time": 29.82395911216736, "mean_episode_reward": 969.5, "best_episode_reward": 998.0, "step": 210000}
{"episode": 844.0, "episode_reward": 968.6, "eval_time": 29.76594877243042, "mean_episode_reward": 968.6, "best_episode_reward": 994.0, "step": 211000}
{"episode": 848.0, "episode_reward": 969.7, "eval_time": 29.708231210708618, "mean_episode_reward": 969.7, "best_episode_reward": 986.0, "step": 212000}
{"episode": 852.0, "episode_reward": 948.4, "eval_time": 29.66077160835266, "mean_episode_reward": 948.4, "best_episode_reward": 994.0, "step": 213000}
{"episode": 856.0, "episode_reward": 906.7, "eval_time": 29.694988012313843, "mean_episode_reward": 906.7, "best_episode_reward": 997.0, "step": 214000}
{"episode": 860.0, "episode_reward": 977.2, "eval_time": 29.704688549041748, "mean_episode_reward": 977.2, "best_episode_reward": 996.0, "step": 215000}
{"episode": 864.0, "episode_reward": 883.7, "eval_time": 29.731711864471436, "mean_episode_reward": 883.7, "best_episode_reward": 996.0, "step": 216000}
{"episode": 868.0, "episode_reward": 978.2, "eval_time": 29.74561595916748, "mean_episode_reward": 978.2, "best_episode_reward": 992.0, "step": 217000}
{"episode": 872.0, "episode_reward": 863.5, "eval_time": 29.706166744232178, "mean_episode_reward": 863.5, "best_episode_reward": 991.0, "step": 218000}
{"episode": 876.0, "episode_reward": 979.0, "eval_time": 29.696442127227783, "mean_episode_reward": 979.0, "best_episode_reward": 996.0, "step": 219000}
{"episode": 880.0, "episode_reward": 874.0, "eval_time": 29.710928678512573, "mean_episode_reward": 874.0, "best_episode_reward": 1000.0, "step": 220000}
{"episode": 884.0, "episode_reward": 973.9, "eval_time": 29.6894850730896, "mean_episode_reward": 973.9, "best_episode_reward": 993.0, "step": 221000}
{"episode": 888.0, "episode_reward": 977.1, "eval_time": 29.6279137134552, "mean_episode_reward": 977.1, "best_episode_reward": 999.0, "step": 222000}
{"episode": 892.0, "episode_reward": 968.4, "eval_time": 29.614922523498535, "mean_episode_reward": 968.4, "best_episode_reward": 988.0, "step": 223000}
{"episode": 896.0, "episode_reward": 974.4, "eval_time": 29.73406457901001, "mean_episode_reward": 974.4, "best_episode_reward": 1000.0, "step": 224000}
{"episode": 900.0, "episode_reward": 980.2, "eval_time": 29.71089220046997, "mean_episode_reward": 980.2, "best_episode_reward": 1000.0, "step": 225000}
{"episode": 904.0, "episode_reward": 970.6, "eval_time": 29.71768355369568, "mean_episode_reward": 970.6, "best_episode_reward": 990.0, "step": 226000}
{"episode": 908.0, "episode_reward": 972.7, "eval_time": 29.705831050872803, "mean_episode_reward": 972.7, "best_episode_reward": 1000.0, "step": 227000}
{"episode": 912.0, "episode_reward": 975.3, "eval_time": 29.74739646911621, "mean_episode_reward": 975.3, "best_episode_reward": 1000.0, "step": 228000}
{"episode": 916.0, "episode_reward": 973.3, "eval_time": 29.730878114700317, "mean_episode_reward": 973.3, "best_episode_reward": 1000.0, "step": 229000}
{"episode": 920.0, "episode_reward": 961.7, "eval_time": 29.66873836517334, "mean_episode_reward": 961.7, "best_episode_reward": 994.0, "step": 230000}
{"episode": 924.0, "episode_reward": 963.0, "eval_time": 29.71228003501892, "mean_episode_reward": 963.0, "best_episode_reward": 987.0, "step": 231000}
{"episode": 928.0, "episode_reward": 979.2, "eval_time": 29.744441509246826, "mean_episode_reward": 979.2, "best_episode_reward": 990.0, "step": 232000}
{"episode": 932.0, "episode_reward": 977.0, "eval_time": 29.752607583999634, "mean_episode_reward": 977.0, "best_episode_reward": 1000.0, "step": 233000}
{"episode": 936.0, "episode_reward": 958.8, "eval_time": 29.727145433425903, "mean_episode_reward": 958.8, "best_episode_reward": 998.0, "step": 234000}
{"episode": 940.0, "episode_reward": 974.9, "eval_time": 29.720889568328857, "mean_episode_reward": 974.9, "best_episode_reward": 1000.0, "step": 235000}
{"episode": 944.0, "episode_reward": 971.6, "eval_time": 29.748537302017212, "mean_episode_reward": 971.6, "best_episode_reward": 992.0, "step": 236000}
{"episode": 948.0, "episode_reward": 942.4, "eval_time": 29.821685552597046, "mean_episode_reward": 942.4, "best_episode_reward": 992.0, "step": 237000}
{"episode": 952.0, "episode_reward": 977.6, "eval_time": 29.677047729492188, "mean_episode_reward": 977.6, "best_episode_reward": 995.0, "step": 238000}
{"episode": 956.0, "episode_reward": 984.3, "eval_time": 29.662721633911133, "mean_episode_reward": 984.3, "best_episode_reward": 1000.0, "step": 239000}
{"episode": 960.0, "episode_reward": 976.8, "eval_time": 29.714727640151978, "mean_episode_reward": 976.8, "best_episode_reward": 995.0, "step": 240000}
{"episode": 964.0, "episode_reward": 879.8, "eval_time": 29.748597383499146, "mean_episode_reward": 879.8, "best_episode_reward": 993.0, "step": 241000}
{"episode": 968.0, "episode_reward": 950.5, "eval_time": 29.71814727783203, "mean_episode_reward": 950.5, "best_episode_reward": 999.0, "step": 242000}
{"episode": 972.0, "episode_reward": 856.1, "eval_time": 29.671897649765015, "mean_episode_reward": 856.1, "best_episode_reward": 989.0, "step": 243000}
{"episode": 976.0, "episode_reward": 881.0, "eval_time": 29.833025693893433, "mean_episode_reward": 881.0, "best_episode_reward": 1000.0, "step": 244000}
{"episode": 980.0, "episode_reward": 872.1, "eval_time": 29.754955768585205, "mean_episode_reward": 872.1, "best_episode_reward": 991.0, "step": 245000}
{"episode": 984.0, "episode_reward": 873.1, "eval_time": 29.680245637893677, "mean_episode_reward": 873.1, "best_episode_reward": 997.0, "step": 246000}
{"episode": 988.0, "episode_reward": 977.8, "eval_time": 29.763925075531006, "mean_episode_reward": 977.8, "best_episode_reward": 1000.0, "step": 247000}
{"episode": 992.0, "episode_reward": 978.2, "eval_time": 29.736780405044556, "mean_episode_reward": 978.2, "best_episode_reward": 997.0, "step": 248000}
{"episode": 996.0, "episode_reward": 975.7, "eval_time": 29.787276029586792, "mean_episode_reward": 975.7, "best_episode_reward": 1000.0, "step": 249000}
{"episode": 1000.0, "episode_reward": 987.6, "eval_time": 29.726617336273193, "mean_episode_reward": 987.6, "best_episode_reward": 1000.0, "step": 250000}
{"episode": 1004.0, "episode_reward": 977.8, "eval_time": 29.778098583221436, "mean_episode_reward": 977.8, "best_episode_reward": 996.0, "step": 251000}
{"episode": 1008.0, "episode_reward": 978.8, "eval_time": 29.794116497039795, "mean_episode_reward": 978.8, "best_episode_reward": 995.0, "step": 252000}
{"episode": 1012.0, "episode_reward": 975.6, "eval_time": 29.730966806411743, "mean_episode_reward": 975.6, "best_episode_reward": 998.0, "step": 253000}
{"episode": 1016.0, "episode_reward": 980.7, "eval_time": 29.777855396270752, "mean_episode_reward": 980.7, "best_episode_reward": 993.0, "step": 254000}
{"episode": 1020.0, "episode_reward": 871.1, "eval_time": 29.81860613822937, "mean_episode_reward": 871.1, "best_episode_reward": 991.0, "step": 255000}
{"episode": 1024.0, "episode_reward": 972.4, "eval_time": 29.77481245994568, "mean_episode_reward": 972.4, "best_episode_reward": 997.0, "step": 256000}
{"episode": 1028.0, "episode_reward": 968.1, "eval_time": 29.759410619735718, "mean_episode_reward": 968.1, "best_episode_reward": 987.0, "step": 257000}
{"episode": 1032.0, "episode_reward": 975.2, "eval_time": 29.786877870559692, "mean_episode_reward": 975.2, "best_episode_reward": 1000.0, "step": 258000}
{"episode": 1036.0, "episode_reward": 965.5, "eval_time": 29.88130807876587, "mean_episode_reward": 965.5, "best_episode_reward": 1000.0, "step": 259000}
{"episode": 1040.0, "episode_reward": 980.5, "eval_time": 29.842220306396484, "mean_episode_reward": 980.5, "best_episode_reward": 996.0, "step": 260000}
{"episode": 1044.0, "episode_reward": 984.6, "eval_time": 29.76010274887085, "mean_episode_reward": 984.6, "best_episode_reward": 1000.0, "step": 261000}
{"episode": 1048.0, "episode_reward": 881.3, "eval_time": 29.792492866516113, "mean_episode_reward": 881.3, "best_episode_reward": 991.0, "step": 262000}
{"episode": 1052.0, "episode_reward": 972.0, "eval_time": 29.769376277923584, "mean_episode_reward": 972.0, "best_episode_reward": 1000.0, "step": 263000}
{"episode": 1056.0, "episode_reward": 969.2, "eval_time": 29.837045431137085, "mean_episode_reward": 969.2, "best_episode_reward": 986.0, "step": 264000}
{"episode": 1060.0, "episode_reward": 881.1, "eval_time": 29.80088782310486, "mean_episode_reward": 881.1, "best_episode_reward": 990.0, "step": 265000}
{"episode": 1064.0, "episode_reward": 868.9, "eval_time": 29.794450283050537, "mean_episode_reward": 868.9, "best_episode_reward": 980.0, "step": 266000}
{"episode": 1068.0, "episode_reward": 976.8, "eval_time": 29.785221576690674, "mean_episode_reward": 976.8, "best_episode_reward": 992.0, "step": 267000}
{"episode": 1072.0, "episode_reward": 969.7, "eval_time": 29.821993112564087, "mean_episode_reward": 969.7, "best_episode_reward": 992.0, "step": 268000}
{"episode": 1076.0, "episode_reward": 969.4, "eval_time": 29.759204387664795, "mean_episode_reward": 969.4, "best_episode_reward": 983.0, "step": 269000}
{"episode": 1080.0, "episode_reward": 975.5, "eval_time": 29.752012014389038, "mean_episode_reward": 975.5, "best_episode_reward": 988.0, "step": 270000}
{"episode": 1084.0, "episode_reward": 970.9, "eval_time": 29.82667064666748, "mean_episode_reward": 970.9, "best_episode_reward": 987.0, "step": 271000}
{"episode": 1088.0, "episode_reward": 974.8, "eval_time": 29.687437772750854, "mean_episode_reward": 974.8, "best_episode_reward": 1000.0, "step": 272000}
{"episode": 1092.0, "episode_reward": 975.5, "eval_time": 29.73098611831665, "mean_episode_reward": 975.5, "best_episode_reward": 996.0, "step": 273000}
{"episode": 1096.0, "episode_reward": 969.7, "eval_time": 29.89092469215393, "mean_episode_reward": 969.7, "best_episode_reward": 998.0, "step": 274000}
{"episode": 1100.0, "episode_reward": 973.8, "eval_time": 29.728752374649048, "mean_episode_reward": 973.8, "best_episode_reward": 995.0, "step": 275000}
{"episode": 1104.0, "episode_reward": 976.8, "eval_time": 29.73940873146057, "mean_episode_reward": 976.8, "best_episode_reward": 999.0, "step": 276000}
{"episode": 1108.0, "episode_reward": 978.6, "eval_time": 29.740736722946167, "mean_episode_reward": 978.6, "best_episode_reward": 995.0, "step": 277000}
{"episode": 1112.0, "episode_reward": 976.6, "eval_time": 29.77414035797119, "mean_episode_reward": 976.6, "best_episode_reward": 994.0, "step": 278000}
{"episode": 1116.0, "episode_reward": 933.9, "eval_time": 29.846495628356934, "mean_episode_reward": 933.9, "best_episode_reward": 1000.0, "step": 279000}
{"episode": 1120.0, "episode_reward": 881.7, "eval_time": 29.76503825187683, "mean_episode_reward": 881.7, "best_episode_reward": 1000.0, "step": 280000}
{"episode": 1124.0, "episode_reward": 976.9, "eval_time": 29.711400985717773, "mean_episode_reward": 976.9, "best_episode_reward": 995.0, "step": 281000}
{"episode": 1128.0, "episode_reward": 977.1, "eval_time": 29.772336959838867, "mean_episode_reward": 977.1, "best_episode_reward": 1000.0, "step": 282000}
{"episode": 1132.0, "episode_reward": 877.6, "eval_time": 29.803605556488037, "mean_episode_reward": 877.6, "best_episode_reward": 992.0, "step": 283000}
{"episode": 1136.0, "episode_reward": 878.2, "eval_time": 29.796188592910767, "mean_episode_reward": 878.2, "best_episode_reward": 991.0, "step": 284000}
{"episode": 1140.0, "episode_reward": 981.4, "eval_time": 29.704419136047363, "mean_episode_reward": 981.4, "best_episode_reward": 1000.0, "step": 285000}
{"episode": 1144.0, "episode_reward": 879.0, "eval_time": 29.804453134536743, "mean_episode_reward": 879.0, "best_episode_reward": 1000.0, "step": 286000}
{"episode": 1148.0, "episode_reward": 979.3, "eval_time": 29.76252031326294, "mean_episode_reward": 979.3, "best_episode_reward": 991.0, "step": 287000}
{"episode": 1152.0, "episode_reward": 870.8, "eval_time": 29.827924966812134, "mean_episode_reward": 870.8, "best_episode_reward": 994.0, "step": 288000}
{"episode": 1156.0, "episode_reward": 980.5, "eval_time": 29.739259958267212, "mean_episode_reward": 980.5, "best_episode_reward": 1000.0, "step": 289000}
{"episode": 1160.0, "episode_reward": 783.7, "eval_time": 29.69663691520691, "mean_episode_reward": 783.7, "best_episode_reward": 1000.0, "step": 290000}
{"episode": 1164.0, "episode_reward": 874.6, "eval_time": 29.734431505203247, "mean_episode_reward": 874.6, "best_episode_reward": 994.0, "step": 291000}
{"episode": 1168.0, "episode_reward": 873.1, "eval_time": 29.713621139526367, "mean_episode_reward": 873.1, "best_episode_reward": 999.0, "step": 292000}
{"episode": 1172.0, "episode_reward": 980.9, "eval_time": 29.730371713638306, "mean_episode_reward": 980.9, "best_episode_reward": 996.0, "step": 293000}
{"episode": 1176.0, "episode_reward": 977.5, "eval_time": 29.729689359664917, "mean_episode_reward": 977.5, "best_episode_reward": 1000.0, "step": 294000}
{"episode": 1180.0, "episode_reward": 976.7, "eval_time": 29.77368927001953, "mean_episode_reward": 976.7, "best_episode_reward": 1000.0, "step": 295000}
{"episode": 1184.0, "episode_reward": 884.1, "eval_time": 29.66849660873413, "mean_episode_reward": 884.1, "best_episode_reward": 996.0, "step": 296000}
{"episode": 1188.0, "episode_reward": 974.8, "eval_time": 29.694480895996094, "mean_episode_reward": 974.8, "best_episode_reward": 999.0, "step": 297000}
{"episode": 1192.0, "episode_reward": 960.7, "eval_time": 30.07129144668579, "mean_episode_reward": 960.7, "best_episode_reward": 982.0, "step": 298000}
{"episode": 1196.0, "episode_reward": 874.2, "eval_time": 29.73210644721985, "mean_episode_reward": 874.2, "best_episode_reward": 1000.0, "step": 299000}
{"episode": 1200.0, "episode_reward": 953.1, "eval_time": 29.773768424987793, "mean_episode_reward": 953.1, "best_episode_reward": 991.0, "step": 300000}
{"episode": 1204.0, "episode_reward": 915.6, "eval_time": 29.752538204193115, "mean_episode_reward": 915.6, "best_episode_reward": 989.0, "step": 301000}
{"episode": 1208.0, "episode_reward": 976.5, "eval_time": 29.822651147842407, "mean_episode_reward": 976.5, "best_episode_reward": 990.0, "step": 302000}
{"episode": 1212.0, "episode_reward": 861.0, "eval_time": 29.69049334526062, "mean_episode_reward": 861.0, "best_episode_reward": 990.0, "step": 303000}
{"episode": 1216.0, "episode_reward": 966.6, "eval_time": 29.721086502075195, "mean_episode_reward": 966.6, "best_episode_reward": 1000.0, "step": 304000}
{"episode": 1220.0, "episode_reward": 920.0, "eval_time": 29.733798503875732, "mean_episode_reward": 920.0, "best_episode_reward": 1000.0, "step": 305000}
{"episode": 1224.0, "episode_reward": 884.5, "eval_time": 29.966670036315918, "mean_episode_reward": 884.5, "best_episode_reward": 997.0, "step": 306000}
{"episode": 1228.0, "episode_reward": 899.6, "eval_time": 29.809991598129272, "mean_episode_reward": 899.6, "best_episode_reward": 998.0, "step": 307000}
{"episode": 1232.0, "episode_reward": 973.3, "eval_time": 29.766196489334106, "mean_episode_reward": 973.3, "best_episode_reward": 997.0, "step": 308000}
{"episode": 1236.0, "episode_reward": 786.7, "eval_time": 29.799872159957886, "mean_episode_reward": 786.7, "best_episode_reward": 1000.0, "step": 309000}
{"episode": 1240.0, "episode_reward": 748.8, "eval_time": 29.675518035888672, "mean_episode_reward": 748.8, "best_episode_reward": 1000.0, "step": 310000}
{"episode": 1244.0, "episode_reward": 882.7, "eval_time": 29.723029136657715, "mean_episode_reward": 882.7, "best_episode_reward": 985.0, "step": 311000}
{"episode": 1248.0, "episode_reward": 977.6, "eval_time": 29.669922828674316, "mean_episode_reward": 977.6, "best_episode_reward": 1000.0, "step": 312000}
{"episode": 1252.0, "episode_reward": 932.0, "eval_time": 29.68965220451355, "mean_episode_reward": 932.0, "best_episode_reward": 998.0, "step": 313000}
{"episode": 1256.0, "episode_reward": 802.0, "eval_time": 29.680420637130737, "mean_episode_reward": 802.0, "best_episode_reward": 990.0, "step": 314000}
{"episode": 1260.0, "episode_reward": 868.9, "eval_time": 29.706820011138916, "mean_episode_reward": 868.9, "best_episode_reward": 998.0, "step": 315000}
{"episode": 1264.0, "episode_reward": 889.7, "eval_time": 29.670570373535156, "mean_episode_reward": 889.7, "best_episode_reward": 994.0, "step": 316000}
{"episode": 1268.0, "episode_reward": 876.2, "eval_time": 29.698097705841064, "mean_episode_reward": 876.2, "best_episode_reward": 997.0, "step": 317000}
{"episode": 1272.0, "episode_reward": 918.7, "eval_time": 29.682816982269287, "mean_episode_reward": 918.7, "best_episode_reward": 998.0, "step": 318000}
{"episode": 1276.0, "episode_reward": 964.8, "eval_time": 29.62220525741577, "mean_episode_reward": 964.8, "best_episode_reward": 989.0, "step": 319000}
{"episode": 1280.0, "episode_reward": 955.6, "eval_time": 29.753240823745728, "mean_episode_reward": 955.6, "best_episode_reward": 1000.0, "step": 320000}
{"episode": 1284.0, "episode_reward": 978.6, "eval_time": 29.653184175491333, "mean_episode_reward": 978.6, "best_episode_reward": 1000.0, "step": 321000}
{"episode": 1288.0, "episode_reward": 966.3, "eval_time": 29.768088579177856, "mean_episode_reward": 966.3, "best_episode_reward": 991.0, "step": 322000}
{"episode": 1292.0, "episode_reward": 920.5, "eval_time": 29.80515694618225, "mean_episode_reward": 920.5, "best_episode_reward": 992.0, "step": 323000}
{"episode": 1296.0, "episode_reward": 825.5, "eval_time": 29.687427282333374, "mean_episode_reward": 825.5, "best_episode_reward": 992.0, "step": 324000}
{"episode": 1300.0, "episode_reward": 952.2, "eval_time": 29.925448656082153, "mean_episode_reward": 952.2, "best_episode_reward": 986.0, "step": 325000}
{"episode": 1304.0, "episode_reward": 870.3, "eval_time": 29.765770435333252, "mean_episode_reward": 870.3, "best_episode_reward": 997.0, "step": 326000}
{"episode": 1308.0, "episode_reward": 839.9, "eval_time": 29.826465606689453, "mean_episode_reward": 839.9, "best_episode_reward": 1000.0, "step": 327000}
{"episode": 1312.0, "episode_reward": 899.7, "eval_time": 29.78414011001587, "mean_episode_reward": 899.7, "best_episode_reward": 989.0, "step": 328000}
{"episode": 1316.0, "episode_reward": 877.2, "eval_time": 29.813718795776367, "mean_episode_reward": 877.2, "best_episode_reward": 1000.0, "step": 329000}
{"episode": 1320.0, "episode_reward": 971.8, "eval_time": 29.913525581359863, "mean_episode_reward": 971.8, "best_episode_reward": 1000.0, "step": 330000}
{"episode": 1324.0, "episode_reward": 979.0, "eval_time": 29.83267593383789, "mean_episode_reward": 979.0, "best_episode_reward": 1000.0, "step": 331000}
{"episode": 1328.0, "episode_reward": 873.7, "eval_time": 29.74475622177124, "mean_episode_reward": 873.7, "best_episode_reward": 988.0, "step": 332000}
{"episode": 1332.0, "episode_reward": 979.3, "eval_time": 29.874887943267822, "mean_episode_reward": 979.3, "best_episode_reward": 990.0, "step": 333000}
{"episode": 1336.0, "episode_reward": 965.9, "eval_time": 29.681134462356567, "mean_episode_reward": 965.9, "best_episode_reward": 998.0, "step": 334000}
{"episode": 1340.0, "episode_reward": 956.2, "eval_time": 29.742887258529663, "mean_episode_reward": 956.2, "best_episode_reward": 1000.0, "step": 335000}
{"episode": 1344.0, "episode_reward": 926.0, "eval_time": 29.866062879562378, "mean_episode_reward": 926.0, "best_episode_reward": 998.0, "step": 336000}
{"episode": 1348.0, "episode_reward": 964.2, "eval_time": 29.789317846298218, "mean_episode_reward": 964.2, "best_episode_reward": 992.0, "step": 337000}
{"episode": 1352.0, "episode_reward": 983.3, "eval_time": 29.75963830947876, "mean_episode_reward": 983.3, "best_episode_reward": 1000.0, "step": 338000}
{"episode": 1356.0, "episode_reward": 829.3, "eval_time": 29.825026273727417, "mean_episode_reward": 829.3, "best_episode_reward": 994.0, "step": 339000}
{"episode": 1360.0, "episode_reward": 970.4, "eval_time": 29.762802124023438, "mean_episode_reward": 970.4, "best_episode_reward": 994.0, "step": 340000}
{"episode": 1364.0, "episode_reward": 781.7, "eval_time": 29.804630041122437, "mean_episode_reward": 781.7, "best_episode_reward": 1000.0, "step": 341000}
{"episode": 1368.0, "episode_reward": 850.6, "eval_time": 29.832293272018433, "mean_episode_reward": 850.6, "best_episode_reward": 997.0, "step": 342000}
{"episode": 1372.0, "episode_reward": 973.1, "eval_time": 29.698457717895508, "mean_episode_reward": 973.1, "best_episode_reward": 994.0, "step": 343000}
{"episode": 1376.0, "episode_reward": 943.7, "eval_time": 29.729947805404663, "mean_episode_reward": 943.7, "best_episode_reward": 996.0, "step": 344000}
{"episode": 1380.0, "episode_reward": 878.5, "eval_time": 29.875661849975586, "mean_episode_reward": 878.5, "best_episode_reward": 993.0, "step": 345000}
{"episode": 1384.0, "episode_reward": 879.9, "eval_time": 29.73959493637085, "mean_episode_reward": 879.9, "best_episode_reward": 1000.0, "step": 346000}
{"episode": 1388.0, "episode_reward": 982.3, "eval_time": 29.699405193328857, "mean_episode_reward": 982.3, "best_episode_reward": 998.0, "step": 347000}
{"episode": 1392.0, "episode_reward": 968.8, "eval_time": 29.76267170906067, "mean_episode_reward": 968.8, "best_episode_reward": 982.0, "step": 348000}
{"episode": 1396.0, "episode_reward": 878.9, "eval_time": 29.78687810897827, "mean_episode_reward": 878.9, "best_episode_reward": 1000.0, "step": 349000}
{"episode": 1400.0, "episode_reward": 950.2, "eval_time": 29.669967651367188, "mean_episode_reward": 950.2, "best_episode_reward": 1000.0, "step": 350000}
{"episode": 1404.0, "episode_reward": 911.2, "eval_time": 29.687548398971558, "mean_episode_reward": 911.2, "best_episode_reward": 989.0, "step": 351000}
{"episode": 1408.0, "episode_reward": 971.3, "eval_time": 29.62177562713623, "mean_episode_reward": 971.3, "best_episode_reward": 996.0, "step": 352000}
{"episode": 1412.0, "episode_reward": 886.6, "eval_time": 29.567628145217896, "mean_episode_reward": 886.6, "best_episode_reward": 997.0, "step": 353000}
{"episode": 1416.0, "episode_reward": 977.9, "eval_time": 29.617223024368286, "mean_episode_reward": 977.9, "best_episode_reward": 997.0, "step": 354000}
{"episode": 1420.0, "episode_reward": 741.8, "eval_time": 29.58449935913086, "mean_episode_reward": 741.8, "best_episode_reward": 990.0, "step": 355000}
{"episode": 1424.0, "episode_reward": 980.6, "eval_time": 29.545154571533203, "mean_episode_reward": 980.6, "best_episode_reward": 999.0, "step": 356000}
{"episode": 1428.0, "episode_reward": 949.6, "eval_time": 29.689147233963013, "mean_episode_reward": 949.6, "best_episode_reward": 998.0, "step": 357000}
{"episode": 1432.0, "episode_reward": 966.5, "eval_time": 29.574385166168213, "mean_episode_reward": 966.5, "best_episode_reward": 988.0, "step": 358000}
{"episode": 1436.0, "episode_reward": 971.0, "eval_time": 29.634007930755615, "mean_episode_reward": 971.0, "best_episode_reward": 1000.0, "step": 359000}
{"episode": 1440.0, "episode_reward": 973.7, "eval_time": 29.687522649765015, "mean_episode_reward": 973.7, "best_episode_reward": 992.0, "step": 360000}
{"episode": 1444.0, "episode_reward": 970.6, "eval_time": 29.651002645492554, "mean_episode_reward": 970.6, "best_episode_reward": 990.0, "step": 361000}
{"episode": 1448.0, "episode_reward": 980.3, "eval_time": 29.969582080841064, "mean_episode_reward": 980.3, "best_episode_reward": 998.0, "step": 362000}
{"episode": 1452.0, "episode_reward": 937.8, "eval_time": 29.539750814437866, "mean_episode_reward": 937.8, "best_episode_reward": 999.0, "step": 363000}
{"episode": 1456.0, "episode_reward": 975.2, "eval_time": 29.712193250656128, "mean_episode_reward": 975.2, "best_episode_reward": 995.0, "step": 364000}
{"episode": 1460.0, "episode_reward": 967.9, "eval_time": 29.692049980163574, "mean_episode_reward": 967.9, "best_episode_reward": 989.0, "step": 365000}
{"episode": 1464.0, "episode_reward": 985.8, "eval_time": 29.62042784690857, "mean_episode_reward": 985.8, "best_episode_reward": 996.0, "step": 366000}
{"episode": 1468.0, "episode_reward": 982.8, "eval_time": 29.67546534538269, "mean_episode_reward": 982.8, "best_episode_reward": 1000.0, "step": 367000}
{"episode": 1472.0, "episode_reward": 880.4, "eval_time": 29.623680114746094, "mean_episode_reward": 880.4, "best_episode_reward": 1000.0, "step": 368000}
{"episode": 1476.0, "episode_reward": 781.0, "eval_time": 29.658514261245728, "mean_episode_reward": 781.0, "best_episode_reward": 992.0, "step": 369000}
{"episode": 1480.0, "episode_reward": 949.3, "eval_time": 29.59812021255493, "mean_episode_reward": 949.3, "best_episode_reward": 995.0, "step": 370000}
{"episode": 1484.0, "episode_reward": 956.4, "eval_time": 29.666423082351685, "mean_episode_reward": 956.4, "best_episode_reward": 1000.0, "step": 371000}
{"episode": 1488.0, "episode_reward": 976.9, "eval_time": 29.584193229675293, "mean_episode_reward": 976.9, "best_episode_reward": 999.0, "step": 372000}
{"episode": 1492.0, "episode_reward": 984.4, "eval_time": 29.65312910079956, "mean_episode_reward": 984.4, "best_episode_reward": 995.0, "step": 373000}
{"episode": 1496.0, "episode_reward": 928.4, "eval_time": 29.52115035057068, "mean_episode_reward": 928.4, "best_episode_reward": 997.0, "step": 374000}
{"episode": 1500.0, "episode_reward": 896.9, "eval_time": 29.695314407348633, "mean_episode_reward": 896.9, "best_episode_reward": 1000.0, "step": 375000}
{"episode": 1504.0, "episode_reward": 969.8, "eval_time": 29.583898067474365, "mean_episode_reward": 969.8, "best_episode_reward": 999.0, "step": 376000}
{"episode": 1508.0, "episode_reward": 981.8, "eval_time": 29.71089506149292, "mean_episode_reward": 981.8, "best_episode_reward": 1000.0, "step": 377000}
{"episode": 1512.0, "episode_reward": 962.7, "eval_time": 29.666452646255493, "mean_episode_reward": 962.7, "best_episode_reward": 1000.0, "step": 378000}
{"episode": 1516.0, "episode_reward": 977.2, "eval_time": 29.662766933441162, "mean_episode_reward": 977.2, "best_episode_reward": 1000.0, "step": 379000}
{"episode": 1520.0, "episode_reward": 883.1, "eval_time": 29.523618936538696, "mean_episode_reward": 883.1, "best_episode_reward": 996.0, "step": 380000}
{"episode": 1524.0, "episode_reward": 974.4, "eval_time": 29.584585428237915, "mean_episode_reward": 974.4, "best_episode_reward": 1000.0, "step": 381000}
{"episode": 1528.0, "episode_reward": 966.1, "eval_time": 29.69796848297119, "mean_episode_reward": 966.1, "best_episode_reward": 1000.0, "step": 382000}
{"episode": 1532.0, "episode_reward": 958.0, "eval_time": 29.638370275497437, "mean_episode_reward": 958.0, "best_episode_reward": 992.0, "step": 383000}
{"episode": 1536.0, "episode_reward": 977.7, "eval_time": 29.690816164016724, "mean_episode_reward": 977.7, "best_episode_reward": 997.0, "step": 384000}
{"episode": 1540.0, "episode_reward": 931.3, "eval_time": 29.719261407852173, "mean_episode_reward": 931.3, "best_episode_reward": 995.0, "step": 385000}
{"episode": 1544.0, "episode_reward": 973.4, "eval_time": 29.638388633728027, "mean_episode_reward": 973.4, "best_episode_reward": 992.0, "step": 386000}
{"episode": 1548.0, "episode_reward": 977.4, "eval_time": 29.54818367958069, "mean_episode_reward": 977.4, "best_episode_reward": 999.0, "step": 387000}
{"episode": 1552.0, "episode_reward": 973.8, "eval_time": 29.59341788291931, "mean_episode_reward": 973.8, "best_episode_reward": 987.0, "step": 388000}
{"episode": 1556.0, "episode_reward": 972.9, "eval_time": 29.66389489173889, "mean_episode_reward": 972.9, "best_episode_reward": 998.0, "step": 389000}
{"episode": 1560.0, "episode_reward": 979.3, "eval_time": 29.47245502471924, "mean_episode_reward": 979.3, "best_episode_reward": 995.0, "step": 390000}
{"episode": 1564.0, "episode_reward": 879.6, "eval_time": 29.67173981666565, "mean_episode_reward": 879.6, "best_episode_reward": 987.0, "step": 391000}
{"episode": 1568.0, "episode_reward": 982.8, "eval_time": 29.648046255111694, "mean_episode_reward": 982.8, "best_episode_reward": 996.0, "step": 392000}
{"episode": 1572.0, "episode_reward": 971.3, "eval_time": 29.58954954147339, "mean_episode_reward": 971.3, "best_episode_reward": 989.0, "step": 393000}
{"episode": 1576.0, "episode_reward": 847.1, "eval_time": 29.668550968170166, "mean_episode_reward": 847.1, "best_episode_reward": 988.0, "step": 394000}
{"episode": 1580.0, "episode_reward": 875.2, "eval_time": 29.660415649414062, "mean_episode_reward": 875.2, "best_episode_reward": 994.0, "step": 395000}
{"episode": 1584.0, "episode_reward": 881.5, "eval_time": 29.551416873931885, "mean_episode_reward": 881.5, "best_episode_reward": 994.0, "step": 396000}
{"episode": 1588.0, "episode_reward": 981.9, "eval_time": 29.617307424545288, "mean_episode_reward": 981.9, "best_episode_reward": 997.0, "step": 397000}
{"episode": 1592.0, "episode_reward": 976.7, "eval_time": 29.669288158416748, "mean_episode_reward": 976.7, "best_episode_reward": 1000.0, "step": 398000}
{"episode": 1596.0, "episode_reward": 980.6, "eval_time": 29.598447799682617, "mean_episode_reward": 980.6, "best_episode_reward": 990.0, "step": 399000}
{"episode": 1600.0, "episode_reward": 977.9, "eval_time": 29.63308572769165, "mean_episode_reward": 977.9, "best_episode_reward": 990.0, "step": 400000}
{"episode": 1604.0, "episode_reward": 881.2, "eval_time": 29.642723083496094, "mean_episode_reward": 881.2, "best_episode_reward": 990.0, "step": 401000}
{"episode": 1608.0, "episode_reward": 977.2, "eval_time": 29.616500854492188, "mean_episode_reward": 977.2, "best_episode_reward": 1000.0, "step": 402000}
{"episode": 1612.0, "episode_reward": 975.7, "eval_time": 29.580459117889404, "mean_episode_reward": 975.7, "best_episode_reward": 996.0, "step": 403000}
{"episode": 1616.0, "episode_reward": 985.4, "eval_time": 29.606656551361084, "mean_episode_reward": 985.4, "best_episode_reward": 1000.0, "step": 404000}
{"episode": 1620.0, "episode_reward": 986.0, "eval_time": 29.584238529205322, "mean_episode_reward": 986.0, "best_episode_reward": 998.0, "step": 405000}
{"episode": 1624.0, "episode_reward": 982.0, "eval_time": 29.702757596969604, "mean_episode_reward": 982.0, "best_episode_reward": 997.0, "step": 406000}
{"episode": 1628.0, "episode_reward": 977.5, "eval_time": 29.611979484558105, "mean_episode_reward": 977.5, "best_episode_reward": 1000.0, "step": 407000}
{"episode": 1632.0, "episode_reward": 974.9, "eval_time": 29.64039659500122, "mean_episode_reward": 974.9, "best_episode_reward": 993.0, "step": 408000}
{"episode": 1636.0, "episode_reward": 972.3, "eval_time": 29.625965118408203, "mean_episode_reward": 972.3, "best_episode_reward": 997.0, "step": 409000}
{"episode": 1640.0, "episode_reward": 883.3, "eval_time": 29.626010179519653, "mean_episode_reward": 883.3, "best_episode_reward": 996.0, "step": 410000}
{"episode": 1644.0, "episode_reward": 881.6, "eval_time": 29.53717017173767, "mean_episode_reward": 881.6, "best_episode_reward": 1000.0, "step": 411000}
{"episode": 1648.0, "episode_reward": 843.2, "eval_time": 29.644901275634766, "mean_episode_reward": 843.2, "best_episode_reward": 999.0, "step": 412000}
{"episode": 1652.0, "episode_reward": 935.1, "eval_time": 29.554085969924927, "mean_episode_reward": 935.1, "best_episode_reward": 991.0, "step": 413000}
{"episode": 1656.0, "episode_reward": 980.7, "eval_time": 29.68008852005005, "mean_episode_reward": 980.7, "best_episode_reward": 1000.0, "step": 414000}
{"episode": 1660.0, "episode_reward": 978.6, "eval_time": 29.76670002937317, "mean_episode_reward": 978.6, "best_episode_reward": 999.0, "step": 415000}
{"episode": 1664.0, "episode_reward": 956.6, "eval_time": 29.526015281677246, "mean_episode_reward": 956.6, "best_episode_reward": 999.0, "step": 416000}
{"episode": 1668.0, "episode_reward": 908.2, "eval_time": 29.604554176330566, "mean_episode_reward": 908.2, "best_episode_reward": 987.0, "step": 417000}
{"episode": 1672.0, "episode_reward": 877.7, "eval_time": 29.616419792175293, "mean_episode_reward": 877.7, "best_episode_reward": 996.0, "step": 418000}
{"episode": 1676.0, "episode_reward": 981.3, "eval_time": 29.558207035064697, "mean_episode_reward": 981.3, "best_episode_reward": 1000.0, "step": 419000}
{"episode": 1680.0, "episode_reward": 979.8, "eval_time": 29.66356897354126, "mean_episode_reward": 979.8, "best_episode_reward": 1000.0, "step": 420000}
{"episode": 1684.0, "episode_reward": 980.7, "eval_time": 29.517946481704712, "mean_episode_reward": 980.7, "best_episode_reward": 1000.0, "step": 421000}
{"episode": 1688.0, "episode_reward": 979.7, "eval_time": 29.5818772315979, "mean_episode_reward": 979.7, "best_episode_reward": 997.0, "step": 422000}
{"episode": 1692.0, "episode_reward": 882.3, "eval_time": 29.55109429359436, "mean_episode_reward": 882.3, "best_episode_reward": 998.0, "step": 423000}
{"episode": 1696.0, "episode_reward": 978.8, "eval_time": 29.60130000114441, "mean_episode_reward": 978.8, "best_episode_reward": 990.0, "step": 424000}
{"episode": 1700.0, "episode_reward": 893.0, "eval_time": 29.602237224578857, "mean_episode_reward": 893.0, "best_episode_reward": 1000.0, "step": 425000}
{"episode": 1704.0, "episode_reward": 978.6, "eval_time": 29.485942602157593, "mean_episode_reward": 978.6, "best_episode_reward": 993.0, "step": 426000}
{"episode": 1708.0, "episode_reward": 975.5, "eval_time": 29.553019046783447, "mean_episode_reward": 975.5, "best_episode_reward": 995.0, "step": 427000}
{"episode": 1712.0, "episode_reward": 939.1, "eval_time": 29.55798363685608, "mean_episode_reward": 939.1, "best_episode_reward": 994.0, "step": 428000}
{"episode": 1716.0, "episode_reward": 972.8, "eval_time": 29.547708749771118, "mean_episode_reward": 972.8, "best_episode_reward": 1000.0, "step": 429000}
{"episode": 1720.0, "episode_reward": 942.8, "eval_time": 29.548287868499756, "mean_episode_reward": 942.8, "best_episode_reward": 994.0, "step": 430000}
{"episode": 1724.0, "episode_reward": 883.4, "eval_time": 29.4960196018219, "mean_episode_reward": 883.4, "best_episode_reward": 994.0, "step": 431000}
{"episode": 1728.0, "episode_reward": 973.8, "eval_time": 29.467291355133057, "mean_episode_reward": 973.8, "best_episode_reward": 993.0, "step": 432000}
{"episode": 1732.0, "episode_reward": 976.5, "eval_time": 29.58857750892639, "mean_episode_reward": 976.5, "best_episode_reward": 996.0, "step": 433000}
{"episode": 1736.0, "episode_reward": 977.7, "eval_time": 29.470014572143555, "mean_episode_reward": 977.7, "best_episode_reward": 992.0, "step": 434000}
{"episode": 1740.0, "episode_reward": 915.9, "eval_time": 29.54557752609253, "mean_episode_reward": 915.9, "best_episode_reward": 999.0, "step": 435000}
{"episode": 1744.0, "episode_reward": 954.5, "eval_time": 29.576297760009766, "mean_episode_reward": 954.5, "best_episode_reward": 993.0, "step": 436000}
{"episode": 1748.0, "episode_reward": 974.1, "eval_time": 29.490439891815186, "mean_episode_reward": 974.1, "best_episode_reward": 990.0, "step": 437000}
{"episode": 1752.0, "episode_reward": 872.8, "eval_time": 29.533686876296997, "mean_episode_reward": 872.8, "best_episode_reward": 995.0, "step": 438000}
{"episode": 1756.0, "episode_reward": 980.2, "eval_time": 29.459012746810913, "mean_episode_reward": 980.2, "best_episode_reward": 996.0, "step": 439000}
{"episode": 1760.0, "episode_reward": 960.3, "eval_time": 29.45928168296814, "mean_episode_reward": 960.3, "best_episode_reward": 993.0, "step": 440000}
{"episode": 1764.0, "episode_reward": 920.6, "eval_time": 29.396349906921387, "mean_episode_reward": 920.6, "best_episode_reward": 993.0, "step": 441000}
{"episode": 1768.0, "episode_reward": 981.4, "eval_time": 29.501195430755615, "mean_episode_reward": 981.4, "best_episode_reward": 1000.0, "step": 442000}
{"episode": 1772.0, "episode_reward": 884.4, "eval_time": 29.493507146835327, "mean_episode_reward": 884.4, "best_episode_reward": 1000.0, "step": 443000}
{"episode": 1776.0, "episode_reward": 882.8, "eval_time": 29.432421922683716, "mean_episode_reward": 882.8, "best_episode_reward": 1000.0, "step": 444000}
{"episode": 1780.0, "episode_reward": 690.7, "eval_time": 29.418540477752686, "mean_episode_reward": 690.7, "best_episode_reward": 997.0, "step": 445000}
{"episode": 1784.0, "episode_reward": 952.8, "eval_time": 29.492581129074097, "mean_episode_reward": 952.8, "best_episode_reward": 984.0, "step": 446000}
{"episode": 1788.0, "episode_reward": 783.5, "eval_time": 29.52105736732483, "mean_episode_reward": 783.5, "best_episode_reward": 985.0, "step": 447000}
{"episode": 1792.0, "episode_reward": 921.2, "eval_time": 29.45149517059326, "mean_episode_reward": 921.2, "best_episode_reward": 1000.0, "step": 448000}
{"episode": 1796.0, "episode_reward": 877.6, "eval_time": 29.375126838684082, "mean_episode_reward": 877.6, "best_episode_reward": 999.0, "step": 449000}
{"episode": 1800.0, "episode_reward": 879.4, "eval_time": 29.45575761795044, "mean_episode_reward": 879.4, "best_episode_reward": 997.0, "step": 450000}
{"episode": 1804.0, "episode_reward": 972.8, "eval_time": 29.53082823753357, "mean_episode_reward": 972.8, "best_episode_reward": 993.0, "step": 451000}
{"episode": 1808.0, "episode_reward": 704.4, "eval_time": 29.59162449836731, "mean_episode_reward": 704.4, "best_episode_reward": 988.0, "step": 452000}
{"episode": 1812.0, "episode_reward": 952.5, "eval_time": 29.476602792739868, "mean_episode_reward": 952.5, "best_episode_reward": 998.0, "step": 453000}
{"episode": 1816.0, "episode_reward": 963.9, "eval_time": 29.545671224594116, "mean_episode_reward": 963.9, "best_episode_reward": 1000.0, "step": 454000}
{"episode": 1820.0, "episode_reward": 916.0, "eval_time": 29.411701679229736, "mean_episode_reward": 916.0, "best_episode_reward": 1000.0, "step": 455000}
{"episode": 1824.0, "episode_reward": 965.8, "eval_time": 29.460314750671387, "mean_episode_reward": 965.8, "best_episode_reward": 995.0, "step": 456000}
{"episode": 1828.0, "episode_reward": 965.4, "eval_time": 29.445366144180298, "mean_episode_reward": 965.4, "best_episode_reward": 992.0, "step": 457000}
{"episode": 1832.0, "episode_reward": 980.2, "eval_time": 29.469416618347168, "mean_episode_reward": 980.2, "best_episode_reward": 1000.0, "step": 458000}
{"episode": 1836.0, "episode_reward": 903.9, "eval_time": 29.483872175216675, "mean_episode_reward": 903.9, "best_episode_reward": 994.0, "step": 459000}
{"episode": 1840.0, "episode_reward": 976.6, "eval_time": 29.504977226257324, "mean_episode_reward": 976.6, "best_episode_reward": 995.0, "step": 460000}
{"episode": 1844.0, "episode_reward": 979.5, "eval_time": 29.426356554031372, "mean_episode_reward": 979.5, "best_episode_reward": 1000.0, "step": 461000}
{"episode": 1848.0, "episode_reward": 875.9, "eval_time": 29.4569673538208, "mean_episode_reward": 875.9, "best_episode_reward": 992.0, "step": 462000}
{"episode": 1852.0, "episode_reward": 969.4, "eval_time": 29.37872886657715, "mean_episode_reward": 969.4, "best_episode_reward": 996.0, "step": 463000}
{"episode": 1856.0, "episode_reward": 859.2, "eval_time": 29.441665172576904, "mean_episode_reward": 859.2, "best_episode_reward": 995.0, "step": 464000}
{"episode": 1860.0, "episode_reward": 783.7, "eval_time": 29.508480072021484, "mean_episode_reward": 783.7, "best_episode_reward": 1000.0, "step": 465000}
{"episode": 1864.0, "episode_reward": 812.5, "eval_time": 29.46914839744568, "mean_episode_reward": 812.5, "best_episode_reward": 997.0, "step": 466000}
{"episode": 1868.0, "episode_reward": 964.3, "eval_time": 29.4498291015625, "mean_episode_reward": 964.3, "best_episode_reward": 992.0, "step": 467000}
{"episode": 1872.0, "episode_reward": 882.3, "eval_time": 29.50457215309143, "mean_episode_reward": 882.3, "best_episode_reward": 996.0, "step": 468000}
{"episode": 1876.0, "episode_reward": 955.2, "eval_time": 29.46390151977539, "mean_episode_reward": 955.2, "best_episode_reward": 999.0, "step": 469000}
{"episode": 1880.0, "episode_reward": 881.8, "eval_time": 29.43782687187195, "mean_episode_reward": 881.8, "best_episode_reward": 998.0, "step": 470000}
{"episode": 1884.0, "episode_reward": 879.2, "eval_time": 29.55716896057129, "mean_episode_reward": 879.2, "best_episode_reward": 996.0, "step": 471000}
{"episode": 1888.0, "episode_reward": 975.2, "eval_time": 29.402629852294922, "mean_episode_reward": 975.2, "best_episode_reward": 1000.0, "step": 472000}
{"episode": 1892.0, "episode_reward": 886.2, "eval_time": 29.45629906654358, "mean_episode_reward": 886.2, "best_episode_reward": 991.0, "step": 473000}
{"episode": 1896.0, "episode_reward": 884.8, "eval_time": 29.815856456756592, "mean_episode_reward": 884.8, "best_episode_reward": 999.0, "step": 474000}
{"episode": 1900.0, "episode_reward": 876.0, "eval_time": 29.873427629470825, "mean_episode_reward": 876.0, "best_episode_reward": 989.0, "step": 475000}
{"episode": 1904.0, "episode_reward": 946.6, "eval_time": 29.891316652297974, "mean_episode_reward": 946.6, "best_episode_reward": 1000.0, "step": 476000}
{"episode": 1908.0, "episode_reward": 969.7, "eval_time": 29.971699953079224, "mean_episode_reward": 969.7, "best_episode_reward": 988.0, "step": 477000}
{"episode": 1912.0, "episode_reward": 985.0, "eval_time": 29.880987644195557, "mean_episode_reward": 985.0, "best_episode_reward": 1000.0, "step": 478000}
{"episode": 1916.0, "episode_reward": 963.6, "eval_time": 29.835664749145508, "mean_episode_reward": 963.6, "best_episode_reward": 995.0, "step": 479000}
{"episode": 1920.0, "episode_reward": 782.5, "eval_time": 30.022659301757812, "mean_episode_reward": 782.5, "best_episode_reward": 991.0, "step": 480000}
{"episode": 1924.0, "episode_reward": 783.6, "eval_time": 29.85802674293518, "mean_episode_reward": 783.6, "best_episode_reward": 994.0, "step": 481000}
{"episode": 1928.0, "episode_reward": 687.6, "eval_time": 29.96779775619507, "mean_episode_reward": 687.6, "best_episode_reward": 1000.0, "step": 482000}
{"episode": 1932.0, "episode_reward": 779.0, "eval_time": 29.999324560165405, "mean_episode_reward": 779.0, "best_episode_reward": 993.0, "step": 483000}
{"episode": 1936.0, "episode_reward": 746.7, "eval_time": 29.88659977912903, "mean_episode_reward": 746.7, "best_episode_reward": 996.0, "step": 484000}
{"episode": 1940.0, "episode_reward": 925.8, "eval_time": 30.035550832748413, "mean_episode_reward": 925.8, "best_episode_reward": 997.0, "step": 485000}
{"episode": 1944.0, "episode_reward": 688.6, "eval_time": 29.995665550231934, "mean_episode_reward": 688.6, "best_episode_reward": 996.0, "step": 486000}
{"episode": 1948.0, "episode_reward": 885.3, "eval_time": 29.879862070083618, "mean_episode_reward": 885.3, "best_episode_reward": 1000.0, "step": 487000}
{"episode": 1952.0, "episode_reward": 971.5, "eval_time": 29.9998836517334, "mean_episode_reward": 971.5, "best_episode_reward": 1000.0, "step": 488000}
{"episode": 1956.0, "episode_reward": 837.5, "eval_time": 29.997377395629883, "mean_episode_reward": 837.5, "best_episode_reward": 1000.0, "step": 489000}
{"episode": 1960.0, "episode_reward": 778.6, "eval_time": 29.989792346954346, "mean_episode_reward": 778.6, "best_episode_reward": 985.0, "step": 490000}
{"episode": 1964.0, "episode_reward": 851.6, "eval_time": 29.9357647895813, "mean_episode_reward": 851.6, "best_episode_reward": 990.0, "step": 491000}
{"episode": 1968.0, "episode_reward": 967.1, "eval_time": 30.016929149627686, "mean_episode_reward": 967.1, "best_episode_reward": 994.0, "step": 492000}
{"episode": 1972.0, "episode_reward": 964.9, "eval_time": 29.965527772903442, "mean_episode_reward": 964.9, "best_episode_reward": 1000.0, "step": 493000}
{"episode": 1976.0, "episode_reward": 979.4, "eval_time": 29.972918033599854, "mean_episode_reward": 979.4, "best_episode_reward": 1000.0, "step": 494000}
{"episode": 1980.0, "episode_reward": 979.7, "eval_time": 30.092095375061035, "mean_episode_reward": 979.7, "best_episode_reward": 1000.0, "step": 495000}
{"episode": 1984.0, "episode_reward": 935.8, "eval_time": 29.956288814544678, "mean_episode_reward": 935.8, "best_episode_reward": 998.0, "step": 496000}
{"episode": 1988.0, "episode_reward": 975.8, "eval_time": 29.959741353988647, "mean_episode_reward": 975.8, "best_episode_reward": 991.0, "step": 497000}
{"episode": 1992.0, "episode_reward": 761.2, "eval_time": 30.086488723754883, "mean_episode_reward": 761.2, "best_episode_reward": 996.0, "step": 498000}
{"episode": 1996.0, "episode_reward": 875.4, "eval_time": 30.082451820373535, "mean_episode_reward": 875.4, "best_episode_reward": 998.0, "step": 499000}
