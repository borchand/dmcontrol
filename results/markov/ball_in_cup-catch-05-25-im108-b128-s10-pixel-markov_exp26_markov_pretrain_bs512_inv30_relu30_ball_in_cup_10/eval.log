{"episode": 0.0, "episode_reward": 0.0, "eval_time": 54.082968950271606, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 0}
{"episode": 4.0, "episode_reward": 198.2, "eval_time": 55.91731142997742, "mean_episode_reward": 198.2, "best_episode_reward": 993.0, "step": 1000}
{"episode": 8.0, "episode_reward": 99.1, "eval_time": 52.62079405784607, "mean_episode_reward": 99.1, "best_episode_reward": 991.0, "step": 2000}
{"episode": 12.0, "episode_reward": 99.8, "eval_time": 47.77894997596741, "mean_episode_reward": 99.8, "best_episode_reward": 998.0, "step": 3000}
{"episode": 16.0, "episode_reward": 99.3, "eval_time": 56.99110651016235, "mean_episode_reward": 99.3, "best_episode_reward": 993.0, "step": 4000}
{"episode": 20.0, "episode_reward": 199.2, "eval_time": 55.76592683792114, "mean_episode_reward": 199.2, "best_episode_reward": 1000.0, "step": 5000}
{"episode": 24.0, "episode_reward": 76.0, "eval_time": 56.248116970062256, "mean_episode_reward": 76.0, "best_episode_reward": 760.0, "step": 6000}
{"episode": 28.0, "episode_reward": 79.0, "eval_time": 62.38381624221802, "mean_episode_reward": 79.0, "best_episode_reward": 790.0, "step": 7000}
{"episode": 32.0, "episode_reward": 0.0, "eval_time": 62.11268591880798, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 8000}
{"episode": 36.0, "episode_reward": 0.0, "eval_time": 60.31434512138367, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 9000}
{"episode": 40.0, "episode_reward": 582.3, "eval_time": 58.604265451431274, "mean_episode_reward": 582.3, "best_episode_reward": 873.0, "step": 10000}
{"episode": 44.0, "episode_reward": 487.8, "eval_time": 65.24583745002747, "mean_episode_reward": 487.8, "best_episode_reward": 893.0, "step": 11000}
{"episode": 48.0, "episode_reward": 872.0, "eval_time": 67.30621027946472, "mean_episode_reward": 872.0, "best_episode_reward": 988.0, "step": 12000}
{"episode": 52.0, "episode_reward": 824.8, "eval_time": 65.12447714805603, "mean_episode_reward": 824.8, "best_episode_reward": 948.0, "step": 13000}
{"episode": 56.0, "episode_reward": 892.0, "eval_time": 64.06066131591797, "mean_episode_reward": 892.0, "best_episode_reward": 996.0, "step": 14000}
{"episode": 60.0, "episode_reward": 816.7, "eval_time": 67.38190007209778, "mean_episode_reward": 816.7, "best_episode_reward": 988.0, "step": 15000}
{"episode": 64.0, "episode_reward": 154.6, "eval_time": 62.778321504592896, "mean_episode_reward": 154.6, "best_episode_reward": 928.0, "step": 16000}
{"episode": 68.0, "episode_reward": 750.2, "eval_time": 60.71235775947571, "mean_episode_reward": 750.2, "best_episode_reward": 990.0, "step": 17000}
{"episode": 72.0, "episode_reward": 842.2, "eval_time": 63.96904540061951, "mean_episode_reward": 842.2, "best_episode_reward": 996.0, "step": 18000}
{"episode": 76.0, "episode_reward": 840.3, "eval_time": 67.80414342880249, "mean_episode_reward": 840.3, "best_episode_reward": 991.0, "step": 19000}
{"episode": 80.0, "episode_reward": 910.7, "eval_time": 62.72443866729736, "mean_episode_reward": 910.7, "best_episode_reward": 990.0, "step": 20000}
{"episode": 84.0, "episode_reward": 898.8, "eval_time": 64.37182307243347, "mean_episode_reward": 898.8, "best_episode_reward": 989.0, "step": 21000}
{"episode": 88.0, "episode_reward": 950.9, "eval_time": 63.108107805252075, "mean_episode_reward": 950.9, "best_episode_reward": 1000.0, "step": 22000}
{"episode": 92.0, "episode_reward": 931.6, "eval_time": 61.725472927093506, "mean_episode_reward": 931.6, "best_episode_reward": 991.0, "step": 23000}
{"episode": 96.0, "episode_reward": 943.8, "eval_time": 62.65938591957092, "mean_episode_reward": 943.8, "best_episode_reward": 991.0, "step": 24000}
{"episode": 100.0, "episode_reward": 930.6, "eval_time": 62.70351600646973, "mean_episode_reward": 930.6, "best_episode_reward": 984.0, "step": 25000}
{"episode": 104.0, "episode_reward": 967.1, "eval_time": 65.10884284973145, "mean_episode_reward": 967.1, "best_episode_reward": 996.0, "step": 26000}
{"episode": 108.0, "episode_reward": 939.6, "eval_time": 62.115642786026, "mean_episode_reward": 939.6, "best_episode_reward": 992.0, "step": 27000}
{"episode": 112.0, "episode_reward": 907.8, "eval_time": 59.14035940170288, "mean_episode_reward": 907.8, "best_episode_reward": 990.0, "step": 28000}
{"episode": 116.0, "episode_reward": 880.3, "eval_time": 59.96070957183838, "mean_episode_reward": 880.3, "best_episode_reward": 988.0, "step": 29000}
{"episode": 120.0, "episode_reward": 930.3, "eval_time": 44.52407646179199, "mean_episode_reward": 930.3, "best_episode_reward": 998.0, "step": 30000}
{"episode": 124.0, "episode_reward": 937.2, "eval_time": 57.615352392196655, "mean_episode_reward": 937.2, "best_episode_reward": 1000.0, "step": 31000}
{"episode": 128.0, "episode_reward": 958.5, "eval_time": 44.84780836105347, "mean_episode_reward": 958.5, "best_episode_reward": 991.0, "step": 32000}
{"episode": 132.0, "episode_reward": 938.4, "eval_time": 70.81466579437256, "mean_episode_reward": 938.4, "best_episode_reward": 989.0, "step": 33000}
{"episode": 136.0, "episode_reward": 933.6, "eval_time": 43.3062310218811, "mean_episode_reward": 933.6, "best_episode_reward": 997.0, "step": 34000}
{"episode": 140.0, "episode_reward": 962.5, "eval_time": 72.38771724700928, "mean_episode_reward": 962.5, "best_episode_reward": 993.0, "step": 35000}
{"episode": 144.0, "episode_reward": 942.8, "eval_time": 45.33645749092102, "mean_episode_reward": 942.8, "best_episode_reward": 990.0, "step": 36000}
{"episode": 148.0, "episode_reward": 938.1, "eval_time": 65.85976028442383, "mean_episode_reward": 938.1, "best_episode_reward": 989.0, "step": 37000}
{"episode": 152.0, "episode_reward": 937.0, "eval_time": 45.18679881095886, "mean_episode_reward": 937.0, "best_episode_reward": 995.0, "step": 38000}
{"episode": 156.0, "episode_reward": 942.0, "eval_time": 77.93237042427063, "mean_episode_reward": 942.0, "best_episode_reward": 991.0, "step": 39000}
{"episode": 160.0, "episode_reward": 947.8, "eval_time": 45.2572226524353, "mean_episode_reward": 947.8, "best_episode_reward": 1000.0, "step": 40000}
{"episode": 164.0, "episode_reward": 961.0, "eval_time": 78.7352647781372, "mean_episode_reward": 961.0, "best_episode_reward": 997.0, "step": 41000}
{"episode": 168.0, "episode_reward": 918.1, "eval_time": 45.70086121559143, "mean_episode_reward": 918.1, "best_episode_reward": 989.0, "step": 42000}
{"episode": 172.0, "episode_reward": 970.7, "eval_time": 82.88898968696594, "mean_episode_reward": 970.7, "best_episode_reward": 1000.0, "step": 43000}
{"episode": 176.0, "episode_reward": 959.5, "eval_time": 46.96505308151245, "mean_episode_reward": 959.5, "best_episode_reward": 989.0, "step": 44000}
{"episode": 180.0, "episode_reward": 958.9, "eval_time": 83.19684386253357, "mean_episode_reward": 958.9, "best_episode_reward": 999.0, "step": 45000}
{"episode": 184.0, "episode_reward": 963.8, "eval_time": 46.70622777938843, "mean_episode_reward": 963.8, "best_episode_reward": 992.0, "step": 46000}
{"episode": 188.0, "episode_reward": 965.7, "eval_time": 80.06286811828613, "mean_episode_reward": 965.7, "best_episode_reward": 991.0, "step": 47000}
{"episode": 192.0, "episode_reward": 971.7, "eval_time": 46.5051109790802, "mean_episode_reward": 971.7, "best_episode_reward": 991.0, "step": 48000}
{"episode": 196.0, "episode_reward": 941.1, "eval_time": 78.26744794845581, "mean_episode_reward": 941.1, "best_episode_reward": 991.0, "step": 49000}
{"episode": 200.0, "episode_reward": 956.8, "eval_time": 47.81504201889038, "mean_episode_reward": 956.8, "best_episode_reward": 991.0, "step": 50000}
{"episode": 204.0, "episode_reward": 960.8, "eval_time": 72.62137579917908, "mean_episode_reward": 960.8, "best_episode_reward": 988.0, "step": 51000}
{"episode": 208.0, "episode_reward": 957.1, "eval_time": 47.67263746261597, "mean_episode_reward": 957.1, "best_episode_reward": 992.0, "step": 52000}
{"episode": 212.0, "episode_reward": 971.3, "eval_time": 68.14433574676514, "mean_episode_reward": 971.3, "best_episode_reward": 990.0, "step": 53000}
{"episode": 216.0, "episode_reward": 960.8, "eval_time": 47.317805767059326, "mean_episode_reward": 960.8, "best_episode_reward": 991.0, "step": 54000}
{"episode": 220.0, "episode_reward": 948.8, "eval_time": 62.34310507774353, "mean_episode_reward": 948.8, "best_episode_reward": 990.0, "step": 55000}
{"episode": 224.0, "episode_reward": 968.0, "eval_time": 48.91305994987488, "mean_episode_reward": 968.0, "best_episode_reward": 1000.0, "step": 56000}
{"episode": 228.0, "episode_reward": 971.8, "eval_time": 60.83500003814697, "mean_episode_reward": 971.8, "best_episode_reward": 999.0, "step": 57000}
{"episode": 232.0, "episode_reward": 960.0, "eval_time": 48.170222997665405, "mean_episode_reward": 960.0, "best_episode_reward": 991.0, "step": 58000}
{"episode": 236.0, "episode_reward": 960.7, "eval_time": 62.279284715652466, "mean_episode_reward": 960.7, "best_episode_reward": 997.0, "step": 59000}
{"episode": 240.0, "episode_reward": 958.6, "eval_time": 47.69007158279419, "mean_episode_reward": 958.6, "best_episode_reward": 1000.0, "step": 60000}
{"episode": 244.0, "episode_reward": 940.5, "eval_time": 67.85271191596985, "mean_episode_reward": 940.5, "best_episode_reward": 989.0, "step": 61000}
{"episode": 248.0, "episode_reward": 961.5, "eval_time": 48.02642560005188, "mean_episode_reward": 961.5, "best_episode_reward": 989.0, "step": 62000}
{"episode": 252.0, "episode_reward": 942.7, "eval_time": 76.64151096343994, "mean_episode_reward": 942.7, "best_episode_reward": 991.0, "step": 63000}
{"episode": 256.0, "episode_reward": 948.7, "eval_time": 47.664607524871826, "mean_episode_reward": 948.7, "best_episode_reward": 990.0, "step": 64000}
{"episode": 260.0, "episode_reward": 970.2, "eval_time": 75.40503358840942, "mean_episode_reward": 970.2, "best_episode_reward": 993.0, "step": 65000}
{"episode": 264.0, "episode_reward": 955.6, "eval_time": 46.910805463790894, "mean_episode_reward": 955.6, "best_episode_reward": 989.0, "step": 66000}
{"episode": 268.0, "episode_reward": 959.6, "eval_time": 73.4757969379425, "mean_episode_reward": 959.6, "best_episode_reward": 990.0, "step": 67000}
{"episode": 272.0, "episode_reward": 956.6, "eval_time": 44.69666767120361, "mean_episode_reward": 956.6, "best_episode_reward": 988.0, "step": 68000}
{"episode": 276.0, "episode_reward": 929.0, "eval_time": 69.19669818878174, "mean_episode_reward": 929.0, "best_episode_reward": 990.0, "step": 69000}
{"episode": 280.0, "episode_reward": 971.4, "eval_time": 44.75126838684082, "mean_episode_reward": 971.4, "best_episode_reward": 999.0, "step": 70000}
{"episode": 284.0, "episode_reward": 955.1, "eval_time": 71.16301250457764, "mean_episode_reward": 955.1, "best_episode_reward": 993.0, "step": 71000}
{"episode": 288.0, "episode_reward": 961.3, "eval_time": 46.738775968551636, "mean_episode_reward": 961.3, "best_episode_reward": 991.0, "step": 72000}
{"episode": 292.0, "episode_reward": 926.7, "eval_time": 73.67799782752991, "mean_episode_reward": 926.7, "best_episode_reward": 993.0, "step": 73000}
{"episode": 296.0, "episode_reward": 959.6, "eval_time": 45.622496128082275, "mean_episode_reward": 959.6, "best_episode_reward": 996.0, "step": 74000}
{"episode": 300.0, "episode_reward": 974.1, "eval_time": 71.80394196510315, "mean_episode_reward": 974.1, "best_episode_reward": 993.0, "step": 75000}
{"episode": 304.0, "episode_reward": 948.5, "eval_time": 44.07881283760071, "mean_episode_reward": 948.5, "best_episode_reward": 990.0, "step": 76000}
{"episode": 308.0, "episode_reward": 939.3, "eval_time": 78.94616651535034, "mean_episode_reward": 939.3, "best_episode_reward": 990.0, "step": 77000}
{"episode": 312.0, "episode_reward": 970.3, "eval_time": 44.65287899971008, "mean_episode_reward": 970.3, "best_episode_reward": 1000.0, "step": 78000}
{"episode": 316.0, "episode_reward": 977.5, "eval_time": 70.35282969474792, "mean_episode_reward": 977.5, "best_episode_reward": 993.0, "step": 79000}
{"episode": 320.0, "episode_reward": 971.7, "eval_time": 43.91567349433899, "mean_episode_reward": 971.7, "best_episode_reward": 990.0, "step": 80000}
{"episode": 324.0, "episode_reward": 961.7, "eval_time": 67.24853277206421, "mean_episode_reward": 961.7, "best_episode_reward": 997.0, "step": 81000}
{"episode": 328.0, "episode_reward": 961.8, "eval_time": 44.43032455444336, "mean_episode_reward": 961.8, "best_episode_reward": 989.0, "step": 82000}
{"episode": 332.0, "episode_reward": 967.1, "eval_time": 70.31366658210754, "mean_episode_reward": 967.1, "best_episode_reward": 998.0, "step": 83000}
{"episode": 336.0, "episode_reward": 969.7, "eval_time": 43.97403430938721, "mean_episode_reward": 969.7, "best_episode_reward": 1000.0, "step": 84000}
{"episode": 340.0, "episode_reward": 961.1, "eval_time": 68.71588134765625, "mean_episode_reward": 961.1, "best_episode_reward": 991.0, "step": 85000}
{"episode": 344.0, "episode_reward": 974.0, "eval_time": 44.46939826011658, "mean_episode_reward": 974.0, "best_episode_reward": 999.0, "step": 86000}
{"episode": 348.0, "episode_reward": 978.1, "eval_time": 77.37653827667236, "mean_episode_reward": 978.1, "best_episode_reward": 991.0, "step": 87000}
{"episode": 352.0, "episode_reward": 964.8, "eval_time": 48.40940618515015, "mean_episode_reward": 964.8, "best_episode_reward": 994.0, "step": 88000}
{"episode": 356.0, "episode_reward": 949.0, "eval_time": 73.48911190032959, "mean_episode_reward": 949.0, "best_episode_reward": 990.0, "step": 89000}
{"episode": 360.0, "episode_reward": 963.7, "eval_time": 50.32524871826172, "mean_episode_reward": 963.7, "best_episode_reward": 989.0, "step": 90000}
{"episode": 364.0, "episode_reward": 962.9, "eval_time": 83.40809106826782, "mean_episode_reward": 962.9, "best_episode_reward": 998.0, "step": 91000}
{"episode": 368.0, "episode_reward": 954.9, "eval_time": 52.99634385108948, "mean_episode_reward": 954.9, "best_episode_reward": 993.0, "step": 92000}
{"episode": 372.0, "episode_reward": 964.2, "eval_time": 84.80820512771606, "mean_episode_reward": 964.2, "best_episode_reward": 1000.0, "step": 93000}
{"episode": 376.0, "episode_reward": 979.5, "eval_time": 53.60532069206238, "mean_episode_reward": 979.5, "best_episode_reward": 996.0, "step": 94000}
{"episode": 380.0, "episode_reward": 966.1, "eval_time": 67.29895830154419, "mean_episode_reward": 966.1, "best_episode_reward": 996.0, "step": 95000}
{"episode": 384.0, "episode_reward": 958.9, "eval_time": 51.97088980674744, "mean_episode_reward": 958.9, "best_episode_reward": 994.0, "step": 96000}
{"episode": 388.0, "episode_reward": 982.4, "eval_time": 59.53853249549866, "mean_episode_reward": 982.4, "best_episode_reward": 1000.0, "step": 97000}
{"episode": 392.0, "episode_reward": 966.9, "eval_time": 52.1146035194397, "mean_episode_reward": 966.9, "best_episode_reward": 992.0, "step": 98000}
{"episode": 396.0, "episode_reward": 954.7, "eval_time": 73.11075925827026, "mean_episode_reward": 954.7, "best_episode_reward": 991.0, "step": 99000}
{"episode": 400.0, "episode_reward": 970.3, "eval_time": 50.37043499946594, "mean_episode_reward": 970.3, "best_episode_reward": 990.0, "step": 100000}
{"episode": 404.0, "episode_reward": 969.8, "eval_time": 69.07044458389282, "mean_episode_reward": 969.8, "best_episode_reward": 999.0, "step": 101000}
{"episode": 408.0, "episode_reward": 974.0, "eval_time": 51.14556908607483, "mean_episode_reward": 974.0, "best_episode_reward": 1000.0, "step": 102000}
{"episode": 412.0, "episode_reward": 968.0, "eval_time": 68.90222072601318, "mean_episode_reward": 968.0, "best_episode_reward": 989.0, "step": 103000}
{"episode": 416.0, "episode_reward": 956.3, "eval_time": 49.21500325202942, "mean_episode_reward": 956.3, "best_episode_reward": 991.0, "step": 104000}
{"episode": 420.0, "episode_reward": 975.4, "eval_time": 60.022348165512085, "mean_episode_reward": 975.4, "best_episode_reward": 992.0, "step": 105000}
{"episode": 424.0, "episode_reward": 961.1, "eval_time": 48.77959680557251, "mean_episode_reward": 961.1, "best_episode_reward": 989.0, "step": 106000}
{"episode": 428.0, "episode_reward": 974.1, "eval_time": 61.323710441589355, "mean_episode_reward": 974.1, "best_episode_reward": 993.0, "step": 107000}
{"episode": 432.0, "episode_reward": 972.2, "eval_time": 46.56919622421265, "mean_episode_reward": 972.2, "best_episode_reward": 991.0, "step": 108000}
{"episode": 436.0, "episode_reward": 968.4, "eval_time": 68.45904207229614, "mean_episode_reward": 968.4, "best_episode_reward": 999.0, "step": 109000}
{"episode": 440.0, "episode_reward": 964.6, "eval_time": 47.59861612319946, "mean_episode_reward": 964.6, "best_episode_reward": 990.0, "step": 110000}
{"episode": 444.0, "episode_reward": 968.3, "eval_time": 58.36529302597046, "mean_episode_reward": 968.3, "best_episode_reward": 992.0, "step": 111000}
{"episode": 448.0, "episode_reward": 959.7, "eval_time": 45.22063207626343, "mean_episode_reward": 959.7, "best_episode_reward": 994.0, "step": 112000}
{"episode": 452.0, "episode_reward": 974.8, "eval_time": 69.67121362686157, "mean_episode_reward": 974.8, "best_episode_reward": 993.0, "step": 113000}
{"episode": 456.0, "episode_reward": 971.2, "eval_time": 46.788453578948975, "mean_episode_reward": 971.2, "best_episode_reward": 993.0, "step": 114000}
{"episode": 460.0, "episode_reward": 973.1, "eval_time": 72.018634557724, "mean_episode_reward": 973.1, "best_episode_reward": 998.0, "step": 115000}
{"episode": 464.0, "episode_reward": 954.6, "eval_time": 45.99989628791809, "mean_episode_reward": 954.6, "best_episode_reward": 988.0, "step": 116000}
{"episode": 468.0, "episode_reward": 956.6, "eval_time": 69.95946478843689, "mean_episode_reward": 956.6, "best_episode_reward": 998.0, "step": 117000}
{"episode": 472.0, "episode_reward": 959.3, "eval_time": 46.998308420181274, "mean_episode_reward": 959.3, "best_episode_reward": 992.0, "step": 118000}
{"episode": 476.0, "episode_reward": 973.1, "eval_time": 73.16304421424866, "mean_episode_reward": 973.1, "best_episode_reward": 991.0, "step": 119000}
{"episode": 480.0, "episode_reward": 961.9, "eval_time": 46.37888264656067, "mean_episode_reward": 961.9, "best_episode_reward": 993.0, "step": 120000}
{"episode": 484.0, "episode_reward": 964.3, "eval_time": 78.27793788909912, "mean_episode_reward": 964.3, "best_episode_reward": 995.0, "step": 121000}
{"episode": 488.0, "episode_reward": 965.9, "eval_time": 45.36883997917175, "mean_episode_reward": 965.9, "best_episode_reward": 991.0, "step": 122000}
{"episode": 492.0, "episode_reward": 963.4, "eval_time": 73.88908791542053, "mean_episode_reward": 963.4, "best_episode_reward": 991.0, "step": 123000}
{"episode": 496.0, "episode_reward": 965.5, "eval_time": 47.68991756439209, "mean_episode_reward": 965.5, "best_episode_reward": 996.0, "step": 124000}
{"episode": 500.0, "episode_reward": 964.8, "eval_time": 71.30082130432129, "mean_episode_reward": 964.8, "best_episode_reward": 991.0, "step": 125000}
{"episode": 504.0, "episode_reward": 956.8, "eval_time": 46.14533042907715, "mean_episode_reward": 956.8, "best_episode_reward": 1000.0, "step": 126000}
{"episode": 508.0, "episode_reward": 948.2, "eval_time": 56.628047943115234, "mean_episode_reward": 948.2, "best_episode_reward": 995.0, "step": 127000}
{"episode": 512.0, "episode_reward": 968.4, "eval_time": 50.96929907798767, "mean_episode_reward": 968.4, "best_episode_reward": 991.0, "step": 128000}
{"episode": 516.0, "episode_reward": 959.0, "eval_time": 63.224326610565186, "mean_episode_reward": 959.0, "best_episode_reward": 990.0, "step": 129000}
{"episode": 520.0, "episode_reward": 971.0, "eval_time": 50.95301127433777, "mean_episode_reward": 971.0, "best_episode_reward": 996.0, "step": 130000}
{"episode": 524.0, "episode_reward": 922.7, "eval_time": 70.02613115310669, "mean_episode_reward": 922.7, "best_episode_reward": 991.0, "step": 131000}
{"episode": 528.0, "episode_reward": 961.0, "eval_time": 49.525877952575684, "mean_episode_reward": 961.0, "best_episode_reward": 991.0, "step": 132000}
{"episode": 532.0, "episode_reward": 962.3, "eval_time": 70.9294981956482, "mean_episode_reward": 962.3, "best_episode_reward": 996.0, "step": 133000}
{"episode": 536.0, "episode_reward": 968.5, "eval_time": 52.396026611328125, "mean_episode_reward": 968.5, "best_episode_reward": 998.0, "step": 134000}
{"episode": 540.0, "episode_reward": 966.3, "eval_time": 68.03649520874023, "mean_episode_reward": 966.3, "best_episode_reward": 990.0, "step": 135000}
{"episode": 544.0, "episode_reward": 977.1, "eval_time": 53.91413950920105, "mean_episode_reward": 977.1, "best_episode_reward": 1000.0, "step": 136000}
{"episode": 548.0, "episode_reward": 972.0, "eval_time": 70.74165534973145, "mean_episode_reward": 972.0, "best_episode_reward": 997.0, "step": 137000}
{"episode": 552.0, "episode_reward": 967.6, "eval_time": 52.87692356109619, "mean_episode_reward": 967.6, "best_episode_reward": 991.0, "step": 138000}
{"episode": 556.0, "episode_reward": 965.3, "eval_time": 60.93616700172424, "mean_episode_reward": 965.3, "best_episode_reward": 992.0, "step": 139000}
{"episode": 560.0, "episode_reward": 969.0, "eval_time": 54.122658491134644, "mean_episode_reward": 969.0, "best_episode_reward": 1000.0, "step": 140000}
{"episode": 564.0, "episode_reward": 968.4, "eval_time": 66.41927862167358, "mean_episode_reward": 968.4, "best_episode_reward": 992.0, "step": 141000}
{"episode": 568.0, "episode_reward": 967.3, "eval_time": 53.141196966171265, "mean_episode_reward": 967.3, "best_episode_reward": 998.0, "step": 142000}
{"episode": 572.0, "episode_reward": 975.8, "eval_time": 64.06354069709778, "mean_episode_reward": 975.8, "best_episode_reward": 996.0, "step": 143000}
{"episode": 576.0, "episode_reward": 962.8, "eval_time": 50.58455991744995, "mean_episode_reward": 962.8, "best_episode_reward": 1000.0, "step": 144000}
{"episode": 580.0, "episode_reward": 967.4, "eval_time": 50.75726389884949, "mean_episode_reward": 967.4, "best_episode_reward": 1000.0, "step": 145000}
{"episode": 584.0, "episode_reward": 978.3, "eval_time": 45.38392353057861, "mean_episode_reward": 978.3, "best_episode_reward": 993.0, "step": 146000}
{"episode": 588.0, "episode_reward": 960.2, "eval_time": 55.08471441268921, "mean_episode_reward": 960.2, "best_episode_reward": 991.0, "step": 147000}
{"episode": 592.0, "episode_reward": 976.1, "eval_time": 47.4446542263031, "mean_episode_reward": 976.1, "best_episode_reward": 992.0, "step": 148000}
{"episode": 596.0, "episode_reward": 976.4, "eval_time": 59.47702598571777, "mean_episode_reward": 976.4, "best_episode_reward": 1000.0, "step": 149000}
{"episode": 600.0, "episode_reward": 956.5, "eval_time": 46.81541442871094, "mean_episode_reward": 956.5, "best_episode_reward": 991.0, "step": 150000}
{"episode": 604.0, "episode_reward": 977.1, "eval_time": 60.48506808280945, "mean_episode_reward": 977.1, "best_episode_reward": 994.0, "step": 151000}
{"episode": 608.0, "episode_reward": 972.3, "eval_time": 48.49940204620361, "mean_episode_reward": 972.3, "best_episode_reward": 991.0, "step": 152000}
{"episode": 612.0, "episode_reward": 972.6, "eval_time": 56.65871477127075, "mean_episode_reward": 972.6, "best_episode_reward": 1000.0, "step": 153000}
{"episode": 616.0, "episode_reward": 959.5, "eval_time": 46.33227491378784, "mean_episode_reward": 959.5, "best_episode_reward": 994.0, "step": 154000}
{"episode": 620.0, "episode_reward": 976.7, "eval_time": 63.87462401390076, "mean_episode_reward": 976.7, "best_episode_reward": 999.0, "step": 155000}
{"episode": 624.0, "episode_reward": 972.6, "eval_time": 46.717780351638794, "mean_episode_reward": 972.6, "best_episode_reward": 995.0, "step": 156000}
{"episode": 628.0, "episode_reward": 974.0, "eval_time": 59.768129110336304, "mean_episode_reward": 974.0, "best_episode_reward": 991.0, "step": 157000}
{"episode": 632.0, "episode_reward": 964.1, "eval_time": 47.635764360427856, "mean_episode_reward": 964.1, "best_episode_reward": 989.0, "step": 158000}
{"episode": 636.0, "episode_reward": 973.9, "eval_time": 53.78846764564514, "mean_episode_reward": 973.9, "best_episode_reward": 992.0, "step": 159000}
{"episode": 640.0, "episode_reward": 967.4, "eval_time": 47.16627645492554, "mean_episode_reward": 967.4, "best_episode_reward": 996.0, "step": 160000}
{"episode": 644.0, "episode_reward": 963.5, "eval_time": 32.15988302230835, "mean_episode_reward": 963.5, "best_episode_reward": 989.0, "step": 161000}
{"episode": 648.0, "episode_reward": 979.0, "eval_time": 31.986023902893066, "mean_episode_reward": 979.0, "best_episode_reward": 996.0, "step": 162000}
{"episode": 652.0, "episode_reward": 972.9, "eval_time": 32.79931044578552, "mean_episode_reward": 972.9, "best_episode_reward": 991.0, "step": 163000}
{"episode": 656.0, "episode_reward": 970.4, "eval_time": 32.38684344291687, "mean_episode_reward": 970.4, "best_episode_reward": 991.0, "step": 164000}
{"episode": 660.0, "episode_reward": 955.8, "eval_time": 32.48914909362793, "mean_episode_reward": 955.8, "best_episode_reward": 997.0, "step": 165000}
{"episode": 664.0, "episode_reward": 967.9, "eval_time": 32.06662893295288, "mean_episode_reward": 967.9, "best_episode_reward": 1000.0, "step": 166000}
{"episode": 668.0, "episode_reward": 973.0, "eval_time": 32.00088405609131, "mean_episode_reward": 973.0, "best_episode_reward": 992.0, "step": 167000}
{"episode": 672.0, "episode_reward": 982.8, "eval_time": 31.9131338596344, "mean_episode_reward": 982.8, "best_episode_reward": 1000.0, "step": 168000}
{"episode": 676.0, "episode_reward": 945.8, "eval_time": 32.078171253204346, "mean_episode_reward": 945.8, "best_episode_reward": 991.0, "step": 169000}
{"episode": 680.0, "episode_reward": 976.9, "eval_time": 32.103854179382324, "mean_episode_reward": 976.9, "best_episode_reward": 1000.0, "step": 170000}
{"episode": 684.0, "episode_reward": 970.8, "eval_time": 32.2584764957428, "mean_episode_reward": 970.8, "best_episode_reward": 997.0, "step": 171000}
{"episode": 688.0, "episode_reward": 966.7, "eval_time": 32.06470012664795, "mean_episode_reward": 966.7, "best_episode_reward": 990.0, "step": 172000}
{"episode": 692.0, "episode_reward": 960.5, "eval_time": 33.874499559402466, "mean_episode_reward": 960.5, "best_episode_reward": 988.0, "step": 173000}
{"episode": 696.0, "episode_reward": 957.3, "eval_time": 33.936054706573486, "mean_episode_reward": 957.3, "best_episode_reward": 991.0, "step": 174000}
{"episode": 700.0, "episode_reward": 950.0, "eval_time": 34.81003260612488, "mean_episode_reward": 950.0, "best_episode_reward": 996.0, "step": 175000}
{"episode": 704.0, "episode_reward": 955.6, "eval_time": 35.65629768371582, "mean_episode_reward": 955.6, "best_episode_reward": 991.0, "step": 176000}
{"episode": 708.0, "episode_reward": 970.1, "eval_time": 35.9515962600708, "mean_episode_reward": 970.1, "best_episode_reward": 991.0, "step": 177000}
{"episode": 712.0, "episode_reward": 968.7, "eval_time": 34.89044189453125, "mean_episode_reward": 968.7, "best_episode_reward": 991.0, "step": 178000}
{"episode": 716.0, "episode_reward": 976.8, "eval_time": 33.8002769947052, "mean_episode_reward": 976.8, "best_episode_reward": 996.0, "step": 179000}
{"episode": 720.0, "episode_reward": 970.5, "eval_time": 33.69925618171692, "mean_episode_reward": 970.5, "best_episode_reward": 1000.0, "step": 180000}
{"episode": 724.0, "episode_reward": 974.5, "eval_time": 33.3825626373291, "mean_episode_reward": 974.5, "best_episode_reward": 997.0, "step": 181000}
{"episode": 728.0, "episode_reward": 959.1, "eval_time": 33.591957569122314, "mean_episode_reward": 959.1, "best_episode_reward": 996.0, "step": 182000}
{"episode": 732.0, "episode_reward": 969.4, "eval_time": 33.76006507873535, "mean_episode_reward": 969.4, "best_episode_reward": 990.0, "step": 183000}
{"episode": 736.0, "episode_reward": 961.6, "eval_time": 31.53370952606201, "mean_episode_reward": 961.6, "best_episode_reward": 996.0, "step": 184000}
{"episode": 740.0, "episode_reward": 960.2, "eval_time": 31.494736671447754, "mean_episode_reward": 960.2, "best_episode_reward": 989.0, "step": 185000}
{"episode": 744.0, "episode_reward": 981.0, "eval_time": 32.16846966743469, "mean_episode_reward": 981.0, "best_episode_reward": 1000.0, "step": 186000}
{"episode": 748.0, "episode_reward": 974.5, "eval_time": 31.57987880706787, "mean_episode_reward": 974.5, "best_episode_reward": 996.0, "step": 187000}
{"episode": 752.0, "episode_reward": 973.8, "eval_time": 31.5886709690094, "mean_episode_reward": 973.8, "best_episode_reward": 997.0, "step": 188000}
{"episode": 756.0, "episode_reward": 962.9, "eval_time": 31.053245067596436, "mean_episode_reward": 962.9, "best_episode_reward": 990.0, "step": 189000}
{"episode": 760.0, "episode_reward": 969.2, "eval_time": 31.608731508255005, "mean_episode_reward": 969.2, "best_episode_reward": 1000.0, "step": 190000}
{"episode": 764.0, "episode_reward": 958.9, "eval_time": 31.26408815383911, "mean_episode_reward": 958.9, "best_episode_reward": 991.0, "step": 191000}
{"episode": 768.0, "episode_reward": 981.2, "eval_time": 31.2918484210968, "mean_episode_reward": 981.2, "best_episode_reward": 997.0, "step": 192000}
{"episode": 772.0, "episode_reward": 963.7, "eval_time": 31.626906633377075, "mean_episode_reward": 963.7, "best_episode_reward": 990.0, "step": 193000}
{"episode": 776.0, "episode_reward": 968.6, "eval_time": 31.361286401748657, "mean_episode_reward": 968.6, "best_episode_reward": 990.0, "step": 194000}
{"episode": 780.0, "episode_reward": 977.2, "eval_time": 31.12443494796753, "mean_episode_reward": 977.2, "best_episode_reward": 1000.0, "step": 195000}
{"episode": 784.0, "episode_reward": 975.3, "eval_time": 31.505016326904297, "mean_episode_reward": 975.3, "best_episode_reward": 996.0, "step": 196000}
{"episode": 788.0, "episode_reward": 966.5, "eval_time": 31.864222764968872, "mean_episode_reward": 966.5, "best_episode_reward": 993.0, "step": 197000}
{"episode": 792.0, "episode_reward": 972.4, "eval_time": 32.284523010253906, "mean_episode_reward": 972.4, "best_episode_reward": 991.0, "step": 198000}
{"episode": 796.0, "episode_reward": 954.8, "eval_time": 32.73421359062195, "mean_episode_reward": 954.8, "best_episode_reward": 987.0, "step": 199000}
{"episode": 800.0, "episode_reward": 966.7, "eval_time": 32.70543599128723, "mean_episode_reward": 966.7, "best_episode_reward": 996.0, "step": 200000}
{"episode": 804.0, "episode_reward": 970.6, "eval_time": 31.980311155319214, "mean_episode_reward": 970.6, "best_episode_reward": 996.0, "step": 201000}
{"episode": 808.0, "episode_reward": 973.5, "eval_time": 32.05531096458435, "mean_episode_reward": 973.5, "best_episode_reward": 990.0, "step": 202000}
{"episode": 812.0, "episode_reward": 972.6, "eval_time": 32.56448745727539, "mean_episode_reward": 972.6, "best_episode_reward": 990.0, "step": 203000}
{"episode": 816.0, "episode_reward": 958.0, "eval_time": 32.86701202392578, "mean_episode_reward": 958.0, "best_episode_reward": 967.0, "step": 204000}
{"episode": 820.0, "episode_reward": 975.0, "eval_time": 33.88784837722778, "mean_episode_reward": 975.0, "best_episode_reward": 999.0, "step": 205000}
{"episode": 824.0, "episode_reward": 969.3, "eval_time": 34.57579207420349, "mean_episode_reward": 969.3, "best_episode_reward": 997.0, "step": 206000}
{"episode": 828.0, "episode_reward": 965.4, "eval_time": 34.70201230049133, "mean_episode_reward": 965.4, "best_episode_reward": 991.0, "step": 207000}
{"episode": 832.0, "episode_reward": 980.3, "eval_time": 34.684041023254395, "mean_episode_reward": 980.3, "best_episode_reward": 998.0, "step": 208000}
{"episode": 836.0, "episode_reward": 963.2, "eval_time": 34.00631833076477, "mean_episode_reward": 963.2, "best_episode_reward": 991.0, "step": 209000}
{"episode": 840.0, "episode_reward": 979.2, "eval_time": 33.692365884780884, "mean_episode_reward": 979.2, "best_episode_reward": 1000.0, "step": 210000}
{"episode": 844.0, "episode_reward": 971.0, "eval_time": 33.787904262542725, "mean_episode_reward": 971.0, "best_episode_reward": 991.0, "step": 211000}
{"episode": 848.0, "episode_reward": 973.2, "eval_time": 33.6863968372345, "mean_episode_reward": 973.2, "best_episode_reward": 1000.0, "step": 212000}
{"episode": 852.0, "episode_reward": 974.9, "eval_time": 32.68584084510803, "mean_episode_reward": 974.9, "best_episode_reward": 994.0, "step": 213000}
{"episode": 856.0, "episode_reward": 975.7, "eval_time": 32.56710910797119, "mean_episode_reward": 975.7, "best_episode_reward": 992.0, "step": 214000}
{"episode": 860.0, "episode_reward": 968.7, "eval_time": 32.71123552322388, "mean_episode_reward": 968.7, "best_episode_reward": 996.0, "step": 215000}
{"episode": 864.0, "episode_reward": 967.0, "eval_time": 31.7258243560791, "mean_episode_reward": 967.0, "best_episode_reward": 989.0, "step": 216000}
{"episode": 868.0, "episode_reward": 965.5, "eval_time": 33.022430181503296, "mean_episode_reward": 965.5, "best_episode_reward": 991.0, "step": 217000}
{"episode": 872.0, "episode_reward": 970.6, "eval_time": 32.69137263298035, "mean_episode_reward": 970.6, "best_episode_reward": 996.0, "step": 218000}
{"episode": 876.0, "episode_reward": 970.6, "eval_time": 32.7940092086792, "mean_episode_reward": 970.6, "best_episode_reward": 992.0, "step": 219000}
{"episode": 880.0, "episode_reward": 958.5, "eval_time": 31.89264416694641, "mean_episode_reward": 958.5, "best_episode_reward": 997.0, "step": 220000}
{"episode": 884.0, "episode_reward": 979.1, "eval_time": 32.227195262908936, "mean_episode_reward": 979.1, "best_episode_reward": 1000.0, "step": 221000}
{"episode": 888.0, "episode_reward": 967.9, "eval_time": 32.34440612792969, "mean_episode_reward": 967.9, "best_episode_reward": 996.0, "step": 222000}
{"episode": 892.0, "episode_reward": 963.7, "eval_time": 31.991711854934692, "mean_episode_reward": 963.7, "best_episode_reward": 996.0, "step": 223000}
{"episode": 896.0, "episode_reward": 979.1, "eval_time": 33.059027433395386, "mean_episode_reward": 979.1, "best_episode_reward": 1000.0, "step": 224000}
{"episode": 900.0, "episode_reward": 931.3, "eval_time": 31.93057632446289, "mean_episode_reward": 931.3, "best_episode_reward": 997.0, "step": 225000}
{"episode": 904.0, "episode_reward": 973.4, "eval_time": 31.833332538604736, "mean_episode_reward": 973.4, "best_episode_reward": 997.0, "step": 226000}
{"episode": 908.0, "episode_reward": 979.5, "eval_time": 33.18852233886719, "mean_episode_reward": 979.5, "best_episode_reward": 997.0, "step": 227000}
{"episode": 912.0, "episode_reward": 974.6, "eval_time": 32.179863929748535, "mean_episode_reward": 974.6, "best_episode_reward": 995.0, "step": 228000}
{"episode": 916.0, "episode_reward": 974.2, "eval_time": 32.37792205810547, "mean_episode_reward": 974.2, "best_episode_reward": 992.0, "step": 229000}
{"episode": 920.0, "episode_reward": 972.6, "eval_time": 32.65191578865051, "mean_episode_reward": 972.6, "best_episode_reward": 992.0, "step": 230000}
{"episode": 924.0, "episode_reward": 973.0, "eval_time": 32.65260863304138, "mean_episode_reward": 973.0, "best_episode_reward": 990.0, "step": 231000}
{"episode": 928.0, "episode_reward": 979.5, "eval_time": 32.26307988166809, "mean_episode_reward": 979.5, "best_episode_reward": 1000.0, "step": 232000}
{"episode": 932.0, "episode_reward": 972.8, "eval_time": 32.85562300682068, "mean_episode_reward": 972.8, "best_episode_reward": 996.0, "step": 233000}
{"episode": 936.0, "episode_reward": 961.6, "eval_time": 32.462095499038696, "mean_episode_reward": 961.6, "best_episode_reward": 991.0, "step": 234000}
{"episode": 940.0, "episode_reward": 976.3, "eval_time": 31.96048069000244, "mean_episode_reward": 976.3, "best_episode_reward": 997.0, "step": 235000}
{"episode": 944.0, "episode_reward": 954.4, "eval_time": 32.061949014663696, "mean_episode_reward": 954.4, "best_episode_reward": 991.0, "step": 236000}
{"episode": 948.0, "episode_reward": 959.1, "eval_time": 32.15614342689514, "mean_episode_reward": 959.1, "best_episode_reward": 992.0, "step": 237000}
{"episode": 952.0, "episode_reward": 960.0, "eval_time": 32.30170440673828, "mean_episode_reward": 960.0, "best_episode_reward": 998.0, "step": 238000}
{"episode": 956.0, "episode_reward": 969.7, "eval_time": 32.94209098815918, "mean_episode_reward": 969.7, "best_episode_reward": 1000.0, "step": 239000}
{"episode": 960.0, "episode_reward": 959.8, "eval_time": 33.360729455947876, "mean_episode_reward": 959.8, "best_episode_reward": 991.0, "step": 240000}
{"episode": 964.0, "episode_reward": 976.9, "eval_time": 33.19246435165405, "mean_episode_reward": 976.9, "best_episode_reward": 1000.0, "step": 241000}
{"episode": 968.0, "episode_reward": 966.5, "eval_time": 33.08205556869507, "mean_episode_reward": 966.5, "best_episode_reward": 996.0, "step": 242000}
{"episode": 972.0, "episode_reward": 960.9, "eval_time": 33.54041838645935, "mean_episode_reward": 960.9, "best_episode_reward": 1000.0, "step": 243000}
{"episode": 976.0, "episode_reward": 972.5, "eval_time": 34.144667625427246, "mean_episode_reward": 972.5, "best_episode_reward": 995.0, "step": 244000}
{"episode": 980.0, "episode_reward": 971.9, "eval_time": 34.69581174850464, "mean_episode_reward": 971.9, "best_episode_reward": 991.0, "step": 245000}
{"episode": 984.0, "episode_reward": 965.4, "eval_time": 34.0443217754364, "mean_episode_reward": 965.4, "best_episode_reward": 990.0, "step": 246000}
{"episode": 988.0, "episode_reward": 969.6, "eval_time": 34.84140372276306, "mean_episode_reward": 969.6, "best_episode_reward": 991.0, "step": 247000}
{"episode": 992.0, "episode_reward": 954.3, "eval_time": 34.27858066558838, "mean_episode_reward": 954.3, "best_episode_reward": 997.0, "step": 248000}
{"episode": 996.0, "episode_reward": 971.3, "eval_time": 33.165900468826294, "mean_episode_reward": 971.3, "best_episode_reward": 998.0, "step": 249000}
{"episode": 1000.0, "episode_reward": 960.9, "eval_time": 33.17012000083923, "mean_episode_reward": 960.9, "best_episode_reward": 987.0, "step": 250000}
{"episode": 1004.0, "episode_reward": 976.5, "eval_time": 33.489359855651855, "mean_episode_reward": 976.5, "best_episode_reward": 992.0, "step": 251000}
{"episode": 1008.0, "episode_reward": 975.7, "eval_time": 33.537227153778076, "mean_episode_reward": 975.7, "best_episode_reward": 998.0, "step": 252000}
{"episode": 1012.0, "episode_reward": 978.8, "eval_time": 31.94210648536682, "mean_episode_reward": 978.8, "best_episode_reward": 1000.0, "step": 253000}
{"episode": 1016.0, "episode_reward": 976.1, "eval_time": 32.97355818748474, "mean_episode_reward": 976.1, "best_episode_reward": 989.0, "step": 254000}
{"episode": 1020.0, "episode_reward": 950.1, "eval_time": 32.7813401222229, "mean_episode_reward": 950.1, "best_episode_reward": 989.0, "step": 255000}
{"episode": 1024.0, "episode_reward": 937.5, "eval_time": 31.855597734451294, "mean_episode_reward": 937.5, "best_episode_reward": 1000.0, "step": 256000}
{"episode": 1028.0, "episode_reward": 962.5, "eval_time": 32.850295066833496, "mean_episode_reward": 962.5, "best_episode_reward": 998.0, "step": 257000}
{"episode": 1032.0, "episode_reward": 967.2, "eval_time": 31.917898416519165, "mean_episode_reward": 967.2, "best_episode_reward": 998.0, "step": 258000}
{"episode": 1036.0, "episode_reward": 952.6, "eval_time": 31.887365579605103, "mean_episode_reward": 952.6, "best_episode_reward": 991.0, "step": 259000}
{"episode": 1040.0, "episode_reward": 917.7, "eval_time": 31.82958197593689, "mean_episode_reward": 917.7, "best_episode_reward": 997.0, "step": 260000}
{"episode": 1044.0, "episode_reward": 973.2, "eval_time": 32.165252923965454, "mean_episode_reward": 973.2, "best_episode_reward": 990.0, "step": 261000}
{"episode": 1048.0, "episode_reward": 981.7, "eval_time": 32.636030435562134, "mean_episode_reward": 981.7, "best_episode_reward": 992.0, "step": 262000}
{"episode": 1052.0, "episode_reward": 964.9, "eval_time": 31.70396375656128, "mean_episode_reward": 964.9, "best_episode_reward": 997.0, "step": 263000}
{"episode": 1056.0, "episode_reward": 971.5, "eval_time": 32.52086901664734, "mean_episode_reward": 971.5, "best_episode_reward": 991.0, "step": 264000}
{"episode": 1060.0, "episode_reward": 963.7, "eval_time": 32.573896408081055, "mean_episode_reward": 963.7, "best_episode_reward": 993.0, "step": 265000}
{"episode": 1064.0, "episode_reward": 960.7, "eval_time": 32.413898229599, "mean_episode_reward": 960.7, "best_episode_reward": 994.0, "step": 266000}
{"episode": 1068.0, "episode_reward": 968.0, "eval_time": 32.58505392074585, "mean_episode_reward": 968.0, "best_episode_reward": 998.0, "step": 267000}
{"episode": 1072.0, "episode_reward": 963.2, "eval_time": 31.918287754058838, "mean_episode_reward": 963.2, "best_episode_reward": 995.0, "step": 268000}
{"episode": 1076.0, "episode_reward": 972.1, "eval_time": 32.06272840499878, "mean_episode_reward": 972.1, "best_episode_reward": 992.0, "step": 269000}
{"episode": 1080.0, "episode_reward": 951.6, "eval_time": 32.313382387161255, "mean_episode_reward": 951.6, "best_episode_reward": 991.0, "step": 270000}
{"episode": 1084.0, "episode_reward": 973.8, "eval_time": 32.003623247146606, "mean_episode_reward": 973.8, "best_episode_reward": 990.0, "step": 271000}
{"episode": 1088.0, "episode_reward": 977.0, "eval_time": 32.41960787773132, "mean_episode_reward": 977.0, "best_episode_reward": 997.0, "step": 272000}
{"episode": 1092.0, "episode_reward": 962.1, "eval_time": 31.997002124786377, "mean_episode_reward": 962.1, "best_episode_reward": 998.0, "step": 273000}
{"episode": 1096.0, "episode_reward": 964.8, "eval_time": 31.778637409210205, "mean_episode_reward": 964.8, "best_episode_reward": 1000.0, "step": 274000}
{"episode": 1100.0, "episode_reward": 972.3, "eval_time": 32.7271466255188, "mean_episode_reward": 972.3, "best_episode_reward": 996.0, "step": 275000}
{"episode": 1104.0, "episode_reward": 969.9, "eval_time": 32.02293086051941, "mean_episode_reward": 969.9, "best_episode_reward": 989.0, "step": 276000}
{"episode": 1108.0, "episode_reward": 966.2, "eval_time": 31.875906229019165, "mean_episode_reward": 966.2, "best_episode_reward": 991.0, "step": 277000}
{"episode": 1112.0, "episode_reward": 976.8, "eval_time": 31.525676727294922, "mean_episode_reward": 976.8, "best_episode_reward": 1000.0, "step": 278000}
{"episode": 1116.0, "episode_reward": 915.6, "eval_time": 31.861485242843628, "mean_episode_reward": 915.6, "best_episode_reward": 991.0, "step": 279000}
{"episode": 1120.0, "episode_reward": 987.3, "eval_time": 31.250025749206543, "mean_episode_reward": 987.3, "best_episode_reward": 1000.0, "step": 280000}
{"episode": 1124.0, "episode_reward": 953.1, "eval_time": 31.089030504226685, "mean_episode_reward": 953.1, "best_episode_reward": 991.0, "step": 281000}
{"episode": 1128.0, "episode_reward": 976.9, "eval_time": 31.767310857772827, "mean_episode_reward": 976.9, "best_episode_reward": 992.0, "step": 282000}
{"episode": 1132.0, "episode_reward": 971.8, "eval_time": 31.312143087387085, "mean_episode_reward": 971.8, "best_episode_reward": 999.0, "step": 283000}
{"episode": 1136.0, "episode_reward": 969.4, "eval_time": 31.538261651992798, "mean_episode_reward": 969.4, "best_episode_reward": 994.0, "step": 284000}
{"episode": 1140.0, "episode_reward": 986.7, "eval_time": 31.38999319076538, "mean_episode_reward": 986.7, "best_episode_reward": 1000.0, "step": 285000}
{"episode": 1144.0, "episode_reward": 981.0, "eval_time": 31.269001722335815, "mean_episode_reward": 981.0, "best_episode_reward": 1000.0, "step": 286000}
{"episode": 1148.0, "episode_reward": 978.1, "eval_time": 31.545187950134277, "mean_episode_reward": 978.1, "best_episode_reward": 997.0, "step": 287000}
{"episode": 1152.0, "episode_reward": 977.8, "eval_time": 31.560563802719116, "mean_episode_reward": 977.8, "best_episode_reward": 1000.0, "step": 288000}
{"episode": 1156.0, "episode_reward": 980.0, "eval_time": 31.28804087638855, "mean_episode_reward": 980.0, "best_episode_reward": 996.0, "step": 289000}
{"episode": 1160.0, "episode_reward": 871.5, "eval_time": 30.97050714492798, "mean_episode_reward": 871.5, "best_episode_reward": 988.0, "step": 290000}
{"episode": 1164.0, "episode_reward": 975.4, "eval_time": 31.23868751525879, "mean_episode_reward": 975.4, "best_episode_reward": 999.0, "step": 291000}
{"episode": 1168.0, "episode_reward": 979.1, "eval_time": 31.549019813537598, "mean_episode_reward": 979.1, "best_episode_reward": 998.0, "step": 292000}
{"episode": 1172.0, "episode_reward": 981.8, "eval_time": 31.499166250228882, "mean_episode_reward": 981.8, "best_episode_reward": 998.0, "step": 293000}
{"episode": 1176.0, "episode_reward": 969.3, "eval_time": 31.684772729873657, "mean_episode_reward": 969.3, "best_episode_reward": 996.0, "step": 294000}
{"episode": 1180.0, "episode_reward": 965.4, "eval_time": 31.052502632141113, "mean_episode_reward": 965.4, "best_episode_reward": 991.0, "step": 295000}
{"episode": 1184.0, "episode_reward": 973.3, "eval_time": 31.256662607192993, "mean_episode_reward": 973.3, "best_episode_reward": 996.0, "step": 296000}
{"episode": 1188.0, "episode_reward": 975.1, "eval_time": 31.61320471763611, "mean_episode_reward": 975.1, "best_episode_reward": 991.0, "step": 297000}
{"episode": 1192.0, "episode_reward": 952.3, "eval_time": 31.14000630378723, "mean_episode_reward": 952.3, "best_episode_reward": 990.0, "step": 298000}
{"episode": 1196.0, "episode_reward": 971.1, "eval_time": 32.60247874259949, "mean_episode_reward": 971.1, "best_episode_reward": 997.0, "step": 299000}
{"episode": 1200.0, "episode_reward": 977.8, "eval_time": 31.339536666870117, "mean_episode_reward": 977.8, "best_episode_reward": 994.0, "step": 300000}
{"episode": 1204.0, "episode_reward": 970.3, "eval_time": 31.476230144500732, "mean_episode_reward": 970.3, "best_episode_reward": 990.0, "step": 301000}
{"episode": 1208.0, "episode_reward": 976.8, "eval_time": 31.118833541870117, "mean_episode_reward": 976.8, "best_episode_reward": 1000.0, "step": 302000}
{"episode": 1212.0, "episode_reward": 976.7, "eval_time": 31.518432140350342, "mean_episode_reward": 976.7, "best_episode_reward": 993.0, "step": 303000}
{"episode": 1216.0, "episode_reward": 978.8, "eval_time": 31.54634380340576, "mean_episode_reward": 978.8, "best_episode_reward": 992.0, "step": 304000}
{"episode": 1220.0, "episode_reward": 973.9, "eval_time": 31.083808422088623, "mean_episode_reward": 973.9, "best_episode_reward": 1000.0, "step": 305000}
{"episode": 1224.0, "episode_reward": 970.6, "eval_time": 31.90281319618225, "mean_episode_reward": 970.6, "best_episode_reward": 992.0, "step": 306000}
{"episode": 1228.0, "episode_reward": 972.5, "eval_time": 32.05463910102844, "mean_episode_reward": 972.5, "best_episode_reward": 991.0, "step": 307000}
{"episode": 1232.0, "episode_reward": 975.1, "eval_time": 32.20873546600342, "mean_episode_reward": 975.1, "best_episode_reward": 993.0, "step": 308000}
{"episode": 1236.0, "episode_reward": 976.0, "eval_time": 31.951513290405273, "mean_episode_reward": 976.0, "best_episode_reward": 994.0, "step": 309000}
{"episode": 1240.0, "episode_reward": 980.6, "eval_time": 31.68195867538452, "mean_episode_reward": 980.6, "best_episode_reward": 1000.0, "step": 310000}
{"episode": 1244.0, "episode_reward": 979.5, "eval_time": 31.60276484489441, "mean_episode_reward": 979.5, "best_episode_reward": 996.0, "step": 311000}
{"episode": 1248.0, "episode_reward": 969.8, "eval_time": 31.07081413269043, "mean_episode_reward": 969.8, "best_episode_reward": 994.0, "step": 312000}
{"episode": 1252.0, "episode_reward": 974.2, "eval_time": 31.38196063041687, "mean_episode_reward": 974.2, "best_episode_reward": 993.0, "step": 313000}
{"episode": 1256.0, "episode_reward": 981.4, "eval_time": 31.808247327804565, "mean_episode_reward": 981.4, "best_episode_reward": 1000.0, "step": 314000}
{"episode": 1260.0, "episode_reward": 975.3, "eval_time": 31.86069416999817, "mean_episode_reward": 975.3, "best_episode_reward": 996.0, "step": 315000}
{"episode": 1264.0, "episode_reward": 976.3, "eval_time": 31.572673320770264, "mean_episode_reward": 976.3, "best_episode_reward": 997.0, "step": 316000}
{"episode": 1268.0, "episode_reward": 963.7, "eval_time": 31.97810935974121, "mean_episode_reward": 963.7, "best_episode_reward": 994.0, "step": 317000}
{"episode": 1272.0, "episode_reward": 974.1, "eval_time": 31.84944462776184, "mean_episode_reward": 974.1, "best_episode_reward": 991.0, "step": 318000}
{"episode": 1276.0, "episode_reward": 968.0, "eval_time": 31.927034378051758, "mean_episode_reward": 968.0, "best_episode_reward": 994.0, "step": 319000}
{"episode": 1280.0, "episode_reward": 966.6, "eval_time": 31.221643686294556, "mean_episode_reward": 966.6, "best_episode_reward": 996.0, "step": 320000}
{"episode": 1284.0, "episode_reward": 969.0, "eval_time": 31.292699337005615, "mean_episode_reward": 969.0, "best_episode_reward": 997.0, "step": 321000}
{"episode": 1288.0, "episode_reward": 969.0, "eval_time": 31.23682689666748, "mean_episode_reward": 969.0, "best_episode_reward": 992.0, "step": 322000}
{"episode": 1292.0, "episode_reward": 973.9, "eval_time": 31.56796431541443, "mean_episode_reward": 973.9, "best_episode_reward": 995.0, "step": 323000}
{"episode": 1296.0, "episode_reward": 966.2, "eval_time": 31.170467853546143, "mean_episode_reward": 966.2, "best_episode_reward": 990.0, "step": 324000}
{"episode": 1300.0, "episode_reward": 983.3, "eval_time": 31.054258108139038, "mean_episode_reward": 983.3, "best_episode_reward": 997.0, "step": 325000}
{"episode": 1304.0, "episode_reward": 973.5, "eval_time": 34.642709732055664, "mean_episode_reward": 973.5, "best_episode_reward": 996.0, "step": 326000}
{"episode": 1308.0, "episode_reward": 963.0, "eval_time": 36.24615430831909, "mean_episode_reward": 963.0, "best_episode_reward": 996.0, "step": 327000}
{"episode": 1312.0, "episode_reward": 979.9, "eval_time": 33.07980823516846, "mean_episode_reward": 979.9, "best_episode_reward": 998.0, "step": 328000}
{"episode": 1316.0, "episode_reward": 967.2, "eval_time": 31.428780555725098, "mean_episode_reward": 967.2, "best_episode_reward": 994.0, "step": 329000}
{"episode": 1320.0, "episode_reward": 972.9, "eval_time": 31.8298556804657, "mean_episode_reward": 972.9, "best_episode_reward": 998.0, "step": 330000}
{"episode": 1324.0, "episode_reward": 978.4, "eval_time": 31.5514075756073, "mean_episode_reward": 978.4, "best_episode_reward": 997.0, "step": 331000}
{"episode": 1328.0, "episode_reward": 982.4, "eval_time": 31.540306568145752, "mean_episode_reward": 982.4, "best_episode_reward": 998.0, "step": 332000}
{"episode": 1332.0, "episode_reward": 972.3, "eval_time": 31.292160511016846, "mean_episode_reward": 972.3, "best_episode_reward": 991.0, "step": 333000}
{"episode": 1336.0, "episode_reward": 975.9, "eval_time": 31.26436972618103, "mean_episode_reward": 975.9, "best_episode_reward": 991.0, "step": 334000}
{"episode": 1340.0, "episode_reward": 982.4, "eval_time": 30.956790447235107, "mean_episode_reward": 982.4, "best_episode_reward": 993.0, "step": 335000}
{"episode": 1344.0, "episode_reward": 980.6, "eval_time": 31.06289553642273, "mean_episode_reward": 980.6, "best_episode_reward": 997.0, "step": 336000}
{"episode": 1348.0, "episode_reward": 977.6, "eval_time": 31.56641411781311, "mean_episode_reward": 977.6, "best_episode_reward": 997.0, "step": 337000}
{"episode": 1352.0, "episode_reward": 970.1, "eval_time": 30.634244918823242, "mean_episode_reward": 970.1, "best_episode_reward": 997.0, "step": 338000}
{"episode": 1356.0, "episode_reward": 969.0, "eval_time": 30.502312183380127, "mean_episode_reward": 969.0, "best_episode_reward": 996.0, "step": 339000}
{"episode": 1360.0, "episode_reward": 962.0, "eval_time": 30.668137550354004, "mean_episode_reward": 962.0, "best_episode_reward": 1000.0, "step": 340000}
{"episode": 1364.0, "episode_reward": 962.6, "eval_time": 30.975570917129517, "mean_episode_reward": 962.6, "best_episode_reward": 998.0, "step": 341000}
{"episode": 1368.0, "episode_reward": 974.3, "eval_time": 31.535115480422974, "mean_episode_reward": 974.3, "best_episode_reward": 997.0, "step": 342000}
{"episode": 1372.0, "episode_reward": 989.4, "eval_time": 31.41231083869934, "mean_episode_reward": 989.4, "best_episode_reward": 996.0, "step": 343000}
{"episode": 1376.0, "episode_reward": 977.6, "eval_time": 31.76851224899292, "mean_episode_reward": 977.6, "best_episode_reward": 1000.0, "step": 344000}
{"episode": 1380.0, "episode_reward": 975.2, "eval_time": 31.004719972610474, "mean_episode_reward": 975.2, "best_episode_reward": 995.0, "step": 345000}
{"episode": 1384.0, "episode_reward": 979.9, "eval_time": 31.365958213806152, "mean_episode_reward": 979.9, "best_episode_reward": 994.0, "step": 346000}
{"episode": 1388.0, "episode_reward": 975.5, "eval_time": 31.390377521514893, "mean_episode_reward": 975.5, "best_episode_reward": 1000.0, "step": 347000}
{"episode": 1392.0, "episode_reward": 977.6, "eval_time": 30.676989555358887, "mean_episode_reward": 977.6, "best_episode_reward": 995.0, "step": 348000}
{"episode": 1396.0, "episode_reward": 979.6, "eval_time": 30.808741807937622, "mean_episode_reward": 979.6, "best_episode_reward": 995.0, "step": 349000}
{"episode": 1400.0, "episode_reward": 975.8, "eval_time": 31.60005021095276, "mean_episode_reward": 975.8, "best_episode_reward": 993.0, "step": 350000}
{"episode": 1404.0, "episode_reward": 975.7, "eval_time": 30.965850830078125, "mean_episode_reward": 975.7, "best_episode_reward": 996.0, "step": 351000}
{"episode": 1408.0, "episode_reward": 974.5, "eval_time": 31.323679447174072, "mean_episode_reward": 974.5, "best_episode_reward": 998.0, "step": 352000}
{"episode": 1412.0, "episode_reward": 970.7, "eval_time": 30.954355001449585, "mean_episode_reward": 970.7, "best_episode_reward": 998.0, "step": 353000}
{"episode": 1416.0, "episode_reward": 978.4, "eval_time": 31.475057363510132, "mean_episode_reward": 978.4, "best_episode_reward": 991.0, "step": 354000}
{"episode": 1420.0, "episode_reward": 980.3, "eval_time": 31.06951069831848, "mean_episode_reward": 980.3, "best_episode_reward": 994.0, "step": 355000}
{"episode": 1424.0, "episode_reward": 972.6, "eval_time": 31.522476196289062, "mean_episode_reward": 972.6, "best_episode_reward": 996.0, "step": 356000}
{"episode": 1428.0, "episode_reward": 959.7, "eval_time": 31.592347621917725, "mean_episode_reward": 959.7, "best_episode_reward": 991.0, "step": 357000}
{"episode": 1432.0, "episode_reward": 979.8, "eval_time": 32.0690438747406, "mean_episode_reward": 979.8, "best_episode_reward": 997.0, "step": 358000}
{"episode": 1436.0, "episode_reward": 977.4, "eval_time": 31.573886394500732, "mean_episode_reward": 977.4, "best_episode_reward": 998.0, "step": 359000}
{"episode": 1440.0, "episode_reward": 979.0, "eval_time": 31.331910133361816, "mean_episode_reward": 979.0, "best_episode_reward": 997.0, "step": 360000}
{"episode": 1444.0, "episode_reward": 956.4, "eval_time": 31.313363790512085, "mean_episode_reward": 956.4, "best_episode_reward": 998.0, "step": 361000}
{"episode": 1448.0, "episode_reward": 971.1, "eval_time": 31.339052438735962, "mean_episode_reward": 971.1, "best_episode_reward": 995.0, "step": 362000}
{"episode": 1452.0, "episode_reward": 964.4, "eval_time": 31.0674409866333, "mean_episode_reward": 964.4, "best_episode_reward": 990.0, "step": 363000}
{"episode": 1456.0, "episode_reward": 937.2, "eval_time": 31.502208471298218, "mean_episode_reward": 937.2, "best_episode_reward": 998.0, "step": 364000}
{"episode": 1460.0, "episode_reward": 942.3, "eval_time": 31.864985942840576, "mean_episode_reward": 942.3, "best_episode_reward": 997.0, "step": 365000}
{"episode": 1464.0, "episode_reward": 966.8, "eval_time": 31.94473648071289, "mean_episode_reward": 966.8, "best_episode_reward": 1000.0, "step": 366000}
{"episode": 1468.0, "episode_reward": 979.1, "eval_time": 31.493032217025757, "mean_episode_reward": 979.1, "best_episode_reward": 996.0, "step": 367000}
{"episode": 1472.0, "episode_reward": 966.1, "eval_time": 31.74250292778015, "mean_episode_reward": 966.1, "best_episode_reward": 990.0, "step": 368000}
{"episode": 1476.0, "episode_reward": 981.5, "eval_time": 31.681804895401, "mean_episode_reward": 981.5, "best_episode_reward": 1000.0, "step": 369000}
{"episode": 1480.0, "episode_reward": 964.9, "eval_time": 31.37885332107544, "mean_episode_reward": 964.9, "best_episode_reward": 991.0, "step": 370000}
{"episode": 1484.0, "episode_reward": 976.7, "eval_time": 31.44562602043152, "mean_episode_reward": 976.7, "best_episode_reward": 994.0, "step": 371000}
{"episode": 1488.0, "episode_reward": 981.1, "eval_time": 31.909544706344604, "mean_episode_reward": 981.1, "best_episode_reward": 997.0, "step": 372000}
{"episode": 1492.0, "episode_reward": 964.9, "eval_time": 31.065102577209473, "mean_episode_reward": 964.9, "best_episode_reward": 992.0, "step": 373000}
{"episode": 1496.0, "episode_reward": 981.5, "eval_time": 31.7670476436615, "mean_episode_reward": 981.5, "best_episode_reward": 997.0, "step": 374000}
{"episode": 1500.0, "episode_reward": 978.8, "eval_time": 31.839500188827515, "mean_episode_reward": 978.8, "best_episode_reward": 1000.0, "step": 375000}
{"episode": 1504.0, "episode_reward": 972.9, "eval_time": 32.06337761878967, "mean_episode_reward": 972.9, "best_episode_reward": 990.0, "step": 376000}
{"episode": 1508.0, "episode_reward": 974.8, "eval_time": 31.840229749679565, "mean_episode_reward": 974.8, "best_episode_reward": 992.0, "step": 377000}
{"episode": 1512.0, "episode_reward": 963.9, "eval_time": 31.82845664024353, "mean_episode_reward": 963.9, "best_episode_reward": 991.0, "step": 378000}
{"episode": 1516.0, "episode_reward": 971.2, "eval_time": 32.06989932060242, "mean_episode_reward": 971.2, "best_episode_reward": 993.0, "step": 379000}
{"episode": 1520.0, "episode_reward": 981.3, "eval_time": 33.125826835632324, "mean_episode_reward": 981.3, "best_episode_reward": 995.0, "step": 380000}
{"episode": 1524.0, "episode_reward": 973.0, "eval_time": 32.49922752380371, "mean_episode_reward": 973.0, "best_episode_reward": 990.0, "step": 381000}
{"episode": 1528.0, "episode_reward": 968.8, "eval_time": 31.996421575546265, "mean_episode_reward": 968.8, "best_episode_reward": 996.0, "step": 382000}
{"episode": 1532.0, "episode_reward": 965.7, "eval_time": 32.07224464416504, "mean_episode_reward": 965.7, "best_episode_reward": 998.0, "step": 383000}
{"episode": 1536.0, "episode_reward": 968.4, "eval_time": 32.10995173454285, "mean_episode_reward": 968.4, "best_episode_reward": 997.0, "step": 384000}
{"episode": 1540.0, "episode_reward": 973.6, "eval_time": 31.93899917602539, "mean_episode_reward": 973.6, "best_episode_reward": 998.0, "step": 385000}
{"episode": 1544.0, "episode_reward": 978.5, "eval_time": 32.11450219154358, "mean_episode_reward": 978.5, "best_episode_reward": 990.0, "step": 386000}
{"episode": 1548.0, "episode_reward": 980.3, "eval_time": 32.05701971054077, "mean_episode_reward": 980.3, "best_episode_reward": 1000.0, "step": 387000}
{"episode": 1552.0, "episode_reward": 966.3, "eval_time": 31.924354076385498, "mean_episode_reward": 966.3, "best_episode_reward": 1000.0, "step": 388000}
{"episode": 1556.0, "episode_reward": 970.8, "eval_time": 31.934911966323853, "mean_episode_reward": 970.8, "best_episode_reward": 998.0, "step": 389000}
{"episode": 1560.0, "episode_reward": 974.5, "eval_time": 31.801997900009155, "mean_episode_reward": 974.5, "best_episode_reward": 991.0, "step": 390000}
{"episode": 1564.0, "episode_reward": 976.7, "eval_time": 32.11106848716736, "mean_episode_reward": 976.7, "best_episode_reward": 1000.0, "step": 391000}
{"episode": 1568.0, "episode_reward": 973.2, "eval_time": 31.665964365005493, "mean_episode_reward": 973.2, "best_episode_reward": 992.0, "step": 392000}
{"episode": 1572.0, "episode_reward": 980.2, "eval_time": 32.52322554588318, "mean_episode_reward": 980.2, "best_episode_reward": 992.0, "step": 393000}
{"episode": 1576.0, "episode_reward": 975.3, "eval_time": 31.40240216255188, "mean_episode_reward": 975.3, "best_episode_reward": 996.0, "step": 394000}
{"episode": 1580.0, "episode_reward": 891.1, "eval_time": 31.726349353790283, "mean_episode_reward": 891.1, "best_episode_reward": 996.0, "step": 395000}
{"episode": 1584.0, "episode_reward": 978.3, "eval_time": 32.136061906814575, "mean_episode_reward": 978.3, "best_episode_reward": 991.0, "step": 396000}
{"episode": 1588.0, "episode_reward": 975.1, "eval_time": 31.555909633636475, "mean_episode_reward": 975.1, "best_episode_reward": 991.0, "step": 397000}
{"episode": 1592.0, "episode_reward": 978.3, "eval_time": 30.856910228729248, "mean_episode_reward": 978.3, "best_episode_reward": 1000.0, "step": 398000}
{"episode": 1596.0, "episode_reward": 977.4, "eval_time": 30.96698570251465, "mean_episode_reward": 977.4, "best_episode_reward": 991.0, "step": 399000}
{"episode": 1600.0, "episode_reward": 973.1, "eval_time": 31.409608602523804, "mean_episode_reward": 973.1, "best_episode_reward": 991.0, "step": 400000}
{"episode": 1604.0, "episode_reward": 979.1, "eval_time": 31.624377012252808, "mean_episode_reward": 979.1, "best_episode_reward": 997.0, "step": 401000}
{"episode": 1608.0, "episode_reward": 967.7, "eval_time": 31.858771324157715, "mean_episode_reward": 967.7, "best_episode_reward": 991.0, "step": 402000}
{"episode": 1612.0, "episode_reward": 971.6, "eval_time": 31.652726650238037, "mean_episode_reward": 971.6, "best_episode_reward": 992.0, "step": 403000}
{"episode": 1616.0, "episode_reward": 974.0, "eval_time": 32.04787540435791, "mean_episode_reward": 974.0, "best_episode_reward": 997.0, "step": 404000}
{"episode": 1620.0, "episode_reward": 972.1, "eval_time": 32.22331881523132, "mean_episode_reward": 972.1, "best_episode_reward": 992.0, "step": 405000}
{"episode": 1624.0, "episode_reward": 977.5, "eval_time": 33.407498598098755, "mean_episode_reward": 977.5, "best_episode_reward": 991.0, "step": 406000}
{"episode": 1628.0, "episode_reward": 966.3, "eval_time": 31.901898860931396, "mean_episode_reward": 966.3, "best_episode_reward": 995.0, "step": 407000}
{"episode": 1632.0, "episode_reward": 978.1, "eval_time": 32.72482204437256, "mean_episode_reward": 978.1, "best_episode_reward": 992.0, "step": 408000}
{"episode": 1636.0, "episode_reward": 969.0, "eval_time": 32.55168604850769, "mean_episode_reward": 969.0, "best_episode_reward": 997.0, "step": 409000}
{"episode": 1640.0, "episode_reward": 968.6, "eval_time": 32.36535382270813, "mean_episode_reward": 968.6, "best_episode_reward": 996.0, "step": 410000}
{"episode": 1644.0, "episode_reward": 959.6, "eval_time": 32.48709201812744, "mean_episode_reward": 959.6, "best_episode_reward": 991.0, "step": 411000}
{"episode": 1648.0, "episode_reward": 973.9, "eval_time": 32.428436040878296, "mean_episode_reward": 973.9, "best_episode_reward": 991.0, "step": 412000}
{"episode": 1652.0, "episode_reward": 971.1, "eval_time": 32.60504341125488, "mean_episode_reward": 971.1, "best_episode_reward": 997.0, "step": 413000}
{"episode": 1656.0, "episode_reward": 971.9, "eval_time": 32.2843337059021, "mean_episode_reward": 971.9, "best_episode_reward": 991.0, "step": 414000}
{"episode": 1660.0, "episode_reward": 955.3, "eval_time": 32.89969277381897, "mean_episode_reward": 955.3, "best_episode_reward": 998.0, "step": 415000}
{"episode": 1664.0, "episode_reward": 978.2, "eval_time": 32.585970640182495, "mean_episode_reward": 978.2, "best_episode_reward": 992.0, "step": 416000}
{"episode": 1668.0, "episode_reward": 880.3, "eval_time": 31.742422819137573, "mean_episode_reward": 880.3, "best_episode_reward": 995.0, "step": 417000}
{"episode": 1672.0, "episode_reward": 963.1, "eval_time": 32.73699641227722, "mean_episode_reward": 963.1, "best_episode_reward": 1000.0, "step": 418000}
{"episode": 1676.0, "episode_reward": 963.5, "eval_time": 31.719775915145874, "mean_episode_reward": 963.5, "best_episode_reward": 989.0, "step": 419000}
{"episode": 1680.0, "episode_reward": 980.5, "eval_time": 32.739954233169556, "mean_episode_reward": 980.5, "best_episode_reward": 992.0, "step": 420000}
{"episode": 1684.0, "episode_reward": 969.1, "eval_time": 31.800264358520508, "mean_episode_reward": 969.1, "best_episode_reward": 997.0, "step": 421000}
{"episode": 1688.0, "episode_reward": 967.1, "eval_time": 31.79022216796875, "mean_episode_reward": 967.1, "best_episode_reward": 995.0, "step": 422000}
{"episode": 1692.0, "episode_reward": 979.7, "eval_time": 31.661350965499878, "mean_episode_reward": 979.7, "best_episode_reward": 999.0, "step": 423000}
{"episode": 1696.0, "episode_reward": 968.6, "eval_time": 31.76997399330139, "mean_episode_reward": 968.6, "best_episode_reward": 993.0, "step": 424000}
{"episode": 1700.0, "episode_reward": 971.5, "eval_time": 32.08428335189819, "mean_episode_reward": 971.5, "best_episode_reward": 999.0, "step": 425000}
{"episode": 1704.0, "episode_reward": 948.3, "eval_time": 32.507129192352295, "mean_episode_reward": 948.3, "best_episode_reward": 1000.0, "step": 426000}
{"episode": 1708.0, "episode_reward": 976.5, "eval_time": 32.26547074317932, "mean_episode_reward": 976.5, "best_episode_reward": 993.0, "step": 427000}
{"episode": 1712.0, "episode_reward": 971.3, "eval_time": 32.83162713050842, "mean_episode_reward": 971.3, "best_episode_reward": 993.0, "step": 428000}
{"episode": 1716.0, "episode_reward": 956.0, "eval_time": 32.056588888168335, "mean_episode_reward": 956.0, "best_episode_reward": 996.0, "step": 429000}
{"episode": 1720.0, "episode_reward": 979.1, "eval_time": 32.136491537094116, "mean_episode_reward": 979.1, "best_episode_reward": 996.0, "step": 430000}
{"episode": 1724.0, "episode_reward": 955.0, "eval_time": 32.87576198577881, "mean_episode_reward": 955.0, "best_episode_reward": 991.0, "step": 431000}
{"episode": 1728.0, "episode_reward": 973.0, "eval_time": 32.26334500312805, "mean_episode_reward": 973.0, "best_episode_reward": 995.0, "step": 432000}
{"episode": 1732.0, "episode_reward": 971.4, "eval_time": 32.668583393096924, "mean_episode_reward": 971.4, "best_episode_reward": 992.0, "step": 433000}
{"episode": 1736.0, "episode_reward": 973.7, "eval_time": 33.108341455459595, "mean_episode_reward": 973.7, "best_episode_reward": 992.0, "step": 434000}
{"episode": 1740.0, "episode_reward": 981.0, "eval_time": 32.67020082473755, "mean_episode_reward": 981.0, "best_episode_reward": 992.0, "step": 435000}
{"episode": 1744.0, "episode_reward": 946.0, "eval_time": 32.93031096458435, "mean_episode_reward": 946.0, "best_episode_reward": 990.0, "step": 436000}
{"episode": 1748.0, "episode_reward": 972.1, "eval_time": 33.619707107543945, "mean_episode_reward": 972.1, "best_episode_reward": 998.0, "step": 437000}
{"episode": 1752.0, "episode_reward": 955.4, "eval_time": 32.80833697319031, "mean_episode_reward": 955.4, "best_episode_reward": 991.0, "step": 438000}
{"episode": 1756.0, "episode_reward": 983.6, "eval_time": 33.790701389312744, "mean_episode_reward": 983.6, "best_episode_reward": 1000.0, "step": 439000}
{"episode": 1760.0, "episode_reward": 980.9, "eval_time": 34.382927894592285, "mean_episode_reward": 980.9, "best_episode_reward": 990.0, "step": 440000}
{"episode": 1764.0, "episode_reward": 975.4, "eval_time": 33.59252095222473, "mean_episode_reward": 975.4, "best_episode_reward": 996.0, "step": 441000}
{"episode": 1768.0, "episode_reward": 982.4, "eval_time": 33.21735715866089, "mean_episode_reward": 982.4, "best_episode_reward": 1000.0, "step": 442000}
{"episode": 1772.0, "episode_reward": 973.8, "eval_time": 34.188435077667236, "mean_episode_reward": 973.8, "best_episode_reward": 999.0, "step": 443000}
{"episode": 1776.0, "episode_reward": 966.8, "eval_time": 34.197813272476196, "mean_episode_reward": 966.8, "best_episode_reward": 990.0, "step": 444000}
{"episode": 1780.0, "episode_reward": 947.7, "eval_time": 33.49753379821777, "mean_episode_reward": 947.7, "best_episode_reward": 990.0, "step": 445000}
{"episode": 1784.0, "episode_reward": 974.6, "eval_time": 33.46904993057251, "mean_episode_reward": 974.6, "best_episode_reward": 991.0, "step": 446000}
{"episode": 1788.0, "episode_reward": 981.2, "eval_time": 33.66912627220154, "mean_episode_reward": 981.2, "best_episode_reward": 999.0, "step": 447000}
{"episode": 1792.0, "episode_reward": 972.8, "eval_time": 32.89262080192566, "mean_episode_reward": 972.8, "best_episode_reward": 991.0, "step": 448000}
{"episode": 1796.0, "episode_reward": 974.6, "eval_time": 32.99120497703552, "mean_episode_reward": 974.6, "best_episode_reward": 996.0, "step": 449000}
{"episode": 1800.0, "episode_reward": 970.4, "eval_time": 33.56210923194885, "mean_episode_reward": 970.4, "best_episode_reward": 997.0, "step": 450000}
{"episode": 1804.0, "episode_reward": 967.9, "eval_time": 33.04452872276306, "mean_episode_reward": 967.9, "best_episode_reward": 992.0, "step": 451000}
{"episode": 1808.0, "episode_reward": 973.2, "eval_time": 33.13156247138977, "mean_episode_reward": 973.2, "best_episode_reward": 1000.0, "step": 452000}
{"episode": 1812.0, "episode_reward": 976.8, "eval_time": 33.165205001831055, "mean_episode_reward": 976.8, "best_episode_reward": 999.0, "step": 453000}
{"episode": 1816.0, "episode_reward": 978.1, "eval_time": 33.110116958618164, "mean_episode_reward": 978.1, "best_episode_reward": 992.0, "step": 454000}
{"episode": 1820.0, "episode_reward": 956.5, "eval_time": 33.258493423461914, "mean_episode_reward": 956.5, "best_episode_reward": 996.0, "step": 455000}
{"episode": 1824.0, "episode_reward": 969.4, "eval_time": 33.04730725288391, "mean_episode_reward": 969.4, "best_episode_reward": 996.0, "step": 456000}
{"episode": 1828.0, "episode_reward": 969.7, "eval_time": 32.467283487319946, "mean_episode_reward": 969.7, "best_episode_reward": 990.0, "step": 457000}
{"episode": 1832.0, "episode_reward": 978.9, "eval_time": 33.294878244400024, "mean_episode_reward": 978.9, "best_episode_reward": 998.0, "step": 458000}
{"episode": 1836.0, "episode_reward": 969.6, "eval_time": 32.20394468307495, "mean_episode_reward": 969.6, "best_episode_reward": 990.0, "step": 459000}
{"episode": 1840.0, "episode_reward": 970.9, "eval_time": 32.39804291725159, "mean_episode_reward": 970.9, "best_episode_reward": 991.0, "step": 460000}
{"episode": 1844.0, "episode_reward": 978.9, "eval_time": 31.753661394119263, "mean_episode_reward": 978.9, "best_episode_reward": 998.0, "step": 461000}
{"episode": 1848.0, "episode_reward": 978.1, "eval_time": 31.838239192962646, "mean_episode_reward": 978.1, "best_episode_reward": 992.0, "step": 462000}
{"episode": 1852.0, "episode_reward": 963.5, "eval_time": 32.414623498916626, "mean_episode_reward": 963.5, "best_episode_reward": 988.0, "step": 463000}
{"episode": 1856.0, "episode_reward": 976.3, "eval_time": 31.938063621520996, "mean_episode_reward": 976.3, "best_episode_reward": 1000.0, "step": 464000}
{"episode": 1860.0, "episode_reward": 977.4, "eval_time": 32.71094250679016, "mean_episode_reward": 977.4, "best_episode_reward": 992.0, "step": 465000}
{"episode": 1864.0, "episode_reward": 969.5, "eval_time": 33.080970287323, "mean_episode_reward": 969.5, "best_episode_reward": 1000.0, "step": 466000}
{"episode": 1868.0, "episode_reward": 975.7, "eval_time": 32.402167558670044, "mean_episode_reward": 975.7, "best_episode_reward": 1000.0, "step": 467000}
{"episode": 1872.0, "episode_reward": 965.5, "eval_time": 31.849663257598877, "mean_episode_reward": 965.5, "best_episode_reward": 991.0, "step": 468000}
{"episode": 1876.0, "episode_reward": 975.5, "eval_time": 31.697484731674194, "mean_episode_reward": 975.5, "best_episode_reward": 991.0, "step": 469000}
{"episode": 1880.0, "episode_reward": 976.0, "eval_time": 32.16825199127197, "mean_episode_reward": 976.0, "best_episode_reward": 991.0, "step": 470000}
{"episode": 1884.0, "episode_reward": 972.1, "eval_time": 32.02385210990906, "mean_episode_reward": 972.1, "best_episode_reward": 987.0, "step": 471000}
{"episode": 1888.0, "episode_reward": 974.2, "eval_time": 31.970889806747437, "mean_episode_reward": 974.2, "best_episode_reward": 1000.0, "step": 472000}
{"episode": 1892.0, "episode_reward": 980.5, "eval_time": 32.444939374923706, "mean_episode_reward": 980.5, "best_episode_reward": 996.0, "step": 473000}
{"episode": 1896.0, "episode_reward": 976.3, "eval_time": 33.048935651779175, "mean_episode_reward": 976.3, "best_episode_reward": 993.0, "step": 474000}
{"episode": 1900.0, "episode_reward": 970.8, "eval_time": 31.787204027175903, "mean_episode_reward": 970.8, "best_episode_reward": 993.0, "step": 475000}
{"episode": 1904.0, "episode_reward": 967.7, "eval_time": 31.969263553619385, "mean_episode_reward": 967.7, "best_episode_reward": 1000.0, "step": 476000}
{"episode": 1908.0, "episode_reward": 971.1, "eval_time": 31.863620281219482, "mean_episode_reward": 971.1, "best_episode_reward": 990.0, "step": 477000}
{"episode": 1912.0, "episode_reward": 985.6, "eval_time": 31.40153431892395, "mean_episode_reward": 985.6, "best_episode_reward": 994.0, "step": 478000}
{"episode": 1916.0, "episode_reward": 971.5, "eval_time": 31.565860748291016, "mean_episode_reward": 971.5, "best_episode_reward": 996.0, "step": 479000}
{"episode": 1920.0, "episode_reward": 980.0, "eval_time": 31.886348009109497, "mean_episode_reward": 980.0, "best_episode_reward": 998.0, "step": 480000}
{"episode": 1924.0, "episode_reward": 974.1, "eval_time": 31.69843339920044, "mean_episode_reward": 974.1, "best_episode_reward": 1000.0, "step": 481000}
{"episode": 1928.0, "episode_reward": 971.3, "eval_time": 31.999329328536987, "mean_episode_reward": 971.3, "best_episode_reward": 991.0, "step": 482000}
{"episode": 1932.0, "episode_reward": 963.6, "eval_time": 32.41479778289795, "mean_episode_reward": 963.6, "best_episode_reward": 993.0, "step": 483000}
{"episode": 1936.0, "episode_reward": 967.2, "eval_time": 32.06599450111389, "mean_episode_reward": 967.2, "best_episode_reward": 990.0, "step": 484000}
{"episode": 1940.0, "episode_reward": 978.9, "eval_time": 31.622409105300903, "mean_episode_reward": 978.9, "best_episode_reward": 998.0, "step": 485000}
{"episode": 1944.0, "episode_reward": 977.6, "eval_time": 31.900089263916016, "mean_episode_reward": 977.6, "best_episode_reward": 997.0, "step": 486000}
{"episode": 1948.0, "episode_reward": 983.1, "eval_time": 32.44752883911133, "mean_episode_reward": 983.1, "best_episode_reward": 1000.0, "step": 487000}
{"episode": 1952.0, "episode_reward": 973.9, "eval_time": 32.31446075439453, "mean_episode_reward": 973.9, "best_episode_reward": 989.0, "step": 488000}
{"episode": 1956.0, "episode_reward": 976.4, "eval_time": 32.033528089523315, "mean_episode_reward": 976.4, "best_episode_reward": 993.0, "step": 489000}
{"episode": 1960.0, "episode_reward": 984.2, "eval_time": 32.25592565536499, "mean_episode_reward": 984.2, "best_episode_reward": 997.0, "step": 490000}
{"episode": 1964.0, "episode_reward": 974.1, "eval_time": 31.463600635528564, "mean_episode_reward": 974.1, "best_episode_reward": 999.0, "step": 491000}
{"episode": 1968.0, "episode_reward": 976.1, "eval_time": 32.553722620010376, "mean_episode_reward": 976.1, "best_episode_reward": 991.0, "step": 492000}
{"episode": 1972.0, "episode_reward": 969.9, "eval_time": 32.727415800094604, "mean_episode_reward": 969.9, "best_episode_reward": 992.0, "step": 493000}
{"episode": 1976.0, "episode_reward": 966.7, "eval_time": 31.878839015960693, "mean_episode_reward": 966.7, "best_episode_reward": 997.0, "step": 494000}
{"episode": 1980.0, "episode_reward": 974.5, "eval_time": 31.490731716156006, "mean_episode_reward": 974.5, "best_episode_reward": 993.0, "step": 495000}
{"episode": 1984.0, "episode_reward": 989.4, "eval_time": 32.14894723892212, "mean_episode_reward": 989.4, "best_episode_reward": 1000.0, "step": 496000}
{"episode": 1988.0, "episode_reward": 971.5, "eval_time": 32.212656021118164, "mean_episode_reward": 971.5, "best_episode_reward": 994.0, "step": 497000}
{"episode": 1992.0, "episode_reward": 969.1, "eval_time": 31.661346197128296, "mean_episode_reward": 969.1, "best_episode_reward": 992.0, "step": 498000}
{"episode": 1996.0, "episode_reward": 976.5, "eval_time": 31.523028135299683, "mean_episode_reward": 976.5, "best_episode_reward": 996.0, "step": 499000}
