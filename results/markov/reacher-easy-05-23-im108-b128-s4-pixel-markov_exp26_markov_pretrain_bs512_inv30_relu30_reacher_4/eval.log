{"episode": 0.0, "episode_reward": 80.4, "eval_time": 40.19223713874817, "mean_episode_reward": 80.4, "best_episode_reward": 331.0, "step": 0}
{"episode": 4.0, "episode_reward": 56.7, "eval_time": 37.477543354034424, "mean_episode_reward": 56.7, "best_episode_reward": 208.0, "step": 1000}
{"episode": 8.0, "episode_reward": 37.8, "eval_time": 38.28142309188843, "mean_episode_reward": 37.8, "best_episode_reward": 156.0, "step": 2000}
{"episode": 12.0, "episode_reward": 54.2, "eval_time": 38.066163778305054, "mean_episode_reward": 54.2, "best_episode_reward": 199.0, "step": 3000}
{"episode": 16.0, "episode_reward": 173.4, "eval_time": 37.2219672203064, "mean_episode_reward": 173.4, "best_episode_reward": 466.0, "step": 4000}
{"episode": 20.0, "episode_reward": 97.3, "eval_time": 36.72992563247681, "mean_episode_reward": 97.3, "best_episode_reward": 376.0, "step": 5000}
{"episode": 24.0, "episode_reward": 1.5, "eval_time": 33.27204918861389, "mean_episode_reward": 1.5, "best_episode_reward": 7.0, "step": 6000}
{"episode": 28.0, "episode_reward": 185.2, "eval_time": 33.1161847114563, "mean_episode_reward": 185.2, "best_episode_reward": 988.0, "step": 7000}
{"episode": 32.0, "episode_reward": 197.2, "eval_time": 33.758413314819336, "mean_episode_reward": 197.2, "best_episode_reward": 945.0, "step": 8000}
{"episode": 36.0, "episode_reward": 101.9, "eval_time": 33.316476345062256, "mean_episode_reward": 101.9, "best_episode_reward": 996.0, "step": 9000}
{"episode": 40.0, "episode_reward": 392.2, "eval_time": 33.04098176956177, "mean_episode_reward": 392.2, "best_episode_reward": 1000.0, "step": 10000}
{"episode": 44.0, "episode_reward": 199.2, "eval_time": 33.79814577102661, "mean_episode_reward": 199.2, "best_episode_reward": 963.0, "step": 11000}
{"episode": 48.0, "episode_reward": 124.1, "eval_time": 33.50622057914734, "mean_episode_reward": 124.1, "best_episode_reward": 979.0, "step": 12000}
{"episode": 52.0, "episode_reward": 389.9, "eval_time": 33.20079016685486, "mean_episode_reward": 389.9, "best_episode_reward": 979.0, "step": 13000}
{"episode": 56.0, "episode_reward": 290.0, "eval_time": 33.399393796920776, "mean_episode_reward": 290.0, "best_episode_reward": 979.0, "step": 14000}
{"episode": 60.0, "episode_reward": 274.1, "eval_time": 33.09324097633362, "mean_episode_reward": 274.1, "best_episode_reward": 994.0, "step": 15000}
{"episode": 64.0, "episode_reward": 389.9, "eval_time": 33.16916608810425, "mean_episode_reward": 389.9, "best_episode_reward": 985.0, "step": 16000}
{"episode": 68.0, "episode_reward": 482.7, "eval_time": 33.814722537994385, "mean_episode_reward": 482.7, "best_episode_reward": 986.0, "step": 17000}
{"episode": 72.0, "episode_reward": 507.3, "eval_time": 32.85624146461487, "mean_episode_reward": 507.3, "best_episode_reward": 1000.0, "step": 18000}
{"episode": 76.0, "episode_reward": 311.2, "eval_time": 32.9667706489563, "mean_episode_reward": 311.2, "best_episode_reward": 999.0, "step": 19000}
{"episode": 80.0, "episode_reward": 145.5, "eval_time": 33.01591944694519, "mean_episode_reward": 145.5, "best_episode_reward": 1000.0, "step": 20000}
{"episode": 84.0, "episode_reward": 772.7, "eval_time": 32.98252773284912, "mean_episode_reward": 772.7, "best_episode_reward": 1000.0, "step": 21000}
{"episode": 88.0, "episode_reward": 584.5, "eval_time": 32.28969407081604, "mean_episode_reward": 584.5, "best_episode_reward": 1000.0, "step": 22000}
{"episode": 92.0, "episode_reward": 576.6, "eval_time": 32.294150590896606, "mean_episode_reward": 576.6, "best_episode_reward": 982.0, "step": 23000}
{"episode": 96.0, "episode_reward": 308.7, "eval_time": 32.70555377006531, "mean_episode_reward": 308.7, "best_episode_reward": 995.0, "step": 24000}
{"episode": 100.0, "episode_reward": 2.4, "eval_time": 32.694008588790894, "mean_episode_reward": 2.4, "best_episode_reward": 10.0, "step": 25000}
{"episode": 104.0, "episode_reward": 287.5, "eval_time": 33.36958408355713, "mean_episode_reward": 287.5, "best_episode_reward": 967.0, "step": 26000}
{"episode": 108.0, "episode_reward": 241.6, "eval_time": 32.565332651138306, "mean_episode_reward": 241.6, "best_episode_reward": 974.0, "step": 27000}
{"episode": 112.0, "episode_reward": 490.4, "eval_time": 25.001365184783936, "mean_episode_reward": 490.4, "best_episode_reward": 999.0, "step": 28000}
{"episode": 116.0, "episode_reward": 384.8, "eval_time": 25.15809464454651, "mean_episode_reward": 384.8, "best_episode_reward": 985.0, "step": 29000}
{"episode": 120.0, "episode_reward": 776.2, "eval_time": 24.908496856689453, "mean_episode_reward": 776.2, "best_episode_reward": 997.0, "step": 30000}
{"episode": 124.0, "episode_reward": 679.7, "eval_time": 24.797178506851196, "mean_episode_reward": 679.7, "best_episode_reward": 989.0, "step": 31000}
{"episode": 128.0, "episode_reward": 587.8, "eval_time": 39.003753900527954, "mean_episode_reward": 587.8, "best_episode_reward": 1000.0, "step": 32000}
{"episode": 132.0, "episode_reward": 589.0, "eval_time": 36.70489740371704, "mean_episode_reward": 589.0, "best_episode_reward": 999.0, "step": 33000}
{"episode": 136.0, "episode_reward": 694.0, "eval_time": 37.98005986213684, "mean_episode_reward": 694.0, "best_episode_reward": 990.0, "step": 34000}
{"episode": 140.0, "episode_reward": 580.5, "eval_time": 37.09022498130798, "mean_episode_reward": 580.5, "best_episode_reward": 984.0, "step": 35000}
{"episode": 144.0, "episode_reward": 698.5, "eval_time": 37.46108627319336, "mean_episode_reward": 698.5, "best_episode_reward": 998.0, "step": 36000}
{"episode": 148.0, "episode_reward": 479.4, "eval_time": 37.11750793457031, "mean_episode_reward": 479.4, "best_episode_reward": 988.0, "step": 37000}
{"episode": 152.0, "episode_reward": 392.9, "eval_time": 39.03125810623169, "mean_episode_reward": 392.9, "best_episode_reward": 987.0, "step": 38000}
{"episode": 156.0, "episode_reward": 475.5, "eval_time": 37.94805669784546, "mean_episode_reward": 475.5, "best_episode_reward": 986.0, "step": 39000}
{"episode": 160.0, "episode_reward": 609.9, "eval_time": 38.29844355583191, "mean_episode_reward": 609.9, "best_episode_reward": 987.0, "step": 40000}
{"episode": 164.0, "episode_reward": 872.1, "eval_time": 37.305992126464844, "mean_episode_reward": 872.1, "best_episode_reward": 991.0, "step": 41000}
{"episode": 168.0, "episode_reward": 756.1, "eval_time": 38.71221446990967, "mean_episode_reward": 756.1, "best_episode_reward": 976.0, "step": 42000}
{"episode": 172.0, "episode_reward": 486.6, "eval_time": 38.730276107788086, "mean_episode_reward": 486.6, "best_episode_reward": 1000.0, "step": 43000}
{"episode": 176.0, "episode_reward": 787.1, "eval_time": 37.27400231361389, "mean_episode_reward": 787.1, "best_episode_reward": 1000.0, "step": 44000}
{"episode": 180.0, "episode_reward": 707.5, "eval_time": 37.81500434875488, "mean_episode_reward": 707.5, "best_episode_reward": 983.0, "step": 45000}
{"episode": 184.0, "episode_reward": 680.4, "eval_time": 36.74223566055298, "mean_episode_reward": 680.4, "best_episode_reward": 1000.0, "step": 46000}
{"episode": 188.0, "episode_reward": 476.1, "eval_time": 37.90520405769348, "mean_episode_reward": 476.1, "best_episode_reward": 987.0, "step": 47000}
{"episode": 192.0, "episode_reward": 676.8, "eval_time": 38.42175889015198, "mean_episode_reward": 676.8, "best_episode_reward": 990.0, "step": 48000}
{"episode": 196.0, "episode_reward": 698.3, "eval_time": 38.14931535720825, "mean_episode_reward": 698.3, "best_episode_reward": 1000.0, "step": 49000}
{"episode": 200.0, "episode_reward": 978.5, "eval_time": 37.24061346054077, "mean_episode_reward": 978.5, "best_episode_reward": 997.0, "step": 50000}
{"episode": 204.0, "episode_reward": 675.4, "eval_time": 38.43030309677124, "mean_episode_reward": 675.4, "best_episode_reward": 991.0, "step": 51000}
{"episode": 208.0, "episode_reward": 582.2, "eval_time": 37.64165782928467, "mean_episode_reward": 582.2, "best_episode_reward": 1000.0, "step": 52000}
{"episode": 212.0, "episode_reward": 863.9, "eval_time": 36.620705366134644, "mean_episode_reward": 863.9, "best_episode_reward": 992.0, "step": 53000}
{"episode": 216.0, "episode_reward": 878.9, "eval_time": 25.02311611175537, "mean_episode_reward": 878.9, "best_episode_reward": 993.0, "step": 54000}
{"episode": 220.0, "episode_reward": 679.9, "eval_time": 25.95080065727234, "mean_episode_reward": 679.9, "best_episode_reward": 984.0, "step": 55000}
{"episode": 224.0, "episode_reward": 386.3, "eval_time": 25.8782799243927, "mean_episode_reward": 386.3, "best_episode_reward": 974.0, "step": 56000}
{"episode": 228.0, "episode_reward": 779.0, "eval_time": 25.22069239616394, "mean_episode_reward": 779.0, "best_episode_reward": 1000.0, "step": 57000}
{"episode": 232.0, "episode_reward": 950.1, "eval_time": 25.829176902770996, "mean_episode_reward": 950.1, "best_episode_reward": 979.0, "step": 58000}
{"episode": 236.0, "episode_reward": 961.9, "eval_time": 26.29077172279358, "mean_episode_reward": 961.9, "best_episode_reward": 1000.0, "step": 59000}
{"episode": 240.0, "episode_reward": 681.7, "eval_time": 25.589842796325684, "mean_episode_reward": 681.7, "best_episode_reward": 984.0, "step": 60000}
{"episode": 244.0, "episode_reward": 699.2, "eval_time": 25.031855583190918, "mean_episode_reward": 699.2, "best_episode_reward": 1000.0, "step": 61000}
{"episode": 248.0, "episode_reward": 730.4, "eval_time": 26.216649055480957, "mean_episode_reward": 730.4, "best_episode_reward": 983.0, "step": 62000}
{"episode": 252.0, "episode_reward": 864.5, "eval_time": 26.123725414276123, "mean_episode_reward": 864.5, "best_episode_reward": 978.0, "step": 63000}
{"episode": 256.0, "episode_reward": 964.7, "eval_time": 26.733192682266235, "mean_episode_reward": 964.7, "best_episode_reward": 1000.0, "step": 64000}
{"episode": 260.0, "episode_reward": 968.9, "eval_time": 27.172773838043213, "mean_episode_reward": 968.9, "best_episode_reward": 994.0, "step": 65000}
{"episode": 264.0, "episode_reward": 593.5, "eval_time": 26.221213340759277, "mean_episode_reward": 593.5, "best_episode_reward": 994.0, "step": 66000}
{"episode": 268.0, "episode_reward": 974.2, "eval_time": 26.171214818954468, "mean_episode_reward": 974.2, "best_episode_reward": 1000.0, "step": 67000}
{"episode": 272.0, "episode_reward": 881.6, "eval_time": 27.063528776168823, "mean_episode_reward": 881.6, "best_episode_reward": 995.0, "step": 68000}
{"episode": 276.0, "episode_reward": 979.8, "eval_time": 26.457086086273193, "mean_episode_reward": 979.8, "best_episode_reward": 1000.0, "step": 69000}
{"episode": 280.0, "episode_reward": 874.4, "eval_time": 23.72327160835266, "mean_episode_reward": 874.4, "best_episode_reward": 987.0, "step": 70000}
{"episode": 284.0, "episode_reward": 783.7, "eval_time": 23.429985761642456, "mean_episode_reward": 783.7, "best_episode_reward": 1000.0, "step": 71000}
{"episode": 288.0, "episode_reward": 964.9, "eval_time": 22.03647208213806, "mean_episode_reward": 964.9, "best_episode_reward": 990.0, "step": 72000}
{"episode": 292.0, "episode_reward": 971.0, "eval_time": 23.30897808074951, "mean_episode_reward": 971.0, "best_episode_reward": 1000.0, "step": 73000}
{"episode": 296.0, "episode_reward": 877.1, "eval_time": 24.362724542617798, "mean_episode_reward": 877.1, "best_episode_reward": 1000.0, "step": 74000}
{"episode": 300.0, "episode_reward": 780.2, "eval_time": 23.799468994140625, "mean_episode_reward": 780.2, "best_episode_reward": 1000.0, "step": 75000}
{"episode": 304.0, "episode_reward": 680.7, "eval_time": 24.322218656539917, "mean_episode_reward": 680.7, "best_episode_reward": 996.0, "step": 76000}
{"episode": 308.0, "episode_reward": 964.7, "eval_time": 24.047758102416992, "mean_episode_reward": 964.7, "best_episode_reward": 1000.0, "step": 77000}
{"episode": 312.0, "episode_reward": 699.6, "eval_time": 22.781325578689575, "mean_episode_reward": 699.6, "best_episode_reward": 1000.0, "step": 78000}
{"episode": 316.0, "episode_reward": 876.9, "eval_time": 22.669272422790527, "mean_episode_reward": 876.9, "best_episode_reward": 992.0, "step": 79000}
{"episode": 320.0, "episode_reward": 789.8, "eval_time": 23.32932424545288, "mean_episode_reward": 789.8, "best_episode_reward": 1000.0, "step": 80000}
{"episode": 324.0, "episode_reward": 779.1, "eval_time": 24.09570026397705, "mean_episode_reward": 779.1, "best_episode_reward": 995.0, "step": 81000}
{"episode": 328.0, "episode_reward": 761.4, "eval_time": 22.868282794952393, "mean_episode_reward": 761.4, "best_episode_reward": 1000.0, "step": 82000}
{"episode": 332.0, "episode_reward": 875.1, "eval_time": 24.514562606811523, "mean_episode_reward": 875.1, "best_episode_reward": 986.0, "step": 83000}
{"episode": 336.0, "episode_reward": 780.0, "eval_time": 23.804917812347412, "mean_episode_reward": 780.0, "best_episode_reward": 995.0, "step": 84000}
{"episode": 340.0, "episode_reward": 783.0, "eval_time": 23.27237844467163, "mean_episode_reward": 783.0, "best_episode_reward": 1000.0, "step": 85000}
{"episode": 344.0, "episode_reward": 686.6, "eval_time": 23.73520040512085, "mean_episode_reward": 686.6, "best_episode_reward": 1000.0, "step": 86000}
{"episode": 348.0, "episode_reward": 777.8, "eval_time": 23.538190364837646, "mean_episode_reward": 777.8, "best_episode_reward": 1000.0, "step": 87000}
{"episode": 352.0, "episode_reward": 961.2, "eval_time": 22.785414218902588, "mean_episode_reward": 961.2, "best_episode_reward": 1000.0, "step": 88000}
{"episode": 356.0, "episode_reward": 838.7, "eval_time": 23.643936157226562, "mean_episode_reward": 838.7, "best_episode_reward": 991.0, "step": 89000}
{"episode": 360.0, "episode_reward": 879.9, "eval_time": 23.394488096237183, "mean_episode_reward": 879.9, "best_episode_reward": 983.0, "step": 90000}
{"episode": 364.0, "episode_reward": 887.1, "eval_time": 22.968069314956665, "mean_episode_reward": 887.1, "best_episode_reward": 1000.0, "step": 91000}
{"episode": 368.0, "episode_reward": 976.6, "eval_time": 23.07575297355652, "mean_episode_reward": 976.6, "best_episode_reward": 986.0, "step": 92000}
{"episode": 372.0, "episode_reward": 971.3, "eval_time": 24.194777011871338, "mean_episode_reward": 971.3, "best_episode_reward": 993.0, "step": 93000}
{"episode": 376.0, "episode_reward": 970.5, "eval_time": 23.750004768371582, "mean_episode_reward": 970.5, "best_episode_reward": 1000.0, "step": 94000}
{"episode": 380.0, "episode_reward": 953.5, "eval_time": 23.313220500946045, "mean_episode_reward": 953.5, "best_episode_reward": 996.0, "step": 95000}
{"episode": 384.0, "episode_reward": 980.6, "eval_time": 23.03457760810852, "mean_episode_reward": 980.6, "best_episode_reward": 1000.0, "step": 96000}
{"episode": 388.0, "episode_reward": 878.6, "eval_time": 24.284606456756592, "mean_episode_reward": 878.6, "best_episode_reward": 988.0, "step": 97000}
{"episode": 392.0, "episode_reward": 778.3, "eval_time": 23.712580919265747, "mean_episode_reward": 778.3, "best_episode_reward": 990.0, "step": 98000}
{"episode": 396.0, "episode_reward": 952.1, "eval_time": 23.70252561569214, "mean_episode_reward": 952.1, "best_episode_reward": 988.0, "step": 99000}
{"episode": 400.0, "episode_reward": 961.9, "eval_time": 23.57131862640381, "mean_episode_reward": 961.9, "best_episode_reward": 989.0, "step": 100000}
{"episode": 404.0, "episode_reward": 787.9, "eval_time": 23.016944646835327, "mean_episode_reward": 787.9, "best_episode_reward": 992.0, "step": 101000}
{"episode": 408.0, "episode_reward": 888.7, "eval_time": 23.648447275161743, "mean_episode_reward": 888.7, "best_episode_reward": 993.0, "step": 102000}
{"episode": 412.0, "episode_reward": 861.9, "eval_time": 23.33409357070923, "mean_episode_reward": 861.9, "best_episode_reward": 1000.0, "step": 103000}
{"episode": 416.0, "episode_reward": 880.7, "eval_time": 23.706961154937744, "mean_episode_reward": 880.7, "best_episode_reward": 1000.0, "step": 104000}
{"episode": 420.0, "episode_reward": 869.2, "eval_time": 23.973239421844482, "mean_episode_reward": 869.2, "best_episode_reward": 993.0, "step": 105000}
{"episode": 424.0, "episode_reward": 972.0, "eval_time": 22.94674015045166, "mean_episode_reward": 972.0, "best_episode_reward": 991.0, "step": 106000}
{"episode": 428.0, "episode_reward": 868.2, "eval_time": 24.170111179351807, "mean_episode_reward": 868.2, "best_episode_reward": 983.0, "step": 107000}
{"episode": 432.0, "episode_reward": 786.0, "eval_time": 23.975331783294678, "mean_episode_reward": 786.0, "best_episode_reward": 995.0, "step": 108000}
{"episode": 436.0, "episode_reward": 785.8, "eval_time": 23.62643527984619, "mean_episode_reward": 785.8, "best_episode_reward": 999.0, "step": 109000}
{"episode": 440.0, "episode_reward": 844.8, "eval_time": 23.35473656654358, "mean_episode_reward": 844.8, "best_episode_reward": 994.0, "step": 110000}
{"episode": 444.0, "episode_reward": 868.5, "eval_time": 23.58335041999817, "mean_episode_reward": 868.5, "best_episode_reward": 991.0, "step": 111000}
{"episode": 448.0, "episode_reward": 882.9, "eval_time": 23.761501789093018, "mean_episode_reward": 882.9, "best_episode_reward": 1000.0, "step": 112000}
{"episode": 452.0, "episode_reward": 962.3, "eval_time": 23.94498348236084, "mean_episode_reward": 962.3, "best_episode_reward": 1000.0, "step": 113000}
{"episode": 456.0, "episode_reward": 976.2, "eval_time": 22.790302276611328, "mean_episode_reward": 976.2, "best_episode_reward": 1000.0, "step": 114000}
{"episode": 460.0, "episode_reward": 865.3, "eval_time": 23.89122748374939, "mean_episode_reward": 865.3, "best_episode_reward": 995.0, "step": 115000}
{"episode": 464.0, "episode_reward": 868.8, "eval_time": 23.795847415924072, "mean_episode_reward": 868.8, "best_episode_reward": 985.0, "step": 116000}
{"episode": 468.0, "episode_reward": 877.4, "eval_time": 23.99870800971985, "mean_episode_reward": 877.4, "best_episode_reward": 998.0, "step": 117000}
{"episode": 472.0, "episode_reward": 953.1, "eval_time": 23.827885389328003, "mean_episode_reward": 953.1, "best_episode_reward": 999.0, "step": 118000}
{"episode": 476.0, "episode_reward": 974.5, "eval_time": 24.27479314804077, "mean_episode_reward": 974.5, "best_episode_reward": 1000.0, "step": 119000}
{"episode": 480.0, "episode_reward": 867.7, "eval_time": 23.35224676132202, "mean_episode_reward": 867.7, "best_episode_reward": 993.0, "step": 120000}
{"episode": 484.0, "episode_reward": 876.5, "eval_time": 22.97062349319458, "mean_episode_reward": 876.5, "best_episode_reward": 1000.0, "step": 121000}
{"episode": 488.0, "episode_reward": 877.9, "eval_time": 24.355533361434937, "mean_episode_reward": 877.9, "best_episode_reward": 999.0, "step": 122000}
{"episode": 492.0, "episode_reward": 966.5, "eval_time": 23.796517848968506, "mean_episode_reward": 966.5, "best_episode_reward": 996.0, "step": 123000}
{"episode": 496.0, "episode_reward": 967.8, "eval_time": 23.6026713848114, "mean_episode_reward": 967.8, "best_episode_reward": 997.0, "step": 124000}
{"episode": 500.0, "episode_reward": 872.8, "eval_time": 23.857578992843628, "mean_episode_reward": 872.8, "best_episode_reward": 983.0, "step": 125000}
{"episode": 504.0, "episode_reward": 970.4, "eval_time": 23.623075246810913, "mean_episode_reward": 970.4, "best_episode_reward": 989.0, "step": 126000}
{"episode": 508.0, "episode_reward": 979.3, "eval_time": 24.033358812332153, "mean_episode_reward": 979.3, "best_episode_reward": 993.0, "step": 127000}
{"episode": 512.0, "episode_reward": 780.4, "eval_time": 24.008207082748413, "mean_episode_reward": 780.4, "best_episode_reward": 1000.0, "step": 128000}
{"episode": 516.0, "episode_reward": 883.4, "eval_time": 23.64442491531372, "mean_episode_reward": 883.4, "best_episode_reward": 990.0, "step": 129000}
{"episode": 520.0, "episode_reward": 875.7, "eval_time": 23.5815486907959, "mean_episode_reward": 875.7, "best_episode_reward": 1000.0, "step": 130000}
{"episode": 524.0, "episode_reward": 979.4, "eval_time": 24.31346559524536, "mean_episode_reward": 979.4, "best_episode_reward": 1000.0, "step": 131000}
{"episode": 528.0, "episode_reward": 950.8, "eval_time": 24.606321573257446, "mean_episode_reward": 950.8, "best_episode_reward": 987.0, "step": 132000}
{"episode": 532.0, "episode_reward": 975.9, "eval_time": 24.184101819992065, "mean_episode_reward": 975.9, "best_episode_reward": 996.0, "step": 133000}
{"episode": 536.0, "episode_reward": 887.1, "eval_time": 24.496565341949463, "mean_episode_reward": 887.1, "best_episode_reward": 998.0, "step": 134000}
{"episode": 540.0, "episode_reward": 778.8, "eval_time": 23.72089910507202, "mean_episode_reward": 778.8, "best_episode_reward": 986.0, "step": 135000}
{"episode": 544.0, "episode_reward": 885.4, "eval_time": 24.378371000289917, "mean_episode_reward": 885.4, "best_episode_reward": 996.0, "step": 136000}
{"episode": 548.0, "episode_reward": 982.2, "eval_time": 24.34614896774292, "mean_episode_reward": 982.2, "best_episode_reward": 1000.0, "step": 137000}
{"episode": 552.0, "episode_reward": 963.0, "eval_time": 24.547718286514282, "mean_episode_reward": 963.0, "best_episode_reward": 987.0, "step": 138000}
{"episode": 556.0, "episode_reward": 972.3, "eval_time": 24.674906969070435, "mean_episode_reward": 972.3, "best_episode_reward": 1000.0, "step": 139000}
{"episode": 560.0, "episode_reward": 970.2, "eval_time": 24.17772889137268, "mean_episode_reward": 970.2, "best_episode_reward": 1000.0, "step": 140000}
{"episode": 564.0, "episode_reward": 973.7, "eval_time": 24.178887844085693, "mean_episode_reward": 973.7, "best_episode_reward": 1000.0, "step": 141000}
{"episode": 568.0, "episode_reward": 878.5, "eval_time": 24.095879793167114, "mean_episode_reward": 878.5, "best_episode_reward": 1000.0, "step": 142000}
{"episode": 572.0, "episode_reward": 877.1, "eval_time": 23.938057899475098, "mean_episode_reward": 877.1, "best_episode_reward": 985.0, "step": 143000}
{"episode": 576.0, "episode_reward": 876.0, "eval_time": 23.919408798217773, "mean_episode_reward": 876.0, "best_episode_reward": 993.0, "step": 144000}
{"episode": 580.0, "episode_reward": 977.9, "eval_time": 23.955435514450073, "mean_episode_reward": 977.9, "best_episode_reward": 1000.0, "step": 145000}
{"episode": 584.0, "episode_reward": 775.2, "eval_time": 24.463479042053223, "mean_episode_reward": 775.2, "best_episode_reward": 979.0, "step": 146000}
{"episode": 588.0, "episode_reward": 971.6, "eval_time": 24.32979106903076, "mean_episode_reward": 971.6, "best_episode_reward": 993.0, "step": 147000}
{"episode": 592.0, "episode_reward": 971.6, "eval_time": 24.094648599624634, "mean_episode_reward": 971.6, "best_episode_reward": 981.0, "step": 148000}
{"episode": 596.0, "episode_reward": 885.3, "eval_time": 24.259276866912842, "mean_episode_reward": 885.3, "best_episode_reward": 997.0, "step": 149000}
{"episode": 600.0, "episode_reward": 848.1, "eval_time": 24.493431329727173, "mean_episode_reward": 848.1, "best_episode_reward": 1000.0, "step": 150000}
{"episode": 604.0, "episode_reward": 875.4, "eval_time": 24.251853704452515, "mean_episode_reward": 875.4, "best_episode_reward": 1000.0, "step": 151000}
{"episode": 608.0, "episode_reward": 970.4, "eval_time": 24.233017683029175, "mean_episode_reward": 970.4, "best_episode_reward": 1000.0, "step": 152000}
{"episode": 612.0, "episode_reward": 882.6, "eval_time": 24.809348821640015, "mean_episode_reward": 882.6, "best_episode_reward": 998.0, "step": 153000}
{"episode": 616.0, "episode_reward": 979.6, "eval_time": 24.632427215576172, "mean_episode_reward": 979.6, "best_episode_reward": 1000.0, "step": 154000}
{"episode": 620.0, "episode_reward": 740.6, "eval_time": 24.259803295135498, "mean_episode_reward": 740.6, "best_episode_reward": 997.0, "step": 155000}
{"episode": 624.0, "episode_reward": 787.5, "eval_time": 24.228500843048096, "mean_episode_reward": 787.5, "best_episode_reward": 1000.0, "step": 156000}
{"episode": 628.0, "episode_reward": 975.0, "eval_time": 23.87883496284485, "mean_episode_reward": 975.0, "best_episode_reward": 990.0, "step": 157000}
{"episode": 632.0, "episode_reward": 973.0, "eval_time": 23.947545289993286, "mean_episode_reward": 973.0, "best_episode_reward": 1000.0, "step": 158000}
{"episode": 636.0, "episode_reward": 892.6, "eval_time": 23.64839005470276, "mean_episode_reward": 892.6, "best_episode_reward": 999.0, "step": 159000}
{"episode": 640.0, "episode_reward": 786.1, "eval_time": 24.244281768798828, "mean_episode_reward": 786.1, "best_episode_reward": 993.0, "step": 160000}
{"episode": 644.0, "episode_reward": 875.1, "eval_time": 24.472894430160522, "mean_episode_reward": 875.1, "best_episode_reward": 990.0, "step": 161000}
{"episode": 648.0, "episode_reward": 884.7, "eval_time": 23.905756950378418, "mean_episode_reward": 884.7, "best_episode_reward": 998.0, "step": 162000}
{"episode": 652.0, "episode_reward": 972.8, "eval_time": 24.290204286575317, "mean_episode_reward": 972.8, "best_episode_reward": 997.0, "step": 163000}
{"episode": 656.0, "episode_reward": 875.5, "eval_time": 24.051672220230103, "mean_episode_reward": 875.5, "best_episode_reward": 998.0, "step": 164000}
{"episode": 660.0, "episode_reward": 877.2, "eval_time": 24.0408296585083, "mean_episode_reward": 877.2, "best_episode_reward": 986.0, "step": 165000}
{"episode": 664.0, "episode_reward": 784.1, "eval_time": 24.143471717834473, "mean_episode_reward": 784.1, "best_episode_reward": 980.0, "step": 166000}
{"episode": 668.0, "episode_reward": 874.5, "eval_time": 24.258164644241333, "mean_episode_reward": 874.5, "best_episode_reward": 995.0, "step": 167000}
{"episode": 672.0, "episode_reward": 875.7, "eval_time": 24.161171674728394, "mean_episode_reward": 875.7, "best_episode_reward": 1000.0, "step": 168000}
{"episode": 676.0, "episode_reward": 871.6, "eval_time": 24.570961475372314, "mean_episode_reward": 871.6, "best_episode_reward": 1000.0, "step": 169000}
{"episode": 680.0, "episode_reward": 778.0, "eval_time": 23.964131116867065, "mean_episode_reward": 778.0, "best_episode_reward": 992.0, "step": 170000}
{"episode": 684.0, "episode_reward": 961.6, "eval_time": 24.452120780944824, "mean_episode_reward": 961.6, "best_episode_reward": 991.0, "step": 171000}
{"episode": 688.0, "episode_reward": 960.0, "eval_time": 23.750468969345093, "mean_episode_reward": 960.0, "best_episode_reward": 998.0, "step": 172000}
{"episode": 692.0, "episode_reward": 793.1, "eval_time": 24.813302516937256, "mean_episode_reward": 793.1, "best_episode_reward": 1000.0, "step": 173000}
{"episode": 696.0, "episode_reward": 869.4, "eval_time": 23.960575103759766, "mean_episode_reward": 869.4, "best_episode_reward": 994.0, "step": 174000}
{"episode": 700.0, "episode_reward": 968.8, "eval_time": 24.125631093978882, "mean_episode_reward": 968.8, "best_episode_reward": 994.0, "step": 175000}
{"episode": 704.0, "episode_reward": 875.6, "eval_time": 26.20830750465393, "mean_episode_reward": 875.6, "best_episode_reward": 1000.0, "step": 176000}
{"episode": 708.0, "episode_reward": 780.0, "eval_time": 24.090476989746094, "mean_episode_reward": 780.0, "best_episode_reward": 988.0, "step": 177000}
{"episode": 712.0, "episode_reward": 981.2, "eval_time": 23.449891805648804, "mean_episode_reward": 981.2, "best_episode_reward": 1000.0, "step": 178000}
{"episode": 716.0, "episode_reward": 875.0, "eval_time": 24.783804655075073, "mean_episode_reward": 875.0, "best_episode_reward": 999.0, "step": 179000}
{"episode": 720.0, "episode_reward": 879.4, "eval_time": 25.133761405944824, "mean_episode_reward": 879.4, "best_episode_reward": 994.0, "step": 180000}
{"episode": 724.0, "episode_reward": 885.0, "eval_time": 24.610807418823242, "mean_episode_reward": 885.0, "best_episode_reward": 995.0, "step": 181000}
{"episode": 728.0, "episode_reward": 977.4, "eval_time": 25.014002323150635, "mean_episode_reward": 977.4, "best_episode_reward": 992.0, "step": 182000}
{"episode": 732.0, "episode_reward": 940.3, "eval_time": 24.523974180221558, "mean_episode_reward": 940.3, "best_episode_reward": 1000.0, "step": 183000}
{"episode": 736.0, "episode_reward": 770.0, "eval_time": 24.93133306503296, "mean_episode_reward": 770.0, "best_episode_reward": 1000.0, "step": 184000}
{"episode": 740.0, "episode_reward": 876.3, "eval_time": 24.33210253715515, "mean_episode_reward": 876.3, "best_episode_reward": 984.0, "step": 185000}
{"episode": 744.0, "episode_reward": 982.5, "eval_time": 24.58223843574524, "mean_episode_reward": 982.5, "best_episode_reward": 996.0, "step": 186000}
{"episode": 748.0, "episode_reward": 870.7, "eval_time": 24.904011726379395, "mean_episode_reward": 870.7, "best_episode_reward": 980.0, "step": 187000}
{"episode": 752.0, "episode_reward": 878.7, "eval_time": 24.876681089401245, "mean_episode_reward": 878.7, "best_episode_reward": 993.0, "step": 188000}
{"episode": 756.0, "episode_reward": 876.5, "eval_time": 24.842260360717773, "mean_episode_reward": 876.5, "best_episode_reward": 998.0, "step": 189000}
{"episode": 760.0, "episode_reward": 977.9, "eval_time": 24.46634840965271, "mean_episode_reward": 977.9, "best_episode_reward": 1000.0, "step": 190000}
{"episode": 764.0, "episode_reward": 885.0, "eval_time": 24.557021856307983, "mean_episode_reward": 885.0, "best_episode_reward": 1000.0, "step": 191000}
{"episode": 768.0, "episode_reward": 970.6, "eval_time": 24.473861932754517, "mean_episode_reward": 970.6, "best_episode_reward": 985.0, "step": 192000}
{"episode": 772.0, "episode_reward": 874.9, "eval_time": 24.80482792854309, "mean_episode_reward": 874.9, "best_episode_reward": 988.0, "step": 193000}
{"episode": 776.0, "episode_reward": 877.7, "eval_time": 24.208516597747803, "mean_episode_reward": 877.7, "best_episode_reward": 994.0, "step": 194000}
{"episode": 780.0, "episode_reward": 754.9, "eval_time": 24.222683668136597, "mean_episode_reward": 754.9, "best_episode_reward": 976.0, "step": 195000}
{"episode": 784.0, "episode_reward": 789.2, "eval_time": 24.607120513916016, "mean_episode_reward": 789.2, "best_episode_reward": 990.0, "step": 196000}
{"episode": 788.0, "episode_reward": 873.0, "eval_time": 24.449885606765747, "mean_episode_reward": 873.0, "best_episode_reward": 998.0, "step": 197000}
{"episode": 792.0, "episode_reward": 976.4, "eval_time": 24.54107666015625, "mean_episode_reward": 976.4, "best_episode_reward": 1000.0, "step": 198000}
{"episode": 796.0, "episode_reward": 880.3, "eval_time": 24.290183544158936, "mean_episode_reward": 880.3, "best_episode_reward": 997.0, "step": 199000}
{"episode": 800.0, "episode_reward": 799.9, "eval_time": 24.563355684280396, "mean_episode_reward": 799.9, "best_episode_reward": 991.0, "step": 200000}
{"episode": 804.0, "episode_reward": 926.1, "eval_time": 24.63179063796997, "mean_episode_reward": 926.1, "best_episode_reward": 990.0, "step": 201000}
{"episode": 808.0, "episode_reward": 871.8, "eval_time": 25.01974892616272, "mean_episode_reward": 871.8, "best_episode_reward": 997.0, "step": 202000}
{"episode": 812.0, "episode_reward": 689.4, "eval_time": 24.349603414535522, "mean_episode_reward": 689.4, "best_episode_reward": 1000.0, "step": 203000}
{"episode": 816.0, "episode_reward": 979.7, "eval_time": 24.642956972122192, "mean_episode_reward": 979.7, "best_episode_reward": 995.0, "step": 204000}
{"episode": 820.0, "episode_reward": 973.5, "eval_time": 24.540027856826782, "mean_episode_reward": 973.5, "best_episode_reward": 982.0, "step": 205000}
{"episode": 824.0, "episode_reward": 864.9, "eval_time": 24.533289670944214, "mean_episode_reward": 864.9, "best_episode_reward": 989.0, "step": 206000}
{"episode": 828.0, "episode_reward": 970.9, "eval_time": 25.055981397628784, "mean_episode_reward": 970.9, "best_episode_reward": 994.0, "step": 207000}
{"episode": 832.0, "episode_reward": 879.7, "eval_time": 24.785393238067627, "mean_episode_reward": 879.7, "best_episode_reward": 993.0, "step": 208000}
{"episode": 836.0, "episode_reward": 768.1, "eval_time": 24.50512981414795, "mean_episode_reward": 768.1, "best_episode_reward": 989.0, "step": 209000}
{"episode": 840.0, "episode_reward": 878.8, "eval_time": 24.96190571784973, "mean_episode_reward": 878.8, "best_episode_reward": 991.0, "step": 210000}
{"episode": 844.0, "episode_reward": 877.1, "eval_time": 24.455100774765015, "mean_episode_reward": 877.1, "best_episode_reward": 995.0, "step": 211000}
{"episode": 848.0, "episode_reward": 879.1, "eval_time": 24.552356481552124, "mean_episode_reward": 879.1, "best_episode_reward": 993.0, "step": 212000}
{"episode": 852.0, "episode_reward": 970.6, "eval_time": 24.3996639251709, "mean_episode_reward": 970.6, "best_episode_reward": 1000.0, "step": 213000}
{"episode": 856.0, "episode_reward": 885.9, "eval_time": 24.47610878944397, "mean_episode_reward": 885.9, "best_episode_reward": 1000.0, "step": 214000}
{"episode": 860.0, "episode_reward": 973.0, "eval_time": 24.20746684074402, "mean_episode_reward": 973.0, "best_episode_reward": 999.0, "step": 215000}
{"episode": 864.0, "episode_reward": 973.9, "eval_time": 23.903266191482544, "mean_episode_reward": 973.9, "best_episode_reward": 1000.0, "step": 216000}
{"episode": 868.0, "episode_reward": 794.4, "eval_time": 24.441653728485107, "mean_episode_reward": 794.4, "best_episode_reward": 997.0, "step": 217000}
{"episode": 872.0, "episode_reward": 714.5, "eval_time": 24.151808977127075, "mean_episode_reward": 714.5, "best_episode_reward": 1000.0, "step": 218000}
{"episode": 876.0, "episode_reward": 780.1, "eval_time": 24.61517024040222, "mean_episode_reward": 780.1, "best_episode_reward": 999.0, "step": 219000}
{"episode": 880.0, "episode_reward": 682.5, "eval_time": 24.255704164505005, "mean_episode_reward": 682.5, "best_episode_reward": 993.0, "step": 220000}
{"episode": 884.0, "episode_reward": 975.8, "eval_time": 24.513177633285522, "mean_episode_reward": 975.8, "best_episode_reward": 992.0, "step": 221000}
{"episode": 888.0, "episode_reward": 826.0, "eval_time": 24.522829055786133, "mean_episode_reward": 826.0, "best_episode_reward": 991.0, "step": 222000}
{"episode": 892.0, "episode_reward": 866.1, "eval_time": 24.932889461517334, "mean_episode_reward": 866.1, "best_episode_reward": 997.0, "step": 223000}
{"episode": 896.0, "episode_reward": 859.6, "eval_time": 24.65708327293396, "mean_episode_reward": 859.6, "best_episode_reward": 994.0, "step": 224000}
{"episode": 900.0, "episode_reward": 879.4, "eval_time": 24.519843578338623, "mean_episode_reward": 879.4, "best_episode_reward": 990.0, "step": 225000}
{"episode": 904.0, "episode_reward": 876.9, "eval_time": 24.372321844100952, "mean_episode_reward": 876.9, "best_episode_reward": 989.0, "step": 226000}
{"episode": 908.0, "episode_reward": 881.7, "eval_time": 24.112921953201294, "mean_episode_reward": 881.7, "best_episode_reward": 998.0, "step": 227000}
{"episode": 912.0, "episode_reward": 872.2, "eval_time": 24.55432915687561, "mean_episode_reward": 872.2, "best_episode_reward": 991.0, "step": 228000}
{"episode": 916.0, "episode_reward": 875.7, "eval_time": 23.98197650909424, "mean_episode_reward": 875.7, "best_episode_reward": 992.0, "step": 229000}
{"episode": 920.0, "episode_reward": 973.4, "eval_time": 24.0936439037323, "mean_episode_reward": 973.4, "best_episode_reward": 988.0, "step": 230000}
{"episode": 924.0, "episode_reward": 860.1, "eval_time": 23.672275066375732, "mean_episode_reward": 860.1, "best_episode_reward": 1000.0, "step": 231000}
{"episode": 928.0, "episode_reward": 974.5, "eval_time": 24.450026035308838, "mean_episode_reward": 974.5, "best_episode_reward": 998.0, "step": 232000}
{"episode": 932.0, "episode_reward": 771.0, "eval_time": 23.918795824050903, "mean_episode_reward": 771.0, "best_episode_reward": 978.0, "step": 233000}
{"episode": 936.0, "episode_reward": 969.2, "eval_time": 24.594030618667603, "mean_episode_reward": 969.2, "best_episode_reward": 982.0, "step": 234000}
{"episode": 940.0, "episode_reward": 979.0, "eval_time": 24.079935789108276, "mean_episode_reward": 979.0, "best_episode_reward": 985.0, "step": 235000}
{"episode": 944.0, "episode_reward": 706.8, "eval_time": 24.415851831436157, "mean_episode_reward": 706.8, "best_episode_reward": 1000.0, "step": 236000}
{"episode": 948.0, "episode_reward": 972.3, "eval_time": 23.90446138381958, "mean_episode_reward": 972.3, "best_episode_reward": 993.0, "step": 237000}
{"episode": 952.0, "episode_reward": 965.4, "eval_time": 23.900951147079468, "mean_episode_reward": 965.4, "best_episode_reward": 988.0, "step": 238000}
{"episode": 956.0, "episode_reward": 871.8, "eval_time": 24.461350440979004, "mean_episode_reward": 871.8, "best_episode_reward": 981.0, "step": 239000}
{"episode": 960.0, "episode_reward": 876.1, "eval_time": 24.053998470306396, "mean_episode_reward": 876.1, "best_episode_reward": 998.0, "step": 240000}
{"episode": 964.0, "episode_reward": 882.7, "eval_time": 23.99545431137085, "mean_episode_reward": 882.7, "best_episode_reward": 996.0, "step": 241000}
{"episode": 968.0, "episode_reward": 977.2, "eval_time": 23.86168360710144, "mean_episode_reward": 977.2, "best_episode_reward": 997.0, "step": 242000}
{"episode": 972.0, "episode_reward": 973.4, "eval_time": 24.436984539031982, "mean_episode_reward": 973.4, "best_episode_reward": 993.0, "step": 243000}
{"episode": 976.0, "episode_reward": 959.7, "eval_time": 24.475587129592896, "mean_episode_reward": 959.7, "best_episode_reward": 1000.0, "step": 244000}
{"episode": 980.0, "episode_reward": 907.8, "eval_time": 24.22564935684204, "mean_episode_reward": 907.8, "best_episode_reward": 1000.0, "step": 245000}
{"episode": 984.0, "episode_reward": 888.5, "eval_time": 24.274932384490967, "mean_episode_reward": 888.5, "best_episode_reward": 1000.0, "step": 246000}
{"episode": 988.0, "episode_reward": 971.2, "eval_time": 23.68504023551941, "mean_episode_reward": 971.2, "best_episode_reward": 988.0, "step": 247000}
{"episode": 992.0, "episode_reward": 974.0, "eval_time": 24.007906436920166, "mean_episode_reward": 974.0, "best_episode_reward": 989.0, "step": 248000}
{"episode": 996.0, "episode_reward": 766.8, "eval_time": 24.08612322807312, "mean_episode_reward": 766.8, "best_episode_reward": 985.0, "step": 249000}
{"episode": 1000.0, "episode_reward": 873.1, "eval_time": 23.837785959243774, "mean_episode_reward": 873.1, "best_episode_reward": 1000.0, "step": 250000}
{"episode": 1004.0, "episode_reward": 879.7, "eval_time": 24.419145584106445, "mean_episode_reward": 879.7, "best_episode_reward": 993.0, "step": 251000}
{"episode": 1008.0, "episode_reward": 872.7, "eval_time": 23.736247301101685, "mean_episode_reward": 872.7, "best_episode_reward": 983.0, "step": 252000}
{"episode": 1012.0, "episode_reward": 874.8, "eval_time": 24.41808009147644, "mean_episode_reward": 874.8, "best_episode_reward": 986.0, "step": 253000}
{"episode": 1016.0, "episode_reward": 794.9, "eval_time": 24.212462425231934, "mean_episode_reward": 794.9, "best_episode_reward": 999.0, "step": 254000}
{"episode": 1020.0, "episode_reward": 979.9, "eval_time": 23.53656554222107, "mean_episode_reward": 979.9, "best_episode_reward": 996.0, "step": 255000}
{"episode": 1024.0, "episode_reward": 968.6, "eval_time": 23.66652536392212, "mean_episode_reward": 968.6, "best_episode_reward": 993.0, "step": 256000}
{"episode": 1028.0, "episode_reward": 889.6, "eval_time": 24.354668140411377, "mean_episode_reward": 889.6, "best_episode_reward": 995.0, "step": 257000}
{"episode": 1032.0, "episode_reward": 968.6, "eval_time": 24.15412974357605, "mean_episode_reward": 968.6, "best_episode_reward": 988.0, "step": 258000}
{"episode": 1036.0, "episode_reward": 856.2, "eval_time": 23.62773585319519, "mean_episode_reward": 856.2, "best_episode_reward": 980.0, "step": 259000}
{"episode": 1040.0, "episode_reward": 874.7, "eval_time": 23.771281719207764, "mean_episode_reward": 874.7, "best_episode_reward": 993.0, "step": 260000}
{"episode": 1044.0, "episode_reward": 883.2, "eval_time": 24.462780475616455, "mean_episode_reward": 883.2, "best_episode_reward": 992.0, "step": 261000}
{"episode": 1048.0, "episode_reward": 968.6, "eval_time": 24.16950249671936, "mean_episode_reward": 968.6, "best_episode_reward": 998.0, "step": 262000}
{"episode": 1052.0, "episode_reward": 973.0, "eval_time": 24.403830766677856, "mean_episode_reward": 973.0, "best_episode_reward": 984.0, "step": 263000}
{"episode": 1056.0, "episode_reward": 880.5, "eval_time": 24.240010023117065, "mean_episode_reward": 880.5, "best_episode_reward": 1000.0, "step": 264000}
{"episode": 1060.0, "episode_reward": 884.0, "eval_time": 24.244107484817505, "mean_episode_reward": 884.0, "best_episode_reward": 1000.0, "step": 265000}
{"episode": 1064.0, "episode_reward": 776.9, "eval_time": 23.95062518119812, "mean_episode_reward": 776.9, "best_episode_reward": 978.0, "step": 266000}
{"episode": 1068.0, "episode_reward": 884.6, "eval_time": 24.12853693962097, "mean_episode_reward": 884.6, "best_episode_reward": 1000.0, "step": 267000}
{"episode": 1072.0, "episode_reward": 976.2, "eval_time": 24.259660959243774, "mean_episode_reward": 976.2, "best_episode_reward": 995.0, "step": 268000}
{"episode": 1076.0, "episode_reward": 981.2, "eval_time": 24.257308959960938, "mean_episode_reward": 981.2, "best_episode_reward": 1000.0, "step": 269000}
{"episode": 1080.0, "episode_reward": 879.4, "eval_time": 23.386964082717896, "mean_episode_reward": 879.4, "best_episode_reward": 996.0, "step": 270000}
{"episode": 1084.0, "episode_reward": 883.9, "eval_time": 24.380553245544434, "mean_episode_reward": 883.9, "best_episode_reward": 996.0, "step": 271000}
{"episode": 1088.0, "episode_reward": 975.2, "eval_time": 24.157517910003662, "mean_episode_reward": 975.2, "best_episode_reward": 991.0, "step": 272000}
{"episode": 1092.0, "episode_reward": 887.1, "eval_time": 24.031514644622803, "mean_episode_reward": 887.1, "best_episode_reward": 998.0, "step": 273000}
{"episode": 1096.0, "episode_reward": 974.3, "eval_time": 23.86894178390503, "mean_episode_reward": 974.3, "best_episode_reward": 988.0, "step": 274000}
{"episode": 1100.0, "episode_reward": 965.6, "eval_time": 23.75422763824463, "mean_episode_reward": 965.6, "best_episode_reward": 988.0, "step": 275000}
{"episode": 1104.0, "episode_reward": 885.4, "eval_time": 23.585819482803345, "mean_episode_reward": 885.4, "best_episode_reward": 984.0, "step": 276000}
{"episode": 1108.0, "episode_reward": 873.8, "eval_time": 23.62413740158081, "mean_episode_reward": 873.8, "best_episode_reward": 993.0, "step": 277000}
{"episode": 1112.0, "episode_reward": 785.9, "eval_time": 24.594298601150513, "mean_episode_reward": 785.9, "best_episode_reward": 1000.0, "step": 278000}
{"episode": 1116.0, "episode_reward": 977.4, "eval_time": 24.04800796508789, "mean_episode_reward": 977.4, "best_episode_reward": 996.0, "step": 279000}
{"episode": 1120.0, "episode_reward": 965.6, "eval_time": 23.622752904891968, "mean_episode_reward": 965.6, "best_episode_reward": 1000.0, "step": 280000}
{"episode": 1124.0, "episode_reward": 981.7, "eval_time": 23.984197854995728, "mean_episode_reward": 981.7, "best_episode_reward": 1000.0, "step": 281000}
{"episode": 1128.0, "episode_reward": 970.6, "eval_time": 23.681426525115967, "mean_episode_reward": 970.6, "best_episode_reward": 1000.0, "step": 282000}
{"episode": 1132.0, "episode_reward": 971.7, "eval_time": 24.096815586090088, "mean_episode_reward": 971.7, "best_episode_reward": 987.0, "step": 283000}
{"episode": 1136.0, "episode_reward": 785.4, "eval_time": 23.783592462539673, "mean_episode_reward": 785.4, "best_episode_reward": 996.0, "step": 284000}
{"episode": 1140.0, "episode_reward": 978.8, "eval_time": 24.6280255317688, "mean_episode_reward": 978.8, "best_episode_reward": 994.0, "step": 285000}
{"episode": 1144.0, "episode_reward": 888.6, "eval_time": 25.283571004867554, "mean_episode_reward": 888.6, "best_episode_reward": 993.0, "step": 286000}
{"episode": 1148.0, "episode_reward": 875.8, "eval_time": 24.873087406158447, "mean_episode_reward": 875.8, "best_episode_reward": 995.0, "step": 287000}
{"episode": 1152.0, "episode_reward": 966.9, "eval_time": 26.048250913619995, "mean_episode_reward": 966.9, "best_episode_reward": 990.0, "step": 288000}
{"episode": 1156.0, "episode_reward": 975.3, "eval_time": 26.55975651741028, "mean_episode_reward": 975.3, "best_episode_reward": 1000.0, "step": 289000}
{"episode": 1160.0, "episode_reward": 876.6, "eval_time": 27.690160512924194, "mean_episode_reward": 876.6, "best_episode_reward": 1000.0, "step": 290000}
{"episode": 1164.0, "episode_reward": 784.6, "eval_time": 26.538845539093018, "mean_episode_reward": 784.6, "best_episode_reward": 989.0, "step": 291000}
{"episode": 1168.0, "episode_reward": 979.9, "eval_time": 26.153809785842896, "mean_episode_reward": 979.9, "best_episode_reward": 996.0, "step": 292000}
{"episode": 1172.0, "episode_reward": 873.7, "eval_time": 26.405118703842163, "mean_episode_reward": 873.7, "best_episode_reward": 982.0, "step": 293000}
{"episode": 1176.0, "episode_reward": 880.0, "eval_time": 26.93266773223877, "mean_episode_reward": 880.0, "best_episode_reward": 984.0, "step": 294000}
{"episode": 1180.0, "episode_reward": 969.4, "eval_time": 27.32205104827881, "mean_episode_reward": 969.4, "best_episode_reward": 993.0, "step": 295000}
{"episode": 1184.0, "episode_reward": 979.1, "eval_time": 27.276829719543457, "mean_episode_reward": 979.1, "best_episode_reward": 1000.0, "step": 296000}
{"episode": 1188.0, "episode_reward": 883.4, "eval_time": 26.903830766677856, "mean_episode_reward": 883.4, "best_episode_reward": 1000.0, "step": 297000}
{"episode": 1192.0, "episode_reward": 759.6, "eval_time": 26.87666130065918, "mean_episode_reward": 759.6, "best_episode_reward": 1000.0, "step": 298000}
{"episode": 1196.0, "episode_reward": 968.9, "eval_time": 27.2662832736969, "mean_episode_reward": 968.9, "best_episode_reward": 1000.0, "step": 299000}
{"episode": 1200.0, "episode_reward": 882.2, "eval_time": 27.04679274559021, "mean_episode_reward": 882.2, "best_episode_reward": 996.0, "step": 300000}
{"episode": 1204.0, "episode_reward": 764.3, "eval_time": 27.615259647369385, "mean_episode_reward": 764.3, "best_episode_reward": 997.0, "step": 301000}
{"episode": 1208.0, "episode_reward": 775.6, "eval_time": 27.452434539794922, "mean_episode_reward": 775.6, "best_episode_reward": 991.0, "step": 302000}
{"episode": 1212.0, "episode_reward": 881.8, "eval_time": 27.474531412124634, "mean_episode_reward": 881.8, "best_episode_reward": 993.0, "step": 303000}
{"episode": 1216.0, "episode_reward": 971.9, "eval_time": 27.805707693099976, "mean_episode_reward": 971.9, "best_episode_reward": 990.0, "step": 304000}
{"episode": 1220.0, "episode_reward": 789.0, "eval_time": 27.64191961288452, "mean_episode_reward": 789.0, "best_episode_reward": 999.0, "step": 305000}
{"episode": 1224.0, "episode_reward": 879.4, "eval_time": 27.129873752593994, "mean_episode_reward": 879.4, "best_episode_reward": 994.0, "step": 306000}
{"episode": 1228.0, "episode_reward": 807.4, "eval_time": 27.59401035308838, "mean_episode_reward": 807.4, "best_episode_reward": 1000.0, "step": 307000}
{"episode": 1232.0, "episode_reward": 974.4, "eval_time": 27.750072717666626, "mean_episode_reward": 974.4, "best_episode_reward": 995.0, "step": 308000}
{"episode": 1236.0, "episode_reward": 952.1, "eval_time": 27.36608076095581, "mean_episode_reward": 952.1, "best_episode_reward": 1000.0, "step": 309000}
{"episode": 1240.0, "episode_reward": 973.2, "eval_time": 27.723185300827026, "mean_episode_reward": 973.2, "best_episode_reward": 1000.0, "step": 310000}
{"episode": 1244.0, "episode_reward": 874.9, "eval_time": 27.172601461410522, "mean_episode_reward": 874.9, "best_episode_reward": 997.0, "step": 311000}
{"episode": 1248.0, "episode_reward": 878.9, "eval_time": 27.523910760879517, "mean_episode_reward": 878.9, "best_episode_reward": 1000.0, "step": 312000}
{"episode": 1252.0, "episode_reward": 960.4, "eval_time": 26.081479787826538, "mean_episode_reward": 960.4, "best_episode_reward": 988.0, "step": 313000}
{"episode": 1256.0, "episode_reward": 782.5, "eval_time": 24.9930899143219, "mean_episode_reward": 782.5, "best_episode_reward": 1000.0, "step": 314000}
{"episode": 1260.0, "episode_reward": 980.6, "eval_time": 25.181123733520508, "mean_episode_reward": 980.6, "best_episode_reward": 999.0, "step": 315000}
{"episode": 1264.0, "episode_reward": 964.9, "eval_time": 25.12150239944458, "mean_episode_reward": 964.9, "best_episode_reward": 990.0, "step": 316000}
{"episode": 1268.0, "episode_reward": 735.3, "eval_time": 25.249149084091187, "mean_episode_reward": 735.3, "best_episode_reward": 988.0, "step": 317000}
{"episode": 1272.0, "episode_reward": 775.7, "eval_time": 24.387914419174194, "mean_episode_reward": 775.7, "best_episode_reward": 998.0, "step": 318000}
{"episode": 1276.0, "episode_reward": 971.9, "eval_time": 25.438740968704224, "mean_episode_reward": 971.9, "best_episode_reward": 991.0, "step": 319000}
{"episode": 1280.0, "episode_reward": 889.3, "eval_time": 24.58833122253418, "mean_episode_reward": 889.3, "best_episode_reward": 992.0, "step": 320000}
{"episode": 1284.0, "episode_reward": 973.3, "eval_time": 24.796149969100952, "mean_episode_reward": 973.3, "best_episode_reward": 995.0, "step": 321000}
{"episode": 1288.0, "episode_reward": 888.9, "eval_time": 24.45440912246704, "mean_episode_reward": 888.9, "best_episode_reward": 1000.0, "step": 322000}
{"episode": 1292.0, "episode_reward": 972.9, "eval_time": 24.600237369537354, "mean_episode_reward": 972.9, "best_episode_reward": 999.0, "step": 323000}
{"episode": 1296.0, "episode_reward": 976.6, "eval_time": 28.410205602645874, "mean_episode_reward": 976.6, "best_episode_reward": 994.0, "step": 324000}
{"episode": 1300.0, "episode_reward": 868.8, "eval_time": 39.22126245498657, "mean_episode_reward": 868.8, "best_episode_reward": 1000.0, "step": 325000}
{"episode": 1304.0, "episode_reward": 985.6, "eval_time": 24.48029112815857, "mean_episode_reward": 985.6, "best_episode_reward": 998.0, "step": 326000}
{"episode": 1308.0, "episode_reward": 975.0, "eval_time": 48.21941137313843, "mean_episode_reward": 975.0, "best_episode_reward": 1000.0, "step": 327000}
{"episode": 1312.0, "episode_reward": 888.8, "eval_time": 24.349883556365967, "mean_episode_reward": 888.8, "best_episode_reward": 1000.0, "step": 328000}
{"episode": 1316.0, "episode_reward": 969.9, "eval_time": 33.5671603679657, "mean_episode_reward": 969.9, "best_episode_reward": 999.0, "step": 329000}
{"episode": 1320.0, "episode_reward": 935.3, "eval_time": 38.73061203956604, "mean_episode_reward": 935.3, "best_episode_reward": 984.0, "step": 330000}
{"episode": 1324.0, "episode_reward": 973.5, "eval_time": 27.11021614074707, "mean_episode_reward": 973.5, "best_episode_reward": 998.0, "step": 331000}
{"episode": 1328.0, "episode_reward": 976.4, "eval_time": 52.12216901779175, "mean_episode_reward": 976.4, "best_episode_reward": 1000.0, "step": 332000}
{"episode": 1332.0, "episode_reward": 959.3, "eval_time": 27.549968004226685, "mean_episode_reward": 959.3, "best_episode_reward": 985.0, "step": 333000}
{"episode": 1336.0, "episode_reward": 979.6, "eval_time": 27.571523427963257, "mean_episode_reward": 979.6, "best_episode_reward": 994.0, "step": 334000}
{"episode": 1340.0, "episode_reward": 981.9, "eval_time": 51.37337255477905, "mean_episode_reward": 981.9, "best_episode_reward": 994.0, "step": 335000}
{"episode": 1344.0, "episode_reward": 871.2, "eval_time": 26.921949863433838, "mean_episode_reward": 871.2, "best_episode_reward": 979.0, "step": 336000}
{"episode": 1348.0, "episode_reward": 979.1, "eval_time": 35.22040247917175, "mean_episode_reward": 979.1, "best_episode_reward": 993.0, "step": 337000}
{"episode": 1352.0, "episode_reward": 880.9, "eval_time": 43.133368730545044, "mean_episode_reward": 880.9, "best_episode_reward": 1000.0, "step": 338000}
{"episode": 1356.0, "episode_reward": 976.4, "eval_time": 27.610240697860718, "mean_episode_reward": 976.4, "best_episode_reward": 1000.0, "step": 339000}
{"episode": 1360.0, "episode_reward": 978.6, "eval_time": 42.112388610839844, "mean_episode_reward": 978.6, "best_episode_reward": 1000.0, "step": 340000}
{"episode": 1364.0, "episode_reward": 979.0, "eval_time": 53.83944916725159, "mean_episode_reward": 979.0, "best_episode_reward": 996.0, "step": 341000}
{"episode": 1368.0, "episode_reward": 974.2, "eval_time": 27.485608339309692, "mean_episode_reward": 974.2, "best_episode_reward": 999.0, "step": 342000}
{"episode": 1372.0, "episode_reward": 876.9, "eval_time": 33.07521677017212, "mean_episode_reward": 876.9, "best_episode_reward": 1000.0, "step": 343000}
{"episode": 1376.0, "episode_reward": 953.2, "eval_time": 46.498059034347534, "mean_episode_reward": 953.2, "best_episode_reward": 992.0, "step": 344000}
{"episode": 1380.0, "episode_reward": 619.4, "eval_time": 25.6691951751709, "mean_episode_reward": 619.4, "best_episode_reward": 998.0, "step": 345000}
{"episode": 1384.0, "episode_reward": 884.7, "eval_time": 32.54564952850342, "mean_episode_reward": 884.7, "best_episode_reward": 997.0, "step": 346000}
{"episode": 1388.0, "episode_reward": 878.9, "eval_time": 50.98128628730774, "mean_episode_reward": 878.9, "best_episode_reward": 996.0, "step": 347000}
{"episode": 1392.0, "episode_reward": 977.0, "eval_time": 29.787417888641357, "mean_episode_reward": 977.0, "best_episode_reward": 1000.0, "step": 348000}
{"episode": 1396.0, "episode_reward": 976.5, "eval_time": 44.42279648780823, "mean_episode_reward": 976.5, "best_episode_reward": 983.0, "step": 349000}
{"episode": 1400.0, "episode_reward": 869.2, "eval_time": 27.279925107955933, "mean_episode_reward": 869.2, "best_episode_reward": 992.0, "step": 350000}
{"episode": 1404.0, "episode_reward": 914.0, "eval_time": 25.062347888946533, "mean_episode_reward": 914.0, "best_episode_reward": 1000.0, "step": 351000}
{"episode": 1408.0, "episode_reward": 980.9, "eval_time": 24.93889093399048, "mean_episode_reward": 980.9, "best_episode_reward": 990.0, "step": 352000}
{"episode": 1412.0, "episode_reward": 982.1, "eval_time": 25.053419828414917, "mean_episode_reward": 982.1, "best_episode_reward": 1000.0, "step": 353000}
{"episode": 1416.0, "episode_reward": 981.8, "eval_time": 24.99033808708191, "mean_episode_reward": 981.8, "best_episode_reward": 999.0, "step": 354000}
{"episode": 1420.0, "episode_reward": 878.6, "eval_time": 24.497318267822266, "mean_episode_reward": 878.6, "best_episode_reward": 993.0, "step": 355000}
{"episode": 1424.0, "episode_reward": 973.8, "eval_time": 24.550695657730103, "mean_episode_reward": 973.8, "best_episode_reward": 982.0, "step": 356000}
{"episode": 1428.0, "episode_reward": 979.5, "eval_time": 24.655869007110596, "mean_episode_reward": 979.5, "best_episode_reward": 999.0, "step": 357000}
{"episode": 1432.0, "episode_reward": 793.1, "eval_time": 25.153070211410522, "mean_episode_reward": 793.1, "best_episode_reward": 986.0, "step": 358000}
{"episode": 1436.0, "episode_reward": 968.7, "eval_time": 24.561087131500244, "mean_episode_reward": 968.7, "best_episode_reward": 1000.0, "step": 359000}
{"episode": 1440.0, "episode_reward": 684.9, "eval_time": 24.632917404174805, "mean_episode_reward": 684.9, "best_episode_reward": 985.0, "step": 360000}
{"episode": 1444.0, "episode_reward": 982.2, "eval_time": 24.49472188949585, "mean_episode_reward": 982.2, "best_episode_reward": 1000.0, "step": 361000}
{"episode": 1448.0, "episode_reward": 962.0, "eval_time": 24.630404710769653, "mean_episode_reward": 962.0, "best_episode_reward": 990.0, "step": 362000}
{"episode": 1452.0, "episode_reward": 836.7, "eval_time": 24.770397424697876, "mean_episode_reward": 836.7, "best_episode_reward": 1000.0, "step": 363000}
{"episode": 1456.0, "episode_reward": 971.9, "eval_time": 24.709028959274292, "mean_episode_reward": 971.9, "best_episode_reward": 996.0, "step": 364000}
{"episode": 1460.0, "episode_reward": 983.0, "eval_time": 24.672005653381348, "mean_episode_reward": 983.0, "best_episode_reward": 1000.0, "step": 365000}
{"episode": 1464.0, "episode_reward": 690.2, "eval_time": 25.195093631744385, "mean_episode_reward": 690.2, "best_episode_reward": 998.0, "step": 366000}
{"episode": 1468.0, "episode_reward": 830.5, "eval_time": 24.127150058746338, "mean_episode_reward": 830.5, "best_episode_reward": 993.0, "step": 367000}
{"episode": 1472.0, "episode_reward": 774.8, "eval_time": 24.1110360622406, "mean_episode_reward": 774.8, "best_episode_reward": 985.0, "step": 368000}
{"episode": 1476.0, "episode_reward": 880.9, "eval_time": 23.83630895614624, "mean_episode_reward": 880.9, "best_episode_reward": 1000.0, "step": 369000}
{"episode": 1480.0, "episode_reward": 876.4, "eval_time": 24.08224391937256, "mean_episode_reward": 876.4, "best_episode_reward": 986.0, "step": 370000}
{"episode": 1484.0, "episode_reward": 881.2, "eval_time": 23.405437231063843, "mean_episode_reward": 881.2, "best_episode_reward": 996.0, "step": 371000}
{"episode": 1488.0, "episode_reward": 870.9, "eval_time": 24.793242931365967, "mean_episode_reward": 870.9, "best_episode_reward": 991.0, "step": 372000}
{"episode": 1492.0, "episode_reward": 886.5, "eval_time": 24.36091637611389, "mean_episode_reward": 886.5, "best_episode_reward": 998.0, "step": 373000}
{"episode": 1496.0, "episode_reward": 971.8, "eval_time": 24.45105743408203, "mean_episode_reward": 971.8, "best_episode_reward": 1000.0, "step": 374000}
{"episode": 1500.0, "episode_reward": 860.1, "eval_time": 24.00625467300415, "mean_episode_reward": 860.1, "best_episode_reward": 995.0, "step": 375000}
{"episode": 1504.0, "episode_reward": 975.6, "eval_time": 24.409632205963135, "mean_episode_reward": 975.6, "best_episode_reward": 1000.0, "step": 376000}
{"episode": 1508.0, "episode_reward": 881.9, "eval_time": 23.290313005447388, "mean_episode_reward": 881.9, "best_episode_reward": 995.0, "step": 377000}
{"episode": 1512.0, "episode_reward": 981.2, "eval_time": 24.725110292434692, "mean_episode_reward": 981.2, "best_episode_reward": 1000.0, "step": 378000}
{"episode": 1516.0, "episode_reward": 965.0, "eval_time": 23.34688901901245, "mean_episode_reward": 965.0, "best_episode_reward": 983.0, "step": 379000}
{"episode": 1520.0, "episode_reward": 986.3, "eval_time": 23.68470859527588, "mean_episode_reward": 986.3, "best_episode_reward": 1000.0, "step": 380000}
{"episode": 1524.0, "episode_reward": 916.1, "eval_time": 24.08316993713379, "mean_episode_reward": 916.1, "best_episode_reward": 1000.0, "step": 381000}
{"episode": 1528.0, "episode_reward": 921.8, "eval_time": 23.474987983703613, "mean_episode_reward": 921.8, "best_episode_reward": 995.0, "step": 382000}
{"episode": 1532.0, "episode_reward": 698.7, "eval_time": 23.5538547039032, "mean_episode_reward": 698.7, "best_episode_reward": 999.0, "step": 383000}
{"episode": 1536.0, "episode_reward": 885.4, "eval_time": 23.04099464416504, "mean_episode_reward": 885.4, "best_episode_reward": 1000.0, "step": 384000}
{"episode": 1540.0, "episode_reward": 871.8, "eval_time": 23.869974851608276, "mean_episode_reward": 871.8, "best_episode_reward": 987.0, "step": 385000}
{"episode": 1544.0, "episode_reward": 875.1, "eval_time": 24.464792490005493, "mean_episode_reward": 875.1, "best_episode_reward": 985.0, "step": 386000}
{"episode": 1548.0, "episode_reward": 885.4, "eval_time": 23.2617027759552, "mean_episode_reward": 885.4, "best_episode_reward": 1000.0, "step": 387000}
{"episode": 1552.0, "episode_reward": 979.1, "eval_time": 22.98301410675049, "mean_episode_reward": 979.1, "best_episode_reward": 1000.0, "step": 388000}
{"episode": 1556.0, "episode_reward": 787.3, "eval_time": 23.588330507278442, "mean_episode_reward": 787.3, "best_episode_reward": 1000.0, "step": 389000}
{"episode": 1560.0, "episode_reward": 888.6, "eval_time": 23.505021333694458, "mean_episode_reward": 888.6, "best_episode_reward": 1000.0, "step": 390000}
{"episode": 1564.0, "episode_reward": 979.6, "eval_time": 23.34228777885437, "mean_episode_reward": 979.6, "best_episode_reward": 1000.0, "step": 391000}
{"episode": 1568.0, "episode_reward": 743.0, "eval_time": 22.44351840019226, "mean_episode_reward": 743.0, "best_episode_reward": 989.0, "step": 392000}
{"episode": 1572.0, "episode_reward": 788.3, "eval_time": 22.638550519943237, "mean_episode_reward": 788.3, "best_episode_reward": 1000.0, "step": 393000}
{"episode": 1576.0, "episode_reward": 744.4, "eval_time": 23.923205852508545, "mean_episode_reward": 744.4, "best_episode_reward": 993.0, "step": 394000}
{"episode": 1580.0, "episode_reward": 785.8, "eval_time": 23.0220627784729, "mean_episode_reward": 785.8, "best_episode_reward": 981.0, "step": 395000}
{"episode": 1584.0, "episode_reward": 966.0, "eval_time": 23.2304904460907, "mean_episode_reward": 966.0, "best_episode_reward": 988.0, "step": 396000}
{"episode": 1588.0, "episode_reward": 876.5, "eval_time": 23.807239055633545, "mean_episode_reward": 876.5, "best_episode_reward": 995.0, "step": 397000}
{"episode": 1592.0, "episode_reward": 876.8, "eval_time": 22.362791299819946, "mean_episode_reward": 876.8, "best_episode_reward": 992.0, "step": 398000}
{"episode": 1596.0, "episode_reward": 879.4, "eval_time": 24.05706262588501, "mean_episode_reward": 879.4, "best_episode_reward": 994.0, "step": 399000}
{"episode": 1600.0, "episode_reward": 970.3, "eval_time": 23.885331869125366, "mean_episode_reward": 970.3, "best_episode_reward": 989.0, "step": 400000}
{"episode": 1604.0, "episode_reward": 965.6, "eval_time": 24.667240142822266, "mean_episode_reward": 965.6, "best_episode_reward": 1000.0, "step": 401000}
{"episode": 1608.0, "episode_reward": 879.3, "eval_time": 25.636240005493164, "mean_episode_reward": 879.3, "best_episode_reward": 983.0, "step": 402000}
{"episode": 1612.0, "episode_reward": 977.6, "eval_time": 26.30259132385254, "mean_episode_reward": 977.6, "best_episode_reward": 991.0, "step": 403000}
{"episode": 1616.0, "episode_reward": 979.2, "eval_time": 41.8197386264801, "mean_episode_reward": 979.2, "best_episode_reward": 1000.0, "step": 404000}
{"episode": 1620.0, "episode_reward": 983.4, "eval_time": 47.354363441467285, "mean_episode_reward": 983.4, "best_episode_reward": 1000.0, "step": 405000}
{"episode": 1624.0, "episode_reward": 979.3, "eval_time": 46.01425790786743, "mean_episode_reward": 979.3, "best_episode_reward": 998.0, "step": 406000}
{"episode": 1628.0, "episode_reward": 974.2, "eval_time": 46.232839584350586, "mean_episode_reward": 974.2, "best_episode_reward": 1000.0, "step": 407000}
{"episode": 1632.0, "episode_reward": 976.7, "eval_time": 49.723169803619385, "mean_episode_reward": 976.7, "best_episode_reward": 1000.0, "step": 408000}
{"episode": 1636.0, "episode_reward": 972.2, "eval_time": 51.41315174102783, "mean_episode_reward": 972.2, "best_episode_reward": 1000.0, "step": 409000}
{"episode": 1640.0, "episode_reward": 976.8, "eval_time": 51.89116430282593, "mean_episode_reward": 976.8, "best_episode_reward": 999.0, "step": 410000}
{"episode": 1644.0, "episode_reward": 971.8, "eval_time": 47.94548559188843, "mean_episode_reward": 971.8, "best_episode_reward": 1000.0, "step": 411000}
{"episode": 1648.0, "episode_reward": 879.8, "eval_time": 48.93927884101868, "mean_episode_reward": 879.8, "best_episode_reward": 995.0, "step": 412000}
{"episode": 1652.0, "episode_reward": 966.1, "eval_time": 48.35989451408386, "mean_episode_reward": 966.1, "best_episode_reward": 996.0, "step": 413000}
{"episode": 1656.0, "episode_reward": 979.5, "eval_time": 50.35343885421753, "mean_episode_reward": 979.5, "best_episode_reward": 1000.0, "step": 414000}
{"episode": 1660.0, "episode_reward": 978.6, "eval_time": 50.412437438964844, "mean_episode_reward": 978.6, "best_episode_reward": 1000.0, "step": 415000}
{"episode": 1664.0, "episode_reward": 967.0, "eval_time": 52.49018168449402, "mean_episode_reward": 967.0, "best_episode_reward": 977.0, "step": 416000}
{"episode": 1668.0, "episode_reward": 886.1, "eval_time": 51.77914643287659, "mean_episode_reward": 886.1, "best_episode_reward": 995.0, "step": 417000}
{"episode": 1672.0, "episode_reward": 982.3, "eval_time": 66.69493627548218, "mean_episode_reward": 982.3, "best_episode_reward": 1000.0, "step": 418000}
{"episode": 1676.0, "episode_reward": 946.6, "eval_time": 63.23001027107239, "mean_episode_reward": 946.6, "best_episode_reward": 998.0, "step": 419000}
{"episode": 1680.0, "episode_reward": 964.3, "eval_time": 64.79089713096619, "mean_episode_reward": 964.3, "best_episode_reward": 998.0, "step": 420000}
{"episode": 1684.0, "episode_reward": 981.3, "eval_time": 59.63340449333191, "mean_episode_reward": 981.3, "best_episode_reward": 1000.0, "step": 421000}
{"episode": 1688.0, "episode_reward": 981.3, "eval_time": 51.86140990257263, "mean_episode_reward": 981.3, "best_episode_reward": 1000.0, "step": 422000}
{"episode": 1692.0, "episode_reward": 980.9, "eval_time": 47.714762449264526, "mean_episode_reward": 980.9, "best_episode_reward": 1000.0, "step": 423000}
{"episode": 1696.0, "episode_reward": 924.2, "eval_time": 92.76167368888855, "mean_episode_reward": 924.2, "best_episode_reward": 988.0, "step": 424000}
{"episode": 1700.0, "episode_reward": 895.5, "eval_time": 89.82639336585999, "mean_episode_reward": 895.5, "best_episode_reward": 998.0, "step": 425000}
{"episode": 1704.0, "episode_reward": 851.3, "eval_time": 85.58868646621704, "mean_episode_reward": 851.3, "best_episode_reward": 986.0, "step": 426000}
{"episode": 1708.0, "episode_reward": 979.0, "eval_time": 87.2238199710846, "mean_episode_reward": 979.0, "best_episode_reward": 994.0, "step": 427000}
{"episode": 1712.0, "episode_reward": 695.5, "eval_time": 86.35893726348877, "mean_episode_reward": 695.5, "best_episode_reward": 1000.0, "step": 428000}
{"episode": 1716.0, "episode_reward": 977.9, "eval_time": 89.30771136283875, "mean_episode_reward": 977.9, "best_episode_reward": 995.0, "step": 429000}
{"episode": 1720.0, "episode_reward": 799.4, "eval_time": 84.76540064811707, "mean_episode_reward": 799.4, "best_episode_reward": 991.0, "step": 430000}
{"episode": 1724.0, "episode_reward": 877.9, "eval_time": 79.2821204662323, "mean_episode_reward": 877.9, "best_episode_reward": 999.0, "step": 431000}
{"episode": 1728.0, "episode_reward": 923.2, "eval_time": 81.73168611526489, "mean_episode_reward": 923.2, "best_episode_reward": 1000.0, "step": 432000}
{"episode": 1732.0, "episode_reward": 976.1, "eval_time": 77.37266063690186, "mean_episode_reward": 976.1, "best_episode_reward": 1000.0, "step": 433000}
{"episode": 1736.0, "episode_reward": 977.8, "eval_time": 78.52431297302246, "mean_episode_reward": 977.8, "best_episode_reward": 1000.0, "step": 434000}
{"episode": 1740.0, "episode_reward": 975.3, "eval_time": 78.07791757583618, "mean_episode_reward": 975.3, "best_episode_reward": 1000.0, "step": 435000}
{"episode": 1744.0, "episode_reward": 798.9, "eval_time": 88.0762529373169, "mean_episode_reward": 798.9, "best_episode_reward": 997.0, "step": 436000}
{"episode": 1748.0, "episode_reward": 973.8, "eval_time": 87.82397127151489, "mean_episode_reward": 973.8, "best_episode_reward": 997.0, "step": 437000}
{"episode": 1752.0, "episode_reward": 977.5, "eval_time": 96.2059371471405, "mean_episode_reward": 977.5, "best_episode_reward": 1000.0, "step": 438000}
{"episode": 1756.0, "episode_reward": 975.7, "eval_time": 95.85355496406555, "mean_episode_reward": 975.7, "best_episode_reward": 989.0, "step": 439000}
{"episode": 1760.0, "episode_reward": 930.8, "eval_time": 90.77296447753906, "mean_episode_reward": 930.8, "best_episode_reward": 990.0, "step": 440000}
{"episode": 1764.0, "episode_reward": 880.5, "eval_time": 88.87995958328247, "mean_episode_reward": 880.5, "best_episode_reward": 988.0, "step": 441000}
{"episode": 1768.0, "episode_reward": 883.3, "eval_time": 94.4981210231781, "mean_episode_reward": 883.3, "best_episode_reward": 1000.0, "step": 442000}
{"episode": 1772.0, "episode_reward": 982.8, "eval_time": 92.5948486328125, "mean_episode_reward": 982.8, "best_episode_reward": 1000.0, "step": 443000}
{"episode": 1776.0, "episode_reward": 881.3, "eval_time": 90.58290767669678, "mean_episode_reward": 881.3, "best_episode_reward": 994.0, "step": 444000}
{"episode": 1780.0, "episode_reward": 978.1, "eval_time": 84.84666204452515, "mean_episode_reward": 978.1, "best_episode_reward": 1000.0, "step": 445000}
{"episode": 1784.0, "episode_reward": 979.1, "eval_time": 80.6542956829071, "mean_episode_reward": 979.1, "best_episode_reward": 987.0, "step": 446000}
{"episode": 1788.0, "episode_reward": 868.0, "eval_time": 84.12793064117432, "mean_episode_reward": 868.0, "best_episode_reward": 1000.0, "step": 447000}
{"episode": 1792.0, "episode_reward": 869.2, "eval_time": 88.01121544837952, "mean_episode_reward": 869.2, "best_episode_reward": 982.0, "step": 448000}
{"episode": 1796.0, "episode_reward": 776.4, "eval_time": 90.90128374099731, "mean_episode_reward": 776.4, "best_episode_reward": 990.0, "step": 449000}
{"episode": 1800.0, "episode_reward": 966.8, "eval_time": 79.64144015312195, "mean_episode_reward": 966.8, "best_episode_reward": 990.0, "step": 450000}
{"episode": 1804.0, "episode_reward": 974.4, "eval_time": 75.11410927772522, "mean_episode_reward": 974.4, "best_episode_reward": 995.0, "step": 451000}
{"episode": 1808.0, "episode_reward": 876.5, "eval_time": 81.92323660850525, "mean_episode_reward": 876.5, "best_episode_reward": 1000.0, "step": 452000}
{"episode": 1812.0, "episode_reward": 860.8, "eval_time": 85.61745953559875, "mean_episode_reward": 860.8, "best_episode_reward": 986.0, "step": 453000}
{"episode": 1816.0, "episode_reward": 974.4, "eval_time": 93.4962990283966, "mean_episode_reward": 974.4, "best_episode_reward": 991.0, "step": 454000}
{"episode": 1820.0, "episode_reward": 975.3, "eval_time": 104.19059109687805, "mean_episode_reward": 975.3, "best_episode_reward": 1000.0, "step": 455000}
{"episode": 1824.0, "episode_reward": 870.7, "eval_time": 99.47278642654419, "mean_episode_reward": 870.7, "best_episode_reward": 997.0, "step": 456000}
{"episode": 1828.0, "episode_reward": 967.6, "eval_time": 107.06679201126099, "mean_episode_reward": 967.6, "best_episode_reward": 986.0, "step": 457000}
{"episode": 1832.0, "episode_reward": 978.4, "eval_time": 103.74260759353638, "mean_episode_reward": 978.4, "best_episode_reward": 993.0, "step": 458000}
{"episode": 1836.0, "episode_reward": 980.9, "eval_time": 95.46685528755188, "mean_episode_reward": 980.9, "best_episode_reward": 992.0, "step": 459000}
{"episode": 1840.0, "episode_reward": 972.3, "eval_time": 91.86510181427002, "mean_episode_reward": 972.3, "best_episode_reward": 1000.0, "step": 460000}
{"episode": 1844.0, "episode_reward": 788.3, "eval_time": 100.212233543396, "mean_episode_reward": 788.3, "best_episode_reward": 1000.0, "step": 461000}
{"episode": 1848.0, "episode_reward": 982.2, "eval_time": 83.66234040260315, "mean_episode_reward": 982.2, "best_episode_reward": 1000.0, "step": 462000}
{"episode": 1852.0, "episode_reward": 827.1, "eval_time": 88.91596031188965, "mean_episode_reward": 827.1, "best_episode_reward": 992.0, "step": 463000}
{"episode": 1856.0, "episode_reward": 712.4, "eval_time": 86.17588663101196, "mean_episode_reward": 712.4, "best_episode_reward": 995.0, "step": 464000}
{"episode": 1860.0, "episode_reward": 693.3, "eval_time": 81.97582221031189, "mean_episode_reward": 693.3, "best_episode_reward": 989.0, "step": 465000}
{"episode": 1864.0, "episode_reward": 884.1, "eval_time": 87.07288122177124, "mean_episode_reward": 884.1, "best_episode_reward": 999.0, "step": 466000}
{"episode": 1868.0, "episode_reward": 676.8, "eval_time": 70.89438319206238, "mean_episode_reward": 676.8, "best_episode_reward": 977.0, "step": 467000}
{"episode": 1872.0, "episode_reward": 964.9, "eval_time": 75.4715416431427, "mean_episode_reward": 964.9, "best_episode_reward": 991.0, "step": 468000}
{"episode": 1876.0, "episode_reward": 789.0, "eval_time": 78.05945634841919, "mean_episode_reward": 789.0, "best_episode_reward": 1000.0, "step": 469000}
{"episode": 1880.0, "episode_reward": 853.0, "eval_time": 92.85538458824158, "mean_episode_reward": 853.0, "best_episode_reward": 999.0, "step": 470000}
{"episode": 1884.0, "episode_reward": 878.2, "eval_time": 97.21990299224854, "mean_episode_reward": 878.2, "best_episode_reward": 1000.0, "step": 471000}
{"episode": 1888.0, "episode_reward": 785.7, "eval_time": 82.4098105430603, "mean_episode_reward": 785.7, "best_episode_reward": 994.0, "step": 472000}
{"episode": 1892.0, "episode_reward": 864.0, "eval_time": 69.57415771484375, "mean_episode_reward": 864.0, "best_episode_reward": 1000.0, "step": 473000}
{"episode": 1896.0, "episode_reward": 879.4, "eval_time": 87.44944858551025, "mean_episode_reward": 879.4, "best_episode_reward": 993.0, "step": 474000}
{"episode": 1900.0, "episode_reward": 878.4, "eval_time": 90.069091796875, "mean_episode_reward": 878.4, "best_episode_reward": 998.0, "step": 475000}
{"episode": 1904.0, "episode_reward": 877.8, "eval_time": 70.14501714706421, "mean_episode_reward": 877.8, "best_episode_reward": 1000.0, "step": 476000}
{"episode": 1908.0, "episode_reward": 890.8, "eval_time": 69.72160506248474, "mean_episode_reward": 890.8, "best_episode_reward": 996.0, "step": 477000}
{"episode": 1912.0, "episode_reward": 784.5, "eval_time": 94.3064181804657, "mean_episode_reward": 784.5, "best_episode_reward": 995.0, "step": 478000}
{"episode": 1916.0, "episode_reward": 589.1, "eval_time": 83.88946533203125, "mean_episode_reward": 589.1, "best_episode_reward": 995.0, "step": 479000}
{"episode": 1920.0, "episode_reward": 880.4, "eval_time": 91.42473554611206, "mean_episode_reward": 880.4, "best_episode_reward": 1000.0, "step": 480000}
{"episode": 1924.0, "episode_reward": 966.2, "eval_time": 92.10931158065796, "mean_episode_reward": 966.2, "best_episode_reward": 995.0, "step": 481000}
{"episode": 1928.0, "episode_reward": 775.2, "eval_time": 93.192862033844, "mean_episode_reward": 775.2, "best_episode_reward": 1000.0, "step": 482000}
{"episode": 1932.0, "episode_reward": 972.4, "eval_time": 92.060231924057, "mean_episode_reward": 972.4, "best_episode_reward": 1000.0, "step": 483000}
{"episode": 1936.0, "episode_reward": 780.3, "eval_time": 89.93340110778809, "mean_episode_reward": 780.3, "best_episode_reward": 987.0, "step": 484000}
{"episode": 1940.0, "episode_reward": 601.0, "eval_time": 86.55029797554016, "mean_episode_reward": 601.0, "best_episode_reward": 1000.0, "step": 485000}
{"episode": 1944.0, "episode_reward": 877.5, "eval_time": 89.28937292098999, "mean_episode_reward": 877.5, "best_episode_reward": 1000.0, "step": 486000}
{"episode": 1948.0, "episode_reward": 785.4, "eval_time": 85.28868055343628, "mean_episode_reward": 785.4, "best_episode_reward": 1000.0, "step": 487000}
{"episode": 1952.0, "episode_reward": 685.7, "eval_time": 83.28916478157043, "mean_episode_reward": 685.7, "best_episode_reward": 994.0, "step": 488000}
{"episode": 1956.0, "episode_reward": 698.9, "eval_time": 101.49445223808289, "mean_episode_reward": 698.9, "best_episode_reward": 1000.0, "step": 489000}
{"episode": 1960.0, "episode_reward": 760.2, "eval_time": 95.91418075561523, "mean_episode_reward": 760.2, "best_episode_reward": 1000.0, "step": 490000}
{"episode": 1964.0, "episode_reward": 782.0, "eval_time": 103.53774070739746, "mean_episode_reward": 782.0, "best_episode_reward": 997.0, "step": 491000}
{"episode": 1968.0, "episode_reward": 772.0, "eval_time": 100.21399974822998, "mean_episode_reward": 772.0, "best_episode_reward": 987.0, "step": 492000}
{"episode": 1972.0, "episode_reward": 879.6, "eval_time": 70.55587768554688, "mean_episode_reward": 879.6, "best_episode_reward": 994.0, "step": 493000}
{"episode": 1976.0, "episode_reward": 884.4, "eval_time": 97.99185395240784, "mean_episode_reward": 884.4, "best_episode_reward": 1000.0, "step": 494000}
{"episode": 1980.0, "episode_reward": 975.9, "eval_time": 69.08633518218994, "mean_episode_reward": 975.9, "best_episode_reward": 1000.0, "step": 495000}
{"episode": 1984.0, "episode_reward": 977.3, "eval_time": 60.83088779449463, "mean_episode_reward": 977.3, "best_episode_reward": 998.0, "step": 496000}
{"episode": 1988.0, "episode_reward": 786.4, "eval_time": 71.68905711174011, "mean_episode_reward": 786.4, "best_episode_reward": 1000.0, "step": 497000}
{"episode": 1992.0, "episode_reward": 787.4, "eval_time": 67.65904259681702, "mean_episode_reward": 787.4, "best_episode_reward": 1000.0, "step": 498000}
{"episode": 1996.0, "episode_reward": 509.1, "eval_time": 72.59291577339172, "mean_episode_reward": 509.1, "best_episode_reward": 990.0, "step": 499000}
