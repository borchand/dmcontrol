{"episode": 0.0, "episode_reward": 0.0, "eval_time": 251.00040411949158, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 0}
{"episode": 2.0, "episode_reward": 0.0, "eval_time": 236.63193154335022, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 1000}
{"episode": 4.0, "episode_reward": 0.0, "eval_time": 230.47440791130066, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 2000}
{"episode": 6.0, "episode_reward": 0.0, "eval_time": 246.04174041748047, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 3000}
{"episode": 8.0, "episode_reward": 0.0, "eval_time": 243.55014443397522, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 4000}
{"episode": 10.0, "episode_reward": 0.0, "eval_time": 214.59570407867432, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 5000}
{"episode": 12.0, "episode_reward": 0.0, "eval_time": 257.7120192050934, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 6000}
{"episode": 14.0, "episode_reward": 0.0, "eval_time": 242.8711712360382, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 7000}
{"episode": 16.0, "episode_reward": 0.0, "eval_time": 217.9428210258484, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 8000}
{"episode": 18.0, "episode_reward": 0.0, "eval_time": 209.60157370567322, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 9000}
{"episode": 20.0, "episode_reward": 0.0, "eval_time": 225.58345580101013, "mean_episode_reward": 0.0, "best_episode_reward": 0.0, "step": 10000}
{"episode": 22.0, "episode_reward": 8.0, "eval_time": 213.28624987602234, "mean_episode_reward": 8.0, "best_episode_reward": 28.0, "step": 11000}
{"episode": 24.0, "episode_reward": 101.1, "eval_time": 192.21102929115295, "mean_episode_reward": 101.1, "best_episode_reward": 126.0, "step": 12000}
{"episode": 26.0, "episode_reward": 361.3, "eval_time": 159.41817092895508, "mean_episode_reward": 361.3, "best_episode_reward": 407.0, "step": 13000}
{"episode": 28.0, "episode_reward": 298.3, "eval_time": 198.08620595932007, "mean_episode_reward": 298.3, "best_episode_reward": 320.0, "step": 14000}
{"episode": 30.0, "episode_reward": 480.9, "eval_time": 202.77633619308472, "mean_episode_reward": 480.9, "best_episode_reward": 500.0, "step": 15000}
{"episode": 32.0, "episode_reward": 552.9, "eval_time": 215.51990342140198, "mean_episode_reward": 552.9, "best_episode_reward": 594.0, "step": 16000}
{"episode": 34.0, "episode_reward": 608.4, "eval_time": 212.42149829864502, "mean_episode_reward": 608.4, "best_episode_reward": 637.0, "step": 17000}
{"episode": 36.0, "episode_reward": 595.6, "eval_time": 214.11926126480103, "mean_episode_reward": 595.6, "best_episode_reward": 640.0, "step": 18000}
{"episode": 38.0, "episode_reward": 721.6, "eval_time": 184.23292231559753, "mean_episode_reward": 721.6, "best_episode_reward": 755.0, "step": 19000}
{"episode": 40.0, "episode_reward": 715.8, "eval_time": 172.95855236053467, "mean_episode_reward": 715.8, "best_episode_reward": 752.0, "step": 20000}
{"episode": 42.0, "episode_reward": 772.3, "eval_time": 172.442467212677, "mean_episode_reward": 772.3, "best_episode_reward": 812.0, "step": 21000}
{"episode": 44.0, "episode_reward": 780.1, "eval_time": 158.23650789260864, "mean_episode_reward": 780.1, "best_episode_reward": 805.0, "step": 22000}
{"episode": 46.0, "episode_reward": 794.9, "eval_time": 168.96870374679565, "mean_episode_reward": 794.9, "best_episode_reward": 824.0, "step": 23000}
{"episode": 48.0, "episode_reward": 787.3, "eval_time": 167.67884254455566, "mean_episode_reward": 787.3, "best_episode_reward": 820.0, "step": 24000}
{"episode": 50.0, "episode_reward": 766.5, "eval_time": 110.03633499145508, "mean_episode_reward": 766.5, "best_episode_reward": 790.0, "step": 25000}
{"episode": 52.0, "episode_reward": 807.1, "eval_time": 106.50091791152954, "mean_episode_reward": 807.1, "best_episode_reward": 824.0, "step": 26000}
{"episode": 54.0, "episode_reward": 790.4, "eval_time": 106.92269515991211, "mean_episode_reward": 790.4, "best_episode_reward": 813.0, "step": 27000}
{"episode": 56.0, "episode_reward": 816.3, "eval_time": 126.65483522415161, "mean_episode_reward": 816.3, "best_episode_reward": 841.0, "step": 28000}
{"episode": 58.0, "episode_reward": 797.2, "eval_time": 119.41296410560608, "mean_episode_reward": 797.2, "best_episode_reward": 820.0, "step": 29000}
{"episode": 60.0, "episode_reward": 797.9, "eval_time": 178.65242791175842, "mean_episode_reward": 797.9, "best_episode_reward": 807.0, "step": 30000}
{"episode": 62.0, "episode_reward": 804.4, "eval_time": 132.73326563835144, "mean_episode_reward": 804.4, "best_episode_reward": 822.0, "step": 31000}
{"episode": 64.0, "episode_reward": 860.2, "eval_time": 178.0717625617981, "mean_episode_reward": 860.2, "best_episode_reward": 871.0, "step": 32000}
{"episode": 66.0, "episode_reward": 802.4, "eval_time": 142.06083393096924, "mean_episode_reward": 802.4, "best_episode_reward": 825.0, "step": 33000}
{"episode": 68.0, "episode_reward": 857.1, "eval_time": 195.75597167015076, "mean_episode_reward": 857.1, "best_episode_reward": 865.0, "step": 34000}
{"episode": 70.0, "episode_reward": 835.3, "eval_time": 157.4434778690338, "mean_episode_reward": 835.3, "best_episode_reward": 848.0, "step": 35000}
{"episode": 72.0, "episode_reward": 851.7, "eval_time": 165.55999660491943, "mean_episode_reward": 851.7, "best_episode_reward": 865.0, "step": 36000}
{"episode": 74.0, "episode_reward": 790.8, "eval_time": 156.0871684551239, "mean_episode_reward": 790.8, "best_episode_reward": 828.0, "step": 37000}
{"episode": 76.0, "episode_reward": 858.4, "eval_time": 172.72152590751648, "mean_episode_reward": 858.4, "best_episode_reward": 867.0, "step": 38000}
{"episode": 78.0, "episode_reward": 855.2, "eval_time": 198.60205817222595, "mean_episode_reward": 855.2, "best_episode_reward": 866.0, "step": 39000}
{"episode": 80.0, "episode_reward": 855.8, "eval_time": 138.364807844162, "mean_episode_reward": 855.8, "best_episode_reward": 867.0, "step": 40000}
{"episode": 82.0, "episode_reward": 851.3, "eval_time": 178.9547941684723, "mean_episode_reward": 851.3, "best_episode_reward": 862.0, "step": 41000}
{"episode": 84.0, "episode_reward": 861.5, "eval_time": 120.50360321998596, "mean_episode_reward": 861.5, "best_episode_reward": 874.0, "step": 42000}
{"episode": 86.0, "episode_reward": 855.8, "eval_time": 179.9863224029541, "mean_episode_reward": 855.8, "best_episode_reward": 870.0, "step": 43000}
{"episode": 88.0, "episode_reward": 859.2, "eval_time": 153.30397391319275, "mean_episode_reward": 859.2, "best_episode_reward": 867.0, "step": 44000}
{"episode": 90.0, "episode_reward": 855.6, "eval_time": 192.3081669807434, "mean_episode_reward": 855.6, "best_episode_reward": 863.0, "step": 45000}
{"episode": 92.0, "episode_reward": 859.6, "eval_time": 174.5368628501892, "mean_episode_reward": 859.6, "best_episode_reward": 873.0, "step": 46000}
{"episode": 94.0, "episode_reward": 860.9, "eval_time": 134.6834375858307, "mean_episode_reward": 860.9, "best_episode_reward": 869.0, "step": 47000}
{"episode": 96.0, "episode_reward": 858.9, "eval_time": 175.91371273994446, "mean_episode_reward": 858.9, "best_episode_reward": 870.0, "step": 48000}
{"episode": 98.0, "episode_reward": 870.9, "eval_time": 157.2763397693634, "mean_episode_reward": 870.9, "best_episode_reward": 891.0, "step": 49000}
{"episode": 100.0, "episode_reward": 873.9, "eval_time": 186.4396049976349, "mean_episode_reward": 873.9, "best_episode_reward": 913.0, "step": 50000}
{"episode": 102.0, "episode_reward": 864.1, "eval_time": 139.38469123840332, "mean_episode_reward": 864.1, "best_episode_reward": 881.0, "step": 51000}
{"episode": 104.0, "episode_reward": 853.6, "eval_time": 177.37672328948975, "mean_episode_reward": 853.6, "best_episode_reward": 866.0, "step": 52000}
{"episode": 106.0, "episode_reward": 861.8, "eval_time": 125.11741590499878, "mean_episode_reward": 861.8, "best_episode_reward": 876.0, "step": 53000}
{"episode": 108.0, "episode_reward": 866.2, "eval_time": 151.49883675575256, "mean_episode_reward": 866.2, "best_episode_reward": 881.0, "step": 54000}
{"episode": 110.0, "episode_reward": 889.7, "eval_time": 158.71632075309753, "mean_episode_reward": 889.7, "best_episode_reward": 899.0, "step": 55000}
{"episode": 112.0, "episode_reward": 839.8, "eval_time": 156.75357604026794, "mean_episode_reward": 839.8, "best_episode_reward": 871.0, "step": 56000}
{"episode": 114.0, "episode_reward": 865.4, "eval_time": 156.61187434196472, "mean_episode_reward": 865.4, "best_episode_reward": 873.0, "step": 57000}
{"episode": 116.0, "episode_reward": 863.8, "eval_time": 148.9764301776886, "mean_episode_reward": 863.8, "best_episode_reward": 875.0, "step": 58000}
{"episode": 118.0, "episode_reward": 871.1, "eval_time": 145.49904346466064, "mean_episode_reward": 871.1, "best_episode_reward": 894.0, "step": 59000}
{"episode": 120.0, "episode_reward": 893.4, "eval_time": 157.41030287742615, "mean_episode_reward": 893.4, "best_episode_reward": 913.0, "step": 60000}
{"episode": 122.0, "episode_reward": 908.5, "eval_time": 167.75198650360107, "mean_episode_reward": 908.5, "best_episode_reward": 924.0, "step": 61000}
{"episode": 124.0, "episode_reward": 865.9, "eval_time": 139.01522588729858, "mean_episode_reward": 865.9, "best_episode_reward": 874.0, "step": 62000}
{"episode": 126.0, "episode_reward": 878.3, "eval_time": 151.45248985290527, "mean_episode_reward": 878.3, "best_episode_reward": 895.0, "step": 63000}
{"episode": 128.0, "episode_reward": 912.9, "eval_time": 137.36383962631226, "mean_episode_reward": 912.9, "best_episode_reward": 925.0, "step": 64000}
{"episode": 130.0, "episode_reward": 900.8, "eval_time": 140.36705923080444, "mean_episode_reward": 900.8, "best_episode_reward": 914.0, "step": 65000}
{"episode": 132.0, "episode_reward": 882.4, "eval_time": 166.63537979125977, "mean_episode_reward": 882.4, "best_episode_reward": 935.0, "step": 66000}
{"episode": 134.0, "episode_reward": 925.2, "eval_time": 164.4690182209015, "mean_episode_reward": 925.2, "best_episode_reward": 945.0, "step": 67000}
{"episode": 136.0, "episode_reward": 936.9, "eval_time": 148.6299865245819, "mean_episode_reward": 936.9, "best_episode_reward": 948.0, "step": 68000}
{"episode": 138.0, "episode_reward": 973.0, "eval_time": 182.22102761268616, "mean_episode_reward": 973.0, "best_episode_reward": 987.0, "step": 69000}
{"episode": 140.0, "episode_reward": 957.8, "eval_time": 186.34417152404785, "mean_episode_reward": 957.8, "best_episode_reward": 977.0, "step": 70000}
{"episode": 142.0, "episode_reward": 919.5, "eval_time": 175.43136763572693, "mean_episode_reward": 919.5, "best_episode_reward": 935.0, "step": 71000}
{"episode": 144.0, "episode_reward": 914.4, "eval_time": 170.41244435310364, "mean_episode_reward": 914.4, "best_episode_reward": 936.0, "step": 72000}
{"episode": 146.0, "episode_reward": 924.7, "eval_time": 173.86812829971313, "mean_episode_reward": 924.7, "best_episode_reward": 945.0, "step": 73000}
{"episode": 148.0, "episode_reward": 943.5, "eval_time": 178.38134455680847, "mean_episode_reward": 943.5, "best_episode_reward": 951.0, "step": 74000}
{"episode": 150.0, "episode_reward": 927.4, "eval_time": 191.3892002105713, "mean_episode_reward": 927.4, "best_episode_reward": 942.0, "step": 75000}
{"episode": 152.0, "episode_reward": 879.8, "eval_time": 197.28133606910706, "mean_episode_reward": 879.8, "best_episode_reward": 897.0, "step": 76000}
{"episode": 154.0, "episode_reward": 927.8, "eval_time": 193.44940614700317, "mean_episode_reward": 927.8, "best_episode_reward": 989.0, "step": 77000}
{"episode": 156.0, "episode_reward": 938.1, "eval_time": 195.9969663619995, "mean_episode_reward": 938.1, "best_episode_reward": 954.0, "step": 78000}
{"episode": 158.0, "episode_reward": 939.4, "eval_time": 213.06740999221802, "mean_episode_reward": 939.4, "best_episode_reward": 955.0, "step": 79000}
{"episode": 160.0, "episode_reward": 909.7, "eval_time": 322.65366291999817, "mean_episode_reward": 909.7, "best_episode_reward": 920.0, "step": 80000}
{"episode": 162.0, "episode_reward": 979.3, "eval_time": 383.55447578430176, "mean_episode_reward": 979.3, "best_episode_reward": 994.0, "step": 81000}
{"episode": 164.0, "episode_reward": 980.5, "eval_time": 368.37744092941284, "mean_episode_reward": 980.5, "best_episode_reward": 994.0, "step": 82000}
{"episode": 166.0, "episode_reward": 940.5, "eval_time": 354.84792947769165, "mean_episode_reward": 940.5, "best_episode_reward": 947.0, "step": 83000}
{"episode": 168.0, "episode_reward": 935.5, "eval_time": 344.59337639808655, "mean_episode_reward": 935.5, "best_episode_reward": 950.0, "step": 84000}
{"episode": 170.0, "episode_reward": 982.3, "eval_time": 356.026127576828, "mean_episode_reward": 982.3, "best_episode_reward": 991.0, "step": 85000}
{"episode": 172.0, "episode_reward": 960.7, "eval_time": 365.3966658115387, "mean_episode_reward": 960.7, "best_episode_reward": 969.0, "step": 86000}
{"episode": 174.0, "episode_reward": 979.3, "eval_time": 347.695027589798, "mean_episode_reward": 979.3, "best_episode_reward": 994.0, "step": 87000}
{"episode": 176.0, "episode_reward": 983.9, "eval_time": 348.6290509700775, "mean_episode_reward": 983.9, "best_episode_reward": 994.0, "step": 88000}
{"episode": 178.0, "episode_reward": 981.4, "eval_time": 347.9790029525757, "mean_episode_reward": 981.4, "best_episode_reward": 988.0, "step": 89000}
{"episode": 180.0, "episode_reward": 978.6, "eval_time": 356.765344619751, "mean_episode_reward": 978.6, "best_episode_reward": 992.0, "step": 90000}
{"episode": 182.0, "episode_reward": 972.8, "eval_time": 356.36258721351624, "mean_episode_reward": 972.8, "best_episode_reward": 986.0, "step": 91000}
{"episode": 184.0, "episode_reward": 981.4, "eval_time": 357.0153241157532, "mean_episode_reward": 981.4, "best_episode_reward": 988.0, "step": 92000}
{"episode": 186.0, "episode_reward": 983.0, "eval_time": 340.29851746559143, "mean_episode_reward": 983.0, "best_episode_reward": 991.0, "step": 93000}
{"episode": 188.0, "episode_reward": 974.6, "eval_time": 350.8577287197113, "mean_episode_reward": 974.6, "best_episode_reward": 989.0, "step": 94000}
{"episode": 190.0, "episode_reward": 979.8, "eval_time": 364.2196168899536, "mean_episode_reward": 979.8, "best_episode_reward": 990.0, "step": 95000}
{"episode": 192.0, "episode_reward": 984.0, "eval_time": 349.1437110900879, "mean_episode_reward": 984.0, "best_episode_reward": 995.0, "step": 96000}
{"episode": 194.0, "episode_reward": 983.5, "eval_time": 353.79444575309753, "mean_episode_reward": 983.5, "best_episode_reward": 993.0, "step": 97000}
{"episode": 196.0, "episode_reward": 981.8, "eval_time": 342.6371490955353, "mean_episode_reward": 981.8, "best_episode_reward": 990.0, "step": 98000}
{"episode": 198.0, "episode_reward": 979.2, "eval_time": 332.8673405647278, "mean_episode_reward": 979.2, "best_episode_reward": 994.0, "step": 99000}
{"episode": 200.0, "episode_reward": 983.2, "eval_time": 341.78958463668823, "mean_episode_reward": 983.2, "best_episode_reward": 998.0, "step": 100000}
{"episode": 202.0, "episode_reward": 979.3, "eval_time": 355.52367544174194, "mean_episode_reward": 979.3, "best_episode_reward": 989.0, "step": 101000}
{"episode": 204.0, "episode_reward": 983.5, "eval_time": 340.9468574523926, "mean_episode_reward": 983.5, "best_episode_reward": 988.0, "step": 102000}
{"episode": 206.0, "episode_reward": 978.7, "eval_time": 351.942969083786, "mean_episode_reward": 978.7, "best_episode_reward": 988.0, "step": 103000}
{"episode": 208.0, "episode_reward": 985.3, "eval_time": 336.48426604270935, "mean_episode_reward": 985.3, "best_episode_reward": 996.0, "step": 104000}
{"episode": 210.0, "episode_reward": 982.2, "eval_time": 358.13977789878845, "mean_episode_reward": 982.2, "best_episode_reward": 997.0, "step": 105000}
{"episode": 212.0, "episode_reward": 983.5, "eval_time": 364.8180778026581, "mean_episode_reward": 983.5, "best_episode_reward": 995.0, "step": 106000}
{"episode": 214.0, "episode_reward": 983.6, "eval_time": 365.42518520355225, "mean_episode_reward": 983.6, "best_episode_reward": 995.0, "step": 107000}
{"episode": 216.0, "episode_reward": 980.4, "eval_time": 348.37893772125244, "mean_episode_reward": 980.4, "best_episode_reward": 994.0, "step": 108000}
{"episode": 218.0, "episode_reward": 979.8, "eval_time": 335.72414469718933, "mean_episode_reward": 979.8, "best_episode_reward": 992.0, "step": 109000}
{"episode": 220.0, "episode_reward": 983.9, "eval_time": 329.93200755119324, "mean_episode_reward": 983.9, "best_episode_reward": 992.0, "step": 110000}
{"episode": 222.0, "episode_reward": 979.1, "eval_time": 343.7986090183258, "mean_episode_reward": 979.1, "best_episode_reward": 992.0, "step": 111000}
{"episode": 224.0, "episode_reward": 984.8, "eval_time": 341.54348039627075, "mean_episode_reward": 984.8, "best_episode_reward": 991.0, "step": 112000}
{"episode": 226.0, "episode_reward": 984.3, "eval_time": 332.4064154624939, "mean_episode_reward": 984.3, "best_episode_reward": 996.0, "step": 113000}
{"episode": 228.0, "episode_reward": 981.2, "eval_time": 331.171147108078, "mean_episode_reward": 981.2, "best_episode_reward": 993.0, "step": 114000}
{"episode": 230.0, "episode_reward": 979.3, "eval_time": 321.37399315834045, "mean_episode_reward": 979.3, "best_episode_reward": 993.0, "step": 115000}
{"episode": 232.0, "episode_reward": 979.1, "eval_time": 345.0500271320343, "mean_episode_reward": 979.1, "best_episode_reward": 990.0, "step": 116000}
{"episode": 234.0, "episode_reward": 983.9, "eval_time": 356.5015263557434, "mean_episode_reward": 983.9, "best_episode_reward": 994.0, "step": 117000}
{"episode": 236.0, "episode_reward": 981.5, "eval_time": 351.7060377597809, "mean_episode_reward": 981.5, "best_episode_reward": 990.0, "step": 118000}
{"episode": 238.0, "episode_reward": 985.1, "eval_time": 351.36861419677734, "mean_episode_reward": 985.1, "best_episode_reward": 996.0, "step": 119000}
{"episode": 240.0, "episode_reward": 983.5, "eval_time": 342.95448780059814, "mean_episode_reward": 983.5, "best_episode_reward": 993.0, "step": 120000}
{"episode": 242.0, "episode_reward": 983.5, "eval_time": 346.40407705307007, "mean_episode_reward": 983.5, "best_episode_reward": 992.0, "step": 121000}
{"episode": 244.0, "episode_reward": 982.6, "eval_time": 358.33173537254333, "mean_episode_reward": 982.6, "best_episode_reward": 994.0, "step": 122000}
{"episode": 246.0, "episode_reward": 980.8, "eval_time": 337.5374915599823, "mean_episode_reward": 980.8, "best_episode_reward": 996.0, "step": 123000}
{"episode": 248.0, "episode_reward": 982.9, "eval_time": 360.981023311615, "mean_episode_reward": 982.9, "best_episode_reward": 996.0, "step": 124000}
{"episode": 250.0, "episode_reward": 980.6, "eval_time": 324.5415892601013, "mean_episode_reward": 980.6, "best_episode_reward": 988.0, "step": 125000}
{"episode": 252.0, "episode_reward": 981.2, "eval_time": 341.79355239868164, "mean_episode_reward": 981.2, "best_episode_reward": 995.0, "step": 126000}
{"episode": 254.0, "episode_reward": 985.7, "eval_time": 337.45383763313293, "mean_episode_reward": 985.7, "best_episode_reward": 996.0, "step": 127000}
{"episode": 256.0, "episode_reward": 981.6, "eval_time": 340.7639980316162, "mean_episode_reward": 981.6, "best_episode_reward": 987.0, "step": 128000}
{"episode": 258.0, "episode_reward": 982.4, "eval_time": 341.4700312614441, "mean_episode_reward": 982.4, "best_episode_reward": 993.0, "step": 129000}
{"episode": 260.0, "episode_reward": 982.1, "eval_time": 330.2981822490692, "mean_episode_reward": 982.1, "best_episode_reward": 997.0, "step": 130000}
{"episode": 262.0, "episode_reward": 985.2, "eval_time": 332.79021310806274, "mean_episode_reward": 985.2, "best_episode_reward": 994.0, "step": 131000}
{"episode": 264.0, "episode_reward": 982.8, "eval_time": 306.45758390426636, "mean_episode_reward": 982.8, "best_episode_reward": 991.0, "step": 132000}
{"episode": 266.0, "episode_reward": 984.9, "eval_time": 317.1300718784332, "mean_episode_reward": 984.9, "best_episode_reward": 994.0, "step": 133000}
{"episode": 268.0, "episode_reward": 985.4, "eval_time": 310.0562765598297, "mean_episode_reward": 985.4, "best_episode_reward": 993.0, "step": 134000}
{"episode": 270.0, "episode_reward": 983.7, "eval_time": 309.5624005794525, "mean_episode_reward": 983.7, "best_episode_reward": 995.0, "step": 135000}
{"episode": 272.0, "episode_reward": 983.2, "eval_time": 295.1376748085022, "mean_episode_reward": 983.2, "best_episode_reward": 996.0, "step": 136000}
{"episode": 274.0, "episode_reward": 983.6, "eval_time": 319.91850543022156, "mean_episode_reward": 983.6, "best_episode_reward": 996.0, "step": 137000}
{"episode": 276.0, "episode_reward": 979.4, "eval_time": 336.5858619213104, "mean_episode_reward": 979.4, "best_episode_reward": 994.0, "step": 138000}
{"episode": 278.0, "episode_reward": 977.0, "eval_time": 336.6647765636444, "mean_episode_reward": 977.0, "best_episode_reward": 988.0, "step": 139000}
{"episode": 280.0, "episode_reward": 980.9, "eval_time": 336.1792039871216, "mean_episode_reward": 980.9, "best_episode_reward": 994.0, "step": 140000}
{"episode": 282.0, "episode_reward": 981.5, "eval_time": 313.8248870372772, "mean_episode_reward": 981.5, "best_episode_reward": 993.0, "step": 141000}
{"episode": 284.0, "episode_reward": 983.2, "eval_time": 321.4427933692932, "mean_episode_reward": 983.2, "best_episode_reward": 991.0, "step": 142000}
{"episode": 286.0, "episode_reward": 984.9, "eval_time": 341.2959768772125, "mean_episode_reward": 984.9, "best_episode_reward": 998.0, "step": 143000}
{"episode": 288.0, "episode_reward": 981.4, "eval_time": 344.0244867801666, "mean_episode_reward": 981.4, "best_episode_reward": 996.0, "step": 144000}
{"episode": 290.0, "episode_reward": 982.1, "eval_time": 308.25053310394287, "mean_episode_reward": 982.1, "best_episode_reward": 996.0, "step": 145000}
{"episode": 292.0, "episode_reward": 981.0, "eval_time": 329.76252579689026, "mean_episode_reward": 981.0, "best_episode_reward": 993.0, "step": 146000}
{"episode": 294.0, "episode_reward": 981.2, "eval_time": 372.7135157585144, "mean_episode_reward": 981.2, "best_episode_reward": 992.0, "step": 147000}
{"episode": 296.0, "episode_reward": 985.3, "eval_time": 375.59675455093384, "mean_episode_reward": 985.3, "best_episode_reward": 992.0, "step": 148000}
{"episode": 298.0, "episode_reward": 883.6, "eval_time": 363.15871024131775, "mean_episode_reward": 883.6, "best_episode_reward": 986.0, "step": 149000}
{"episode": 300.0, "episode_reward": 986.5, "eval_time": 349.907452583313, "mean_episode_reward": 986.5, "best_episode_reward": 998.0, "step": 150000}
{"episode": 302.0, "episode_reward": 981.5, "eval_time": 355.90781688690186, "mean_episode_reward": 981.5, "best_episode_reward": 989.0, "step": 151000}
{"episode": 304.0, "episode_reward": 985.8, "eval_time": 380.6297528743744, "mean_episode_reward": 985.8, "best_episode_reward": 996.0, "step": 152000}
{"episode": 306.0, "episode_reward": 983.3, "eval_time": 365.7441403865814, "mean_episode_reward": 983.3, "best_episode_reward": 992.0, "step": 153000}
{"episode": 308.0, "episode_reward": 983.6, "eval_time": 351.8845012187958, "mean_episode_reward": 983.6, "best_episode_reward": 990.0, "step": 154000}
{"episode": 310.0, "episode_reward": 983.9, "eval_time": 355.8399178981781, "mean_episode_reward": 983.9, "best_episode_reward": 995.0, "step": 155000}
{"episode": 312.0, "episode_reward": 886.9, "eval_time": 350.56634855270386, "mean_episode_reward": 886.9, "best_episode_reward": 991.0, "step": 156000}
{"episode": 314.0, "episode_reward": 982.5, "eval_time": 332.51909923553467, "mean_episode_reward": 982.5, "best_episode_reward": 994.0, "step": 157000}
{"episode": 316.0, "episode_reward": 981.2, "eval_time": 363.88793683052063, "mean_episode_reward": 981.2, "best_episode_reward": 989.0, "step": 158000}
{"episode": 318.0, "episode_reward": 886.8, "eval_time": 326.4705846309662, "mean_episode_reward": 886.8, "best_episode_reward": 990.0, "step": 159000}
{"episode": 320.0, "episode_reward": 985.4, "eval_time": 334.9226965904236, "mean_episode_reward": 985.4, "best_episode_reward": 996.0, "step": 160000}
{"episode": 322.0, "episode_reward": 983.5, "eval_time": 340.34493255615234, "mean_episode_reward": 983.5, "best_episode_reward": 992.0, "step": 161000}
{"episode": 324.0, "episode_reward": 882.6, "eval_time": 330.1365761756897, "mean_episode_reward": 882.6, "best_episode_reward": 986.0, "step": 162000}
{"episode": 326.0, "episode_reward": 885.8, "eval_time": 298.58776926994324, "mean_episode_reward": 885.8, "best_episode_reward": 992.0, "step": 163000}
{"episode": 328.0, "episode_reward": 885.8, "eval_time": 338.9266905784607, "mean_episode_reward": 885.8, "best_episode_reward": 990.0, "step": 164000}
{"episode": 330.0, "episode_reward": 885.1, "eval_time": 337.76355719566345, "mean_episode_reward": 885.1, "best_episode_reward": 989.0, "step": 165000}
{"episode": 332.0, "episode_reward": 983.1, "eval_time": 345.4512050151825, "mean_episode_reward": 983.1, "best_episode_reward": 997.0, "step": 166000}
{"episode": 334.0, "episode_reward": 983.8, "eval_time": 332.53114318847656, "mean_episode_reward": 983.8, "best_episode_reward": 995.0, "step": 167000}
{"episode": 336.0, "episode_reward": 976.7, "eval_time": 331.1540949344635, "mean_episode_reward": 976.7, "best_episode_reward": 984.0, "step": 168000}
{"episode": 338.0, "episode_reward": 981.9, "eval_time": 337.55709171295166, "mean_episode_reward": 981.9, "best_episode_reward": 993.0, "step": 169000}
{"episode": 340.0, "episode_reward": 986.1, "eval_time": 347.5101933479309, "mean_episode_reward": 986.1, "best_episode_reward": 996.0, "step": 170000}
{"episode": 342.0, "episode_reward": 982.6, "eval_time": 342.7863698005676, "mean_episode_reward": 982.6, "best_episode_reward": 991.0, "step": 171000}
{"episode": 344.0, "episode_reward": 984.4, "eval_time": 345.84427523612976, "mean_episode_reward": 984.4, "best_episode_reward": 994.0, "step": 172000}
{"episode": 346.0, "episode_reward": 981.2, "eval_time": 340.550612449646, "mean_episode_reward": 981.2, "best_episode_reward": 992.0, "step": 173000}
{"episode": 348.0, "episode_reward": 982.8, "eval_time": 333.8535454273224, "mean_episode_reward": 982.8, "best_episode_reward": 991.0, "step": 174000}
{"episode": 350.0, "episode_reward": 982.1, "eval_time": 326.9392318725586, "mean_episode_reward": 982.1, "best_episode_reward": 994.0, "step": 175000}
{"episode": 352.0, "episode_reward": 981.2, "eval_time": 352.3757700920105, "mean_episode_reward": 981.2, "best_episode_reward": 996.0, "step": 176000}
{"episode": 354.0, "episode_reward": 985.0, "eval_time": 341.6919331550598, "mean_episode_reward": 985.0, "best_episode_reward": 994.0, "step": 177000}
{"episode": 356.0, "episode_reward": 987.0, "eval_time": 316.7161202430725, "mean_episode_reward": 987.0, "best_episode_reward": 993.0, "step": 178000}
{"episode": 358.0, "episode_reward": 989.3, "eval_time": 333.24529361724854, "mean_episode_reward": 989.3, "best_episode_reward": 998.0, "step": 179000}
{"episode": 360.0, "episode_reward": 985.8, "eval_time": 332.882700920105, "mean_episode_reward": 985.8, "best_episode_reward": 996.0, "step": 180000}
{"episode": 362.0, "episode_reward": 979.0, "eval_time": 337.5144534111023, "mean_episode_reward": 979.0, "best_episode_reward": 994.0, "step": 181000}
{"episode": 364.0, "episode_reward": 986.0, "eval_time": 347.7660632133484, "mean_episode_reward": 986.0, "best_episode_reward": 997.0, "step": 182000}
{"episode": 366.0, "episode_reward": 980.9, "eval_time": 289.465539932251, "mean_episode_reward": 980.9, "best_episode_reward": 996.0, "step": 183000}
{"episode": 368.0, "episode_reward": 983.9, "eval_time": 282.1942970752716, "mean_episode_reward": 983.9, "best_episode_reward": 994.0, "step": 184000}
{"episode": 370.0, "episode_reward": 983.9, "eval_time": 288.97150349617004, "mean_episode_reward": 983.9, "best_episode_reward": 992.0, "step": 185000}
{"episode": 372.0, "episode_reward": 979.7, "eval_time": 292.21858048439026, "mean_episode_reward": 979.7, "best_episode_reward": 989.0, "step": 186000}
{"episode": 374.0, "episode_reward": 985.1, "eval_time": 296.0660078525543, "mean_episode_reward": 985.1, "best_episode_reward": 993.0, "step": 187000}
{"episode": 376.0, "episode_reward": 987.5, "eval_time": 286.8712115287781, "mean_episode_reward": 987.5, "best_episode_reward": 994.0, "step": 188000}
{"episode": 378.0, "episode_reward": 984.6, "eval_time": 275.26520800590515, "mean_episode_reward": 984.6, "best_episode_reward": 996.0, "step": 189000}
{"episode": 380.0, "episode_reward": 981.7, "eval_time": 276.26600408554077, "mean_episode_reward": 981.7, "best_episode_reward": 986.0, "step": 190000}
{"episode": 382.0, "episode_reward": 982.8, "eval_time": 290.6513237953186, "mean_episode_reward": 982.8, "best_episode_reward": 995.0, "step": 191000}
{"episode": 384.0, "episode_reward": 982.6, "eval_time": 283.08842062950134, "mean_episode_reward": 982.6, "best_episode_reward": 994.0, "step": 192000}
{"episode": 386.0, "episode_reward": 984.8, "eval_time": 279.08451771736145, "mean_episode_reward": 984.8, "best_episode_reward": 996.0, "step": 193000}
{"episode": 388.0, "episode_reward": 985.7, "eval_time": 274.6109585762024, "mean_episode_reward": 985.7, "best_episode_reward": 993.0, "step": 194000}
{"episode": 390.0, "episode_reward": 984.3, "eval_time": 265.7273120880127, "mean_episode_reward": 984.3, "best_episode_reward": 994.0, "step": 195000}
{"episode": 392.0, "episode_reward": 985.8, "eval_time": 273.6720290184021, "mean_episode_reward": 985.8, "best_episode_reward": 991.0, "step": 196000}
{"episode": 394.0, "episode_reward": 979.5, "eval_time": 292.22196412086487, "mean_episode_reward": 979.5, "best_episode_reward": 994.0, "step": 197000}
{"episode": 396.0, "episode_reward": 984.3, "eval_time": 278.26319313049316, "mean_episode_reward": 984.3, "best_episode_reward": 994.0, "step": 198000}
{"episode": 398.0, "episode_reward": 984.3, "eval_time": 263.51774168014526, "mean_episode_reward": 984.3, "best_episode_reward": 993.0, "step": 199000}
{"episode": 400.0, "episode_reward": 981.5, "eval_time": 261.8573045730591, "mean_episode_reward": 981.5, "best_episode_reward": 993.0, "step": 200000}
{"episode": 402.0, "episode_reward": 985.2, "eval_time": 284.19359254837036, "mean_episode_reward": 985.2, "best_episode_reward": 994.0, "step": 201000}
{"episode": 404.0, "episode_reward": 983.8, "eval_time": 261.9393925666809, "mean_episode_reward": 983.8, "best_episode_reward": 993.0, "step": 202000}
{"episode": 406.0, "episode_reward": 988.3, "eval_time": 284.66946482658386, "mean_episode_reward": 988.3, "best_episode_reward": 993.0, "step": 203000}
{"episode": 408.0, "episode_reward": 978.2, "eval_time": 289.79975175857544, "mean_episode_reward": 978.2, "best_episode_reward": 992.0, "step": 204000}
{"episode": 410.0, "episode_reward": 982.3, "eval_time": 274.5927503108978, "mean_episode_reward": 982.3, "best_episode_reward": 989.0, "step": 205000}
{"episode": 412.0, "episode_reward": 985.8, "eval_time": 269.0189919471741, "mean_episode_reward": 985.8, "best_episode_reward": 998.0, "step": 206000}
{"episode": 414.0, "episode_reward": 986.4, "eval_time": 271.5470926761627, "mean_episode_reward": 986.4, "best_episode_reward": 998.0, "step": 207000}
{"episode": 416.0, "episode_reward": 985.6, "eval_time": 287.8858115673065, "mean_episode_reward": 985.6, "best_episode_reward": 994.0, "step": 208000}
{"episode": 418.0, "episode_reward": 981.5, "eval_time": 296.6629538536072, "mean_episode_reward": 981.5, "best_episode_reward": 991.0, "step": 209000}
{"episode": 420.0, "episode_reward": 984.0, "eval_time": 282.27637457847595, "mean_episode_reward": 984.0, "best_episode_reward": 991.0, "step": 210000}
{"episode": 422.0, "episode_reward": 982.4, "eval_time": 286.8686182498932, "mean_episode_reward": 982.4, "best_episode_reward": 996.0, "step": 211000}
{"episode": 424.0, "episode_reward": 986.3, "eval_time": 273.86285066604614, "mean_episode_reward": 986.3, "best_episode_reward": 994.0, "step": 212000}
{"episode": 426.0, "episode_reward": 987.2, "eval_time": 276.99535274505615, "mean_episode_reward": 987.2, "best_episode_reward": 995.0, "step": 213000}
{"episode": 428.0, "episode_reward": 985.5, "eval_time": 281.2843019962311, "mean_episode_reward": 985.5, "best_episode_reward": 993.0, "step": 214000}
{"episode": 430.0, "episode_reward": 986.2, "eval_time": 291.8601360321045, "mean_episode_reward": 986.2, "best_episode_reward": 995.0, "step": 215000}
{"episode": 432.0, "episode_reward": 981.6, "eval_time": 280.51121759414673, "mean_episode_reward": 981.6, "best_episode_reward": 992.0, "step": 216000}
{"episode": 434.0, "episode_reward": 981.6, "eval_time": 273.22447776794434, "mean_episode_reward": 981.6, "best_episode_reward": 992.0, "step": 217000}
{"episode": 436.0, "episode_reward": 923.7, "eval_time": 269.2220633029938, "mean_episode_reward": 923.7, "best_episode_reward": 946.0, "step": 218000}
{"episode": 438.0, "episode_reward": 982.9, "eval_time": 279.2185776233673, "mean_episode_reward": 982.9, "best_episode_reward": 994.0, "step": 219000}
{"episode": 440.0, "episode_reward": 985.8, "eval_time": 282.6085772514343, "mean_episode_reward": 985.8, "best_episode_reward": 996.0, "step": 220000}
{"episode": 442.0, "episode_reward": 984.8, "eval_time": 290.80309867858887, "mean_episode_reward": 984.8, "best_episode_reward": 994.0, "step": 221000}
{"episode": 444.0, "episode_reward": 981.1, "eval_time": 321.0322518348694, "mean_episode_reward": 981.1, "best_episode_reward": 993.0, "step": 222000}
{"episode": 446.0, "episode_reward": 985.1, "eval_time": 345.6931436061859, "mean_episode_reward": 985.1, "best_episode_reward": 991.0, "step": 223000}
{"episode": 448.0, "episode_reward": 986.1, "eval_time": 350.1212887763977, "mean_episode_reward": 986.1, "best_episode_reward": 996.0, "step": 224000}
{"episode": 450.0, "episode_reward": 978.4, "eval_time": 366.7280294895172, "mean_episode_reward": 978.4, "best_episode_reward": 991.0, "step": 225000}
{"episode": 452.0, "episode_reward": 981.8, "eval_time": 339.0604703426361, "mean_episode_reward": 981.8, "best_episode_reward": 997.0, "step": 226000}
{"episode": 454.0, "episode_reward": 981.1, "eval_time": 304.9059236049652, "mean_episode_reward": 981.1, "best_episode_reward": 996.0, "step": 227000}
{"episode": 456.0, "episode_reward": 982.9, "eval_time": 311.3642055988312, "mean_episode_reward": 982.9, "best_episode_reward": 993.0, "step": 228000}
{"episode": 458.0, "episode_reward": 984.6, "eval_time": 342.3326508998871, "mean_episode_reward": 984.6, "best_episode_reward": 995.0, "step": 229000}
{"episode": 460.0, "episode_reward": 980.4, "eval_time": 310.8445634841919, "mean_episode_reward": 980.4, "best_episode_reward": 989.0, "step": 230000}
{"episode": 462.0, "episode_reward": 980.8, "eval_time": 317.314337015152, "mean_episode_reward": 980.8, "best_episode_reward": 991.0, "step": 231000}
{"episode": 464.0, "episode_reward": 984.9, "eval_time": 359.49067735671997, "mean_episode_reward": 984.9, "best_episode_reward": 996.0, "step": 232000}
{"episode": 466.0, "episode_reward": 985.6, "eval_time": 293.1540756225586, "mean_episode_reward": 985.6, "best_episode_reward": 992.0, "step": 233000}
{"episode": 468.0, "episode_reward": 981.5, "eval_time": 293.7763195037842, "mean_episode_reward": 981.5, "best_episode_reward": 992.0, "step": 234000}
{"episode": 470.0, "episode_reward": 982.4, "eval_time": 336.3629047870636, "mean_episode_reward": 982.4, "best_episode_reward": 994.0, "step": 235000}
{"episode": 472.0, "episode_reward": 985.3, "eval_time": 315.81384110450745, "mean_episode_reward": 985.3, "best_episode_reward": 998.0, "step": 236000}
{"episode": 474.0, "episode_reward": 984.2, "eval_time": 302.89968824386597, "mean_episode_reward": 984.2, "best_episode_reward": 993.0, "step": 237000}
{"episode": 476.0, "episode_reward": 979.9, "eval_time": 308.03786039352417, "mean_episode_reward": 979.9, "best_episode_reward": 991.0, "step": 238000}
{"episode": 478.0, "episode_reward": 984.8, "eval_time": 319.1224789619446, "mean_episode_reward": 984.8, "best_episode_reward": 996.0, "step": 239000}
{"episode": 480.0, "episode_reward": 987.0, "eval_time": 295.27464175224304, "mean_episode_reward": 987.0, "best_episode_reward": 993.0, "step": 240000}
{"episode": 482.0, "episode_reward": 882.7, "eval_time": 230.34577178955078, "mean_episode_reward": 882.7, "best_episode_reward": 995.0, "step": 241000}
{"episode": 484.0, "episode_reward": 982.9, "eval_time": 258.4439709186554, "mean_episode_reward": 982.9, "best_episode_reward": 992.0, "step": 242000}
{"episode": 486.0, "episode_reward": 986.0, "eval_time": 265.681086063385, "mean_episode_reward": 986.0, "best_episode_reward": 995.0, "step": 243000}
{"episode": 488.0, "episode_reward": 984.9, "eval_time": 259.0872526168823, "mean_episode_reward": 984.9, "best_episode_reward": 996.0, "step": 244000}
{"episode": 490.0, "episode_reward": 981.2, "eval_time": 129.0578875541687, "mean_episode_reward": 981.2, "best_episode_reward": 991.0, "step": 245000}
{"episode": 492.0, "episode_reward": 983.2, "eval_time": 135.71004700660706, "mean_episode_reward": 983.2, "best_episode_reward": 990.0, "step": 246000}
{"episode": 494.0, "episode_reward": 983.5, "eval_time": 98.69170308113098, "mean_episode_reward": 983.5, "best_episode_reward": 994.0, "step": 247000}
{"episode": 496.0, "episode_reward": 982.4, "eval_time": 81.6944227218628, "mean_episode_reward": 982.4, "best_episode_reward": 996.0, "step": 248000}
{"episode": 498.0, "episode_reward": 980.7, "eval_time": 131.98641967773438, "mean_episode_reward": 980.7, "best_episode_reward": 987.0, "step": 249000}
{"episode": 500.0, "episode_reward": 983.0, "eval_time": 98.33456778526306, "mean_episode_reward": 983.0, "best_episode_reward": 993.0, "step": 250000}
{"episode": 502.0, "episode_reward": 980.9, "eval_time": 78.86608171463013, "mean_episode_reward": 980.9, "best_episode_reward": 998.0, "step": 251000}
{"episode": 504.0, "episode_reward": 982.7, "eval_time": 77.49752712249756, "mean_episode_reward": 982.7, "best_episode_reward": 992.0, "step": 252000}
{"episode": 506.0, "episode_reward": 981.0, "eval_time": 152.78297019004822, "mean_episode_reward": 981.0, "best_episode_reward": 993.0, "step": 253000}
{"episode": 508.0, "episode_reward": 982.5, "eval_time": 148.55315732955933, "mean_episode_reward": 982.5, "best_episode_reward": 990.0, "step": 254000}
{"episode": 510.0, "episode_reward": 983.6, "eval_time": 208.90343713760376, "mean_episode_reward": 983.6, "best_episode_reward": 992.0, "step": 255000}
{"episode": 512.0, "episode_reward": 979.3, "eval_time": 163.05909776687622, "mean_episode_reward": 979.3, "best_episode_reward": 987.0, "step": 256000}
{"episode": 514.0, "episode_reward": 987.2, "eval_time": 204.44755864143372, "mean_episode_reward": 987.2, "best_episode_reward": 994.0, "step": 257000}
{"episode": 516.0, "episode_reward": 985.3, "eval_time": 204.01134586334229, "mean_episode_reward": 985.3, "best_episode_reward": 992.0, "step": 258000}
{"episode": 518.0, "episode_reward": 978.4, "eval_time": 231.42564034461975, "mean_episode_reward": 978.4, "best_episode_reward": 989.0, "step": 259000}
{"episode": 520.0, "episode_reward": 983.9, "eval_time": 243.67841792106628, "mean_episode_reward": 983.9, "best_episode_reward": 995.0, "step": 260000}
{"episode": 522.0, "episode_reward": 981.3, "eval_time": 264.93599009513855, "mean_episode_reward": 981.3, "best_episode_reward": 990.0, "step": 261000}
{"episode": 524.0, "episode_reward": 981.4, "eval_time": 249.87202739715576, "mean_episode_reward": 981.4, "best_episode_reward": 998.0, "step": 262000}
{"episode": 526.0, "episode_reward": 988.5, "eval_time": 229.17248702049255, "mean_episode_reward": 988.5, "best_episode_reward": 993.0, "step": 263000}
{"episode": 528.0, "episode_reward": 982.7, "eval_time": 229.11448502540588, "mean_episode_reward": 982.7, "best_episode_reward": 996.0, "step": 264000}
{"episode": 530.0, "episode_reward": 976.8, "eval_time": 211.2893590927124, "mean_episode_reward": 976.8, "best_episode_reward": 986.0, "step": 265000}
{"episode": 532.0, "episode_reward": 983.0, "eval_time": 207.5113389492035, "mean_episode_reward": 983.0, "best_episode_reward": 992.0, "step": 266000}
{"episode": 534.0, "episode_reward": 979.8, "eval_time": 238.76056599617004, "mean_episode_reward": 979.8, "best_episode_reward": 994.0, "step": 267000}
{"episode": 536.0, "episode_reward": 981.2, "eval_time": 217.16135811805725, "mean_episode_reward": 981.2, "best_episode_reward": 992.0, "step": 268000}
{"episode": 538.0, "episode_reward": 984.4, "eval_time": 226.10301613807678, "mean_episode_reward": 984.4, "best_episode_reward": 994.0, "step": 269000}
{"episode": 540.0, "episode_reward": 987.1, "eval_time": 225.39142489433289, "mean_episode_reward": 987.1, "best_episode_reward": 998.0, "step": 270000}
{"episode": 542.0, "episode_reward": 983.8, "eval_time": 221.03485083580017, "mean_episode_reward": 983.8, "best_episode_reward": 996.0, "step": 271000}
{"episode": 544.0, "episode_reward": 886.4, "eval_time": 210.77627325057983, "mean_episode_reward": 886.4, "best_episode_reward": 995.0, "step": 272000}
{"episode": 546.0, "episode_reward": 982.2, "eval_time": 207.69681811332703, "mean_episode_reward": 982.2, "best_episode_reward": 994.0, "step": 273000}
{"episode": 548.0, "episode_reward": 978.6, "eval_time": 209.92789912223816, "mean_episode_reward": 978.6, "best_episode_reward": 993.0, "step": 274000}
{"episode": 550.0, "episode_reward": 983.8, "eval_time": 228.98102569580078, "mean_episode_reward": 983.8, "best_episode_reward": 993.0, "step": 275000}
{"episode": 552.0, "episode_reward": 987.2, "eval_time": 221.77009510993958, "mean_episode_reward": 987.2, "best_episode_reward": 997.0, "step": 276000}
{"episode": 554.0, "episode_reward": 981.8, "eval_time": 220.0731816291809, "mean_episode_reward": 981.8, "best_episode_reward": 990.0, "step": 277000}
{"episode": 556.0, "episode_reward": 884.6, "eval_time": 217.7951695919037, "mean_episode_reward": 884.6, "best_episode_reward": 998.0, "step": 278000}
{"episode": 558.0, "episode_reward": 975.3, "eval_time": 212.1992325782776, "mean_episode_reward": 975.3, "best_episode_reward": 990.0, "step": 279000}
{"episode": 560.0, "episode_reward": 983.6, "eval_time": 204.80842518806458, "mean_episode_reward": 983.6, "best_episode_reward": 994.0, "step": 280000}
{"episode": 562.0, "episode_reward": 982.9, "eval_time": 218.86600470542908, "mean_episode_reward": 982.9, "best_episode_reward": 992.0, "step": 281000}
{"episode": 564.0, "episode_reward": 987.2, "eval_time": 228.6593291759491, "mean_episode_reward": 987.2, "best_episode_reward": 995.0, "step": 282000}
{"episode": 566.0, "episode_reward": 886.3, "eval_time": 221.50233054161072, "mean_episode_reward": 886.3, "best_episode_reward": 996.0, "step": 283000}
{"episode": 568.0, "episode_reward": 982.0, "eval_time": 210.44754433631897, "mean_episode_reward": 982.0, "best_episode_reward": 990.0, "step": 284000}
{"episode": 570.0, "episode_reward": 981.3, "eval_time": 203.23350548744202, "mean_episode_reward": 981.3, "best_episode_reward": 992.0, "step": 285000}
{"episode": 572.0, "episode_reward": 984.3, "eval_time": 200.76496028900146, "mean_episode_reward": 984.3, "best_episode_reward": 997.0, "step": 286000}
{"episode": 574.0, "episode_reward": 986.7, "eval_time": 217.05900764465332, "mean_episode_reward": 986.7, "best_episode_reward": 994.0, "step": 287000}
{"episode": 576.0, "episode_reward": 983.3, "eval_time": 222.85172271728516, "mean_episode_reward": 983.3, "best_episode_reward": 991.0, "step": 288000}
{"episode": 578.0, "episode_reward": 978.5, "eval_time": 235.17959809303284, "mean_episode_reward": 978.5, "best_episode_reward": 991.0, "step": 289000}
{"episode": 580.0, "episode_reward": 981.8, "eval_time": 207.24486780166626, "mean_episode_reward": 981.8, "best_episode_reward": 992.0, "step": 290000}
{"episode": 582.0, "episode_reward": 987.0, "eval_time": 204.37921500205994, "mean_episode_reward": 987.0, "best_episode_reward": 994.0, "step": 291000}
{"episode": 584.0, "episode_reward": 981.9, "eval_time": 208.8797266483307, "mean_episode_reward": 981.9, "best_episode_reward": 996.0, "step": 292000}
{"episode": 586.0, "episode_reward": 984.6, "eval_time": 229.0905737876892, "mean_episode_reward": 984.6, "best_episode_reward": 992.0, "step": 293000}
{"episode": 588.0, "episode_reward": 982.7, "eval_time": 225.26014637947083, "mean_episode_reward": 982.7, "best_episode_reward": 997.0, "step": 294000}
{"episode": 590.0, "episode_reward": 987.0, "eval_time": 212.20832920074463, "mean_episode_reward": 987.0, "best_episode_reward": 996.0, "step": 295000}
{"episode": 592.0, "episode_reward": 986.0, "eval_time": 208.34633231163025, "mean_episode_reward": 986.0, "best_episode_reward": 998.0, "step": 296000}
{"episode": 594.0, "episode_reward": 984.7, "eval_time": 206.87749910354614, "mean_episode_reward": 984.7, "best_episode_reward": 992.0, "step": 297000}
{"episode": 596.0, "episode_reward": 983.4, "eval_time": 223.68166279792786, "mean_episode_reward": 983.4, "best_episode_reward": 994.0, "step": 298000}
{"episode": 598.0, "episode_reward": 984.8, "eval_time": 227.68772768974304, "mean_episode_reward": 984.8, "best_episode_reward": 996.0, "step": 299000}
{"episode": 600.0, "episode_reward": 983.3, "eval_time": 220.86374735832214, "mean_episode_reward": 983.3, "best_episode_reward": 996.0, "step": 300000}
{"episode": 602.0, "episode_reward": 982.6, "eval_time": 211.41759729385376, "mean_episode_reward": 982.6, "best_episode_reward": 993.0, "step": 301000}
{"episode": 604.0, "episode_reward": 980.9, "eval_time": 218.62003111839294, "mean_episode_reward": 980.9, "best_episode_reward": 995.0, "step": 302000}
{"episode": 606.0, "episode_reward": 985.0, "eval_time": 226.96903681755066, "mean_episode_reward": 985.0, "best_episode_reward": 996.0, "step": 303000}
{"episode": 608.0, "episode_reward": 979.4, "eval_time": 231.1963222026825, "mean_episode_reward": 979.4, "best_episode_reward": 996.0, "step": 304000}
{"episode": 610.0, "episode_reward": 981.2, "eval_time": 190.5867941379547, "mean_episode_reward": 981.2, "best_episode_reward": 993.0, "step": 305000}
{"episode": 612.0, "episode_reward": 982.0, "eval_time": 187.59461545944214, "mean_episode_reward": 982.0, "best_episode_reward": 996.0, "step": 306000}
{"episode": 614.0, "episode_reward": 985.9, "eval_time": 190.71359705924988, "mean_episode_reward": 985.9, "best_episode_reward": 990.0, "step": 307000}
{"episode": 616.0, "episode_reward": 983.8, "eval_time": 198.89615178108215, "mean_episode_reward": 983.8, "best_episode_reward": 994.0, "step": 308000}
{"episode": 618.0, "episode_reward": 979.8, "eval_time": 202.19659423828125, "mean_episode_reward": 979.8, "best_episode_reward": 987.0, "step": 309000}
{"episode": 620.0, "episode_reward": 984.8, "eval_time": 181.15193438529968, "mean_episode_reward": 984.8, "best_episode_reward": 992.0, "step": 310000}
{"episode": 622.0, "episode_reward": 984.2, "eval_time": 174.1090214252472, "mean_episode_reward": 984.2, "best_episode_reward": 992.0, "step": 311000}
{"episode": 624.0, "episode_reward": 985.1, "eval_time": 181.76821613311768, "mean_episode_reward": 985.1, "best_episode_reward": 991.0, "step": 312000}
{"episode": 626.0, "episode_reward": 985.9, "eval_time": 201.5446481704712, "mean_episode_reward": 985.9, "best_episode_reward": 996.0, "step": 313000}
{"episode": 628.0, "episode_reward": 981.8, "eval_time": 197.41462802886963, "mean_episode_reward": 981.8, "best_episode_reward": 993.0, "step": 314000}
{"episode": 630.0, "episode_reward": 982.0, "eval_time": 187.40248274803162, "mean_episode_reward": 982.0, "best_episode_reward": 990.0, "step": 315000}
{"episode": 632.0, "episode_reward": 984.3, "eval_time": 177.89260625839233, "mean_episode_reward": 984.3, "best_episode_reward": 997.0, "step": 316000}
{"episode": 634.0, "episode_reward": 985.5, "eval_time": 172.9089069366455, "mean_episode_reward": 985.5, "best_episode_reward": 998.0, "step": 317000}
{"episode": 636.0, "episode_reward": 983.1, "eval_time": 181.04674243927002, "mean_episode_reward": 983.1, "best_episode_reward": 993.0, "step": 318000}
{"episode": 638.0, "episode_reward": 981.8, "eval_time": 196.81740832328796, "mean_episode_reward": 981.8, "best_episode_reward": 989.0, "step": 319000}
{"episode": 640.0, "episode_reward": 986.9, "eval_time": 190.25427174568176, "mean_episode_reward": 986.9, "best_episode_reward": 999.0, "step": 320000}
{"episode": 642.0, "episode_reward": 984.0, "eval_time": 190.7236669063568, "mean_episode_reward": 984.0, "best_episode_reward": 993.0, "step": 321000}
{"episode": 644.0, "episode_reward": 982.1, "eval_time": 174.40926933288574, "mean_episode_reward": 982.1, "best_episode_reward": 992.0, "step": 322000}
{"episode": 646.0, "episode_reward": 985.4, "eval_time": 191.14881038665771, "mean_episode_reward": 985.4, "best_episode_reward": 996.0, "step": 323000}
{"episode": 648.0, "episode_reward": 984.4, "eval_time": 200.37170338630676, "mean_episode_reward": 984.4, "best_episode_reward": 994.0, "step": 324000}
{"episode": 650.0, "episode_reward": 885.6, "eval_time": 195.533593416214, "mean_episode_reward": 885.6, "best_episode_reward": 996.0, "step": 325000}
{"episode": 652.0, "episode_reward": 985.8, "eval_time": 184.82524800300598, "mean_episode_reward": 985.8, "best_episode_reward": 995.0, "step": 326000}
{"episode": 654.0, "episode_reward": 983.0, "eval_time": 183.87467646598816, "mean_episode_reward": 983.0, "best_episode_reward": 994.0, "step": 327000}
{"episode": 656.0, "episode_reward": 985.6, "eval_time": 188.16950225830078, "mean_episode_reward": 985.6, "best_episode_reward": 992.0, "step": 328000}
{"episode": 658.0, "episode_reward": 984.6, "eval_time": 198.26134657859802, "mean_episode_reward": 984.6, "best_episode_reward": 992.0, "step": 329000}
{"episode": 660.0, "episode_reward": 983.1, "eval_time": 190.08729600906372, "mean_episode_reward": 983.1, "best_episode_reward": 994.0, "step": 330000}
{"episode": 662.0, "episode_reward": 983.5, "eval_time": 176.42840337753296, "mean_episode_reward": 983.5, "best_episode_reward": 992.0, "step": 331000}
{"episode": 664.0, "episode_reward": 984.0, "eval_time": 185.6897566318512, "mean_episode_reward": 984.0, "best_episode_reward": 992.0, "step": 332000}
{"episode": 666.0, "episode_reward": 981.5, "eval_time": 182.42584776878357, "mean_episode_reward": 981.5, "best_episode_reward": 995.0, "step": 333000}
{"episode": 668.0, "episode_reward": 987.3, "eval_time": 182.326988697052, "mean_episode_reward": 987.3, "best_episode_reward": 998.0, "step": 334000}
{"episode": 670.0, "episode_reward": 984.4, "eval_time": 170.0118179321289, "mean_episode_reward": 984.4, "best_episode_reward": 998.0, "step": 335000}
{"episode": 672.0, "episode_reward": 980.2, "eval_time": 166.6200475692749, "mean_episode_reward": 980.2, "best_episode_reward": 993.0, "step": 336000}
{"episode": 674.0, "episode_reward": 980.5, "eval_time": 170.73521375656128, "mean_episode_reward": 980.5, "best_episode_reward": 989.0, "step": 337000}
{"episode": 676.0, "episode_reward": 974.3, "eval_time": 167.62281203269958, "mean_episode_reward": 974.3, "best_episode_reward": 985.0, "step": 338000}
{"episode": 678.0, "episode_reward": 989.1, "eval_time": 185.06975769996643, "mean_episode_reward": 989.1, "best_episode_reward": 996.0, "step": 339000}
{"episode": 680.0, "episode_reward": 983.8, "eval_time": 191.3961808681488, "mean_episode_reward": 983.8, "best_episode_reward": 996.0, "step": 340000}
{"episode": 682.0, "episode_reward": 981.6, "eval_time": 270.5142967700958, "mean_episode_reward": 981.6, "best_episode_reward": 996.0, "step": 341000}
{"episode": 684.0, "episode_reward": 985.1, "eval_time": 274.5422954559326, "mean_episode_reward": 985.1, "best_episode_reward": 993.0, "step": 342000}
{"episode": 686.0, "episode_reward": 982.7, "eval_time": 273.7068133354187, "mean_episode_reward": 982.7, "best_episode_reward": 994.0, "step": 343000}
{"episode": 688.0, "episode_reward": 983.5, "eval_time": 271.37878918647766, "mean_episode_reward": 983.5, "best_episode_reward": 994.0, "step": 344000}
{"episode": 690.0, "episode_reward": 983.6, "eval_time": 333.1290874481201, "mean_episode_reward": 983.6, "best_episode_reward": 994.0, "step": 345000}
{"episode": 692.0, "episode_reward": 984.4, "eval_time": 289.3777189254761, "mean_episode_reward": 984.4, "best_episode_reward": 997.0, "step": 346000}
{"episode": 694.0, "episode_reward": 985.4, "eval_time": 329.33420062065125, "mean_episode_reward": 985.4, "best_episode_reward": 994.0, "step": 347000}
{"episode": 696.0, "episode_reward": 982.1, "eval_time": 298.7461233139038, "mean_episode_reward": 982.1, "best_episode_reward": 992.0, "step": 348000}
{"episode": 698.0, "episode_reward": 983.1, "eval_time": 313.0513873100281, "mean_episode_reward": 983.1, "best_episode_reward": 992.0, "step": 349000}
{"episode": 700.0, "episode_reward": 984.3, "eval_time": 319.475661277771, "mean_episode_reward": 984.3, "best_episode_reward": 996.0, "step": 350000}
{"episode": 702.0, "episode_reward": 982.6, "eval_time": 260.0142574310303, "mean_episode_reward": 982.6, "best_episode_reward": 994.0, "step": 351000}
{"episode": 704.0, "episode_reward": 986.7, "eval_time": 292.1651864051819, "mean_episode_reward": 986.7, "best_episode_reward": 995.0, "step": 352000}
{"episode": 706.0, "episode_reward": 980.5, "eval_time": 281.1907663345337, "mean_episode_reward": 980.5, "best_episode_reward": 994.0, "step": 353000}
{"episode": 708.0, "episode_reward": 983.0, "eval_time": 221.1952781677246, "mean_episode_reward": 983.0, "best_episode_reward": 994.0, "step": 354000}
{"episode": 710.0, "episode_reward": 986.5, "eval_time": 282.49584317207336, "mean_episode_reward": 986.5, "best_episode_reward": 995.0, "step": 355000}
{"episode": 712.0, "episode_reward": 986.2, "eval_time": 292.25801515579224, "mean_episode_reward": 986.2, "best_episode_reward": 996.0, "step": 356000}
{"episode": 714.0, "episode_reward": 986.2, "eval_time": 267.9991157054901, "mean_episode_reward": 986.2, "best_episode_reward": 995.0, "step": 357000}
{"episode": 716.0, "episode_reward": 984.2, "eval_time": 300.51159405708313, "mean_episode_reward": 984.2, "best_episode_reward": 992.0, "step": 358000}
{"episode": 718.0, "episode_reward": 982.3, "eval_time": 300.9319484233856, "mean_episode_reward": 982.3, "best_episode_reward": 992.0, "step": 359000}
{"episode": 720.0, "episode_reward": 985.7, "eval_time": 274.3663287162781, "mean_episode_reward": 985.7, "best_episode_reward": 991.0, "step": 360000}
{"episode": 722.0, "episode_reward": 983.0, "eval_time": 285.71570086479187, "mean_episode_reward": 983.0, "best_episode_reward": 989.0, "step": 361000}
{"episode": 724.0, "episode_reward": 984.9, "eval_time": 210.15501356124878, "mean_episode_reward": 984.9, "best_episode_reward": 993.0, "step": 362000}
{"episode": 726.0, "episode_reward": 981.3, "eval_time": 159.14020776748657, "mean_episode_reward": 981.3, "best_episode_reward": 990.0, "step": 363000}
{"episode": 728.0, "episode_reward": 983.8, "eval_time": 240.72588443756104, "mean_episode_reward": 983.8, "best_episode_reward": 990.0, "step": 364000}
{"episode": 730.0, "episode_reward": 980.7, "eval_time": 198.73873805999756, "mean_episode_reward": 980.7, "best_episode_reward": 988.0, "step": 365000}
{"episode": 732.0, "episode_reward": 983.3, "eval_time": 198.13157725334167, "mean_episode_reward": 983.3, "best_episode_reward": 995.0, "step": 366000}
{"episode": 734.0, "episode_reward": 984.6, "eval_time": 228.65563011169434, "mean_episode_reward": 984.6, "best_episode_reward": 997.0, "step": 367000}
{"episode": 736.0, "episode_reward": 982.7, "eval_time": 210.0115203857422, "mean_episode_reward": 982.7, "best_episode_reward": 995.0, "step": 368000}
{"episode": 738.0, "episode_reward": 978.1, "eval_time": 184.3603835105896, "mean_episode_reward": 978.1, "best_episode_reward": 989.0, "step": 369000}
{"episode": 740.0, "episode_reward": 984.3, "eval_time": 221.00537705421448, "mean_episode_reward": 984.3, "best_episode_reward": 996.0, "step": 370000}
{"episode": 742.0, "episode_reward": 982.4, "eval_time": 232.66966819763184, "mean_episode_reward": 982.4, "best_episode_reward": 988.0, "step": 371000}
{"episode": 744.0, "episode_reward": 978.9, "eval_time": 233.48786735534668, "mean_episode_reward": 978.9, "best_episode_reward": 993.0, "step": 372000}
{"episode": 746.0, "episode_reward": 982.9, "eval_time": 236.7601306438446, "mean_episode_reward": 982.9, "best_episode_reward": 993.0, "step": 373000}
{"episode": 748.0, "episode_reward": 982.2, "eval_time": 218.85624289512634, "mean_episode_reward": 982.2, "best_episode_reward": 994.0, "step": 374000}
{"episode": 750.0, "episode_reward": 982.9, "eval_time": 205.5512192249298, "mean_episode_reward": 982.9, "best_episode_reward": 992.0, "step": 375000}
{"episode": 752.0, "episode_reward": 981.2, "eval_time": 208.893408536911, "mean_episode_reward": 981.2, "best_episode_reward": 992.0, "step": 376000}
{"episode": 754.0, "episode_reward": 979.7, "eval_time": 212.10378098487854, "mean_episode_reward": 979.7, "best_episode_reward": 984.0, "step": 377000}
{"episode": 756.0, "episode_reward": 981.4, "eval_time": 180.2571370601654, "mean_episode_reward": 981.4, "best_episode_reward": 989.0, "step": 378000}
{"episode": 758.0, "episode_reward": 982.5, "eval_time": 229.655375957489, "mean_episode_reward": 982.5, "best_episode_reward": 998.0, "step": 379000}
{"episode": 760.0, "episode_reward": 984.4, "eval_time": 235.23457551002502, "mean_episode_reward": 984.4, "best_episode_reward": 992.0, "step": 380000}
{"episode": 762.0, "episode_reward": 982.1, "eval_time": 236.60009956359863, "mean_episode_reward": 982.1, "best_episode_reward": 990.0, "step": 381000}
{"episode": 764.0, "episode_reward": 965.3, "eval_time": 234.99509048461914, "mean_episode_reward": 965.3, "best_episode_reward": 977.0, "step": 382000}
{"episode": 766.0, "episode_reward": 983.9, "eval_time": 222.2663929462433, "mean_episode_reward": 983.9, "best_episode_reward": 993.0, "step": 383000}
{"episode": 768.0, "episode_reward": 988.1, "eval_time": 214.1404504776001, "mean_episode_reward": 988.1, "best_episode_reward": 998.0, "step": 384000}
{"episode": 770.0, "episode_reward": 983.7, "eval_time": 212.1221330165863, "mean_episode_reward": 983.7, "best_episode_reward": 990.0, "step": 385000}
{"episode": 772.0, "episode_reward": 986.3, "eval_time": 203.52034068107605, "mean_episode_reward": 986.3, "best_episode_reward": 993.0, "step": 386000}
{"episode": 774.0, "episode_reward": 988.5, "eval_time": 218.68220329284668, "mean_episode_reward": 988.5, "best_episode_reward": 997.0, "step": 387000}
{"episode": 776.0, "episode_reward": 986.3, "eval_time": 216.96044492721558, "mean_episode_reward": 986.3, "best_episode_reward": 994.0, "step": 388000}
{"episode": 778.0, "episode_reward": 981.9, "eval_time": 213.98315405845642, "mean_episode_reward": 981.9, "best_episode_reward": 996.0, "step": 389000}
{"episode": 780.0, "episode_reward": 982.6, "eval_time": 202.8771493434906, "mean_episode_reward": 982.6, "best_episode_reward": 997.0, "step": 390000}
{"episode": 782.0, "episode_reward": 984.0, "eval_time": 162.7664875984192, "mean_episode_reward": 984.0, "best_episode_reward": 993.0, "step": 391000}
{"episode": 784.0, "episode_reward": 986.8, "eval_time": 170.11383843421936, "mean_episode_reward": 986.8, "best_episode_reward": 995.0, "step": 392000}
{"episode": 786.0, "episode_reward": 983.6, "eval_time": 164.4714376926422, "mean_episode_reward": 983.6, "best_episode_reward": 993.0, "step": 393000}
{"episode": 788.0, "episode_reward": 979.8, "eval_time": 166.31509017944336, "mean_episode_reward": 979.8, "best_episode_reward": 988.0, "step": 394000}
{"episode": 790.0, "episode_reward": 985.2, "eval_time": 177.5773344039917, "mean_episode_reward": 985.2, "best_episode_reward": 998.0, "step": 395000}
{"episode": 792.0, "episode_reward": 985.4, "eval_time": 167.75800251960754, "mean_episode_reward": 985.4, "best_episode_reward": 998.0, "step": 396000}
{"episode": 794.0, "episode_reward": 978.2, "eval_time": 173.09325623512268, "mean_episode_reward": 978.2, "best_episode_reward": 991.0, "step": 397000}
{"episode": 796.0, "episode_reward": 982.9, "eval_time": 171.4583990573883, "mean_episode_reward": 982.9, "best_episode_reward": 988.0, "step": 398000}
{"episode": 798.0, "episode_reward": 986.6, "eval_time": 207.82195258140564, "mean_episode_reward": 986.6, "best_episode_reward": 992.0, "step": 399000}
{"episode": 800.0, "episode_reward": 983.0, "eval_time": 162.93874788284302, "mean_episode_reward": 983.0, "best_episode_reward": 992.0, "step": 400000}
{"episode": 802.0, "episode_reward": 984.0, "eval_time": 201.3858835697174, "mean_episode_reward": 984.0, "best_episode_reward": 996.0, "step": 401000}
{"episode": 804.0, "episode_reward": 979.1, "eval_time": 168.7258198261261, "mean_episode_reward": 979.1, "best_episode_reward": 991.0, "step": 402000}
{"episode": 806.0, "episode_reward": 987.2, "eval_time": 157.05587363243103, "mean_episode_reward": 987.2, "best_episode_reward": 994.0, "step": 403000}
{"episode": 808.0, "episode_reward": 885.9, "eval_time": 197.03641533851624, "mean_episode_reward": 885.9, "best_episode_reward": 995.0, "step": 404000}
{"episode": 810.0, "episode_reward": 982.4, "eval_time": 235.93757820129395, "mean_episode_reward": 982.4, "best_episode_reward": 989.0, "step": 405000}
{"episode": 812.0, "episode_reward": 984.0, "eval_time": 236.84701871871948, "mean_episode_reward": 984.0, "best_episode_reward": 997.0, "step": 406000}
{"episode": 814.0, "episode_reward": 984.8, "eval_time": 242.92403984069824, "mean_episode_reward": 984.8, "best_episode_reward": 993.0, "step": 407000}
{"episode": 816.0, "episode_reward": 790.6, "eval_time": 235.41417121887207, "mean_episode_reward": 790.6, "best_episode_reward": 998.0, "step": 408000}
{"episode": 818.0, "episode_reward": 985.3, "eval_time": 236.40373277664185, "mean_episode_reward": 985.3, "best_episode_reward": 998.0, "step": 409000}
{"episode": 820.0, "episode_reward": 989.8, "eval_time": 230.08291387557983, "mean_episode_reward": 989.8, "best_episode_reward": 996.0, "step": 410000}
{"episode": 822.0, "episode_reward": 986.0, "eval_time": 218.12709188461304, "mean_episode_reward": 986.0, "best_episode_reward": 994.0, "step": 411000}
{"episode": 824.0, "episode_reward": 986.4, "eval_time": 213.39097809791565, "mean_episode_reward": 986.4, "best_episode_reward": 995.0, "step": 412000}
{"episode": 826.0, "episode_reward": 985.1, "eval_time": 231.78779888153076, "mean_episode_reward": 985.1, "best_episode_reward": 991.0, "step": 413000}
{"episode": 828.0, "episode_reward": 980.0, "eval_time": 217.99484491348267, "mean_episode_reward": 980.0, "best_episode_reward": 990.0, "step": 414000}
{"episode": 830.0, "episode_reward": 879.6, "eval_time": 219.09590363502502, "mean_episode_reward": 879.6, "best_episode_reward": 991.0, "step": 415000}
{"episode": 832.0, "episode_reward": 983.2, "eval_time": 209.1018455028534, "mean_episode_reward": 983.2, "best_episode_reward": 991.0, "step": 416000}
{"episode": 834.0, "episode_reward": 988.0, "eval_time": 225.6139166355133, "mean_episode_reward": 988.0, "best_episode_reward": 998.0, "step": 417000}
{"episode": 836.0, "episode_reward": 984.8, "eval_time": 224.69754266738892, "mean_episode_reward": 984.8, "best_episode_reward": 995.0, "step": 418000}
{"episode": 838.0, "episode_reward": 987.7, "eval_time": 223.4027669429779, "mean_episode_reward": 987.7, "best_episode_reward": 996.0, "step": 419000}
{"episode": 840.0, "episode_reward": 984.5, "eval_time": 211.7690041065216, "mean_episode_reward": 984.5, "best_episode_reward": 993.0, "step": 420000}
{"episode": 842.0, "episode_reward": 986.8, "eval_time": 207.9241542816162, "mean_episode_reward": 986.8, "best_episode_reward": 996.0, "step": 421000}
{"episode": 844.0, "episode_reward": 887.2, "eval_time": 214.54847288131714, "mean_episode_reward": 887.2, "best_episode_reward": 995.0, "step": 422000}
{"episode": 846.0, "episode_reward": 988.0, "eval_time": 179.07729721069336, "mean_episode_reward": 988.0, "best_episode_reward": 996.0, "step": 423000}
{"episode": 848.0, "episode_reward": 983.2, "eval_time": 179.82833194732666, "mean_episode_reward": 983.2, "best_episode_reward": 991.0, "step": 424000}
{"episode": 850.0, "episode_reward": 981.1, "eval_time": 187.3953058719635, "mean_episode_reward": 981.1, "best_episode_reward": 994.0, "step": 425000}
{"episode": 852.0, "episode_reward": 982.0, "eval_time": 181.59519910812378, "mean_episode_reward": 982.0, "best_episode_reward": 993.0, "step": 426000}
{"episode": 854.0, "episode_reward": 983.3, "eval_time": 196.6534514427185, "mean_episode_reward": 983.3, "best_episode_reward": 994.0, "step": 427000}
{"episode": 856.0, "episode_reward": 984.7, "eval_time": 201.5597324371338, "mean_episode_reward": 984.7, "best_episode_reward": 996.0, "step": 428000}
{"episode": 858.0, "episode_reward": 983.6, "eval_time": 196.20818853378296, "mean_episode_reward": 983.6, "best_episode_reward": 996.0, "step": 429000}
{"episode": 860.0, "episode_reward": 884.0, "eval_time": 196.04157280921936, "mean_episode_reward": 884.0, "best_episode_reward": 994.0, "step": 430000}
{"episode": 862.0, "episode_reward": 985.2, "eval_time": 190.42533135414124, "mean_episode_reward": 985.2, "best_episode_reward": 995.0, "step": 431000}
{"episode": 864.0, "episode_reward": 987.0, "eval_time": 193.4297318458557, "mean_episode_reward": 987.0, "best_episode_reward": 994.0, "step": 432000}
{"episode": 866.0, "episode_reward": 983.8, "eval_time": 199.66060853004456, "mean_episode_reward": 983.8, "best_episode_reward": 993.0, "step": 433000}
{"episode": 868.0, "episode_reward": 981.7, "eval_time": 188.30003142356873, "mean_episode_reward": 981.7, "best_episode_reward": 992.0, "step": 434000}
{"episode": 870.0, "episode_reward": 979.5, "eval_time": 182.7786078453064, "mean_episode_reward": 979.5, "best_episode_reward": 985.0, "step": 435000}
{"episode": 872.0, "episode_reward": 985.2, "eval_time": 186.44150853157043, "mean_episode_reward": 985.2, "best_episode_reward": 994.0, "step": 436000}
{"episode": 874.0, "episode_reward": 984.8, "eval_time": 184.92554807662964, "mean_episode_reward": 984.8, "best_episode_reward": 994.0, "step": 437000}
{"episode": 876.0, "episode_reward": 983.8, "eval_time": 193.3752419948578, "mean_episode_reward": 983.8, "best_episode_reward": 995.0, "step": 438000}
{"episode": 878.0, "episode_reward": 983.3, "eval_time": 188.39128589630127, "mean_episode_reward": 983.3, "best_episode_reward": 992.0, "step": 439000}
{"episode": 880.0, "episode_reward": 981.9, "eval_time": 163.24887037277222, "mean_episode_reward": 981.9, "best_episode_reward": 992.0, "step": 440000}
{"episode": 882.0, "episode_reward": 984.0, "eval_time": 151.26199102401733, "mean_episode_reward": 984.0, "best_episode_reward": 991.0, "step": 441000}
{"episode": 884.0, "episode_reward": 988.4, "eval_time": 146.47207713127136, "mean_episode_reward": 988.4, "best_episode_reward": 996.0, "step": 442000}
{"episode": 886.0, "episode_reward": 985.8, "eval_time": 144.59753131866455, "mean_episode_reward": 985.8, "best_episode_reward": 993.0, "step": 443000}
{"episode": 888.0, "episode_reward": 987.1, "eval_time": 146.39001321792603, "mean_episode_reward": 987.1, "best_episode_reward": 997.0, "step": 444000}
{"episode": 890.0, "episode_reward": 984.4, "eval_time": 149.97827911376953, "mean_episode_reward": 984.4, "best_episode_reward": 995.0, "step": 445000}
{"episode": 892.0, "episode_reward": 983.7, "eval_time": 143.59238958358765, "mean_episode_reward": 983.7, "best_episode_reward": 993.0, "step": 446000}
{"episode": 894.0, "episode_reward": 888.9, "eval_time": 146.66240882873535, "mean_episode_reward": 888.9, "best_episode_reward": 993.0, "step": 447000}
{"episode": 896.0, "episode_reward": 987.0, "eval_time": 153.15235829353333, "mean_episode_reward": 987.0, "best_episode_reward": 997.0, "step": 448000}
{"episode": 898.0, "episode_reward": 981.6, "eval_time": 146.65702319145203, "mean_episode_reward": 981.6, "best_episode_reward": 991.0, "step": 449000}
{"episode": 900.0, "episode_reward": 980.7, "eval_time": 146.07184219360352, "mean_episode_reward": 980.7, "best_episode_reward": 994.0, "step": 450000}
{"episode": 902.0, "episode_reward": 976.1, "eval_time": 144.90208959579468, "mean_episode_reward": 976.1, "best_episode_reward": 990.0, "step": 451000}
{"episode": 904.0, "episode_reward": 988.9, "eval_time": 126.53716230392456, "mean_episode_reward": 988.9, "best_episode_reward": 995.0, "step": 452000}
{"episode": 906.0, "episode_reward": 981.2, "eval_time": 130.66881108283997, "mean_episode_reward": 981.2, "best_episode_reward": 993.0, "step": 453000}
{"episode": 908.0, "episode_reward": 982.6, "eval_time": 130.0633544921875, "mean_episode_reward": 982.6, "best_episode_reward": 992.0, "step": 454000}
{"episode": 910.0, "episode_reward": 982.3, "eval_time": 102.53257870674133, "mean_episode_reward": 982.3, "best_episode_reward": 996.0, "step": 455000}
{"episode": 912.0, "episode_reward": 985.6, "eval_time": 106.99903535842896, "mean_episode_reward": 985.6, "best_episode_reward": 994.0, "step": 456000}
{"episode": 914.0, "episode_reward": 985.5, "eval_time": 105.93587946891785, "mean_episode_reward": 985.5, "best_episode_reward": 996.0, "step": 457000}
{"episode": 916.0, "episode_reward": 983.9, "eval_time": 107.13092732429504, "mean_episode_reward": 983.9, "best_episode_reward": 998.0, "step": 458000}
{"episode": 918.0, "episode_reward": 985.4, "eval_time": 106.69286441802979, "mean_episode_reward": 985.4, "best_episode_reward": 992.0, "step": 459000}
{"episode": 920.0, "episode_reward": 984.3, "eval_time": 105.84028363227844, "mean_episode_reward": 984.3, "best_episode_reward": 996.0, "step": 460000}
{"episode": 922.0, "episode_reward": 982.5, "eval_time": 117.49728608131409, "mean_episode_reward": 982.5, "best_episode_reward": 993.0, "step": 461000}
{"episode": 924.0, "episode_reward": 983.9, "eval_time": 107.14979982376099, "mean_episode_reward": 983.9, "best_episode_reward": 995.0, "step": 462000}
{"episode": 926.0, "episode_reward": 983.9, "eval_time": 120.38917350769043, "mean_episode_reward": 983.9, "best_episode_reward": 991.0, "step": 463000}
{"episode": 928.0, "episode_reward": 981.7, "eval_time": 123.74749088287354, "mean_episode_reward": 981.7, "best_episode_reward": 992.0, "step": 464000}
{"episode": 930.0, "episode_reward": 985.8, "eval_time": 121.73827457427979, "mean_episode_reward": 985.8, "best_episode_reward": 996.0, "step": 465000}
{"episode": 932.0, "episode_reward": 981.7, "eval_time": 121.54183626174927, "mean_episode_reward": 981.7, "best_episode_reward": 995.0, "step": 466000}
{"episode": 934.0, "episode_reward": 981.3, "eval_time": 106.74842739105225, "mean_episode_reward": 981.3, "best_episode_reward": 994.0, "step": 467000}
{"episode": 936.0, "episode_reward": 983.3, "eval_time": 108.20040798187256, "mean_episode_reward": 983.3, "best_episode_reward": 992.0, "step": 468000}
{"episode": 938.0, "episode_reward": 985.7, "eval_time": 107.25693130493164, "mean_episode_reward": 985.7, "best_episode_reward": 994.0, "step": 469000}
{"episode": 940.0, "episode_reward": 985.0, "eval_time": 107.42159509658813, "mean_episode_reward": 985.0, "best_episode_reward": 995.0, "step": 470000}
{"episode": 942.0, "episode_reward": 991.3, "eval_time": 109.9408757686615, "mean_episode_reward": 991.3, "best_episode_reward": 996.0, "step": 471000}
{"episode": 944.0, "episode_reward": 980.2, "eval_time": 109.33648300170898, "mean_episode_reward": 980.2, "best_episode_reward": 987.0, "step": 472000}
{"episode": 946.0, "episode_reward": 984.3, "eval_time": 122.29985046386719, "mean_episode_reward": 984.3, "best_episode_reward": 992.0, "step": 473000}
{"episode": 948.0, "episode_reward": 983.4, "eval_time": 107.44892024993896, "mean_episode_reward": 983.4, "best_episode_reward": 990.0, "step": 474000}
{"episode": 950.0, "episode_reward": 979.5, "eval_time": 105.40200161933899, "mean_episode_reward": 979.5, "best_episode_reward": 989.0, "step": 475000}
{"episode": 952.0, "episode_reward": 986.3, "eval_time": 149.22890734672546, "mean_episode_reward": 986.3, "best_episode_reward": 995.0, "step": 476000}
{"episode": 954.0, "episode_reward": 981.2, "eval_time": 148.74458193778992, "mean_episode_reward": 981.2, "best_episode_reward": 990.0, "step": 477000}
{"episode": 956.0, "episode_reward": 984.9, "eval_time": 149.70270419120789, "mean_episode_reward": 984.9, "best_episode_reward": 991.0, "step": 478000}
{"episode": 958.0, "episode_reward": 980.2, "eval_time": 144.5440480709076, "mean_episode_reward": 980.2, "best_episode_reward": 998.0, "step": 479000}
{"episode": 960.0, "episode_reward": 980.8, "eval_time": 147.9856185913086, "mean_episode_reward": 980.8, "best_episode_reward": 988.0, "step": 480000}
{"episode": 962.0, "episode_reward": 985.1, "eval_time": 151.727609872818, "mean_episode_reward": 985.1, "best_episode_reward": 997.0, "step": 481000}
{"episode": 964.0, "episode_reward": 984.4, "eval_time": 146.6885540485382, "mean_episode_reward": 984.4, "best_episode_reward": 995.0, "step": 482000}
{"episode": 966.0, "episode_reward": 981.4, "eval_time": 144.68695330619812, "mean_episode_reward": 981.4, "best_episode_reward": 997.0, "step": 483000}
{"episode": 968.0, "episode_reward": 985.6, "eval_time": 144.8633906841278, "mean_episode_reward": 985.6, "best_episode_reward": 996.0, "step": 484000}
{"episode": 970.0, "episode_reward": 984.2, "eval_time": 143.12092852592468, "mean_episode_reward": 984.2, "best_episode_reward": 994.0, "step": 485000}
{"episode": 972.0, "episode_reward": 982.5, "eval_time": 146.31201791763306, "mean_episode_reward": 982.5, "best_episode_reward": 994.0, "step": 486000}
{"episode": 974.0, "episode_reward": 981.2, "eval_time": 146.0485725402832, "mean_episode_reward": 981.2, "best_episode_reward": 990.0, "step": 487000}
{"episode": 976.0, "episode_reward": 883.9, "eval_time": 142.74398946762085, "mean_episode_reward": 883.9, "best_episode_reward": 989.0, "step": 488000}
{"episode": 978.0, "episode_reward": 981.8, "eval_time": 149.50453424453735, "mean_episode_reward": 981.8, "best_episode_reward": 992.0, "step": 489000}
{"episode": 980.0, "episode_reward": 988.4, "eval_time": 142.22899913787842, "mean_episode_reward": 988.4, "best_episode_reward": 996.0, "step": 490000}
{"episode": 982.0, "episode_reward": 983.5, "eval_time": 141.8849744796753, "mean_episode_reward": 983.5, "best_episode_reward": 988.0, "step": 491000}
{"episode": 984.0, "episode_reward": 980.9, "eval_time": 146.01403999328613, "mean_episode_reward": 980.9, "best_episode_reward": 996.0, "step": 492000}
{"episode": 986.0, "episode_reward": 981.1, "eval_time": 142.33677101135254, "mean_episode_reward": 981.1, "best_episode_reward": 994.0, "step": 493000}
{"episode": 988.0, "episode_reward": 986.3, "eval_time": 147.3864643573761, "mean_episode_reward": 986.3, "best_episode_reward": 995.0, "step": 494000}
{"episode": 990.0, "episode_reward": 985.1, "eval_time": 137.61333394050598, "mean_episode_reward": 985.1, "best_episode_reward": 996.0, "step": 495000}
{"episode": 992.0, "episode_reward": 986.7, "eval_time": 146.67237830162048, "mean_episode_reward": 986.7, "best_episode_reward": 990.0, "step": 496000}
{"episode": 994.0, "episode_reward": 986.4, "eval_time": 148.6312439441681, "mean_episode_reward": 986.4, "best_episode_reward": 995.0, "step": 497000}
{"episode": 996.0, "episode_reward": 984.2, "eval_time": 145.70768809318542, "mean_episode_reward": 984.2, "best_episode_reward": 992.0, "step": 498000}
{"episode": 998.0, "episode_reward": 981.8, "eval_time": 144.67955899238586, "mean_episode_reward": 981.8, "best_episode_reward": 994.0, "step": 499000}
